I am looking for a way to convert a long string (from a dump), that represents hex values into a byte array.


I couldn't have phrased it better than the person that posted the same question here:


http://www.experts-exchange.com/Programming/Programming_Languages/Java/Q_21062554.html


But to keep it original, I'll phrase it my own way: suppose I have a string "00A0BF" that I would like interpreted as the byte[] {0x00,0xA0,0xBf} what should I do?


I am a Java novice and ended up using BigInteger and watching out for leading hex zeros. But I think it is ugly and I am sure I am missing something simple... 


Here's a solution that I think is better than any posted so far:


Reasons why it is an improvement:


Safe with leading zeros (unlike BigInteger) and with negative byte values (unlike Byte.parseByte)


Doesn't convert the String into a char[], or create StringBuilder and String objects for every single byte.


Feel free to add argument checking via assert or exceptions if the argument is not known to be safe.


One-liners:


Warnings: 


The Hex class in commons-codec should do that for you.


http://commons.apache.org/codec/


You can now use BaseEncoding in guava to accomplish this.


To reverse it use 


The HexBinaryAdapter provides the ability to marshal and unmarshal between String and byte[].


That's just an example I typed in...I actually just use it as is and don't need to make a separate method for using it.


Actually, I think the BigInteger is solution is very nice:


Edit: Not safe for leading zeros, as noted by the poster.


One-liners:


For those of you interested in the actual code behind the One-liners from FractalizeR (I needed that since javax.xml.bind is not available for Android (by default)), this comes from com.sun.xml.internal.bind.DatatypeConverterImpl.java :


Here is a method that actually works (based on several previous semi-correct answers):


The only possible issue that I can see is if the input string is extremely long; calling toCharArray() makes a copy of the string's internal array.


EDIT: Oh, and by the way, bytes are signed in Java, so your input string converts to [0, -96, -65] instead of [0, 160, 191]. But you probably knew that already.


In android ,if you are working with hex, you can try okio.


simple usage:


and result will be 


EDIT: as pointed out by @mmyers, this method doesn't work on input that contains substrings corresponding to bytes with the high bit set ("80" - "FF").The explanation is at Bug ID: 6259307 Byte.parseByte not working as advertised in the SDK Documentation.


The Code presented by Bert Regelink simply does not work. 
Try the following:


I've always used a method like


this method splits on space delimited hex values but it wouldn't be hard to make it split the string on any other criteria such as into groupings of two characters. 


I like the Character.digit solution, but here is how I solved it


For what it's worth, here's another version which supports odd length strings, without resorting to string concatenation.


The BigInteger() Method from java.math is very Slow and not recommandable.


Integer.parseInt(HEXString, 16)


can cause problems with some characters without
converting to Digit / Integer


a Well Working method:


Function:


Have Fun, Good Luck


I found Kernel Panic to have the solution most useful to me, but ran into problems if the hex string was an odd number.  solved it this way:


I am adding a number of hex numbers to an array, so i pass the reference to the array I am using, and the int I need converted and returning the relative position of the next hex number.  So the final byte array has [0] number of hex pairs, [1...] hex pairs, then the number of pairs...  


Based on the op voted solution, the following should be a bit more efficient:


Because: the initial conversion to a char array spares the length checks in charAt


My formal solution:


Is like the PHP hex2bin() Function but in Java style.


Example:


I think will do it for you. I cobbled it together from a similar function that returned the data as a string:


For Me this was the solution, HEX="FF01" then split to FF(255) and 01(01) 






I need to implement 256 bit AES encryption, but all the examples I have found online use a "KeyGenerator" to generate a 256 bit key, but I would like to use my own passkey. How can I create my own key? I have tried padding it out to 256 bits, but then I get an error saying that the key is too long. I do have the unlimited jurisdiction patch installed, so thats not the problem :)


Ie. The KeyGenerator looks like this ...


Code taken from here


EDIT


I was actually padding the password out to 256 bytes, not bits, which is too long. The following is some code I am using now that I have some more experience with this.


The "TODO" bits you need to do yourself :-)


Share the password (a char[]) and salt (a byte[]—8 bytes selected by a SecureRandom makes a good salt—which doesn't need to be kept secret) with the recipient out-of-band. Then to derive a good key from this information:


The magic numbers (which could be defined as constants somewhere) 65536 and 256 are the key derivation iteration count and the key size, respectively.


The key derivation function is iterated to require significant computational effort, and that prevents attackers from quickly trying many different passwords. The iteration count can be changed depending on the computing resources available. 


The key size can be reduced to 128 bits, which is still considered "strong" encryption, but it doesn't give much of a safety margin if attacks are discovered that weaken AES.


Used with a proper block-chaining mode, the same derived key can be used to encrypt many messages. In CBC, a random initialization vector (IV) is generated for each message, yielding different cipher text even if the plain text is identical. CBC may not be the most secure mode available to you (see AEAD below); there are many other modes with different security properties, but they all use a similar random input. In any case, the outputs of each encryption operation are the cipher text and the initialization vector:


Store the ciphertext and the iv. On decryption, the SecretKey is regenerated in exactly the same way, using using the password with the same salt and iteration parameters. Initialize the cipher with this key and the initialization vector stored with the message:


Java 7 included API support for AEAD cipher modes, and the "SunJCE" provider included with OpenJDK and Oracle distributions implements these beginning with Java 8. One of these modes is strongly recommended in place of CBC; it will protect the integrity of the data as well as their privacy.


A java.security.InvalidKeyException with the message "Illegal key size or default parameters" means that the cryptography strength is limited; the unlimited strength jurisdiction policy files are not in the correct location. In a JDK, they should be placed under ${jdk}/jre/lib/security 


Based on the problem description, it sounds like the policy files are not correctly installed. Systems can easily have multiple Java runtimes; double-check to make sure that the correct location is being used.


The Spring Security Crypto module provides support for symmetric encryption, key generation, and password encoding. The code is distributed as part of the core module but has no dependencies on any other Spring Security (or Spring) code.


It's provides a simple abstraction for encryption and seems to match what's required here,


The "standard" encryption method is 256-bit AES using PKCS #5's PBKDF2 (Password-Based Key Derivation Function #2). This method requires Java 6. The password used to generate the SecretKey should be kept in a secure place and not be shared. The salt is used to prevent dictionary attacks against the key in the event your encrypted data is compromised. A 16-byte random initialization vector is also applied so each encrypted message is unique.


A look at the internals reveals a structure similar to erickson's answer. 


As noted in the question, this also requires the Java Cryptography Extension (JCE) Unlimited Strength Jurisdiction Policy (else you'll encounter InvalidKeyException: Illegal Key Size).  It's downloadable for Java 6, Java 7 and Java 8. 


And sample output,


After reading through erickson's suggestions, and gleaning what I could from a couple other postings and this example here, I've attempted to update Doug's code with the recommended changes. Feel free to edit to make it better.


Some notes: This uses a 128 bit encryption key - java apparently won't do 256 bit encryption out-of-the-box. Implementing 256 requires installing some extra files into the java install directory. 


Also, I'm not a crypto person. Take heed.


I've implemented the erickson's answer in a really simple class:
Java AES 256-bit Encryption/Decryption class
If you get the java.security.InvalidKeyException you have to install the Java Cryptography Extension (JCE) unlimited strength jurisdiction policy files:


Just place the jars in your {JDK HOME}\jre\lib\security


Generating your own key from a byte array is easy:


But creating a 256-bit key isn't enough. If the key generator cannot generate 256-bit keys for you, then the Cipher class probably doesn't support AES 256-bit either. You say you have the unlimited jurisdiction patch installed, so the AES-256 cipher should be supported (but then 256-bit keys should be too, so this might be a configuration problem).


A workaround for lack of AES-256 support is to take some freely available implementation of AES-256, and use it as a custom provider. This involves creating your own Provider subclass and using it with Cipher.getInstance(String, Provider). But this can be an involved process.


What I've done in the past is hash the key via something like SHA256, then extract the bytes from the hash into the key byte[].


After you have your byte[] you can simply do:


Adding to @Wufoo's edits, the following version uses InputStreams rather than files to make working with a variety of files easier. It also stores the IV and Salt in the beginning of the file, making it so only the password needs to be tracked. Since the IV and Salt do not need to be secret, this makes life a little easier.


Use this class for encryption. It works.


}


And these are ivBytes and a random key;


Consider using Encryptor4j


First make sure you have Unlimited Strength Jurisdiction Policy files installed before your proceed so that you can use 256-bit AES keys.


Then do the following:


You can now use the encryptor to encrypt your message. You can also perform streaming encryption if you'd like. It automatically generates and prepends a secure IV for your convenience.


If it's a file that you wish to compress take a look at this answer
Encrypting a large file with AES using JAVA for an even simpler approach.






Right now, my main just calls a gui with 10 rows.  Based on how many of those rows have text, 1 of 9 classes is called (two rows must have text).  The called class performs calculations that I'd like to have the progress bar tied to.  Here is an example of one of the called classes (each class is similar, but different enough to warrant a new class.)  I believe the problem is a violation of EDT rules, but all the examples I've seen on them involve a main argument.  The frame appears when the code is run, but the progress bar doesn't update until all calculations are completed.


SwingWorker is ideal for this. The example below performs a simple iteration in the background, while reporting progress and intermediate results in a window. You can pass whatever parameters you need in a suitable SwingWorker constructor.


I think you premonition is right, you need to adhere to Swing threading rules.  


So what to do?


First, I am not sure how your app is designed exactly.  You say that you have a main frame with a bunch of rows, and potentially each could potentially call one of 9 classes, and they all look like the one above.  It seems that these classes will generate their own JFrame.  I guess that this new frame is solely used for the progress bar.  I will assume that this is the design and will suggest accordingly.


I suggest that you perform a couple actions in instances of Runnable, and you drop those Runnable instances into SwingUtilities.invokeLater to have them run on the EDT. At the same time,  I would take the time to reorganize your code for ease if reading.


Thanks for the help.  I started with trying to use the first response, but I couldn't get the bar to run concurrently, and it ran when the program finished.  I'm sure it would work, but I wasn't able to figure it out.  Using trashgod's response and some other examples, I was able to get it to work using SwingWorker.  Unfortunately, I don't totally understand how it works, but I'll take it for now.


The gui and method to run the calculations are called in another class first:


Then it runs as follows:






I have a string like the following:


Now I have to get the result of 20 by using the string.


I know in some other languages the eval() function will do this.
How can I do this in Java?


You can use the ScriptEngine class and evaluate it as a Javascript string.


There may be a better way, but this one works.


There is no standard Java class or method that will do what you want.  Your options include:


Select and use some third-party expression evaluation library.  For example JEL or any of the half dozen libraries listed here.


Wrap the expression in the Java source code for a class with an eval method, send that to the Java compiler, and then load the resulting compiled class.


Use some scripting language that can be called from Java as an expression evaluator.  Possibilities include Javascript, BeanShell, and so on.


Write your own expression evaluator from scratch.


The first approach is probably simplest.  The second and third approaches are a potential security risk if you get the expression to be evaluated from an untrusted user.  (Think code injection.)


There are very few real use cases in which being able to evaluate a String as a fragment of Java code is necessary or desirable. That is, asking how to do this is really an XY problem: you actually have a different problem, which can be solved a different way.


First ask yourself, where did this String that you wish to evaluate come from? Did another part of your program generate it, or was it input provided by the user?


Another part of my program generated it: so, you want one part of your program to decide the kind of operation to perform,  but not perform the operation, and a second part that performs the chosen operation. Instead of generating and then evaluating  a String, use the Strategy, Command or Builder design pattern, as appropriate for your particular case.


It is user input: the user could input anything, including commands that, when executed, could cause your program to misbehave, crash, expose information that should be secret, damage persistent information (such as the content of a database), and other such nastiness.  The only way to prevent that would be parse the String yourself,  check it was not malicious, and then evaluate it. But parsing it yourself is much of the work that the requested evalfunction would do, so you have saved yourself nothing. Worse still, checking that arbitrary Java was not malicious is impossible, because checking that is the halting problem.


It is user input, but the syntax and semantics of permitted text to evaluate is greatly restricted: No general purpose facility can easily implement a general purpose parser and evaluator for whatever restricted syntax and semantics you have chosen. What you need to do is implement a parser and evaluator for your chosen syntax and semantics. If the task is simple, you could write a simple recursive-descent or finite-state-machine parser by hand. If the task is difficult, you could use a compiler-compiler (such as ANTLR) to do some of the work for you.


I just want to implement a desktop calculator!: A homework assignment, eh? If you could implement the evaluation of the input expression using a provided eval function, it would not be much of a homework assignment, would it? Your program would be three lines long. Your instructor probably expects you to write the code for a simple arithmetic parser/evaluator. There is well known algorithm, shunting-yard, which you might find useful.


I could advise you to use Exp4j. It is easy to understand as you can see from the following example code:


No, you can not have a generic "eval" in Java (or any compiled language). Unless you're willing to write a Java compiler AND a JVM to be executed inside of your Java program.


Yes, you can have some library to evaluate numeric algebraic expressions like the one above - see this thread for discussion. 


As previous answers, there is no standard API in Java for this. 


You can add groovy jar files to your path and groovy.util.Eval.me("4*5") gets your job done. 


Writing your own library is not that hard as u might thing. Here is link for Shunting-yard algorithm with step by step algorithm explenation. Although, you will have to parse the input for tokens first. 


There are 2 other questions wich can give you some information too: 
Turn a String into a Math Expression?
What's a good library for parsing mathematical expressions in java?


There is nothing that will do this in JavaSE; you'd have to find third-party libraries or write your own.






I was trying to load a file in a webapp, and I was getting a FileNotFound exception when I used FileInputStream. However, using the same path, I was able to load the file when I did getResourceAsStream(). 
What is the difference between the two methods, and why does one work while the other doesn't?


The java.io.File and consorts acts on the local disk file system. The root cause of your problem is that relative paths in java.io are dependent on the current working directory. I.e. the directory from which the JVM (in your case: the webserver's one) is started. This may for example be C:\Tomcat\bin or something entirely different, but thus not C:\Tomcat\webapps\contextname or whatever you'd expect it to be. In a normal Eclipse project, that would be C:\Eclipse\workspace\projectname. You can learn about the current working directory the following way:


However, the working directory is in no way programmatically controllable. You should really prefer using absolute paths in the File API instead of relative paths. E.g. C:\full\path\to\file.ext. 


You don't want to hardcode or guess the absolute path in Java (web)applications. That's only portability trouble (i.e. it runs in system X, but not in system Y). The normal practice is to place those kind of resources in the classpath, or to add its full path to the classpath (in an IDE like Eclipse that's the src folder and the "build path" respectively). This way you can grab them with help of the ClassLoader by  ClassLoader#getResource() or ClassLoader#getResourceAsStream(). It is able to locate files relative to the "root" of the classpath, as you by coincidence figured out. In webapplications (or any other application which uses multiple classloaders) it's recommend to use the ClassLoader as returned by Thread.currentThread().getContextClassLoader() for this so you can look "outside" the webapp context as well.


Another alternative in webapps is the ServletContext#getResource() and its counterpart ServletContext#getResourceAsStream(). It is able to access files located in the public web folder of the webapp project, including the /WEB-INF folder. The ServletContext is available in servlets by the inherited getServletContext() method, you can call it as-is. 


getResourceAsStream is the right way to do it for web apps (as you already learned).


The reason is that reading from the file system cannot work if you package your web app in a WAR.  This is the proper way to package a web app.  It's portable that way, because you aren't dependent on an absolute file path or the location where your app server is installed.


The FileInputStream class works directly with the underlying file system. If the file in question is not physically present there, it will fail to open it. The getResourceAsStream() method works differently. It tries to locate and load the resource using the ClassLoader of the class it is called on. This enables it to find, for example, resources embedded into jar files.


FileInputStream will load a the file path you pass to the constructor as relative from the working directory of the Java process. Usually in a web container, this is something like the bin folder.


getResourceAsStream() will load a file path relative from your application's classpath.


classname.getResourceAsStream() loads a file via the classloader of classname. If the class came from a jar file, that is where the resource will be loaded from.


FileInputStream is used to read a file from the filesystem.






This question already has an answer here:


I'm taking user input from System.in using a java.util.Scanner. I need to validate the input for things like:


What's the best way to do this?


java.util.Scanner has many hasNextXXX methods that can be used to validate input. Here's a brief overview of all of them:


Scanner is capable of more, enabled by the fact that it's regex-based. One important feature is useDelimiter(String pattern), which lets you define what pattern separates your tokens. There are also find and skip methods that ignores delimiters.


The following discussion will keep the regex as simple as possible, so the focus remains on Scanner.


Here's a simple example of using hasNextInt() to validate positive int from the input.


Here's an example session:


Please enter a positive number!
  five
That's not a number!
  -3
Please enter a positive number!
  5
Thank you! Got 5


Note how much easier Scanner.hasNextInt() is to use compared to the more verbose try/catch Integer.parseInt/NumberFormatException combo. By contract, a Scanner guarantees that if it hasNextInt(), then nextInt() will peacefully give you that int, and will not throw any NumberFormatException/InputMismatchException/NoSuchElementException.


Note that the snippet above contains a sc.next() statement to advance the Scanner until it hasNextInt(). It's important to realize that none of the hasNextXXX methods advance the Scanner past any input! You will find that if you omit this line from the snippet, then it'd go into an infinite loop on an invalid input!


This has two consequences:


Here's an example of performing multiple hasNextXXX tests.


Here's an example session:


5
(int) 5
  false
(boolean) false
  blah
(String) blah
  1.1
(double) 1.1
  100000000000
(long) 100000000000
  exit  


Note that the order of the tests matters. If a Scanner hasNextInt(), then it also hasNextLong(), but it's not necessarily true the other way around. More often than not you'd want to do the more specific test before the more general test.


Scanner has many advanced features supported by regular expressions. Here's an example of using it to validate vowels.


Here's an example session:


Please enter a vowel, lowercase!
  5
That's not a vowel!
  z
That's not a vowel!
  e
Thank you! Got e


In regex, as a Java string literal, the pattern "[aeiou]" is what is called a "character class"; it matches any of the letters a, e, i, o, u. Note that it's trivial to make the above test case-insensitive: just provide such regex pattern to the Scanner.


Sometimes you need to scan line-by-line, with multiple tokens on a line. The easiest way to accomplish this is to use two Scanner, where the second Scanner takes the nextLine() from the first Scanner as input. Here's an example:


Here's an example session:


Give me a bunch of numbers in a line (or 'exit')
  3 4 5
Sum is 12
  10 100 a million dollar
Sum is 110
  wait what?
Sum is 0
  exit


In addition to Scanner(String) constructor, there's also Scanner(java.io.File) among others.


For checking Strings for letters you can use regular expressions for example:


For checking numbers and stopping the program crashing, I have a quite simple class you can find below where you can define the range of values you want.
Here


Here's a minimalist way to do it.


One idea:


There is also, in commons-lang library the CharUtils class that provides the methods isAsciiNumeric() to check that a character is a number, and isAsciiAlpha() to check that the character is a letter...


If you are parsing string data from the console or similar, the best way is to use regular expressions. Read more on that here:
http://java.sun.com/developer/technicalArticles/releases/1.4regex/


Otherwise, to parse an int from a string, try
Integer.parseInt(string). If the string is not a number, you will get an exception. Otherise you can then perform your checks on that value to make sure it is not negative.


To get a character-only string, you would probably be better of looping over each character checking for digits, using for instance Character.isLetter(char).


Good luck!


what i have tried is that first i took the integer input and checked that whether its is negative or not if its negative then again take the input


Here, you need to take the character input first and check whether user gave character or not if not than again take the character input        






I want to draw a line in a JPanel.
This is my GUI and I want a line in the JPanel in white.





I find many examples but the problem is the how to use it.


In many exmples, always they draw in a JFrame that extends from a JPanel.


I want to add the Panel to the Frame and add some buttons to draw lines in many directions and use the X button in center to clean the JPanel.


This is the code of the interface:


This is the code to draw a line


So how to use this lines ....


Thanks in advance.


Best regards,


Ali


It may be easier to draw lines using the following approach:


This related example may offer some additional guidance.


Is this going to work like an etch-a-sketch? Then you need to track the current position of the point.


Then when the user clicks the buttons you can simply increment or decrement x and y accordingly.


On left arrow:


where INC could be a variable that specifies the length of the distance to draw the line. Maybe 5? Always set a second point p1 to the previous location though.


It is always easier to create a class that extends Canvas or JPanel to draw on rather than draweing directly on the JFrame.


e.g.


There is a simple answer for triggering graphics: e.g. The following code can be placed inside a click event and used for drawing a few simple objects on a jPanel.  jPanel1 in this case was situated on one side of a tabbed jPanel7 and next to the triggering button.  To do this in netbeans GUI, the code was placed inside the button action event. Once the usual errors appeared for not having the proper imports, right click on the code and click on "fix imports".  Bingo, all is well :-) Warning: the setBackground command for the panel will override the graphics object. If you set the background color without using the graphics object, you will not see your objects!


This restores your faith in true love :-) 
The difficulty here is that any change or repaint will erase your effort.  This approach is specifically discouraged by the Java founders.  But in the current rendition of Netbeans Swing, where extending the jPanel is made difficult by locking code changes, this approach could be your only short term solution.  A simple persistent graphic extension for the jPanel would be a most welcome addition to the current Netbeans Swing environment, a graphics panel.  This would allow you to drag and drop the graphics panel and then get on with the event driven use of that panel.  40 other IDE's already have this, it seems Java has been slow to add this feature.    






I am wondering when to use static methods? Say if I have a class with a few getters and setters, a method or two, and I want those methods only to be invokable on an instance object of the class. Does this mean I should use a static method?


e.g


or


(is this the static way?)


I'm rather confused!


One rule-of-thumb: ask yourself "does it make sense to call this method, even if no Obj has been constructed yet?"  If so, it should definitely be static.


So in a class Car you might have a method double convertMpgToKpl(double mpg) which would be static, because one might want to know what 35mpg converts to, even if nobody has ever built a Car.  But void setMileage(double mpg) (which sets the efficiency of one particular Car) can't be static since it's inconceivable to call the method before any Car has been constructed.


(Btw, the converse isn't always true: you might sometimes have a method which involves two Car objects, and still want it to be static.  E.g. Car theMoreEfficientOf( Car c1, Car c2 ).  Although this could be converted to a non-static version, some would argue that since there isn't a "privileged" choice of which Car is more important, you shouldn't force a caller to choose one Car as the object you'll invoke the method on.  This situation accounts for a fairly small fraction of all static methods, though.)


Define static methods in the following scenarios only:


There are some valid reasons to use static methods:


Performance: if you want some code to be run, and don't want to instantiate an extra object to do so, shove it into a static method. The JVM also can optimize static methods a lot (I think I've once read James Gosling declaring that you don't need custom instructions in the JVM, since static methods will be just as fast, but couldn't find the source - thus it could be completely false). Yes, it is micro-optimization, and probably unneeded. And we programmers never do unneeded things just because they are cool, right?


Practicality: instead of calling new Util().method(arg), call Util.method(arg), or method(arg) with static imports. Easier, shorter.


Adding methods: you really wanted the class String to have a removeSpecialChars() instance method, but it's not there (and it shouldn't, since your project's special characters may be different from the other project's), and you can't add it (since Java is somewhat sane), so you create an utility class, and call removeSpecialChars(s) instead of s.removeSpecialChars(). Sweet.


Purity: taking some precautions, your static method will be a pure function, that is, the only thing it depends on is its parameters. Data in, data out. This is easier to read and debug, since you don't have inheritance quirks to worry about. You can do it with instance methods too, but the compiler will help you a little more with static methods (by not allowing references to instance attributes, overriding methods, etc.).


You'll also have to create a static method if you want to make a singleton, but... don't. I mean, think twice.


Now, more importantly, why you wouldn't want to create a static method? Basically, polymorphism goes out of the window. You'll not be able to override the method, nor declare it in an interface (pre-Java 8). It takes a lot of flexibility out from your design. Also, if you need state, you'll end up with lots of concurrency bugs and/or bottlenecks if you are not careful.


After reading Misko's articles I believe that static methods are bad from a testing point of view. You should have factories instead(maybe using a dependency injection tool like Guice).


only have one of something
  The problem of “how do I ensure that I
  only have one of something” is nicely
  sidestepped. You instantiate only a
  single ApplicationFactory in your
  main, and as a result, you only
  instantiate a single instance of all
  of your singletons.


The basic issue with static methods is
  they are procedural code. I have no
  idea how to unit-test procedural code.
  Unit-testing assumes that I can
  instantiate a piece of my application
  in isolation. During the instantiation
  I wire the dependencies with
  mocks/friendlies which replace the
  real dependencies. With procedural
  programing there is nothing to "wire"
  since there are no objects, the code
  and data are separate.


A static method is one type of method which doesn't need any object to be initialized for it to be called. Have you noticed static is used in the main function in Java? Program execution begins from there without an object being created.


Consider the following example:


Static methods in java belong to the class (not an instance of it). They use no instance variables and will usually take input from the parameters, perform actions on it, then return some result. Instances methods are associated with objects and, as the name implies, can use instance variables.


No, static methods aren't associated with an instance; they belong to the class.  Static methods are your second example; instance methods are the first.


Static methods are not associated with an instance, so they can not access any non-static fields in the class. 


You would use a static method if the method does not use any fields (or only static fields) of a class. 


If any non-static fields of a class are used you must use a non-static method.


Actually, we use static properties and methods in a class, when we want to use some part of our program should exists there until our program is running. And we know that, to manipulate static properties, we need static methods as they are not a part of instance variable. And without static methods, to manipulate static properties is time consuming.


If you apply static keyword with any method, it is known as static method.


//Program of changing the common property of all objects(static field).  


O/P:   111 Indian BBDIT
       222 American BBDIT
       333 China BBDIT


Static methods are the methods in Java that can be called without creating an object of class.  It is belong to the class.


We use static method when we no need to be invoked method using instance. 


Use a static method when you want to be able to access the method without an instance of the class.


Static methods and variables are controlled version of 'Global' functions and variables in Java. In which methods can be accessed as classname.methodName() or classInstanceName.methodName(), i.e. static methods and variables can be accessed using class name as well as instances of the class.


Class can't be declared as static(because it makes no sense. if a class is declared public, it can be accessed from anywhere), inner classes can be declared static.


Static methods don't need to be invoked on the object and that is when you use it. Example: your Main()  is a static and you don't create an object to call it. 


Static:
Obj.someMethod


Use static when you want to provide class level access to a method, i.e. where the method should be callable without an instance of the class.


Static methods can be used if


One does not want to perform an action on an instance (utility methods)


As mentioned in few of above answers in this post, converting miles to kilometers, or calculating temperature from Fahrenheit to Celsius and vice-versa. With these examples using static method, it does not need to instantiate whole new object in heap memory. Consider below


the former creates a new class footprint for every method invoke, Performance, Practical. Examples are Math and Apache-Commons library StringUtils class below:


One wants to use as a simple function. Inputs are explictly passed, and getting the result data as return value. Inheritence, object instanciation does not come into picture. Concise, Readable.


NOTE: 
Few folks argue against testability of static methods, but static methods can be tested too! With jMockit, one can mock static methods. Testability. Example below:


I am wondering when to use static methods? 


But you can have static methods, without referencing static variables. Helper methods without referring static variable can be found in some java classes like java.lang.Math


The other use case, I can think of these methods combined with synchronized method is implementation of class level locking in multi threaded environment. 


Say if I have a class with a few getters and setters, a method or two, and I want those methods only to be invokable on an instance object of the class. Does this mean I should use a static method?


If you need to access method on an instance object of the class, your method should should be non static.


Oracle documentation page provides more details. 


Not all combinations of instance and class variables and methods are allowed:


In eclipse you can enable a warning which helps you detect potential static methods. (Above the highlighted line is another one I forgot to highlight)





Static methods are shared between all instances of the class, developers normally use static keyword with utility methods which do some common functionality that is regularly used anywhere in the application.


If the following conditions apply, then make your method static:


P.S: It is worth to mention that it is very difficult or even (not possible) to mock a static method, mocking is a mechanism used in unit testing in order to fake the business of some methods.


For more details, check: Static keyword in java






How can I find the memory used on my Android application, programmatically?


I hope there is a way to do it. Plus, how do I get the free memory of the phone too?


Note that memory usage on modern operating systems like Linux is an extremely complicated and difficult to understand area.  In fact the chances of you actually correctly interpreting whatever numbers you get is extremely low.  (Pretty much every time I look at memory usage numbers with other engineers, there is always a long discussion about what they actually mean that only results in a vague conclusion.)


Note: we now have much more extensive documentation on Managing Your App's Memory that covers much of the material here and is more up-to-date with the state of Android.


First thing is to probably read the last part of this article which has some discussion of how memory is managed on Android:


Service API changes starting with Android 2.0


Now ActivityManager.getMemoryInfo() is our highest-level API for looking at overall memory usage.  This is mostly there to help an application gauge how close the system is coming to having no more memory for background processes, thus needing to start killing needed processes like services.  For pure Java applications, this should be of little use, since the Java heap limit is there in part to avoid one app from being able to stress the system to this point.


Going lower-level, you can use the Debug API to get raw kernel-level information about memory usage: android.os.Debug.MemoryInfo


Note starting with 2.0 there is also an API, ActivityManager.getProcessMemoryInfo, to get this information about another process: ActivityManager.getProcessMemoryInfo(int[])


This returns a low-level MemoryInfo structure with all of this data:


But as to what the difference is between Pss, PrivateDirty, and SharedDirty...  well now the fun begins.


A lot of memory in Android (and Linux systems in general) is actually shared across multiple processes.  So how much memory a processes uses is really not clear.  Add on top of that paging out to disk (let alone swap which we don't use on Android) and it is even less clear.


Thus if you were to take all of the physical RAM actually mapped in to each process, and add up all of the processes, you would probably end up with a number much greater than the actual total RAM.


The Pss number is a metric the kernel computes that takes into account memory sharing -- basically each page of RAM in a process is scaled by a ratio of the number of other processes also using that page.  This way you can (in theory) add up the pss across all processes to see the total RAM they are using, and compare pss between processes to get a rough idea of their relative weight.


The other interesting metric here is PrivateDirty, which is basically the amount of RAM inside the process that can not be paged to disk (it is not backed by the same data on disk), and is not shared with any other processes.  Another way to look at this is the RAM that will become available to the system when that process goes away (and probably quickly subsumed into caches and other uses of it).


That is pretty much the SDK APIs for this.  However there is more you can do as a developer with your device.


Using adb, there is a lot of information you can get about the memory use of a running system.  A common one is the command adb shell dumpsys meminfo which will spit out a bunch of information about the memory use of each Java process, containing the above info as well as a variety of other things.  You can also tack on the name or pid of a single process to see, for example adb shell dumpsys meminfo system give me the system process:


The top section is the main one, where size is the total size in address space of a particular heap, allocated is the kb of actual allocations that heap thinks it has, free is the remaining kb free the heap has for additional allocations, and pss and priv dirty are the same as discussed before specific to pages associated with each of the heaps.


If you just want to look at memory usage across all processes, you can use the command adb shell procrank.  Output of this on the same system looks like:


Here the Vss and Rss columns are basically noise (these are the straight-forward address space and RAM usage of a process, where if you add up the RAM usage across processes you get an ridiculously large number).


Pss is as we've seen before, and Uss is Priv Dirty.


Interesting thing to note here: Pss and Uss are slightly (or more than slightly) different than what we saw in meminfo.  Why is that?  Well procrank uses a different kernel mechanism to collect its data than meminfo does, and they give slightly different results.  Why is that?  Honestly I haven't a clue.  I believe procrank may be the more accurate one...  but really, this just leave the point: "take any memory info you get with a grain of salt; often a very large grain."


Finally there is the command adb shell cat /proc/meminfo that gives a summary of the overall memory usage of the system.  There is a lot of data here, only the first few numbers worth discussing (and the remaining ones understood by few people, and my questions of those few people about them often resulting in conflicting explanations):


MemTotal is the total amount of memory available to the kernel and user space (often less than the actual physical RAM of the device, since some of that RAM is needed for the radio, DMA buffers, etc).


MemFree is the amount of RAM that is not being used at all.  The number you see here is very high; typically on an Android system this would be only a few MB, since we try to use available memory to keep processes running


Cached is the RAM being used for filesystem caches and other such things.  Typical systems will need to have 20MB or so for this to avoid getting into bad paging states; the Android out of memory killer is tuned for a particular system to make sure that background processes are killed before the cached RAM is consumed too much by them to result in such paging.


Yes, you can get memory info programmatically and decide whether to do memory intensive work.


Get VM Heap Size by calling:


Get Allocated VM Memory by calling:


Get VM Heap Size Limit by calling:


Get Native Allocated Memory by calling:


I made an app to figure out the OutOfMemoryError behavior and monitor memory usage.


https://play.google.com/store/apps/details?id=net.coocood.oomresearch


You can get the source code at
https://github.com/coocood/oom-research


This is a work in progress, but this is what I don't understand:


Why isn't the PID mapped to the result in activityManager.getProcessMemoryInfo()?  Clearly you want to make the resulting data meaningful, so why has Google made it so difficult to correlate the results?  The current system doesn't even work well if I want to process the entire memory usage since the returned result is an array of android.os.Debug.MemoryInfo objects, but none of those objects actually tell you what pids they are associated with.  If you simply pass in an array of all pids, you will have no way to understand the results.  As I understand it's use, it makes it meaningless to pass in more than one pid at a time, and then if that's the case, why make it so that activityManager.getProcessMemoryInfo() only takes an int array?


Hackbod's is one of the best answers on Stack Overflow. It throws light on a very obscure subject. It helped me a lot.


Another really helpful resource is this must-see video: Google I/O 2011: Memory management for Android Apps


UPDATE:


Process Stats, a service to discover how your app manages memory explained at the blog post Process Stats: Understanding How Your App Uses RAM by Dianne Hackborn: 


1) I guess not, at least not from Java.
2)


Android Studio 0.8.10+ has introduced an incredibly useful tool called Memory Monitor.





What it's good for:





Figure 1. Forcing a GC (Garbage Collection) event on Android Memory Monitor


You can have plenty good information on your app's RAM real-time consumption by using it. 


We found out that all the standard ways of getting the total memory of the current process have some issues.


Finally, we ended up using the following code:


It returns VmRSS metric. You can find more details about it here: one, two and three.


P.S. I noticed that the theme still has a lack of an actual and simple code snippet of how to estimate the private memory usage of the process if the performance isn't a critical requirement:






I am looking to use Java to get the MD5 checksum of a file.  I was really surprised but I haven't been able to find anything that shows how to get the MD5 checksum of a file.


How is it done?


There's an input stream decorator, java.security.DigestInputStream, so that you can compute the digest while using the input stream as you normally would, instead of having to make an extra pass over the data.


Use DigestUtils from Apache Commons Codec library:


There's an example at Real's Java-How-to using the MessageDigest class.


Check that page for examples using CRC32 and SHA-1 as well.


The com.google.common.hash API offers:


Read the User Guide (IO Explained, Hashing Explained). 


For your use-case Files.hash() computes and returns the digest value for a file.


For example a sha-1 digest calculation (change SHA-1 to MD5 to get MD5 digest)


Note that crc32 is much faster than md5, so use crc32 if you do not need a cryptographically secure checksum. Note also that md5 should not be used to store passwords and the like since it is to easy to brute force, for passwords use bcrypt,  scrypt or sha-256 instead. 


For long term protection with hashes a  Merkle signature scheme adds to the security and The Post Quantum Cryptography Study Group sponsored by the European Commission has recommended use of this cryptography for long term protection against quantum computers (ref).


Note that crc32 has a higher collision rate than the others. 


Using nio2 (Java 7+) and no external libraries:


To compare the result with an expected checksum:


Guava now provides a new, consistent hashing API that is much more user-friendly than the various hashing APIs provided in the JDK. See Hashing Explained. For a file, you can get the MD5 sum, CRC32 (with version 14.0+) or many other hashes easily:


Ok. I had to add. One line implementation for those who already have Spring and Apache Commons dependency or are planning to add it:


For and Apache commons only option (credit @duleshi):


Hope this helps someone.


A simple approach with no third party libraries using Java 7


If you need to print this byte array. Use as below


If you need hex string out of this digest. Use as below


where DatatypeConverter is javax.xml.bind.DatatypeConverter


I recently had to do this for just a dynamic string, MessageDigest can represent the hash in numerous ways. To get the signature of the file like you would get with the md5sum command I had to do something like the this: 


This obviously doesn't answer your question about how to do it specifically for a file, the above answer deals with that quiet nicely. I just spent a lot of time getting the sum to look like most application's display it, and thought you might run into the same trouble. 


Or you may get more info 
http://www.asjava.com/core-java/java-md5-example/ 


We were using code that resembles the code above in a previous post using


However, watch out for using BigInteger.toString() here, as it will truncate leading zeros...
(for an example, try s = "27", checksum should be "02e74f10e0327ad868d138f2b4fdd6f0") 


I second the suggestion to use Apache Commons Codec, I replaced our own code with that.


Standard Java Runtime Environment way:


The result is equal of linux md5sum utility.


Very fast & clean Java-method that doesn't rely on external libraries:


(Simply replace MD5 with SHA-1, SHA-256, SHA-384 or SHA-512 if you want those)


Another implementation: Fast MD5 Implementation in Java


Here is a simple function that wraps around Sunil's code so that it takes a File as a parameter. The function does not need any external libraries, but it does require Java 7.


Example output:


If you're using ANT to build, this is dead-simple.  Add the following to your build.xml:


Where jarFile is the JAR you want to generate the MD5 against, and toDir is the directory you want to place the MD5 file.


More info here.


Google guava provides a new API. Find the one below :






Is there a way to include all the jar files within a directory in the classpath?


I'm trying java -classpath lib/*.jar:. my.package.Program and it is not able to find class files that are certainly in those jars.  Do I need to add each jar file to the classpath separately? 


Using Java 6 or later, the classpath option supports wildcards. Note the following:


Windows


java -cp "Test.jar;lib/*" my.package.MainClass


Unix


java -cp "Test.jar:lib/*" my.package.MainClass


This is similar to Windows, but uses : instead of ;. If you cannot use wildcards, bash allows the following syntax (where lib is the directory containing all the Java archive files):


java -cp $(echo lib/*.jar | tr ' ' ':')


(Note that using a classpath is incompatible with the -jar option. See also: Execute jar file with multiple classpath libraries from command prompt)


Understanding Wildcards


From the Classpath document:


Class path entries can contain the basename wildcard character *, which is considered equivalent to specifying a list of all the files
  in the directory with the extension .jar or .JAR. For example, the
  class path entry foo/* specifies all JAR files in the directory named
  foo. A classpath entry consisting simply of * expands to a list of all
  the jar files in the current directory.


A class path entry that contains * will not match class files. To
  match both classes and JAR files in a single directory foo, use either
  foo;foo/* or foo/*;foo. The order chosen determines whether the
  classes and resources in foo are loaded before JAR files in foo, or
  vice versa.


Subdirectories are not searched recursively. For example, foo/* looks
  for JAR files only in foo, not in foo/bar, foo/baz, etc.


The order in which the JAR files in a directory are enumerated in the
  expanded class path is not specified and may vary from platform to
  platform and even from moment to moment on the same machine. A
  well-constructed application should not depend upon any particular
  order. If a specific order is required then the JAR files can be
  enumerated explicitly in the class path.


Expansion of wildcards is done early, prior to the invocation of a
  program's main method, rather than late, during the class-loading
  process itself. Each element of the input class path containing a
  wildcard is replaced by the (possibly empty) sequence of elements
  generated by enumerating the JAR files in the named directory. For
  example, if the directory foo contains a.jar, b.jar, and c.jar, then
  the class path foo/* is expanded into foo/a.jar;foo/b.jar;foo/c.jar,
  and that string would be the value of the system property
  java.class.path.


The CLASSPATH environment variable is not treated any differently from
  the -classpath (or -cp) command-line option. That is, wildcards are
  honored in all these cases. However, class path wildcards are not
  honored in the Class-Path jar-manifest header.


Under windows this works:


and this does not work:


notice the *.jar, so the * wildcard should be used alone.


On Linux, the following works:


The separators are colons instead of semicolons.


We get around this problem by deploying a main jar file myapp.jar which contains a manifest (Manifest.mf) file specifying a classpath with the other required jars, which are then deployed alongside it. In this case, you only need to declare java -jar myapp.jar when running the code. 


So if you deploy the main jar into some directory, and then put the dependent jars into a lib folder beneath that, the manifest looks like:


NB: this is platform-independent - we can use the same jars to launch on a UNIX server or on a Windows PC.


My solution on Ubuntu 10.04 using java-sun 1.6.0_24 having all jars in "lib" directory:


If this fails, the following command should work (prints out all *.jars in lib directory to the classpath param)


Short answer: java -classpath lib/*:. my.package.Program


Oracle provides documentation on using wildcards in classpaths here for Java 6 and here for Java 7, under the section heading Understanding class path wildcards. (As I write this, the two pages contain the same information.) Here's a summary of the highlights:


In general, to include all of the JARs in a given directory, you can use the wildcard * (not *.jar).


The wildcard only matches JARs, not class files; to get all classes in a directory, just end the classpath entry at the directory name.


The above two options can be combined to include all JAR and class files in a directory, and the usual classpath precedence rules apply. E.g. -cp /classes;/jars/*


The wildcard will not search for JARs in subdirectories.


The above bullet points are true if you use the CLASSPATH system property or the -cp or -classpath command line flags. However, if you use the Class-Path JAR manifest header (as you might do with an ant build file), wildcards will not be honored.


Yes, my first link is the same one provided in the top-scoring answer (which I have no hope of overtaking), but that answer doesn't provide much explanation beyond the link. Since that sort of behavior is discouraged on Stack Overflow these days, I thought I'd expand on it.


For me this works in windows .


For linux


I am using Java 6


Correct:


Incorrect:


You can try java -Djava.ext.dirs=jarDirectory
http://docs.oracle.com/javase/6/docs/technotes/guides/extensions/spec.html


Directory for external jars when running java


Windows:
 java -cp file.jar;dir/* my.app.ClassName


Linux:
java -cp file.jar:dir/* my.app.ClassName


Remind:
- Windows path separator is ";"
- Linux path separator is ":"
- In Windows if cp argument does not contains white space, the "quotes" is optional


If you really need to specify all the .jar files dynamically you could use shell scripts, or Apache Ant. There's a commons project called Commons Launcher which basically lets you specify your startup script as an ant build file (if you see what I mean).


Then, you can specify something like:


In your launch build file, which will launch your application with the correct classpath.


If you are using Java 6, then you can use wildcards in the classpath.


Now it is possible to use wildcards in classpath definition:


Ref: http://www.rekk.de/bloggy/2008/add-all-jars-in-a-directory-to-classpath-with-java-se-6-using-wildcards/


Please note that wildcard expansion is broken for Java 7 on Windows.


Check out this StackOverflow issue for more information.


The workaround is to put a semicolon right after the wildcard. java -cp "somewhere/*;"


To whom it may concern,


I found this strange behaviour on Windows under an MSYS/MinGW shell.


Works:


Doesn't work:


I am quite sure that the wildcard is not expanded by the shell, because e.g.


(Tried it with another program too, rather than the built-in echo, with the same result.)


I believe that it's javac which is trying to expand it, and it behaves differently whether there is a semicolon in the argument or not. First, it may be trying to expand all arguments that look like paths. And only then it would parse them, with -cp taking only the following token. (Note that com.comsol.aco_1.0.0.jar is the second JAR in that directory.) That's all a guess.


This is 


All the above solutions work great if you develop and run the Java application outside any IDE like Eclipse or Netbeans.


If you are on Windows 7 and used Eclipse IDE for Development in Java, you might run into issues if using Command Prompt to run the class files built inside Eclipse.


E.g. Your source code in Eclipse is having the following package hierarchy:
edu.sjsu.myapp.Main.java


You have json.jar as an external dependency for the Main.java


When you try running Main.java from within Eclipse, it will run without any issues.


But when you try running this using Command Prompt after compiling Main.java in Eclipse, it will shoot some weird errors saying "ClassNotDef Error blah blah".


I assume you are in the working directory of your source code !!


Use the following syntax to run it from command prompt:


javac -cp ".;json.jar" Main.java


java -cp ".;json.jar" edu.sjsu.myapp.Main


[Don't miss the . above]


This is because you have placed the Main.java inside the package edu.sjsu.myapp and java.exe will look for the exact pattern.


Hope it helps !!


For windows quotes are required and ; should be used as separator. e.g.:


Short Form: If your main is within a jar, you'll probably need an additional '-jar pathTo/yourJar/YourJarsName.jar '  explicitly declared to get it working (even though 'YourJarsName.jar' was on the classpath)
(or, expressed to answer the original question that was asked 5 years ago: you don't need to redeclare each jar explicitly, but does seem, even with java6 you need to redeclare your own jar ...) 


Long Form: 
(I've made this explicit to the point that I hope even interlopers to java can make use of this) 


Like many here I'm using eclipse to export jars: (File->Export-->'Runnable JAR File'). There are three options on 'Library handling' eclipse (Juno) offers:


Typically I'd use opt2 (and opt1 was definitely breaking), however native code in one of the jars I'm using I discovered breaks with the handy "jarinjar" trick that eclipse leverages when you choose that option. Even after realizing I needed opt3, and then finding this StackOverflow entry, it still took me some time to figure it out how to launch my main outside of eclipse, so here's what worked for me, as it's useful for others...


If  you named your jar: "fooBarTheJarFile.jar" 
and all is set to export to the  dir:     "/theFully/qualifiedPath/toYourChosenDir". 


(meaning the  'Export destination' field will read:   '/theFully/qualifiedPath/toYourChosenDir/fooBarTheJarFile.jar' )


After you hit finish, you'll find eclipse then puts all the libraries into a folder named 'fooBarTheJarFile_lib' within that export directory, giving you something like:


You can then launch from anywhere on your system with: 


(For Java Newbies:  'package.path_to.the_class_with.your_main' is the declared package-path that you'll find at the top of the 'TheClassWithYourMain.java' file that contains the 'main(String[] args){...}' that you wish to run from outside java)


The pitfall to notice: is that having 'fooBarTheJarFile.jar' within the list of jars on your declared classpath is not enough.  You need to explicitly declare '-jar', and redeclare the location of that jar. 


e.g. this breaks:  


restated with relative paths:


(using java version "1.6.0_27"; via  OpenJDK 64-Bit Server VM  on ubuntu 12.04)


The only way I know how is to do it individually, for example:


Hope that helps!


Not a direct solution to being able to set /* to -cp but I hope you could use the following script to ease the situation a bit for dynamic class-paths and lib directories.


Scripted for Linux, could have a similar one for windows too. If proper directory is provided as input to the "libDir2Scan4jars"; the script will scan all the jars and create a classpath string and export it to a env variable "tmpCLASSPATH". 


You need to add them all separately.  Alternatively, if you really need to just specify a directory, you can unjar everything into one dir and add that to your classpath.  I don't recommend this approach however as you risk bizarre problems in classpath versioning and unmanagability.


Think of a jar file as the root of a directory structure. Yes, you need to add them all separately.


class from wepapp:


Set the classpath in a way suitable multiple jars and current directory's class files. 






How does Java handle integer underflows and overflows?


Leading on from that, how would you check/test that this is occurring?


If it overflows, it goes back to the minimum value and continues from there. If it underflows, it goes back to the maximum value and continues from there.


You can check that beforehand as follows:


(you can substitute int by long to perform the same checks for long)


If you think that this may occur more than often, then consider using a datatype or object which can store larger values, e.g. long or maybe java.math.BigInteger. The last one doesn't overflow, practically, the available JVM memory is the limit.


If you happen to be on Java8 already, then you can make use of the new Math#addExact() and Math#subtractExact() methods which will throw an ArithmeticException on overflow.


The source code can be found here and here respectively.


Of course, you could also just use them right away instead of hiding them in a boolean utility method.


Well, as far as primitive integer types go, Java doesnt handle Over/Underflow at all (for float and double the behaviour is different, it will flush to +/- infinity just as IEEE-754 mandates).


When adding two int's, you will get no indication when an overflow occurs. A simple method to check for overflow is to use the next bigger type to actually perform the operation and check if the result is still in range for the source type:


What you would do in place of the throw clauses, depends on your applications requirements (throw, flush to min/max or just log whatever). If you want to detect overflow on long operations, you're out of luck with primitives, use BigInteger instead.


Edit (2014-05-21): Since this question seems to be referred to quite frequently and I had to solve the same problem myself, its quite easy to evaluate the overflow condition by the same method a CPU would calculate its V flag.


Its basically a boolean expression that involves the sign of both operands as well as the result: 


In java its simpler to apply the expression (in the if) to the entire 32 bits, and check the result using < 0 (this will effectively test the sign bit). The principle works exactly the same for all integer primitive types, changing all declarations in above method to long makes it work for long.


For smaller types, due to the implicit conversion to int (see the JLS for bitwise operations for details), instead of checking < 0, the check needs to mask the sign bit explicitly (0x8000 for short operands, 0x80 for byte operands, adjust casts and parameter declaration appropiately):


(Note that above example uses the expression need for subtract overflow detection)


So how/why do these boolean expressions work? First, some logical thinking reveals that an overflow can only occur if the signs of both arguments are the same. Because, if one argument is negative and one positive, the result (of add) must be closer to zero, or in the extreme case one argument is zero, the same as the other argument. Since the arguments by themselves can't create an overflow condition, their sum can't create an overflow either.


So what happens if both arguments have the same sign? Lets take a look at the case both are positive: adding two arguments that create a sum larger than the types MAX_VALUE, will always yield a negative value, so an overflow occurs if arg1 + arg2 > MAX_VALUE. Now the maximum value that could result would be MAX_VALUE + MAX_VALUE (the extreme case both arguments are MAX_VALUE). For a byte (example) that would mean 127 + 127 = 254. Looking at the bit representations of all values that can result from adding two positive values, one finds that those that overflow (128 to 254) all have bit 7 set, while all that do not overflow (0 to 127) have bit 7 (topmost, sign) cleared. Thats exactly what the first (right) part of the expression checks:


(~s & ~d & r) becomes true, only if, both operands (s, d) are positive and the result (r) is negative (the expression works on all 32 bits, but the only bit we're interested in is the topmost (sign) bit, which is checked against by the < 0).


Now if both arguments are negative, their sum can never be closer to zero than any of the arguments, the sum must be closer to minus infinity. The most extreme value we can produce is MIN_VALUE + MIN_VALUE, which (again for byte example) shows that for any in range value (-1 to -128) the sign bit is set, while any possible overflowing value (-129 to -256) has the sign bit cleared. So the sign of the result again reveals the overflow condition. Thats what the left half (s & d & ~r) checks for the case where both arguments (s, d) are negative and a result that is positive. The logic is largely equivalent to the positive case; all bit patterns that can result from adding two negative values will have the sign bit cleared if and only if an underflow occured.


Java doesn't do anything with integer overflow for either int or long primitive types and ignores overflow with positive and negative integers. 


This answer first describes the of integer overflow, gives an example of how it can happen, even with intermediate values in expression evaluation, and then gives links to resources that give detailed techniques for preventing and detecting integer overflow. 


Integer arithmetic and expressions reslulting in unexpected or undetected overflow are a common programming error. Unexpected or undetected integer overflow is also a well-known exploitable security issue, especially as it affects array, stack and list objects. 


Overflow can occur in either a positive or negative direction where the positive or negative value would be beyond the maximum or minimum values for the primitive type in question. Overflow can occur in an intermediate value during expression or operation evaluation and affect the outcome of an expression or operation where the final value would be expected to be within range. 


Sometimes negative overflow is mistakenly called underflow. Underflow is what happens when a value would be closer to zero than the representation allows. Underflow occurs in integer arithmetic and is expected. Integer underflow happens when an integer evaluation would be between -1 and 0 or 0 and 1. What would be a fractional result truncates to 0. This is normal and expected with integer arithmetic and not considered an error. However, it can lead to code throwing an exception. One example is an "ArithmeticException: / by zero" exception if the result of integer underflow is used as a divisor in an expression. 


Consider the following code:


which results in x being assigned 0 and the subsequent evaluation of bigValue / x throws an exception, "ArithmeticException: / by zero" (i.e. divide by zero), instead of y being assigned the value 2. 


The expected result for x would be 858,993,458 which is less than the maximum int value of 2,147,483,647. However, the intermediate result from evaluating Integer.MAX_Value * 2, would be 4,294,967,294, which exceeds the maximum int value and is -2 in accordance with 2s complement integer representations. The subsequent evaluation of -2 / 5 evaluates to 0 which gets assigned to x. 


Rearranging the expression for computing x to an expression that, when evaluated, divides before multiplying, the following code:


results in x being assigned 858,993,458 and y being assigned 2, which is expected.


The intermediate result from bigValue / 5 is 429,496,729 which does not exceed the maximum value for an int. Subsequent evaluation of 429,496,729 * 2 doesn't exceed the maximum value for an int and the expected result gets assigned to x. The evaluation for y then does not divide by zero. The evaluations for x and y work as expected.


Java integer values are stored as and behave in accordance with 2s complement signed integer representations. When a resulting value would be larger or smaller than the maximum or minimum integer values, a 2's complement integer value results instead. In situations not expressly designed to use 2s complement behavior, which is most ordinary integer arithmetic situations, the resulting 2s complement value will cause a programming logic or computation error as was shown in the example above. An excellent Wikipedia article describes 2s compliment binary integers here: Two's complement - Wikipedia


There are techniques for avoiding unintentional integer overflow. Techinques may be categorized as using pre-condition testing, upcasting and BigInteger. 


Pre-condition testing comprises examining the values going into an arithmetic operation or expression to ensure that an overflow won't occur with those values. Programming and design will need to create testing that ensures input values won't cause overflow and then determine what to do if input values occur that will cause overflow. 


Upcasting comprises using a larger primitive type to perform the arithmetic operation or expression and then determining if the resulting value is beyond the maximum or minimum values for an integer. Even with upcasting, it is still possible that the value or some intermediate value in an operation or expression will be beyond the maximum or minimum values for the upcast type and cause overflow, which will also not be detected and will cause unexpected and undesired results. Through analysis or pre-conditions, it may be possible to prevent overflow with upcasting when prevention without upcasting is not possible or practical. If the integers in question are already long primitive types, then upcasting is not possible with primitive types in Java.


The BigInteger technique comprises using BigInteger for the arithmetic operation or expression using library methods that use BigInteger. BigInteger does not overflow. It will use all available memory, if necessary. Its arithmetic methods are normally only slightly less efficient than integer operations. It is still possible that a result using BigInteger may be beyond the maximum or minimum values for an integer, however, overflow will not occur in the arithmetic leading to the result. Programming and design will still need to determine what to do if a BigInteger result is beyond the maximum or minimum values for the desired primitive result type, e.g., int or long. 


The Carnegie Mellon Software Engineering Institute's CERT program and Oracle have created a set of standards for secure Java programming. Included in the standards are techniques for preventing and detecting integer overflow. The standard is published as a freely accessible online resource here: The CERT Oracle Secure Coding Standard for Java


The standard's section that describes and contains practical examples of coding techniques for preventing or detecting integer overflow is here: NUM00-J. Detect or prevent integer overflow


Book form and PDF form of The CERT Oracle Secure Coding Standard for Java are also available.


By default, Java's int and long math silently wrap around on overflow and underflow.  (Integer operations on other integer types are performed by first promoting the operands to int or long, per JLS 4.2.2.)


As of Java 8, java.lang.Math provides addExact, subtractExact, multiplyExact, incrementExact, decrementExact and negateExact static methods for both int and long arguments that perform the named operation, throwing ArithmeticException on overflow.  (There's no divideExact method -- you'll have to check the one special case (MIN_VALUE / -1) yourself.)


As of Java 8, java.lang.Math also provides toIntExact to cast a long to an int, throwing ArithmeticException if the long's value does not fit in an int.  This can be useful for e.g. computing the sum of ints using unchecked long math, then using toIntExact to cast to int at the end (but be careful not to let your sum overflow).


If you're still using an older version of Java, Google Guava provides IntMath and LongMath static methods for checked addition, subtraction, multiplication and exponentiation (throwing on overflow).  These classes also provide methods to compute factorials and binomial coefficients that return MAX_VALUE on overflow (which is less convenient to check).  Guava's primitive utility classes, SignedBytes, UnsignedBytes, Shorts and Ints, provide checkedCast methods for narrowing larger types (throwing IllegalArgumentException on under/overflow, not ArithmeticException), as well as saturatingCast methods that return MIN_VALUE or MAX_VALUE on overflow.


Having just kinda run into this problem myself, here's my solution (for both multiplication and addition):


feel free to correct if wrong or if can be simplified. I've done some testing with the multiplication method, mostly edge cases, but it could still be wrong.


There are libraries that provide safe arithmetic operations, which check integer overflow/underflow . For example, Guava's IntMath.checkedAdd(int a, int b) returns the sum of a and b, provided it does not overflow, and throws ArithmeticException if a + b overflows in signed int arithmetic.


I think you should use something like this and it is called Upcasting:


You can read further here:
Detect or prevent integer overflow


It is quite reliable source.


It doesn't do anything -- the under/overflow just happens.


A "-1" that is the result of a computation that overflowed is no different from the "-1" that resulted from any other information. So you can't tell via some status or by inspecting just a value whether it's overflowed.


But you can be smart about your computations in order to avoid overflow, if it matters, or at least know when it will happen. What's your situation?


It wraps around.


e.g:


public class test {


}


prints


-2147483648


2147483647


There is one case, that is not mentioned above:


will produce:


This case was discussed here:
Integer overflow produces Zero.


I think this should be fine.






The diamond operator in java 7 allows code like the following:


However in Java 5/6, I can simply write:


My understanding of type erasure is that these are exactly the same. (The generic gets removed at runtime anyway). 


Why bother with the diamond at all? What new functionality / type safety does it allow? If it doesn't yield any new functionality why do they mention it as a feature? Is my understanding of this concept flawed?


The issue with


is that on the left hand side, you are using the generic type List<String> where on the right side you are using the raw type LinkedList. Raw types in Java effectively only exist for compatibility with pre-generics code and should never be used in new code unless 
you absolutely have to.


Now, if Java had generics from the beginning and didn't have types, such as LinkedList, that were originally created before it had generics, it probably could have made it so that the constructor for a generic type automatically infers its type parameters from the left-hand side of the assignment if possible. But it didn't, and it must treat raw types and generic types differently for backwards compatibility. That leaves them needing to make a slightly different, but equally convenient, way of declaring a new instance of a generic object without having to repeat its type parameters... the diamond operator.


As far as your original example of List<String> list = new LinkedList(), the compiler generates a warning for that assignment because it must. Consider this:


Generics exist to provide compile-time protection against doing the wrong thing. In the above example, using the raw type means you don't get this protection and will get an error at runtime. This is why you should not use raw types.


The diamond operator, however, allows the right hand side of the assignment to be defined as a true generic instance with the same type parameters as the left side... without having to type those parameters again. It allows you to keep the safety of generics with almost the same effort as using the raw type.


I think the key thing to understand is that raw types (with no <>) cannot be treated the same as generic types. When you declare a raw type, you get none of the benefits and type checking of generics. You also have to keep in mind that generics are a general purpose part of the Java language... they don't just apply to the no-arg constructors of Collections!


Your understanding is slightly flawed. The diamond operator is a nice feature as you don't have to repeat yourself. It makes sense to define the type once when you declare the type but just doesn't make sense to define it again on the right side. The DRY principle.


Now to explain all the fuzz about defining types. You are right that the type is removed at runtime but once you want to retrieve something out of a List with type definition you get it back as the type you've defined when declaring the list otherwise it would lose all specific features and have only the Object features except when you'd cast the retrieved object to it's original type which can sometimes be very tricky and result in a ClassCastException.


Using List<String> list = new LinkedList() will get you rawtype warnings.


This line causes the [unchecked] warning:


So, the question transforms: why [unchecked] warning is not suppressed automatically only for the case when new collection is created?


I think, it would be much more difficult task then adding <> feature. 


UPD: I also think that there would be a mess if it were legally to use raw types 'just for a few things'.


In theory, the diamond operator allows you to write more compact (and readable) code by saving repeated type arguments. In practice, it's just two confusing chars more giving you nothing. Why?


IMHO, having a clear and simple way to mark a source as Java 7 would be more useful than inventing such strange things. In so marked code raw types could be forbidden without losing anything.


Btw., I don't think that it should be done using a compile switch. The Java version of a program file is an attribute of the file, no option at all. Using something as trivial as


could make it clear (you may prefer something more sophisticated including one or more fancy keywords). It would even allow to compile sources written for different Java versions together without any problems. It would allow introducing new keywords (e.g., "module") or dropping some obsolete features (multiple non-public non-nested classes in a single file or whatsoever) without losing any compatibility.


When you write List<String> list = new LinkedList();, compiler produces an "unchecked" warning. You may ignore it, but if you used to ignore these warnings you may also miss a warning that notifies you about a real type safety problem.


So, it's better to write a code that doesn't generate extra warnings, and diamond operator allows you to do it in convenient way without unnecessary repetition.


The point for diamond operator is simply to reduce typing of code when declaring generic types. It doesn't have any effect on runtime whatsoever.


The only difference if you specify in Java 5 and 6,  


is that you have to specify @SuppressWarnings("unchecked") to the list (otherwise you will get an unchecked cast warning). My understanding is that diamond operator is trying to make development easier. It's got nothing to do on runtime execution of generics at all.


All said in the other responses are valid but the use cases are not completely valid IMHO. If one checks out Guava  and especially the collections related stuff, the same has been done with static methods. E.g. Lists.newArrayList() which allows you to write


or with static import


Guava has other very powerful features like this and I actually can't think of much uses for the <>.


It would have been more useful if they went for making the diamond operator behavior the default, that is, the type is inferenced from the left side of the expression or if the type of the left side was inferenced from the right side. The latter is what happens in Scala.






I was writing this code:


The result is 0.  Why is this, and how do I solve this problem?


The two operands (1 and 3) are integers, therefore integer arithmetic (division here) is used. Declaring the result variable as double just causes an implicit conversion to occur after division.


Integer division of course returns the true result of division rounded towards zero. The result of 0.333... is thus rounded down to 0 here. (Note that the processor doesn't actually do any rounding, but you can think of it that way still.)


Also, note that if both operands (numbers) are given as floats; 3.0 and 1.0, or even just the first, then floating-point arithmetic is used, giving you 0.333....


1/3 uses integer division as both sides are integers.


You need at least one of them to be float or double.


If you are entering the values in the source code like your question, you can do 1.0/3 ; the 1.0 is a double.


If you get the values from elsewhere you can use (double) to turn the int into a double.


Explicitly cast it as a double


This happens because Java uses the integer division operation for 1 and 3 since you entered them as integer constants.


you should use


or


Integer division returns integer.


1 ans 3 are integer contants and so Java does an integer division which's result is 0. If you want to write double constants you have to write 1.0 and 3.0.


Because it treats 1 and 3 as integers, therefore rounding the result down to 0, so that it is an integer.


To get the result you are looking for, explicitly tell java that the numbers are doubles like so:


Because you are doing integer division.


As @Noldorin says, if both operators are integers, then integer division is used.


The result 0.33333333 can't be represented as an integer, therefore only the integer part (0) is assigned to the result.


If any of the operators is a double / float, then floating point arithmetic will take place. But you'll have the same problem if you do that:


Many others have failed to point out the real issue:


An operation on only integers casts the result of the operation to an integer.


This necessarily means that floating point results, that could be displayed as an integer, will be truncated (lop off the decimal part).


What is casting (typecasting / type conversion) you ask?


It varies on the implementation of the language, but Wikipedia has a fairly comprehensive view, and it does talk about coercion as well, which is a pivotal piece of information in answering your question.


http://en.wikipedia.org/wiki/Type_conversion


The conversion in JAVA is quite simple but need some understanding. As explain in the JLS for integer operations:


If an integer operator other than a shift operator has at least one operand of type long, then the operation is carried out using 64-bit precision, and the result of the numerical operator is of type long. If the other operand is not long, it is first widened (§5.1.5) to type long by numeric promotion (§5.6). 


And an example is always the best way to translate the JLS ;) 


Otherwise, the operation is carried out using 32-bit precision, and the result of the numerical operator is of type int. If either operand is not an int, it is first widened to type int by numeric promotion. 


A small example using Eclipse to show that even an addition of two shorts will not be that easy :


This will required a casting with a possible loss of precision.


The same is true for the floating point operators


If at least one of the operands to a numerical operator is of type double, then the operation is carried out using 64-bit floating-point arithmetic, and the result of the numerical operator is a value of type double. If the other operand is not a double, it is first widened (§5.1.5) to type double by numeric promotion (§5.6). 


So the promotion is done on the float into double.


And the mix of both integer and floating value result in floating values as said 


If at least one of the operands to a binary operator is of floating-point type, then the operation is a floating-point operation, even if the other is integral. 


This is true for binary operators but not for "Assignment Operators" like +=


A simple working example is enough to prove this


The reason is that there is an implicit cast done here, this will be execute like 


(1/3) means Integer division, thats why you can not get decimal value from this division. To solve this problem use:


Do "double g=1.0/3.0;" instead.


Make the 1 a float and float division will be used






Recently posted a question regarding the HttpClient over Https (found here).  I've made some headway, but I've run into new issues. As with my last problem, I can't seem to find an example anywhere that works for me. Basically, I want my client to accept any certificate (because I'm only ever pointing to one server) but I keep getting a javax.net.ssl.SSLException: Not trusted server certificate exception.


So this is what I have:


And here's the error I'm getting:


Note: Do not implement this in production code you are ever going to use on a network you do not entirely trust. Especially anything going over the public internet. 


Your question is just what I want to know. After I did some searches, the conclusion is as follows.


In HttpClient way, you should create a custom class from org.apache.http.conn.ssl.SSLSocketFactory, not the one org.apache.http.conn.ssl.SSLSocketFactory
 itself. Some clues can be found in this post Custom SSL handling stopped working on Android 2.2 FroYo.


An example is like  ...


and use this class while creating instance of HttpClient.


BTW, the link below is for someone who is looking for HttpURLConnection solution.
Https Connection Android


I have tested the above two kinds of solutions on froyo, and they all work like a charm in my cases. Finally, using HttpURLConnection may face the redirect problems, but this is beyond the topic.


Note: Before you decide to trust all certificates, you probably should know the site full well and won't be harmful of it to end-user.


Indeed, the risk you take should be considered carefully, including the effect of hacker's mock site mentioned in the following comments that I deeply appreciated. In some situation, although it might be hard to take care of all certificates, you'd better know the implicit drawbacks to trust all of them.


You basically have four potential solutions to fix a "Not Trusted" exception on Android using httpclient:


This answer uses solution #4, which seems to me to be the most robust.


The solution is to use an SSLSocketFactory that can accept multiple KeyStores, allowing you to supply your own KeyStore with your own certificates.  This allows you to load additional top-level certificates such as Thawte that might be missing on some Android devices.  It also allows you to load your own self-signed certificates as well.  It will use the built-in default device certificates first, and fall back on your additional certificates only as necessary.


First, you'll want to determine which cert you are missing in your KeyStore.  Run the following command:


And you'll see output like the following:


As you can see, our root certificate is from Thawte.  Go to your provider's website and find the corresponding certificate.  For us, it was here, and you can see that the one we needed was the one Copyright 2006.


If you're using a self-signed certificate, you didn't need to do the previous step since you already have your signing certificate. 


Then, create a keystore file containing the missing signing certificate.  Crazybob has details how to do this on Android, but the idea is to do the following:


If you don't have it already, download the bouncy castle provider library from: http://www.bouncycastle.org/latest_releases.html. This will go on your classpath below.


Run a command to extract the certificate from the server and create a pem file. In this case, mycert.pem.


Then run the following commands to create the keystore.


You'll notice that the above script places the result in res/raw/mystore.bks.  Now you have a file that you'll load into your Android app that provides the missing certificate(s).  


To do this, register your SSLSocketFactory for the SSL scheme:


To create your SSLSocketFactory:


And finally, the AdditionalKeyStoresSSLSocketFactory code, which accepts your new KeyStore and checks if the built-in KeyStore fails to validate an SSL certificate:


Add this code before the HttpsURLConnection and it will be done.  I got it.


I hope this helps you.


This is a bad idea.  Trusting any certificate is only (very) slightly better than using no SSL at all.  When you say "I want my client to accept any certificate (because I'm only ever pointing to one server)" you are assuming this means that somehow pointing to "one server" is safe, which it's not on a public network.  


You are completely open to a man-in-the-middle attack by trusting any certificate.  Anyone can proxy your connection by establishing a separate SSL connection with you and with the end server.  The MITM then has access to your entire request and response.  Unless you didn't really need SSL in the first place (your message has nothing sensitive, and doesn't do authentication) you shouldn't trust all certificates blindly.  


You should consider adding the public cert to a jks using keytool, and using that to build your socket factory, such as this:


This has one caveat to watch out for.  The certificate will expire eventually, and the code will stop working at that time.  You can easily determine when this will happen by looking at the cert.


You can disable HttpURLConnection SSL checking for testing purposes this way since API 8:


The API of HttpComponents has got changed. It works with the code below.


The code above in https://stackoverflow.com/a/6378872/1553004 is correct, except it MUST also call the hostname verifier:


I signed up to stackoverflow expressly to add this fix.  Heed my warning!


Here is a much simple version using 4.1.2 httpclient code.  This can then be modified to any trust algorithm you see fit.


I'm looked response from "emmby" (answered Jun 16 '11 at 21:29), item #4: "Create a custom SSLSocketFactory that uses the built-in certificate KeyStore, but falls back on an alternate KeyStore for anything that fails to verify with the default."


This is a simplified implementation. Load the system keystore & merge with application keystore.


A simple mode to convert from JKS to BKS:


*Note: In Android 4.0 (ICS) the Trust Store has changed, more info: http://nelenkov.blogspot.com.es/2011/12/ics-trust-store-implementation.html


For those who would like to allow all certificates to work (for testing purposes) over OAuth, follow these steps:


1) Download the source code of the Android OAuth API here: https://github.com/kaeppler/signpost


2) Find the file "CommonsHttpOAuthProvider" class


3) Change it as below:


The "MySSLSocketFactory" above is based on the accepted answer. To make it even easier, here goes the complete class:


}


Hope this helps someone.


Trusting all certificates was no real alternative for me, so I did the following to get HttpsURLConnection to trust a new certificate (see also http://nelenkov.blogspot.jp/2011/12/using-custom-certificate-trust-store-on.html).


Get the certificate; I got this done by exporting the certificate in Firefox (click on the little lock icon, get certificate details, click export), then used portecle to export a truststore (BKS).


Load the Truststore from /res/raw/geotrust_cert.bks with the following code:


I'm adding a response for those that use the httpclient-4.5, and probably works for 4.4 as well.


Any body still struggling with StartCom SSL Certificates on Android 2.1 visit https://www.startssl.com/certs/ and download the ca.pem, now in the answer provided by @emmby replace 


with 


Should work out of the box. I was struggling it for over a day even after a perfect answer by @emmby.. Hope this helps someone...


I used this and It works for me on all OS.


/**
     * Disables the SSL certificate checking for new instances of {@link HttpsURLConnection} This has been created to
     * aid testing on a local box, not for use on production.
     */


Just adding -Dtrust_all_cert=true to VM arguments should do. This argument tells java to ignore certificate checks.


work with all https


There a many answers above but I wasn't able to get any of them working correctly (with my limited time), so for anyone else in the same situation you can try the code below which worked perfectly for my java testing purposes:


and call like:


Reference: http://tech.chitgoks.com/2011/04/24/how-to-avoid-javax-net-ssl-sslpeerunverifiedexception-peer-not-authenticated-problem-using-apache-httpclient/


Simply use this - 


Daniel's answer was good except I had to change this code...


to this code...


to get it to work.






If I have two variables:


Without knowing the class of obj, how can I call the method identified by methodName on it?


The method being called has no parameters, and a String return value. It's a getter for a Java bean.


Coding from the hip, it would be something like:


The parameters identify the very specific method you need (if there are several overloaded available, if the method has no arguments, only give methodName).


Then you invoke that method by calling


Again, leave out the arguments in .invoke, if you don't have any. But yeah. Read about Java Reflection


Use reflection:


http://java.sun.com/docs/books/tutorial/reflect/member/methodInvocation.html


Where:


"class name" is the name of the class


objectToInvokeOn is of type Object and is the object you want to invoke the method on
"method name" is the name of the method you want to call


parameterTypes is of type Class [] and decalres the parameters the method takes


params is of type Object [] and declares the parameters to be passed to the method


The method can be invoked like this. There are also more possibilities (check the reflection api), but this is the simplest one:


For those who want a straight-forward code example in Java 7:


Dog class:


ReflectionDemo class:


Output:
Mishka is 3 year(s) old.


You can invoke the constructor with parameters this way:


Alternatively, you can remove


and do


Suggested reading: Creating New Class Instances


First, don't. Avoid this sort of code. It tends to be really bad code and insecure too (see section 6 of Secure Coding Guidelines for the
Java Programming Language, version 2.0).


If you must do it, prefer java.beans to reflection. Beans wraps reflection allowing relatively safe and conventional access.


To complete my colleague's answers, You might want to pay close attention to:


Here is an old java1.4 code which takes into account those points:


This sounds like something that is doable with the Java Reflection package.


http://java.sun.com/developer/technicalArticles/ALT/Reflection/index.html


Particularly under Invoking Methods by Name:


import java.lang.reflect.*;


Please refer following code may help you.


Thanks....


KeyWords is class name and KeyWord is a variable


If you do the call several times you can use the new method handles introduced in Java 7. Here we go for your method returning a String:


I do this manner:


You should use reflection - init a class object, then a method in this class, and then invoke this method on an object with optional parameters. Remember to wrap the following snippet in try-catch block


Hope it helps!


This is working fine for me :


}


Output: 


My input testparam


I am able to invoke the method by passing its name to another method (like main).


using import java.lang.reflect.*;


and here is how you use it:


Student.java


StudentTest.java


for me a pretty simple and fool proof way would be to simply make a method caller method like so:


then when you need to call the method simply put something like this






A module I'm adding to our large Java application has to converse with another company's SSL-secured website.  The problem is that the site uses a self-signed certificate.  I have a copy of the certificate to verify that I'm not encountering a man-in-the-middle attack, and I need to incorporate this certificate into our code in such a way that the connection to the server will be successful.


Here's the basic code:


Without any additional handling in place for the self-signed certificate, this dies at conn.getOutputStream() with the following exception:


Ideally, my code needs to teach Java to accept this one self-signed certificate, for this one spot in the application, and nowhere else.


I know that I can import the certificate into the JRE's certificate authority store, and that will allow Java to accept it.  That's not an approach I want to take if I can help; it seems very invasive to do on all of our customer's machines for one module they may not use; it would affect all other Java applications using the same JRE, and I don't like that even though the odds of any other Java application ever accessing this site are nil.  It's also not a trivial operation: on UNIX I have to obtain access rights to modify the JRE in this way.


I've also seen that I can create a TrustManager instance that does some custom checking.  It looks like I might even be able to create a TrustManager that delegates to the real TrustManager in all instances except this one certificate.  But it looks like that TrustManager gets installed globally, and I presume would affect all other connections from our application, and that doesn't smell quite right to me, either.


What is the preferred, standard, or best way to set up a Java application to accept a self-signed certificate?  Can I accomplish all of the goals I have in mind above, or am I going to have to compromise?  Is there an option involving files and directories and configuration settings, and little-to-no code?


Create an SSLSocket factory yourself, and set it on the HttpsURLConnection before connecting.


You'll want to create one SSLSocketFactory and keep it around. Here's a sketch of how to initialize it:


If you need help creating the key store, please comment.


Here's an example of loading the key store:


To create the key store with a PEM format certificate, you can write your own code using CertificateFactory, or just import it with keytool from the JDK (keytool won't work for a "key entry", but is just fine for a "trusted entry").


If creating a SSLSocketFactory is not an option, just import the key into the JVM


Retrieve the public key:
$openssl s_client -connect dev-server:443, then create a file dev-server.pem that looks like


Import the key: #keytool -import -alias dev-server -keystore $JAVA_HOME/jre/lib/security/cacerts -file dev-server.pem.
Password: changeit


Restart JVM


Source: How to solve javax.net.ssl.SSLHandshakeException?


We copy the JRE's truststore and add our custom certificates to that truststore, then tell the application to use the custom truststore with a system property.  This way we leave the default JRE truststore alone.


The downside is that when you update the JRE you don't get its new truststore automatically merged with your custom one.  


You could maybe handle this scenario by having an installer or startup routine that verifies the truststore/jdk and checks for a mismatch or automatically updates the truststore.  I don't know what happens if you update the truststore while the application is running.


This solution isn't 100% elegant or foolproof but it's simple, works, and requires no code.


I've had to do something like this when using commons-httpclient to access an internal https server with a self-signed certificate. Yes, our solution was to create a custom TrustManager that simply passed everything (logging a debug message).


This comes down to having our own SSLSocketFactory that creates SSL sockets from our local SSLContext, which is set up to have only our local TrustManager associated with it. You don't need to go near a keystore/certstore at all.


So this is in our LocalSSLSocketFactory:


Along with other methods implementing SecureProtocolSocketFactory. LocalSSLTrustManager is the aforementioned dummy trust manager implementation.


I went through LOTS of places in SO and the web to solve this thing. This is the code that worked for me:


app.certificateString is a String that contains the Certificate, for example:


I have tested that you can put any characters in the certificate string, if it is self signed, as long as you keep the exact structure above. I obtained the certificate string with my laptop's Terminal command line.






I have a Wicket page class that sets the page title depending on the result of an abstract method.


NetBeans warns me with the message "Overridable method call in constructor", but what should be wrong with it? The only alternative I can imagine is to pass the results of otherwise abstract methods to the super constructor in subclasses. But that could be hard to read with many parameters.


Simply put, this is wrong because it unnecessarily opens up possibilities to MANY bugs. When the @Override is invoked, the state of the object may be inconsistent and/or incomplete.


A quote from Effective Java 2nd Edition, Item 17: Design and document for inheritance, or else prohibit it:


There are a few more restrictions that a class must obey to allow inheritance. Constructors must not invoke overridable methods, directly or indirectly. If you violate this rule, program failure will result. The superclass constructor runs before the subclass constructor, so the overriding method in the subclass will be invoked before the subclass constructor has run. If the overriding method depends on any initialization performed by the subclass constructor, the method will not behave as expected.


Here's an example to illustrate:


Here, when Base constructor calls overrideMe, Child has not finished initializing the final int x, and the method gets the wrong value. This will almost certainly lead to bugs and errors.


Constructors with many parameters can lead to poor readability, and better alternatives exist.


Here's a quote from Effective Java 2nd Edition, Item 2: Consider a builder pattern when faced with many constructor parameters:


Traditionally, programmers have used the telescoping constructor pattern, in which you provide a constructor with only the required parameters, another with a single optional parameters, a third with two optional parameters, and so on...


The telescoping constructor pattern is essentially something like this:


And now you can do any of the following:


You can't, however, currently set only the name and isAdjustable, and leaving levels at default. You can provide more constructor overloads, but obviously the number would explode as the number of parameters grow, and you may even have multiple boolean and int arguments, which would really make a mess out of things.


As you can see, this isn't a pleasant pattern to write, and even less pleasant to use (What does "true" mean here? What's 13?).


Bloch recommends using a builder pattern, which would allow you to write something like this instead:


Note that now the parameters are named, and you can set them in any order you want, and you can skip the ones that you want to keep at default values. This is certainly much better than telescoping constructors, especially when there's a huge number of parameters that belong to many of the same types.


Here's an example which helps to understand this: 


If you run this code, you get the following output: 


You see? foo() makes use of C before C's constructor has been run. If foo() requires C to have a defined state (i.e. the constructor has finished), then it will encounter an undefined state in C and things might break. And since you can't know in A what the overwritten foo() expects, you get a warning.


Invoking an overridable method in the constructor allows subclasses to subvert the code, so you can't guarantee that it works anymore. That's why you get a warning.


In your example, what happens if a subclass overrides getTitle() and returns null ?


To "fix" this, you can use a factory method instead of a constructor, it's a common pattern of objects instanciation.


If you call methods in your constructor that subclasses override, it means you are less likely to be referencing variables that don’t exist yet if you divide your initialization logically between the constructor and the method.


Have a look on this sample link http://www.javapractices.com/topic/TopicAction.do?Id=215


Here is an example that reveals the logical problems that can occur when calling an overridable method in the super constructor.


The result would actually be:


minWeeklySalary: 0


maxWeeklySalary: 0


This is because the constructor of class B first calls the constructor of class A, where the overridable method inside B gets executed. But inside the method we are using the instance variable factor which has not yet been initialized (because the constructor of A has not yet finished), thus factor is 0 and not 1 and definitely not 2 (the thing that the programmer might think it will be). Imagine how hard would be to track an error if the calculation logic was ten times more twisted. 


I hope that would help someone.


In the specific case of Wicket: This is the very reason why I asked the Wicket 
devs to add support for an explicit two phase component initialization process in the framework's lifecycle of constructing a component i.e. 


There was quite an active debate about whether it was necessary or not (it fully  is necessary IMHO) as this link demonstrates http://apache-wicket.1842946.n4.nabble.com/VOTE-WICKET-3218-Component-onInitialize-is-broken-for-Pages-td3341090i20.html)


The good news is that the excellent devs at Wicket did end up introducing two phase initialization (to make the most aweseome Java UI framework even more awesome!) so with Wicket you can do all your post construction initialization in the onInitialize method that is called by the framework automatically if you override it - at this point in the lifecycle of your component its constructor has completed its work so virtual methods work as expected.


I guess for Wicket it's better to call add method in the onInitialize() (see components lifecycle) :






List your favorite heap analysis tools (e.g. jprofiler, jmap, ...).
Let's keep it one tool per answer, with a short list of pros and cons for each tool.


YourKit : http://www.yourkit.com/


Pros:


Cons:
Of course... it's not free :(


Eclipse Memory analyzer http://www.eclipse.org/mat/


Java VisualVM, jvisualvm, included with the JDK. A pathologic Swing program is examined here.


BHeapSampler http://dr-brenschede.de/bheapsampler/






What are the best practices for using Java's @Override annotation and why?   


It seems like it would be overkill to mark every single overridden method with the @Override annotation.   Are there certain programming situations that call for using the @Override and others that should never use the @Override?   


Use it every time you override a method for two benefits.  Do it so that you can take advantage of the compiler checking to make sure you actually are overriding a method when you think you are.  This way, if you make a common mistake of misspelling a method name or not correctly matching the parameters, you will be warned that you method does not actually override as you think it does.  Secondly, it makes your code easier to understand because it is more obvious when methods are overwritten.


Additionally, in Java 1.6 you can use it to mark when a method implements an interface for the same benefits.  I think it would be better to have a separate annotation (like @Implements), but it's better than nothing.


I think it is most useful as a compile-time reminder that the intention of the method is to override a parent method.  As an example:


You will often see something like the above method that overrides a method in the base class.  This is an important implementation detail of this class -- we don't want sensitive information to be displayed.  


Suppose this method is changed in the parent class to 


This change will not cause any compile time errors or warnings - but it completely changes the intended behavior of the subclass.


To answer your question:  you should use the @Override annotation if the lack of a method with the same signature in a superclass is indicative of a bug.  


There are many good answers here, so let me offer another way to look at it...


There is no overkill when you are coding.  It doesn't cost you anything to type @override, but the savings can be immense if you misspelled a method name or got the signature slightly wrong.


Think about it this way: In the time you navigated here and typed this post, you pretty much used more time than you will spend typing @override for the rest of your life; but one error it prevents can save you hours.


Java does all it can to make sure you didn't make any mistakes at edit/compile time, this is a virtually free way to solve an entire class of mistakes that aren't preventable in any other way outside of comprehensive testing.


Could you come up with a better mechanism in Java to ensure that when the user intended to override a method, he actually did?


Another neat effect is that if you don't provide the annotation it will warn you at compile time that you accidentally overrode a parent method--something that could be significant if you didn't intend to do it.


I always use the tag.  It is a simple compile-time flag to catch little mistakes that I might make.


It will catch things like tostring() instead of toString()


The little things help in large projects.


Using the @Override annotation acts as a compile-time safeguard against a common programming mistake. It will throw a compilation error if you have the annotation on a method you're not actually overriding the superclass method.


The most common case where this is useful is when you are changing a method in the base class to have a different parameter list. A method in a subclass that used to override the superclass method will no longer do so due the changed method signature. This can sometimes cause strange and unexpected behavior, especially when dealing with complex inheritance structures. The @Override annotation safeguards against this.


To take advantage from compiler checking you should always use Override annotation. But don’t forget that Java Compiler 1.5 will not allow this annotation when overriding interface methods. You just can use it to override class methods (abstract, or not).


Some IDEs, as Eclipse, even configured with Java 1.6 runtime or higher, they maintain compliance with Java 1.5 and don’t allow the use @override as described above. To avoid that behaviour you must go to: Project Properties ->Java Compiler -> Check “Enable Project Specific Settings” -> Choose “Compiler Compliance Level” = 6.0, or higher.


I like to use this annotation every time I am overriding a method independently, if the base is an interface, or class. 


This helps you avoiding some typical errors, as when you are thinking that you are overriding an event handler and then you see nothing happening. Imagine you want to add an event listener to some UI component:


The above code compiles and run, but if you move the mouse inside someUIComponent the “do something” code will note run, because actually you are not overriding the base method mouseEntered(MouseEvent ev). You just create a new parameter-less method mouseEntered(). Instead of that code, if you have used the @Override annotation you have seen a compile error and you have not been wasting time thinking why your event handler was not running.


@Override on interface implementation is inconsistent since there is no such thing as "overriding an interface" in java. 


@Override on interface implementation is useless since in practise it catches no bugs that the compilation wouldn't catch anyway. 
There is only one, far fetched scenario where override on implementers actually does something: If you implement an interface, and the interface REMOVES methods, you will be notified on compile time that you should remove the unused implementations. Notice that if the new version of the interface has NEW or CHANGED methods you'll obviously get a compile error anyways as you're not implementing the new stuff.


@Override on interface implementers should never have been permitted in 1.6, and with eclipse sadly choosing to auto-insert the annotations as default behavior, we get a lot of cluttered source files. When reading 1.6 code, you cannot see from the @Override annotation if a method actually overrides a method in the superclass or just implements an interface.


Using @Override when actually overriding a method in a superclass is fine.


Its best to use it for every method intended as an override, and Java 6+, every method intended as an implementation of an interface.


First, it catches misspellings like "hashcode()" instead of "hashCode()" at compile-time. It can be baffling to debug why the result of your method doesn't seem to match your code when the real cause is that your code is never invoked.


Also, if a superclass changes a method signature, overrides of the older signature can be "orphaned", left behind as confusing dead code. The @Override annotation will help you identify these orphans so that they can be modified to match the new signature.


If you find yourself overriding (non-abstract) methods very often, you probably want to take a look at your design. It is very useful when the compiler would not otherwise catch the error. For instance trying to override initValue() in ThreadLocal, which I have done.


Using @Override when implementing interface methods (1.6+ feature) seems a bit overkill for me. If you have loads of methods some of which override and some don't, that probably bad design again (and your editor will probably show which is which if you don't know).


@Override on interfaces actually are helpful, because you will get warnings if you change the interface.


Another thing it does is it makes it more obvious when reading the code that it is changing the behavior of the parent class. Than can help in debugging.


Also, in Joshua Block's book Effective Java (2nd edition), item 36 gives more details on the benefits of the annotation.


It makes absolutely no sense to use @Override when implementing an interface method. There's no advantage to using it in that case--the compiler will already catch your mistake, so it's just unnecessary clutter.


Whenever a method overrides another method, or a method implements a signature in an interface.


The @Override annotation assures you that you did in fact override something. Without the annotation you risk a misspelling or a difference in parameter types and number.


I use it every time. It's more information that I can use to quickly figure out what is going on when I revisit the code in a year and I've forgotten what I was thinking the first time.


The best practive is to always use it (or have the IDE fill them for you)


@Override usefulness is to detect changes in parent classes which has not been reported down the hierarchy.
Without it, you can change a method signature and forget to alter its overrides, with @Override, the compiler will catch it for you.


That kind of safety net is always good to have.


I use it everywhere.
On the topic of the effort for marking methods, I let Eclipse do it for me so, it's no additional effort.


I'm religious about continuous refactoring.... so, I'll use every little thing to make it go more smoothly.


If used consistently, it protects you from a large class of nefarious bugs. 


Use @Override annotation to avoid these bugs:
(Spot the bug in the following code:)


source: Effective Java


Be careful when you use Override, because you can't do reverse engineer in starUML afterwards; make the uml first.


It seems that the wisdom here is changing. Today I installed IntelliJ IDEA 9 and noticed that its "missing @Override inspection" now catches not just implemented abstract methods, but implemented interface methods as well. In my employer's code base and in my own projects, I've long had the habit to only use @Override for the former -- implemented abstract methods. However, rethinking the habit, the merit of using the annotations in both cases becomes clear. Despite being more verbose, it does protect against the fragile base class problem (not as grave as C++-related examples) where the interface method name changes, orphaning the would-be implementing method in a derived class.


Of course, this scenario is mostly hyperbole; the derived class would no longer compile, now lacking an implementation of the renamed interface method, and today one would likely use a Rename Method refactoring operation to address the entire code base en masse.


Given that IDEA's inspection is not configurable to ignore implemented interface methods, today I'll change both my habit and my team's code review criteria.


The annotation @Override is used for helping to check whether the developer what to override the correct method in the parent class or interface. When the name of super's methods changing, the compiler can notify that case, which is only for keep consistency with the super and the subclass. 


BTW, if we didn't announce the annotation @Override in the subclass, but we do override some methods of the super, then the function can work as that one with the @Override. But this method can not notify the developer when the super's method was changed. Because it did not know the developer's purpose -- override super's method or define a new method? 


So when we want to override that method to make use of the Polymorphism, we have better to add @Override above the method. 


I use it as much as can to identify when a method is being overriden.  If you look at the Scala programming language, they also have an override keyword.  I find it useful.


It does allow you (well, the compiler) to catch when you've used the wrong spelling on a method name you are overriding.


Override annotation is used to take advantage of the compiler, for checking whether you actually are overriding a method from parent class. It is used to notify if you make any mistake like mistake of misspelling a method name, mistake of not correctly matching the parameters


i think it's best to code the @override whenever allowed. it helps for coding. however, to be noted, for ecipse Helios, either sdk 5 or 6, the @override annotation for implemented interface methods is allowed. as for Galileo, either 5 or 6, @override annotation is not allowed.


Annotations do provide meta data about the code  to the Compiler and the annotation @Override is used in case of inheritance when we are overriding any method of base class. It just tells the compiler that you are overriding method. It can avoide some kinds common mistakes we can do like not following the proper signature of the method or mispelling in name of the method etc. So its a good practice to use @Override annotation.


For me the @Override ensures me I have the signature of the method correct.  If I put in the annotation and the method is not correctly spelled, then the compiler complains letting me know something is wrong.


Simple–when you want to override a method present in your superclass, use @Override annotation to  make a correct override. The compiler will warn you if you don't override it correctly.






In Swing, the password field has a getPassword() (returns char[]) method instead of the usual getText() (returns String) method. Similarly, I have come across a suggestion not to use String to handle passwords.


Why does String pose a threat to security when it comes to passwords?
It feels inconvenient to use char[].


Strings are immutable. That means once you've created the String, if another process can dump memory, there's no way (aside from reflection) you can get rid of the data before garbage collection kicks in.


With an array, you can explicitly wipe the data after you're done with it. You can overwrite the array with anything you like, and the password won't be present anywhere in the system, even before garbage collection.


So yes, this is a security concern - but even using char[] only reduces the window of opportunity for an attacker, and it's only for this specific type of attack.


As noted in comments, it's possible that arrays being moved by the garbage collector will leave stray copies of the data in memory. I believe this is implementation-specific - the garbage collector may clear all memory as it goes, to avoid this sort of thing. Even if it does, there's still the time during which the char[] contains the actual characters as an attack window.


While other suggestions here seem valid, there is one other good reason. With plain String you have much higher chances of accidentally printing the password to logs, monitors or some other insecure place. char[] is less vulnerable.


Consider this:


Prints:


To quote an official document, the Java Cryptography Architecture guide says this about char[] vs. String passwords (about password-based encryption, but this is more generally about passwords of course):


It would seem logical to collect and store the password in an object
  of type java.lang.String. However, here's the caveat: Objects of
  type String are immutable, i.e., there are no methods defined that
  allow you to change (overwrite) or zero out the contents of a String
  after usage. This feature makes String objects unsuitable for
  storing security sensitive information such as user passwords. You
  should always collect and store security sensitive information in a
  char array instead.


Guideline 2-2 of the Secure Coding Guidelines for the Java Programming Language, Version 4.0 also says something similar (although it is originally in the context of logging):


Guideline 2-2: Do not log highly sensitive information


Some information, such as Social Security numbers (SSNs) and
  passwords, is highly sensitive. This information should not be kept
  for longer than necessary nor where it may be seen, even by
  administrators. For instance, it should not be sent to log files and
  its presence should not be detectable through searches. Some transient
  data may be kept in mutable data structures, such as char arrays, and
  cleared immediately after use. Clearing data structures has reduced
  effectiveness on typical Java runtime systems as objects are moved in
  memory transparently to the programmer.


This guideline also has implications for implementation and use of
  lower-level libraries that do not have semantic knowledge of the data
  they are dealing with. As an example, a low-level string parsing
  library may log the text it works on. An application may parse an SSN
  with the library. This creates a situation where the SSNs are
  available to administrators with access to the log files.


Character arrays (char[]) can be cleared after use by setting each character to zero and Strings not. If someone can somehow see the memory image, they can see a password in plain text if Strings are used, but if char[] is used, after purging data with 0's, the password is secure.


Some people believe that you have to overwrite the memory used to store the password once you no longer need it. This reduces the time window an attacker has to read the password from your system and completely ignores the fact that the attacker already needs enough access to hijack the JVM memory to do this. An attacker with that much access can catch your key events making this completely useless (AFAIK, so please correct me if I am wrong).


Update


Thanks to the comments I have to update my answer. Apparently there are two cases where this can add a (very) minor security improvement as it reduces the time a password could land on the hard drive. Still I think it's overkill for most use cases.


If possible, disabling core dumps and the swap file would take care of both problems. However, they would require administrator rights and may reduce functionality (less memory to use) and pulling RAM from a running system would still be a valid concern.


toString() there is always a risk of printing plain text in log file or console but if use Array you won't print contents of the array instead its memory location get printed. 


String password: passwd


Character password: [C@110b2345


Final thoughts: Though using char[] is not just enough you need to erase content to be more secure. I also suggest working with hashed or encrypted password instead of plain text and clearing it from memory as soon as authentication is completed.


I don't think this is a valid suggestion, but, I can at least guess at the reason.


I think the motivation is wanting to make sure that you can erase all trace of the password in memory promptly and with certainty after it is used. With a char[] you could overwrite each element of the array with a blank or something for sure. You can't edit the internal value of a String that way.


But that alone isn't a good answer; why not just make sure a reference to the char[] or String doesn't escape? Then there's no security issue. But the thing is that String objects can be intern()ed in theory and kept alive inside the constant pool. I suppose using char[] forbids this possibility.


The answer has already been given, but I'd like to share an issue that I discovered lately with Java standard libraries. While they take great care now of replacing password strings with char[] everywhere (which of course is a good thing), other security-critical data seems to be overlooked when it comes to clearing it from memory.


I'm thinking of e.g. the PrivateKey class. Consider a scenario where you would load a private RSA key from a PKCS#12 file, using it to perform some operation. Now in this case, sniffing the password alone wouldn't help you much as long as physical access to the key file is properly restricted. As an attacker, you would be much better off if you obtained the key directly instead of the password. The desired information can be leaked manifold, core dumps, a debugger session or swap files are just some examples.


And as it turns out, there is nothing that lets you clear the private information of a PrivateKey from memory, because there's no API that lets you wipe the bytes that form the corresponding information.


This is a bad situation, as this paper describes how this circumstance could be potentially exploited.


The OpenSSL library for example overwrites critical memory sections before private keys are freed. Since Java is garbage-collected, we would need explicit methods to wipe and invalidate private information for Java keys, which are to be applied immediately after using the key. 


As Jon Skeet states, there is no way except by using reflection. 


However, if reflection is an option for you, you can do this.


when run


Note: if the String's char[] has been copied as a part of a GC cycle, there is a chance the previous copy is somewhere in memory.  


This old copy wouldn't appear in a heap dump, but if you have direct access to the raw memory of the process you could see it.  In general you should avoid anyone having such access.


These are all the reasons, one should choose char[] array instead of String for password.


1.  Since Strings are immutable in Java if you store password as plain text it will be available in memory until Garbage collector clears it and since String are used in String pool for reusability there is pretty high chance that it will be remain in memory for long duration, which pose a security threat. Since any one who has access to memory dump can find the password in clear text and that's another reason you should always used an encrypted password than plain text. Since Strings are immutable there is no way contents of Strings can be changed because any change will produce new String, while if you char[] you can still set all his element as blank or zero. So Storing password in character array clearly mitigates security risk of stealing password.


2.  Java itself recommends using getPassword() method of JPasswordField which returns a char[] and deprecated getText() method which returns password in clear text stating security reason. Its good to follow advice from Java team and adhering to standard rather than going against it.


3.  With String there is always a risk of printing plain text in log file or console but if use Array you won't print contents of array instead its memory location get printed. though not a real reason but still make sense.


Reference from:  http://javarevisited.blogspot.com/2012/03/why-character-array-is-better-than.html
Hope this helps.


Edit: Coming back to this answer after a year of security research, I realize it makes the rather unfortunate implication that you would ever actually compare plaintext passwords. Please don't. Use a secure one-way hash with a salt and a reasonable number of iterations. Consider using a library: this stuff is hard to get right!


Original answer: What about the fact that String.equals() uses short-circuit evaluation, and is therefore vulnerable to a timing attack? It may be unlikely, but you could theoretically time the password comparison in order to determine the correct sequence of characters.


Some more resources on timing attacks:


There is nothing that char array gives you vs String unless you clean it up manually after use, and I haven't seen anyone actually doing that. So to me the preference of char[] vs String is a little exaggerated.


Take a look at the widely used Spring Security library here and ask yourself - are Spring Security guys incompetent or char[] passwords just don't make much sense. When some nasty hacker grabs memory dumps of your RAM be sure she'll get all the passwords even if you use sophisticated ways to hide them.


However, Java changes all the time, and some scary features like String Deduplication feature of Java 8 might intern String objects without your knowledge. But that's different conversation.


Strings are immutable and cannot be altered once they have been created. Creating a password as a string will leave stray references to the password on the heap or on the String pool. Now if someone takes a heap dump of the Java process and carefully scans through he might be able to guess the passwords. Of course these non used strings will be garbage collected but that depends on when the GC kicks in.


On the other side char[] are mutable as soon as the authentication is done you can overwrite them with any character like all M's or backslashes. Now even if someone takes a heap dump he might not be able to get the passwords which are not currently in use. This gives you more control in the sense like clearing the Object content yourself vs waiting for the GC to do it.


Simple and short answer would be because char[] are mutable while String objects are not.


Strings in Java are immutable objects. That is why they can't be modified once created, and therefore the only way for their contents to be removed from memory is to have them garbage collected. It will be only then, when the memory freed by the object can be overwritten and the data will be gone.


Now garbage collection in Java doesn't happen at any kind of guaranteed interval. The String can thus persist in memory for a long time, and if a process crashes during this time, the contents of the string may end up in a memory dump or some log. 


With a character array, you can read the password, finish working with it as soon as you can, and then immediately change the contents.


String in java is immutable. So whenever a string is created, it will remain in the memory until it is garbage collected. So anyone who has access to the memory can read the value of the string. 
If the value of the string is modified then it will end up creating a new string. So both the original value and the modified value stay in the memory until it is garbage collected.  
With the character array, the contents of the array can be modified or erased once the purpose of the password is served. The original contents of the array will not be found in memory after it is modified and even before the garbage collection kicks in.
Because of the security concern it is better to store password as a character array.


1) Since Strings are immutable in Java if you store password as plain text it will be available in memory until Garbage collector clears it and since String are used in String pool for reusability there is pretty high chance that it will be remain in memory for long duration, which pose a security threat. Since any one who has access to memory dump can find the password in clear text and that's another reason you should always used an encrypted password than plain text. Since Strings are immutable there is no way contents of Strings can be changed because any change will produce new String, while if you char[] you can still set all his element as blank or zero. So Storing password in character array clearly mitigates security risk of stealing password.


2) Java itself recommends using getPassword() method of JPasswordField which returns a char[] and deprecated getText() method which returns password in clear text stating security reason. Its good to follow advice from Java team and adhering to standard rather than going against it.






I have a JPanel with a painted background image and a layout manager holding other smaller images, all of this inside a JFrame. The background image is pretty big and I want to be able to have it maintain its aspect ratio whether its on a big or small monitor. 


Eventually, I want to be able to have my LayoutManager and the smaller images in its cells "glued" to the background picture.


I looked around for resources and it seems that many examples use a BufferedImage but I am not; will this pose a problem? I'll post my code below for painting the image, If I lack any information please let me know.


EDIT: I should mention that I know the aspect ratio formula:
 original height / original width x new width = new height
However, I do not know how to use that correctly to my advantage.


Well, the quickest and easiest solution is to use Image.getScaledInstance


If your wondering about the negative number, the java docs say:


If either width or height is a negative number then a value is
  substituted to maintain the aspect ratio of the original image
  dimensions. If both width and height are negative, then the original
  image dimensions are used.


UPDATE


Just as a side note (my Google was playing up).


getScaledInstance is neither the fastest or highest quality approach, but it is the easiest.


Take a read through The Perils of Image.getScaledInstance for some more ideas


UPDATE


Scaling an image to fit an area is slightly more complicated then simply scaling the aspect ratio.  You have to make a choice over if you want the image to "fit" within the area (possibly leaving blank areas around it) or over "fill" the area (so that it's smallest dimension fits the largest dimension of the area).





Fit & Fill


Basically, I work with scale factors


This returns the scaling factor for a particular size.  I use this to make decisions about which factor I want to use based which algorithm I need


It's used by these two methods.  They simply take two Dimensions.  The original and the target.


It's relatively simple to pass an image into (either directly or via a support method).  So for example, you could call this from within your paint method


This will automatically take care of the aspect ratio for you ;)


UPDATED with expanded example


Try something like this:


which will ultimately scale the image to the JPanel's size by using getScaledInstance(int width, int height, ImageObserver io)


For anyone interested ammending the PaintComponent method by MadProgrammer as follows allows much quicker display update


I came up with this solution:






I am learning GoF Java Design Patterns and I want to see some real life examples of them. What are some good examples of these Design Patterns in Java's core libraries?


You can find an overview of a lot of design patterns in Wikipedia. It also mentions which patterns are mentioned by GoF. I'll sum them up here and try to assign as many pattern implementations as possible, found in both the Java SE and Java EE APIs.


and many more I guess


RMI is based on Proxy.


Should be possible to cite one for most of the 23 patterns in GoF:


I can't think of examples in Java for 10 out of the 23, but I'll see if I can do better tomorrow.  That's what edit is for.


The Abstract Factory pattern is used in various places. 
E.g., DatagramSocketImplFactory, PreferencesFactory. There are many more---search the Javadoc for interfaces which have the word "Factory" in their name.


Also there are quite a few instances of the Factory pattern, too.


Even though I'm sort of a broken clock with this one, Java XML API uses Factory a lot. I mean just look at this:


...and so on and so forth.


Additionally various Buffers (StringBuffer, ByteBuffer, StringBuilder) use Builder.


java.util.Collection#Iterator is a good example of a Factory Method. Depending on the concrete subclass of Collection you use, it will create an Iterator implementation. Because both the Factory superclass (Collection) and the Iterator created are interfaces, it is sometimes confused with AbstractFactory. Most of the examples for AbstractFactory in the the accepted answer (BalusC) are examples of Factory, a simplified version of Factory Method, which is not part of the original GoF patterns. In Facory the Factory class hierarchy is collapsed and the factory uses other means to choose the product to be returned.


An abstract factory has multiple factory methods, each creating a different product. The products produced by one factory are intended to be used together (your printer and cartridges better be from the same (abstract) factory). As mentioned in answers above the families of AWT GUI components, differing from platform to platform, are an example of this (although its implementation differs from the structure described in Gof).






There is an online file (such as http://www.example.com/information.asp) I need to grab and save to a directory. I know there are several methods for grabbing and reading online files (URLs) line-by-line, but is there a way to just download and save the file using Java?


Give a try to Java NIO:


Using transferFrom() is potentially much more efficient than a simple loop that reads from the source channel and writes to this channel. Many operating systems can transfer bytes directly from the source channel into the filesystem cache without actually copying them.


Check more about it here.


Note: The third parameter in transferFrom is the maximum number of bytes to transfer.  Integer.MAX_VALUE will transfer at most 2^31 bytes, Long.MAX_VALUE will allow at most 2^63 bytes (larger than any file in existence). 


Use apache commons-io, just one line code:


Simpler nio usage:


You'll need to handle exceptions, probably external to this method.


Downloading a file requires you to read it, either way you will have to go through the file in some way.  Instead of line by line, you can just read it by bytes from the stream:


When using Java 7+ use the following method to download a file from the Internet and save it to some directory:


Documentation here.


This answer is almost exactly like selected answer but with two enhancements:  it's a method and it closes out the FileOutputStream object:


Personally, I've found Apache's HttpClient to be more than capable of everything I've needed to do with regards to this.  Here is a great tutorial on using HttpClient


This is another java7 variant based on Brian Risk's answer with usage of try-with statement:


There are many elegant and efficient answers here. But the conciseness can make us lose some useful information. In particular, one often does not want to consider a connection error an Exception, and one might want to treat differently some kind of network-related errors - for example, to decide if we should retry the download.


Here's a method that does not throw Exceptions for network errors (only for truly exceptional problems, as malformed url or problems writing to the file)


There is an issue with simple usage of:


if you need to download and save very large files, or in general if you need automatic retries in case connection is dropped.


What I suggest in such cases is Apache HttpClient along with org.apache.commons.io.FileUtils. For example:


It's possible to download the file with with Apache's HttpComponents instead of Commons-IO. This code allows you to download a file in Java according to its URL and save it at the specific destination.


In contrast to the single line of code:


this code will give you more control over a process and let you specify not only time outs but User-Agent and Referer values, which are critical for many web-sites.


To summarize (and somehow polish and update) previous answers. The three following methods are practically equivalent. (I added explicit timeouts because I think they are a must, nobody wants a download to freeze forever when the connection is lost.)


I don't find significant differences, all seem right to me. They are safe and efficient. (Differences in speed seem hardly relevant - I write 180Mb from local server to a SSD disk in times that fluctuate around 1.2 to 1.5 segs). They don't require external libraries. All work with arbitrary sizes and (to my experience) HTTP redirections.


Additionally, all throw FileNotFoundException if the resource is not found (error 404, typically), and java.net.UnknownHostException if the DNS resolution failed; other IOException correspond to errors during transmission.


(Marked as community wiki, feel free to add info or corrections)


You can do this in 1 line using netloader for Java:


There is method $.fetch() in underscore-lodash library.


pom.xml:


Code example:






What is the difference between these two following statements?


new String("text");
explicitly creates a new and referentially distinct instance of a String object; String s = "text"; may reuse an instance from the string constant pool if one is available.


You very rarely would ever want to use the new String(anotherString) constructor. From the API:


String(String original) : Initializes a newly created String object so that it represents the same sequence of characters as the argument; in other words, the newly created string is a copy of the argument string. Unless an explicit copy of original is needed, use of this constructor is unnecessary since strings are immutable. 


Examine the following snippet:


== on two reference types is a reference identity comparison. Two objects that are equals are not necessarily ==. It is usually wrong to use == on reference types; most of the time equals need to be used instead.


Nonetheless, if for whatever reason you need to create two equals but not == string, you can use the new String(anotherString) constructor. It needs to be said again, however, that this is very peculiar, and is rarely the intention.


String literals will go into String Constant Pool.


The below snapshot might help you to understand it visually to remember it for longer time.





Object creation line by line:


Using string literal "java5" in the constructor, an new string value is stored in string constant pool
Using new operator a new string object is created in the heap with "java5" as value


Reference "str2" is pointed to already stored value in string constant pool


A new string object is created in the heap with the same value as reference by "str2"


Reference "str4" is pointed to already stored value in string constant pool


Total objects : Heap - 2, Pool - 1


Further reading on Oracle community


One creates a String in the String Constant Pool


the other one creates a string in the constant pool ("text") and another string in normal heap space (s). Both strings will have the same value, that of "text".


s is then lost (eligible for GC) if later unused. 


String literals on the other hand are reused. If you use "text" in multiple places of your class it will in fact be one and only one String (i.e. multiple references to the same string in the pool).


The concept is called "interning" by the JLS. 


Relevant passage from JLS 7 3.10.5:


Moreover, a string literal always refers to the same instance of class String. This is because string literals - or, more generally, strings that are the values of constant expressions (§15.28) - are "interned" so as to share unique instances, using the method String.intern.


Example 3.10.5-1. String Literals


The program consisting of the compilation unit (§7.3): 


and the compilation unit:


produces the output:


JVMS 7 5.1 says:


A string literal is a reference to an instance of class String, and is derived from a CONSTANT_String_info structure (§4.4.3) in the binary representation of a class or interface. The CONSTANT_String_info structure gives the sequence of Unicode code points constituting the string literal.


The Java programming language requires that identical string literals (that is, literals that contain the same sequence of code points) must refer to the same instance of class String (JLS §3.10.5). In addition, if the method String.intern is called on any string, the result is a reference to the same class instance that would be returned if that string appeared as a literal. Thus, the following expression must have the value true:


To derive a string literal, the Java Virtual Machine examines the sequence of code points given by the CONSTANT_String_info structure.


If the method String.intern has previously been called on an instance of class String containing a sequence of Unicode code points identical to that given by the CONSTANT_String_info structure, then the result of string literal derivation is a reference to that same instance of class String.


Otherwise, a new instance of class String is created containing the sequence of Unicode code points given by the CONSTANT_String_info structure; a reference to that class instance is the result of string literal derivation. Finally, the intern method of the new String instance is invoked.


It is also instructive to look at the bytecode implementation on OpenJDK 7.


If we decompile:


we have on the constant pool:


and main:


Note how:


The representation of constant strings is quite magic on the bytecode:


and the JVMS quote above seems to say that whenever the Utf8 pointed to is the same, then identical instances are loaded by ldc.


I have done similar tests for fields, and:


Conclusion: there is direct bytecode support for the string pool, and the memory representation is efficient.


Bonus: compare that to the Integer pool, which does not have direct bytecode support (i.e. no CONSTANT_String_info analogue).


Think of "bla" being a magic factory like Strings.createString("bla") (pseudo). The factory holds a pool of all strings yet created this way. 


If it gets invoked, it checks if there is already string in the pool with this value. If true, it returns this string object, hence to strings obtained this way are indeed the same object.


If not, it creates a new string object internally, saves it in the pool and then returns it. Thus, when the same string value is queried the next time, it returns the same instance.


Manually creating new String("") overrides this behaviour by bypassing the string literal pool. So equality should always be checked using equals() which compares the character sequence instead of the object reference equality.


One simple way to understand the difference is below:-


output is 


Thus new String() will always create a new instance.


Although it looks the same from a programmers point of view, it has big performance impact. You would want to use the first form almost always.


It will check whether String constant pool already contains String "hello"? 
If  present then it will not add an entry in String constant pool. If not present then it will add an entry in String constant pool. 


An object will be created in a heap memory area and str reference points to object created in heap memory location.


if you want str reference to point object containing in String constant pool then one has to explicitly call str.intern(); 


It will check whether String constant pool already contains String "hello"? 
If  present then it will not add an entry in String constant pool. If not present then it will add an entry in String constant pool.


In both the above case, str reference points to String "world" present in Constant pool. 


@Braj : i think u have mentioned the other way around. Please correct me if i am wrong


Object creation line by line:


String str1 = new String("java5")   


String str2 = "java5"


String str3 = new String(str2)


String str4 = "java5"






I've a String representing a date.


I'd like to convert it to a Date and output it in YYYY-MM-DD format.


2011-01-18


How can I achieve this?


Okay, based on the answers I retrieved below, here's something I've tried:


But it outputs 02011-00-1 instead of the desired 2011-01-18. What am I doing wrong?


Use LocalDateTime#parse() (or ZonedDateTime#parse() if the string happens to contain a time zone part) to parse a String in a certain pattern into a LocalDateTime.


Use LocalDateTime#format() (or ZonedDateTime#format()) to format a LocalDateTime into a String in a certain pattern.


Or, when you're not on Java 8 yet, use SimpleDateFormat#parse() to parse a String in a certain pattern into a Date.


Use SimpleDateFormat#format() to format a Date into a String in a certain pattern.


Update: as per your failed attempt: the patterns are case sensitive. Read the java.text.SimpleDateFormat javadoc what the individual parts stands for. So stands for example M for months and m for minutes. Also, years exist of four digits yyyy, not five yyyyy. Look closer at the code snippets I posted here above.


Formatting are CASE-SENSITIVE so USE MM for month not mm (this is for minute) and yyyy 
For Reference you can use following cheatsheet.


Examples:


The answer is of course to create a SimpleDateFormat object and use it to parse Strings to Date and to format Dates to Strings.  If you've tried SimpleDateFormat and it didn't work, then please show your code and any errors you may receive.


Addendum:  "mm" in the format String is not the same as "MM".  Use MM for months and mm for minutes. Also, yyyyy is not the same as yyyy.  e.g.,:


Using the java.time package in Java 8 and later:


Why not simply use this


Also, this is the other way :


or 


Cheers!


[edited to include BalusC's corrections]
The SimpleDateFormat class should do the trick:


Please refer "Date and Time Patterns" here. http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html 


Other answers are correct, basically you had the wrong number of "y" characters in your pattern.


One more problem though… You did not address time zones. If you intended UTC, then you should have said so. If not, the answers are not complete. If all you want is the date portion without the time, then no issue. But if you do further work that may involve time, then you should be specifying a time zone.


Here is the same kind of code but using the third-party open-source Joda-Time 2.3 library


When run…


You can also use substring()


If you want a space in front of the date, use


You can just use:


It works perfectly!


remove one y form SimpleDateFormat dt1 = new SimpleDateFormat("yyyyy-mm-dd"); should be SimpleDateFormat dt1 = new SimpleDateFormat("yyyy-mm-dd");


You could try java 8 new date, more information can be found on the oracle documentation.    


Or you can try the old one 






How are JSP and Servlet related to each other? Is JSP some kind of Servlet? How are JSP and JSF related to each other? Is JSF some kind of prebuild UI based JSP like ASP.NET-MVC?


JSP is a Java view technology running on the server machine which allows you to write template text in client side languages (like HTML, CSS, JavaScript, ect.). JSP supports taglibs, which are backed by pieces of Java code that let you control the page flow or output dynamically. A well-known taglib is JSTL. JSP also supports Expression Language, which can be used to access backend data (via attributes available in the page, request, session and application scopes), mostly in combination with taglibs.


When a JSP is requested for the first time or when the web app starts up, the servlet container will compile it into a class extending HttpServlet and use it during the web app's lifetime. You can find the generated source code in the server's work directory. In for example Tomcat, it's the /work directory. On a JSP request, the servlet container will execute the compiled JSP class and send the generated output (usually just HTML/CSS/JS) through the web server over a network to the client side, which in turn displays it in the web browser.


Servlet is a Java application programming interface (API) running on the server machine, which intercepts requests made by the client and generates/sends a response. A well-known example is the HttpServlet which provides methods to hook on HTTP requests using the popular HTTP methods such as GET and POST. You can configure HttpServlets to listen to a certain HTTP URL pattern, which is configurable in web.xml, or more recently with Java EE 6, with @WebServlet annotation.


When a Servlet is first requested or during web app startup, the servlet container will create an instance of it and keep it in memory during the web app's lifetime. The same instance will be reused for every incoming request whose URL matches the servlet's URL pattern. You can access the request data by HttpServletRequest and handle the response by HttpServletResponse. Both objects are available as method arguments inside any of the overridden methods of HttpServlet, such as doGet() and doPost().


JSF is a component based MVC framework which is built on top of the Servlet API and provides components via taglibs which can be used in JSP or any other Java based view technology such as Facelets. Facelets is much more suited to JSF than JSP. It namely provides great templating capabilities such as composite components, while JSP basically only offers the <jsp:include> for templating, so that you're forced to create custom components with raw Java code (which is a bit opaque and a lot of tedious work in JSF) when you want to replace a repeated group of components with a single component. Since JSF 2.0, JSP has been deprecated as view technology in favor of Facelets.


As being a MVC (Model-View-Controller) framework, JSF provides the FacesServlet as the sole request-response Controller. It takes all the standard and tedious HTTP request/response work from your hands, such as gathering user input, validating/converting them, putting them in model objects, invoking actions and rendering the response. This way you end up with basically a JSP or Facelets (XHTML) page for View and a JavaBean class as Model. The JSF components are used to bind the view with the model (such as your ASP.NET web control does) and the FacesServlet uses the JSF component tree to do all the work.


See http://www.oracle.com/technetwork/java/faq-137059.html


JSP technology is part of the Java
  technology family. JSP pages are
  compiled into servlets and may call
  JavaBeans components (beans) or
  Enterprise JavaBeans components
  (enterprise beans) to perform
  processing on the server. As such, JSP
  technology is a key component in a
  highly scalable architecture for
  web-based applications.


See https://jcp.org/en/introduction/faq


A: JavaServer Faces technology is a
  framework for building user interfaces
  for web applications. JavaServer Faces
  technology includes:


A set of APIs for: representing UI
  components and managing their state,
  handling events and input validation,
  defining page navigation, and
  supporting internationalization and
  accessibility.


A JavaServer Pages (JSP) custom tag
  library for expressing a JavaServer
  Faces interface within a JSP page.


JSP is a specialized kind of servlet.


JSF is a set of tags you can use with JSP.


From Browser/Client perspective


JSP and JSF both looks same, As Per Application Requirements goes, JSP is more suited for request - response based applications. 


JSF is targetted for richer event based Web applications. I see event as much more granular than request/response. 


From Server Perspective


JSP page is converted to servlet, and it has only minimal behaviour.


JSF page is converted to components tree(by specialized FacesServlet) and it follows component lifecycle defined by spec. 


Servlets : 


The Java Servlet API enables Java developers to write server-side code
  for delivering dynamic Web content. Like other proprietary Web server
  APIs, the Java Servlet API offered improved performance over CGI;
  however, it has some key additional advantages. Because servlets were
  coded in Java, they provides an object-oriented (OO) design approach
  and, more important, are able to run on any platform. Thus, the same
  code was portable to any host that supported Java. Servlets greatly
  contributed to the popularity of Java, as it became a widely used
  technology for server-side Web application development.


JSP :


JSP is built on top of servlets and provides a simpler, page-based
  solution to generating large amounts of dynamic HTML content for Web
  user interfaces. JavaServer Pages enables Web developers and designers
  to simply edit HTML pages with special tags for the dynamic, Java
  portions. JavaServer Pages works by having a special servlet known as
  a JSP container, which is installed on a Web server and handles all
  JSP page view requests.      The JSP container translates a requested
  JSP into servlet code that is then compiled and immediately executed.
  Subsequent requests to the same page simply invoke the runtime servlet
  for the page. If a change is made to the JSP on the server, a request
  to view it triggers another translation, compilation, and restart of
  the runtime servlet.


JSF : 


JavaServer Faces is a standard Java framework for building user
  interfaces for Web applications. Most important, it simplifies the
  development of the user interface, which is often one of the more
  difficult and tedious parts of Web application development.
  Although it is possible to build user interfaces by using foundational
  Java Web technologies(such as Java servlets and JavaServer Pages)
  without a comprehensive framework designedfor enterprise Web
  application development, these core technologies can often lead to
  avariety of development and maintenance problems. More important, by
  the time the developers achieve a production-quality solution, the
  same set of problems solved by JSF will have been solved in a
  nonstandard manner.       JavaServer Faces is designed to simplify the
  development of user interfaces for Java Web applications in the
  following ways:
  • It provides a component-centric,
  client-independent development approach to building Web user
  interfaces, thus improving developer productivity and ease of use.
  • It simplifies the access and management of application data from the
  Web user interface.
  • It automatically manages the user interface
  state between multiple requests and multiple clients in a simple and
  unobtrusive manner.
  • It supplies a development framework that is
  friendly to a diverse developer audience with different skill sets.
  • It describes a standard set of architectural patterns for a web
  application.


[ Source : Complete reference:JSF ]


There are also situations where you can favor JSP over JSF. The application nature should be the deciding factor to choose the technology. 


If you have a rich GUI interaction and lot of Java scripting needed then favor JSF. Basically if your GUI app architecture is like Component oriented & even driven like Swing then JSF is the best.


If the application is just a plain form submitting, not much of GUI interaction needed, then JSP could do well if learning a new tech is an overhead and also complex framework is unnecessary.


Servlet - it's java server side layer.


that is true that JSP is converted into servlet at the time of execution, and JSF is totally new thing in order to make the webpage more readable as JSF allows to write all the programming structures in the form of tag.


The basic difference between Servlets and JSP is that in Servlets we write java code and in that we embed HTML code and there is just reverse case with JSP .
In JSP we write HTML code and in that we embed java code using tags provided by JSP.


Java Server Pages (JSP) is java technology which enables Web developers and designers to rapidly develop and easily maintain, information-rich, dynamic Web pages that leverage existing business systems.  JSP technology separates the user interface from content generation, enabling designers to change the overall page layout without altering the underlying dynamic content.


Facelets is the first non JSP page declaration language designed for JSF (Java Server Faces) which provided a simpler and more powerful programming model to JSF developers as compare to JSP. It resolves different issues occurs in JSP for web applications development. 


Here is a table that compares the features of scriplets and facelets:



Source


JSF is a web application that is used to simplify development integration of web based user interfaces; JSP is a Java based technology used specifically in order to help software developers create dynamic web pages.


JSF contains multiple core features, including, but not limited to, Managed Beans, a template based component system, and two XML based tag libraries; JSP must be compiled in Java bytecode in order to function properly.


JSF is an advanced framework wherein its very easy to implement Model-View-Controller (MVC) based architecture for projects. Main advantage of JSF over JSP is the easy dynamic rendering of the components on the browser based upon conditions and easy integration of ajax events.


The front end of the JSF application i.e. xhtml files are the ones which are shown to the user via browser. These xhtml files internally invoke managed beans e.g. controllers wherein actual application logic is written.


The controllers internally invoke various services which communicate with database (using Hibernate or JPA API). This is how the flow happens in short.


JSF is also used in combination with RichFaces which is a framework for giving rich look and feel to your web application. 


JSF + RichFaces + Hibernate/JPA is a good technology to learn for sure !


Jsp is also having in built servlet code which don't need any external compilation it can be run directly run. Changes will take effect in jsp directly in a browser.


Servlet need to be compiled (i.e it will have specific class creation)


Jsf is a view component of MVC Framework


JSP stands for JAVA SERVER PAGE........ 
jsp is not a servlet.
Jsp uses code and HTML tag both in itself you dont need to make a HTML and a servlet seprately.Jsp are playing magnificent role in web application.
Servlet is a java class plays an role to make your HTML page from static to dynamic .


JSPs are the View component of MVC (Model View Controller).  The Controller takes the incoming request and passes it to the Model, which might be a bean that does some database access.  The JSP then formats the output using HTML, CSS and JavaScript, and the output then gets sent back to the requester.


JSP have it's own life cycle
jsp_init()
jsp_service()
jsp_destroy


After first request JSP convert to .java file. There is three type of tag we are using
1.)Scriptless


Here developer can declare all those things which developer want to take the data  


2.)Expression tag


Here developer can use some print related data


3.)Declaration


Here developer can declare some method related data.


Servlet have it's own life cycle.


After first request container will read the data from web.xml file
then after out welcome fill will be display.
Now onward after performing action it will search the url and after this process it will search the particular servlet there it self. service operation will perform.


JSF have it's own ui and it's life cycle can perform in six way,


For ui here for table here we are using panel grid and there is different faces for this that is.






For this code block:


the value of d is 0.0. It can be forced to work by casting:


But is there another way to get the correct double result? I don't like casting primitives, who knows what may happen.


That avoids a cast.  But you'll find that the cast conversions are well-defined.  You don't have to guess, just check the JLS.  int to double is a widening conversion.  From §5.1.2:


Widening primitive conversions do not
  lose information about the overall
  magnitude of a numeric value.


[...]


Conversion of an int or a long value
  to float, or of a long value to
  double, may result in loss of
  precision-that is, the result may lose
  some of the least significant bits of
  the value. In this case, the resulting
  floating-point value will be a
  correctly rounded version of the
  integer value, using IEEE 754
  round-to-nearest mode (§4.2.4).


5 can be expressed exactly as a double.


What's wrong with casting primitives?


If you don't want to cast for some reason, you could do


I don't like casting primitives, who knows what may happen.


Why do you have an irrational fear of casting primitives? Nothing bad will happen when you cast an int to a double. If you're just not sure of how it works, look it up in the Java Language Specification. Casting an int to double is a widening primitive conversion.


You can get rid of the extra pair of parentheses by casting the denominator instead of the numerator:


If you change the type of one the variables you have to remember to sneak in a double again if your formula changes, because if this variable stops being part of the calculation the result is messed up. I make a habit of casting within the calculation, and add a comment next to it.


Note that casting the result won't do it


Cast one of the integers/both of the integer to float to force the operation to be done with floating point Math. Otherwise integer Math is always preferred. So:


Note that casting the result won't do it. Because first division is done as per precedence rule.


I do not think there is any problem with casting as such you are thinking about.


Producing a double from integer division- there is no other way without casting (may be you will not do it explicitly but it will happen).


Now, there are several ways we can try to get precise double value (where num and denom are int type, and of-course with casting)-


with explicit casting:


but not double d = (double) (num / denom);


with implicit casting:


but not double d = num / denom * 1.0;
and not double d = 0.0 + ( num / denom ); 


use something like:


(1d is a cast to double)


You might consider wrapping the operations. For example:


This allows you to look up (just once) whether the cast does exactly what you want. This method could also be subject to tests, to ensure that it continues to do what you want. It also doesn't matter what trick you use to cause the division (you could use any of the answers here), as long as it results in the correct result. Anywhere you need to divide two integers, you can now just call Utils::divide and trust that it does the right thing.


just use this.


Best way to do this is






What's the difference between JavaScript and Java?


Java and Javascript are similar like Car and Carpet are similar.


One is essentially a toy, designed for writing small pieces of code, and traditionally used and abused by inexperienced programmers.


The other is a scripting language for web browsers.


Here are some differences between the two languages:


Here are some features that I think are particular strengths of JavaScript:


Take a look at the Wikipedia link 


JavaScript, despite the name, is essentially unrelated to the Java programming language, although both have the common C syntax, and JavaScript copies many Java names and naming conventions. The language was originally named "LiveScript" but was renamed in a co-marketing deal between Netscape and Sun, in exchange for Netscape bundling Sun's Java runtime with their then-dominant browser. The key design principles within JavaScript are inherited from the Self and Scheme programming languages.


Everything.


JavaScript was named this way by Netscape to confuse the unwary into thinking it had something to do with Java, the buzzword of the day, and it succeeded.


The two languages are entirely distinct.



Java is to JavaScript as ham is to hamster


JavaScript is an object-oriented scripting language that allows you to create dynamic HTML pages, allowing you to process input data and maintain data, usually within the browser.


Java is a programming language, core set of libraries, and virtual machine platform that allows you to create compiled programs that run on nearly every platform, without distribution of source code in its raw form or recompilation.


While the two have similar names, they are really two completely different programming languages/models/platforms, and are used to solve completely different sets of problems.


Also, this is directly from the Wikipedia Javascript article:


A common misconception is that JavaScript is similar or closely related to Java; this is not so. Both have a C-like syntax, are object-oriented, are typically sandboxed and are widely used in client-side Web applications, but the similarities end there. Java has static typing; JavaScript's typing is dynamic (meaning a variable can hold an object of any type and cannot be restricted). Java is loaded from compiled bytecode; JavaScript is loaded as human-readable code. C is their last common ancestor language.


In addittion to being entirely different languages, in my experience:


(But this may just have more to do with my preference of functional programming over OO programming... ;)


Everything.  They're unrelated languages.


They are independent languages with unrelated lineages. Brendan Eich created Javascript originally at Netscape. It was initially called Mocha. The choice of Javascript as a name was a nod, if you will, to the then ascendant Java programming language, developed at Sun by Patrick Naughton, James Gosling, et. al.


Like everybody's saying, they're pretty much entirely different.


However, if you need a scripting language for your Java application, Javascript is actually a really good choice.  There are ways to get Javascript running in the JVM and you can access and manipulate Java classes pretty seamlessly once you do. 


They have nothing to do with each other.


Java is statically typed, compiles, runs on its own VM.


Javascript is dynamically typed, interpreted, and runs in a browser. It also has first-class functions and anonymous functions, which Java does not. It has direct access to web-page elements, which makes it useful for doing client-side processing.


They are also somewhat similar in syntax, but that's about it.


Don't be confused with name..
Java was created at Sun Microsystems (now Oracle).
But, JavaScript was created at Netscape (now Mozilla) in the early days of the Web, and technically, “Java-Script” is a trademark licensed from Sun Microsystems used to describe
Netscape’s implementation of the language. Netscape submitted the
language for standardization to ECMA (European Computer Manufacturer’s Association)
and because of trademark issues, the standardized version of the language
was stuck with the awkward name “ECMAScript.” For the same trademark reasons,
Microsoft’s version of the language is formally known as “JScript.” In practice, just
about everyone calls the language JavaScript. The real name is “ECMAScript”.  


Both are fully different languages!!!


Practically every PC in the world sells with at least one JavaScript interpreter installed on it.


Most (but not "practically all") PCs have a Java VM installed.


A Re-Introduction to Javascript by the Mozilla team (they make Firefox) should explain it.






My code runs inside a JAR file, say foo.jar, and I need to know, in the code, in which folder the running foo.jar is.


So, if foo.jar is in C:\FOO\, I want to get that path no matter what my current working directory is.


Obviously, this will do odd things if your class was loaded from a non-file location.


Best solution for me:


This should solve the problem with spaces and special characters.


To obtain the File for a given Class, there are two steps:


It is important to understand both steps, and not conflate them.


Once you have the File, you can call getParentFile to get the containing folder, if that is what you need.


As discussed in other answers, there are two major ways to find a URL relevant to a Class.


URL url = Bar.class.getProtectionDomain().getCodeSource().getLocation();


URL url = Bar.class.getResource(Bar.class.getSimpleName() + ".class");


Both have pros and cons.


The getProtectionDomain approach yields the base location of the class (e.g., the containing JAR file). However, it is possible that the Java runtime's security policy will throw SecurityException when calling getProtectionDomain(), so if your application needs to run in a variety of environments, it is best to test in all of them.


The getResource approach yields the full URL resource path of the class, from which you will need to perform additional string manipulation. It may be a file: path, but it could also be jar:file: or even something nastier like bundleresource://346.fwk2106232034:4/foo/Bar.class when executing within an OSGi framework. Conversely, the getProtectionDomain approach correctly yields a file: URL even from within OSGi.


Note that both getResource("") and getResource(".") failed in my tests, when the class resided within a JAR file; both invocations returned null. So I recommend the #2 invocation shown above instead, as it seems safer.


Either way, once you have a URL, the next step is convert to a File. This is its own challenge; see Kohsuke Kawaguchi's blog post about it for full details, but in short, you can use new File(url.toURI()) as long as the URL is completely well-formed.


Lastly, I would highly discourage using URLDecoder. Some characters of the URL, : and / in particular, are not valid URL-encoded characters. From the URLDecoder Javadoc:


It is assumed that all characters in the encoded string are one of the following: "a" through "z", "A" through "Z", "0" through "9", and "-", "_", ".", and "*". The character "%" is allowed but is interpreted as the start of a special escaped sequence.


...


There are two possible ways in which this decoder could deal with illegal strings. It could either leave illegal characters alone or it could throw an IllegalArgumentException. Which approach the decoder takes is left to the implementation.


In practice, URLDecoder generally does not throw IllegalArgumentException as threatened above. And if your file path has spaces encoded as %20, this approach may appear to work. However, if your file path has other non-alphameric characters such as + you will have problems with URLDecoder mangling your file path.


To achieve these steps, you might have methods like the following:


You can find these methods in the SciJava Common library:


You can also use:


Use ClassLoader.getResource() to find the URL for your current class.


For example:


(This example taken from a similar question.)


To find the directory, you'd then need to take apart the URL manually. See the JarClassLoader tutorial for the format of a jar URL.


I'm surprised to see that none recently proposed to use Path. Here follows a citation: "The Path class includes various methods that can be used to obtain information about the path, access elements of the path, convert the path to other forms, or extract portions of a path"


Thus, a good alternative is to get the Path objest as:


The only solution that works for me on Linux, Mac and Windows:


the selected answer above is not working if you run your jar by click on it from Gnome desktop environment (not from any script or terminal).


Instead, I have fond that the following solution is working everywhere:


I had the the same problem and I solved it that way:


I hope I was of help to you.


Here's upgrade to other comments, that seem to me incomplete for the specifics of 


using a relative "folder" outside .jar file (in the jar's same
  location):


For getting the path of running jar file I have studied the above solutions and tried all methods which exist some difference each other. If these code are running in Eclipse IDE they all should be able to find the path of the file including the indicated class and open or create an indicated file with the found path.


But it is tricky, when run the runnable jar file directly or through the command line, it will be failed as the path of jar file gotten from the above methods will give an internal path in the jar file, that is it always gives a path as


rsrc:project-name (maybe I should say that it is the package name of the main class file - the indicated class)


I can not convert the rsrc:... path to an external path, that is when run the jar file outside the Eclipse IDE it can not get the path of jar file.


The only possible way for getting the path of running jar file outside Eclipse IDE is 


this code line may return the living path (including the file name) of the running jar file (note that the return path is not the working directory), as the java document and some people said that it will return the paths of all class files in the same directory, but as my tests if in the same directory include many jar files, it only return the path of running jar (about the multiple paths issue indeed it happened in the Eclipse).


Actually here is a better version - the old one failed if a folder name had a space in it.


As for failing with applets, you wouldn't usually have access to local files anyway. I don't know much about JWS but to handle local files might it not be possible to download the app.?


The path always refers to the resource within the jar file.


I tried to get the jar running path using 


c:\app>java -jar application.jar


Running the jar application named "application.jar", on Windows in the folder "c:\app", the value of the String variable "folder" was "\c:\app\application.jar" and I had problems testing for path's correctness  


So I tried to define "test" as:


to get path in a right format like "c:\app" instead of "\c:\app\application.jar" and I noticed that it work.


The simplest solution is to pass the path as an argument when running the jar.


You can automate this with a shell script (.bat in Windows, .sh anywhere else):


I used . to pass the current working directory.


UPDATE


You may want to stick the jar file in a sub-directory so users don't accidentally click it. Your code should also check to make sure that the command line arguments have been supplied, and provide a good error message if the arguments are missing.


Other answers seem to point to the code source which is Jar file location which is not a directory.


Use


I had to mess around a lot before I finally found a working (and short) solution. 
It is possible that the jarLocation comes with a prefix like file:\ or jar:file\, which can be removed by using String#substring().


Works good on Windows


Something that is frustrating is that when you are developing in Eclipse MyClass.class.getProtectionDomain().getCodeSource().getLocation() returns the /bin directory which is great, but when you compile it to a jar, the path includes the /myjarname.jar part which gives you illegal file names. 


To have the code work both in the ide and once it is compiled to a jar, I use the following piece of code:


Not really sure about the others but in my case it didn't work with a "Runnable jar" and i got it working by fixing codes together from phchen2 answer and another from this link :How to get the path of a running JAR file?
The code:


Mention that it is checked only in Windows but i think it works perfect on other Operating Systems [Linux,MacOs,Solaris] :).


I had 2 .jar files in the same directory . I wanted from the one .jar file to start the other .jar file which is in the same directory.


The problem is that when you start it from the cmd the current directory is system32.


Warnings!


🍂..


🍂getBasePathForClass(Class<?> classs):


This code worked for me:


Ignore backup lad answer, it may look ok sometimes but has several problems:


here both should be +1 not -1:


Very dangerous because is not immediately evident if the path has no white spaces, but replacing just the "%" will leave you with a bunch of 20 in each white space:


There are better ways than that loop for the white spaces.


Also it will cause problems at debugging time.


This method, called from code in the archive, returns the folder where the .jar file is. It should work in either Windows or Unix.


Derived from code at: Determine if running from JAR


I write in Java 7, and test in Windows 7 with Oracle's runtime, and Ubuntu with the open source runtime. This works perfect for those systems:


The path for the parent directory of any running jar file (assuming the class calling this code is a direct child of the jar archive itself):


So, the path of foo.jar would be:


Again, this wasn't tested on any Mac or older Windows


The getProtectionDomain approach might not work sometimes e.g. when you have to find the jar for some of the core java classes (e.g in my case StringBuilder class within IBM JDK), however following works seamlessly:


I have another way to get the String location of a class.


The output String will have the form of 


The spaces and other characters are handled, and in the form without file:/. So will be easier to use.


Or you can pass throw the current Thread like this :


This one liner works for folders containing spaces or special characters (like ç or õ). The original question asks for the absolute path (working dir), without the JAR file itself. Tested in here with Java7 on Windows7:


Reference: http://www.mkyong.com/java/how-to-get-the-current-working-directory-in-java/






I have a JPanel to which I'd like to add JPEG and PNG images that I generate on the fly.


All the examples I've seen so far in the Swing Tutorials, specially in the Swing examples use ImageIcons.


I'm generating these images as byte arrays, and they are usually larger than the common icon they use in the examples, at 640x480.


Edit: A more careful examination of the tutorials and the API shows that you cannot add an ImageIcon directly to a JPanel. Instead, they achieve the same effect by setting the image as an icon of a JLabel. This just doesn't feel right...


Here's how I do it (with a little more info on how to load an image):


If you are using JPanels, then are probably working with Swing.  Try this:


The image is now a swing component.  It becomes subject to layout conditions like any other component.


I think there is no need to subclass of anything. Just use a Jlabel. You can set an image into a Jlabel. So, resize the Jlabel then fill it with an image. Its OK. This is the way I do. 


Fred Haslam's way works fine.  I had trouble with the filepath though, since I want to reference an image within my jar.  To do this, I used:


Since I only have a finite number (about 10) images that I need to load using this method, it works quite well.  It gets file without having to have the correct relative filepath.


You can avoid rolling your own Component subclass completely by using the JXImagePanel class from the free SwingX libraries.


Download


You can subclass JPanel - here is an extract from my ImagePanel, which puts an image in any one of 5 locations, top/left, top/right, middle/middle, bottom/left or bottom/right:


JPanel is almost always the wrong class to subclass. Why wouldn't you subclass JComponent?


There is a slight problem with ImageIcon in that the constructor blocks reading the image. Not really a problem when loading from the application jar, but maybe if you're potentially reading over a network connection. There's plenty of AWT-era examples of using MediaTracker, ImageObserver and friends, even in the JDK demos.


I'm doing something very similar in a private project I'm working on. Thus far I've generated images up to 1024x1024 without any problems (except memory) and can display them very quickly and without any performance problems. 


Overriding the paint method of JPanel subclass is overkill and requires more work than you need to do. 


The way I do it is: 


OR


The code you use to generate the image will be in this class. I use a BufferedImage to draw onto then when the paintIcon() is called, use g.drawImvge(bufferedImage); This reduces the amount of flashing done while you generate your images, and you can thread it. 


Next I extend JLabel:


This is because I want to put my image on a scroll pane, I.e. display part of the image and have the user scroll around as needed. 


So then I use a JScrollPane to hold the MapLabel, which contains only the MapIcon. 


But for your scenario (just show the whole image every time). You need to add the MapLabel to the top JPanel, and make sure to size them all to the full size of the image (by overriding the GetPreferredSize()). 


This answer is a complement to @shawalli's answer...


I wanted to reference an image within my jar too, but instead of having a BufferedImage, I simple did this:


Create a source folder in your project directory, in this case I called it Images. 






Say we have these two Runnables:


Then what's the difference between this:


And this:


First example: No multiple threads. Both execute in single (existing) thread. No thread creation.


r1 and r2 are just two different objects of classes that implement the Runnable interface and thus implement the run() method.  When you call r1.run() you are executing it in the current thread.


Second example: Two separate threads.


t1 and t2 are objects of the class Thread.  When you call t1.start(), it starts a new thread and calls the run() method of r1 internally to execute it within that new thread.


If you just invoke run() directly, it's executed on the calling thread, just like any other method call. Thread.start() is required to actually create a new thread so that the runnable's run method is executed in parallel.


The difference is that Thread.start() starts a thread, while Runnable.run() just calls a method.


Main difference is that when program calls start() method a new Thread is created and code inside run() method is executed in new Thread while if you call run() method directly no new Thread is created and code inside run() will execute on current Thread.


Another difference between start vs run in Java thread is that you can not call start() method twice on thread object. once started, second call of start() will throw IllegalStateException in Java while you can call run() method twice.


Actually Thread.start() creates a new thread and have its own execution scenario.


Thread.start() calls the run() method asynchronously,which changes the state of new Thread to Runnable.


But Thread.run() does not create any new thread. Instead it execute the run method in the current running thread synchronously.


If you are using Thread.run() then you are not using the features of multi threading at all. 


invoke run() is  executing on the calling thread, like any other method call. whereas  Thread.start() creates a new thread.
invoking run() is a programmatic bug. 


If you do run() in main method, the thread of main method will invoke the run method instead of the thread you require to run.


The start() method creates new thread and for which the run() method has to be done


Thread.start() code registers the Thread with scheduler and the scheduler calls the run() method. Also, Thread is class while Runnable is an interface.


The points, that the members made are all right so I just want to add something. The thing is that JAVA supports no Multi-inheritance. But What is if you want to derive a class B from another class A, but you can only derive from one Class. The problem now is how to "derive" from both classes: A and Thread. Therefore you can use the Runnable Interface.


If you directly call run() method, you are not using multi-threading feature since run() method is executed as part of caller thread. 


If you call start() method on Thread, the Java Virtual Machine will call run() method and two threads will run concurrently - Current Thread (main() in your example) and Other Thread (Runnable r1 in your example).


Have a look at source code of start() method in Thread class


In above code, you can't see invocation to run() method. 


private native void start0() is responsible for calling run() method. JVM executes this native method.


Most of these answers miss the big picture, which is that, as far as the Java language is concerned, there is no more difference between t.start() and r.run() than there is between any other two methods.


They're both just methods.  They both run in the thread that called them.  They both do whatever they were coded to do, and then they both return, still in the same thread, to their callers.


The biggest difference is that most of the code for t.start() is native code while, in most cases, the code for r.run() is going to be pure Java.  But that's not much of a difference.  Code is code.  Native code is harder to find, and harder to understand when you find it, but it's still just code that tells the computer what to do.


So, what does t.start() do?


It creates a new native thread, it arranges for that thread to call t.run(), and then it tells the OS to let the new thread run.  Then it returns.


And what does r.run() do?


The funny thing is, the person asking this question is the person who wrote it.  r.run() does whatever you (i.e., the developer who wrote it) designed it to do.


t.start() is the method that the library provides for your code to call when you want a new thread.


r.run() is the method that you provide for the library to call in the new thread.


In the first case you are just invoking the run() function of the r1 adn r2 objects.


In the second case you're actually creating 2 new Threads! ;) start() will call run() at same point!


The separate start() and run() methods in the Thread class provide two ways to create threaded programs. The start() method starts the execution of the new thread and calls the run() method. The start() method returns immediately and the new thread normally continues until the run() method returns.


The Thread class' run() method does nothing, so sub-classes should override the method with code to execute in the second thread. If a Thread is instantiated with a Runnable argument, the thread's run() method executes the run() method of the Runnable object in the new thread instead.


Depending on the nature of your threaded program, calling the Thread run() method directly can give the same output as calling via the start() method, but in the latter case the code is actually executed in a new thread.


Suppose you are a Manager of a hotel named Thread. So basically what t1.run() does is that it makes you have to do all the tasks yourself, while your other Thread helpers sit idle twiddling their thumbs. But if you use t1.start(), one of your helpers is assigned some task and then he/she starts doing that task, while you do the job you are supposed to do that is manage the helpers.


Source: Programming Interview: Threads in Operating System (Java ) Part 2 Multithreading 






In my Java application, I want to run a batch file that calls "scons -Q implicit-deps-changed build\file_load_type export\file_load_type"


It seems that I can't even get my batch file to execute. I'm out of ideas. 


This is what I have in Java:


Previously, I had a Python Sconscript file that I wanted to run but since that didn't work I decided I would call the script via a batch file but that method has not been successful as of yet. 


Batch files are not an executable.  They need an application to run them (i.e. cmd).


On UNIX, the script file has shebang (#!) at the start of a file to specify the program that executes it.  Double-clicking in Windows is performed by Windows Explorer.  CreateProcess does not know anything about that.


Note: With the start \"\" command, a separate command window will be opened with a blank title and any output from the batch file will be displayed there.  It should also work with just `cmd /c build.bat", in which case the output can be read from the sub-process in Java if desired.


Sometimes the thread execution process time is higher than JVM thread waiting process time, it use to happen when the process you're invoking takes some time to be processed, use the waitFor() command as follows:


This way the JVM will stop until the process you're invoking is done before it continue with the thread execution stack.


To run batch files using java if that's you're talking about...


This should do it.


ProcessBuilder is the Java 5/6 way to run external processes.


The executable used to run batch scripts is cmd.exe which uses the /c flag to specify the name of the batch file to run:


Theoretically you should also be able to run Scons in this manner, though I haven't tested this:


EDIT: Amara, you say that this isn't working.  The error you listed is the error you'd get when running Java from a Cygwin terminal on a Windows box; is this what you're doing?  The problem with that is that Windows and Cygwin have different paths, so the Windows version of Java won't find the scons executable on your Cygwin path.  I can explain further if this turns out to be your problem.


tested with jdk1.5 and jdk1.6


This was working fine for me, hope it helps others too.
to get this i have struggled more days. :(


I had the same issue. However sometimes CMD failed to run my files.
That's why i create a temp.bat on my desktop, next this temp.bat is going to run my file, and next the temp file is going to be deleted.


I know this is a bigger code, however worked for me in 100% when even Runtime.getRuntime().exec() failed.


The following is working fine:






I have a byte array filled with hex numbers and printing it the easy way is pretty pointless because there are many unprintable elements. What I need is the exact hexcode in the form of: 3a5f771c


From the discussion here, and especially this answer, this is the function I currently use:


My own tiny benchmarks (a million bytes a thousand times, 256 bytes 10 million times) showed it to be much faster than any other alternative, about half the time on long arrays.  Compared to the answer I took it from, switching to bitwise ops --- as suggested in the discussion --- cut about 20% off of the time for long arrays. (Edit: When I say it's faster than the alternatives, I mean the alternative code offered in the discussions. Performance is equivalent to Commons Codec, which uses very similar code.)


The Apache Commons Codec library has a Hex class for doing just this type of work.


Use DatatypeConverter.printHexBinary(). You can read its documentation in http://docs.oracle.com/javase/6/docs/api/javax/xml/bind/DatatypeConverter.html


For example:


Will result in:


As you can see this will retrieve the hexadecimal string representing the array of bytes with leading zeros.


This answer is basically the same as in the question In Java, how do I convert a byte array to a string of hex digits while keeping leading zeros?


Simplest solution, no external libs, no digits constants:


This simple oneliner works for me
String result = new BigInteger(1, inputBytes).toString(16);  
EDIT - Using this will remove the leading zeros, but hey worked for my use-case. Thanks @Voicu for pointing it out


A Guava solution, for completeness:


Now hex is "48656c6c6f20776f726c64".


Use DataTypeConverter classjavax.xml.bind.DataTypeConverter


String hexString = DatatypeConverter.printHexBinary(bytes[] raw);


I found three different ways here:
http://www.rgagnon.com/javadetails/java-0596.html


The most elegant one, as he also notes, I think is this one:


At the minor cost of storing the lookup table this implementation is simple and very fast.


How about this?


I would use something like this for fixed length, like hashes:


I prefer to use this:


It is slightly more flexible adaptation of the accepted answer.
Personally, I keep both the accepted answer and this overload along with it, usable in more contexts.


I usually use the following method for debuf statement, but i don't know if it is the best way of doing it or not


Ok so there are a bunch of ways to do this, but if you decide to use a library I would suggest poking about in your project to see if something has been implemented in a library that is already part of your project before adding a new library just to do this.  For example if you don't already have 


org.apache.commons.codec.binary.Hex


maybe you do have...


org.apache.xerces.impl.dv.util.HexBin


A small variant of the solution proposed by @maybewecouldstealavan, which lets you visually bundle N bytes together in the output hex string:


That is:


// Shifting bytes is more efficient
// You can use this one too 


If you're looking for a byte array exactly like this for python, I have converted this Java implementation into python.






What is an elegant way to find all the permutations of a string. E.g. ba, would be ba and ab, but what about abcdefgh? Is there any example Java implementation?


(via Introduction to Programming in Java)


Use recursion.


Here is my solution that is based on the idea of the book "Cracking the Coding Interview" (P54):


Running output of string "abcd":


Step 1: Merge [a] and b:
[ba, ab]


Step 2: Merge [ba, ab] and c:
[cba, bca, bac, cab, acb, abc]


Step 3: Merge [cba, bca, bac, cab, acb, abc] and d:
[dcba, cdba, cbda, cbad, dbca, bdca, bcda, bcad, dbac, bdac, badc, bacd, dcab, cdab, cadb, cabd, dacb, adcb, acdb, acbd, dabc, adbc, abdc, abcd]


Of all the solutions given here and in other forums, i liked Mark Byers the most. That description actually made me think and code it myself.
Too bad i cannot voteup his solution as i am newbie.
Anyways here is my implementation of his description


I prefer this solution ahead of the first one in this thread because this solution uses StringBuffer.I wouldn't say my solution doesn't create any temporary string (it actually does in system.out.println where the toString() of StringBuffer is called). But i just feel this is better than the first solution where too many string literals are created . May be some performance guy out there can evalute this in terms of 'memory' (for 'time' it already lags due to that extra 'swap')


A very basic solution in Java is to use recursion + Set ( to avoid repetitions ) if you want to store and return the solution strings :


All the previous contributors have done a great job explaining and providing the code. I thought I should share this approach too because it might help someone too. The solution is based on (heaps' algorithm ) 


Couple of things: 


Notice the last item which is depicted in the excel is just for helping you better visualize the logic. So, the actual values in the last column would be 2,1,0 (if we were to run the code because we are dealing with arrays and arrays start with 0).


The swapping algorithm happens based on even or odd values of current position. It's very self explanatory if you look at where the swap method is getting called.You can see what's going on.


Here is what happens:



This one is without recursion 


Let's use input abc as an example.


Start off with just the last element (c) in a set (["c"]), then add the second last element (b) to its front, end and every possible positions in the middle, making it ["bc", "cb"] and then in the same manner it will add the next element from the back (a) to each string in the set making it:


Thus entire permutation:


Code:


Well here is an elegant, non-recursive, O(n!) solution:


One of the simple solution could be just keep swapping the characters recursively using two pointers.


Use recursion.


when the input is an empty string the only permutation is an empty string.Try for each of the letters in the string by making it as the first letter and then find all the permutations of the remaining letters using a recursive call.


this worked for me..  


python implementation


Here is a straightforward minimalist recursive solution in Java:


This is what I did through basic understanding of Permutations and Recursive function calling. Takes a bit of time but it's done independently.


which generates Output as [abc, acb, bac, bca, cab, cba].


Basic logic behind it is 


For each character, consider it as 1st character & find the combinations of remaining characters. e.g. [abc](Combination of abc)->.


And then recursively calling each [bc],[ac] & [ab] independently.


We can use factorial to find how many strings started with particular letter.


Example: take the input abcd. (3!) == 6 strings will start with every letter of abcd.


Here is a java implementation:


http://ideone.com/nWPb3k


Recursion is not necessary, even you can calculate any permutation directly, this solution uses generics to permute any array.


Here is a good information about this algorihtm.


For C# developers here is more useful implementation.


This algorithm has O(N) time and space complexity to calculate each permutation.


Java implementation without recursion


//insert each character into an arraylist


Improved Code for the same


This can be done iteratively by simply inserting each letter of the string in turn in all locations of the previous partial results.


We start with [A], which with B becomes [BA, AB], and with C, [CBA, BCA, BAC, CAB, etc].


The running time would be O(n!), which, for the test case ABCD, is 1 x 2 x 3 x 4.


In the above product, the 1 is for A, the 2 is for B, etc.


Dart sample:


Here are two c# versions (just for reference): 
1. Prints all permuations
2. returns all permutations


Basic gist of the algorithm is (probably below code is more intuitive - nevertheless, here is some explanation of what below code does):
- from the current index to for the rest of the collection, swap the element at current index
- get the permutations for the remaining elements from next index recursively
- restore the order, by re-swapping 


Note: the above recursive function will be invoked from the start index.


version 2 (same as above - but returns the permutations in lieu of printing)


Unit Tests


Another simple way is to loop through the string, pick the character that is not used yet and put it to a buffer, continue the loop till the buffer size equals to the string length. I like this back tracking solution better because:


Here is the java code:


Input str: 1231


Output list: {1123, 1132, 1213, 1231, 1312, 1321, 2113, 2131, 2311, 3112, 3121, 3211}


Noticed that the output is sorted, and there is no duplicate result.


This is a C solution:


My implementation based on Mark Byers's description above:






If I have an object implementing the Map interface in Java and I wish to iterate over every pair contained within it, what is the most efficient way of going through the map?  


Will the ordering of elements depend on the specific map implementation that I have for the interface?


Summarize other answers and what I known, I found 10 main ways to do this (see below). And I wrote some performance tests (see results below), for example, if we want to find sum of all keys and values of map, we can write :


Using iterator and Map.Entry


Using foreach and Map.Entry


Using forEach from Java 8


Using keySet and foreach


Using keySet and iterator


Using for and Map.Entry


Using Java 8 Stream Api


Using Java 8 Stream Api parallel


Using IterableMap of Apache Collections


Using MutableMap of Eclipse (CS) collections


Perfomance tests (mode = AverageTime, system = Win 8.1 64-bit, Intel i7-4790 3.60GHz 3.60GHz, 16 GB)


1) For small map (100 elements),  score 0.308 is the best


2) For map with 10000 elements,  score 37.606 is the best


3) For map with 100000 elements,  score 1184.767 is the best


Graphs (perfomance tests depending on map size)





Table (perfomance tests depending on map size)


All test in github


In Java 8 you can do it clean and fast using the new lambdas features:


The type of k and v will be inferred by the compiler and there is no need to use Map.Entry anymore.


Easy-peasy!


Yes, the order depends on the specific Map implementation.  


@ScArcher2 has the more elegant Java 1.5 syntax.  In 1.4, I would do something like this:


Typical code for iterating over a map is:


HashMap is the canonical map implementation and doesn't make guarantees (or though it should not change order if no mutating operation are performed on it). SortedMap will return entries based on the natural ordering of the keys, or a Comparator, if provided. LinkedHashMap will either return entries in insertion-order or access-order depending upon how it has been constructed. EnumMap returns entries in natural order of keys.


Note, IdentityHashMap entrySet iterator currently has a peculiar implementation which returns the same Map.Entry instance for every item in the entrySet! However, every time a new the iterator advances the Map.Entry is updated.


Example of using iterator and generics:


This is a two part question:


How to iterate over the entries of a Map - @ScArcher2 has answered that perfectly.


What is the order of iteration - if you are just using Map, then strictly speaking, there are no ordering guarantees.  So you shouldn't really rely on the ordering given by any implementation.  However, the SortedMap interface extends Map and provides exactly what you are looking for - implementations will aways give a consistent sort order.


NavigableMap is another useful extension - this is a SortedMap with additional methods for finding entries by their ordered position in the key set.  So potentially this can remove the need for iterating in the first place - you might be able to find the specific entry you are after using the higherEntry, lowerEntry, ceilingEntry, or floorEntry methods.  The descendingMap method even gives you an explicit method of reversing the traversal order.


There are several ways to iterate over map.


Here is comparison of their performances for a common data set stored in map by storing a million key value pairs in map and will iterate over map.


1) Using entrySet() in for each loop


50 milliseconds


2) Using keySet() in for each loop


76 milliseconds


3) Using entrySet() and iterator


50 milliseconds


4) Using keySet() and iterator


75 milliseconds


I have referred this link.


FYI, you can also use map.keySet() and map.values() if you're only interested in keys/values of the map and not the other.


The correct way to do this is to use the accepted answer as it is the most efficient. I find the following code looks a bit cleaner.


With Eclipse Collections (formerly GS Collections), you would use the forEachKeyValue method on the MapIterable interface, which is inherited by the MutableMap and ImmutableMap interfaces and their implementations.


With Java 8 lambda syntax, you can write the code as follows:


Note: I am a committer for Eclipse Collections.


Try this with Java 1.4:


JAVA 8
You can use Lambda Expressions.


For more information follow this.


In Map one can Iteration over keys and/or values and/or both (e.g., entrySet)  depends on one's interested in_ Like:


1.) Iterate through the keys -> keySet() of the map:


2.) Iterate through the values -> values() of the map:


3.) Iterate through the both -> entrySet() of the map:


Moreover, there are 3 difference ways to Iterate Through a HashMap. They are as below_


In theory, the most efficient way will depend on which implementation of Map. The official way to do this is to call map.entrySet(), which returns a set of Map.Entry, each of which contains a key and a value (entry.getKey() and entry.getValue()).


In an idiosyncratic implementation, it might make some difference whether you use map.keySet(), map.entrySet() or something else. But I can't think of a reason why anyone would write it like that. Most likely it makes no difference to performance what you do.


And yes, the order will depend on the implementation - as well as (possibly) the order of insertion and other hard-to-control factors.


[edit] I wrote valueSet() originally but of course entrySet() is actually the answer.


OR


Lambda Expression Java 8


In Java 1.8 (Java 8) this has become lot easier by using forEach method from Aggregate operations(Stream operations) that looks similar to iterators from Iterable Interface. 


Just copy paste below statement to your code and rename the HashMap variable from hm to your HashMap variable to print out key-value pair.


Below is the sample code that i tried using Lambda Expression. This stuff is so cool. Must try.


Also one can use Spliterator for the same.


UPDATE


Including documentation links to Oracle Docs.
For more on Lambda go to this link and must read Aggregate Operations and for Spliterator go to this link.


If you have a generic untyped Map you can use:


You can do it using generics:


Yes, as many people agreed this is the best way to iterate over MAP.


But there are chances to throw nullpointerexception if map is null.Don't forget to put null .check


The best way is entrySet() though.


In Java 8 we have got forEach method that accepts a lambda expression. We have also got stream APIs. Consider a map:


Iterate over keys:


Iterate over values:


Iterate over entries (Using forEach and Streams):


The advantage with streams is they can be parallelized easily in case we want to. We simply need to use parallelStream() in place of stream() above.


It doesn't quite answer the OP's question, but might be useful to others who find this page:


If you only need the values and not the keys, you can do this:


Ktype, Vtype are pseudocode.


Here is a generic; type-safe method which can be called to dump any given Map.


Here is an example of it's use. Notice that they type of the Map is inferred by the method.


If your reason for iterating trough the Map, is to do an operation on the value and write to a resulting Map. I recommend using the transform-methods in the Google Guava Maps class.


After you have added the Maps to your imports, you can use Maps.transformValues and Maps.transformEntries on your maps, like this:


The ordering will always depend on the specific map implementation.
Using Java8 you can use either of these:


Or:


The result will be the same (same order). The entrySet backed by the map so you are getting the same order. The second one is handy as it allows you to use lambdas, e.g. if you want only to print only Integer objects that are greater than 5:


The code below shows iteration through LInkedHashMap and normal HashMap (example). You will see difference in the order:


LinkedHashMap (1): 


10 (#=10):10, 9 (#=9):9, 8 (#=8):8, 7 (#=7):7, 6 (#=6):6, 5 (#=5):5, 4 (#=4):4, 3 (#=3):3, 2 (#=2):2, 1 (#=1):1, 0 (#=0):0, 


LinkedHashMap (2): 


10 : 10, 9 : 9, 8 : 8, 7 : 7, 6 : 6, 5 : 5, 4 : 4, 3 : 3, 2 : 2, 1 : 1, 0 : 0, 


HashMap (1): 


0 (#:0):0, 1 (#:1):1, 2 (#:2):2, 3 (#:3):3, 4 (#:4):4, 5 (#:5):5, 6 (#:6):6, 7 (#:7):7, 8 (#:8):8, 9 (#:9):9, 10 (#:10):10, 


HashMap (2): 


0 : 0, 1 : 1, 2 : 2, 3 : 3, 4 : 4, 5 : 5, 6 : 6, 7 : 7, 8 : 8, 9 : 9, 10 : 10, 


There are the several way to iterate a map please refer the following code 
When you iterate a map using iterator Interface you must to go with Entry or entrySet()
look like this 






I have a String[] with values like so:


Given String s, is there a good way of testing whether VALUES contains s?


Warning: this doesn't work for arrays of primitives (see the comments).


You can now use a Stream to check whether an array of int, double or long contains a value (by respectively using a IntStream, DoubleStream or LongStream)


Just to clear the code up to start with. We have (corrected):


This is a mutable static which FindBugs will tell you is very naughty. It should be private:


(Note, you can actually drop the new String[]; bit.)


So, reference arrays are bad, and in particular here we want a set:


(Paranoid people, such as myself, may feel more at ease if this was wrapped in Collections.unmodifiableSet - it could even be made public.)


"Given String s, is there a good way of testing whether VALUES contains s?"


O(1).


You can use ArrayUtils.contains from Apache Commons Lang


public static boolean contains(Object[] array, Object objectToFind)


Note that this method returns false if the passed array is null.


There are also methods available for primitive arrays of all kinds.


I'm surprised no one suggested to just simply implement it by hand:


Improvement:


The v != null condition is constant inside the method, it always evaluates to the same boolean value during the method call. So if the input array is big, it is more efficient to evaluate this condition only once and we can use a simplified/faster condition inside the for loop based on the result. The improved contains() method:


If the array is not sorted, you will have to iterate over everything and make a call to equals on each.


If the array is sorted, you can do a binary search, there's one in the Arrays class.


Generally speaking, if you are going to do a lot of membership checks, you may want to store everything in a Set, not in an array. 


For what its worth I ran a test comparing the 3 suggestions for speed. I generated random integers, converted them to a String and added them to an array. I then searched for the highest possible number/string, which would be a worst case scenario for the asList().contains().


When using a 10K array size the results where:


When using a 100K array the results where:


So if the array is created in sorted order the binary search is the fastest, otherwise the asList().contains would be the way to go. If you have many searches, then it may be worthwhile to sort the array so you can use the binary search. It all depends on your application.  


I would think those are the results most people would expect. Here is the test code:


Four Different Ways to Check If an Array Contains a Value


1) Using List:


2) Using Set:


3) Using a simple loop:


4) Using Arrays.binarySearch():


The code below is wrong, it is listed here for completeness. binarySearch() can ONLY be used on sorted arrays. You will find the result is weird below. This is the best option when array is sorted.


Instead of using the quick array initialsation syntax to you could just initialise it as a List straight away in a similar manner using the Arrays.asList method e.g.:


Then you can do (like above): STRINGS.contains("the string you want to find");


With Java 8 you can create a stream and check if any entries in the stream matches "s":


Or as a generic method:


You can use the Arrays class to perform a binary search for the value. If your array is not sorted, you will have to use the sort functions in the same class to sort the array, then search through it.


ObStupidAnswer (but I think there's a lesson in here somewhere):


Actually , if you use HashSet as Tom Hawtin proposed you don`t need to worry about sorting and your speed is the same as with Binary Search on a presorted array, probably even faster.


It all depends on how your code is set up, obviously, but from where I stand, the order would be:


On an UNsorted array:


On a sorted array:


So either way, HashSet ftw


If you have the google collections library, Tom's answer can be simplified a lot by using ImmutableSet (http://google-collections.googlecode.com/svn/trunk/javadoc/com/google/common/collect/ImmutableSet.html)


This really removes a lot of clutter from the initialization proposed


In Java 8 use Streams.


Using a simple loop is the most efficient way of doing this. 


Courtesy to Programcreek


Developers often do:


The above code works, but there is no need to convert a list to set first. Converting a list to a set requires extra time. It can as simple as:


or


The first one is more readable than the second one.


For arrays of limited length use the following (as given by camickr).  This is slow for repeated checks, especially for longer arrays (linear search).  


For fast performance if you repeatedly check against a larger set of elements


An array is the wrong structure.  Use a TreeSet and add each element to it.  It sorts elements and has a fast exist() method (binary search).


If the elements implement Comparable & you want the TreeSet sorted accordingly:


ElementClass.compareTo() method must be compatable with ElementClass.equals(): see Triads not showing up to fight? (Java Set missing an item) 


Otherwise, use your own Comparator:


The payoff: check existence of some element:


Arrays.asList => then applying the contains() method will always work, but a search algorithm is much better since first, you have to convert the Array to a list, then calling the contains method, double the overhead, see what I mean? This is because it is O(n) to create the List and O(n) to for contains to find an element through sequential checking. Why suffer O(n) twice when a simple linear search does the job only once.


Use Array.BinarySearch(array,obj) for finding the given object in array or not.
Ex:


if (Array.BinarySearch(str, i) > -1) -->true --exists


false --not exists


Try This:


I am very late to join this discussion, but since my approach in solving this problem, when I faced it a few years ago, was a bit different than the other answers already posted here, I am posting that solution I used at that time, over here, in case anyone finds it usefull: (The contains() method is ArrayUtils.in() in this code.)


ObjectUtils.java


ArrayUtils.java


As you can see in the code above, that there are other utility methods ObjectUtils.equals() and ArrayUtils.indexOf(), that were used at other places as well.


One possible solution would be:


check this


Thank You


It can be as simple as:






How is it possible to read/write to the Windows Registry using java?


I know this question is old, but it is the first search result on google to "java read/write to registry".  Recently I found this amazing piece of code which:


This is pure, Java code.


It uses reflection to work, by actually accessing the private methods in the java.util.prefs.Preferences class. The internals of this class are complicated, but the class itself is very easy to use.


For example, the following code obtains the exact windows distribution from the registry:


Here is the original class. Just copy paste it and it should work:


I was unable to find and give credit to the original author of this code. If you find any details, please add a comment and I will add it here.


You don't actually need a 3rd party package. Windows has a reg utility for all registry operations. To get the command format, go to the DOS propmt and type:


You can invoke reg through the Runtime class:


Editing keys and adding new ones is straightforward using the command above. To read the registry, you need to get reg's output, and it's a little tricky. Here's the code:


Java Native Access (JNA) is an excellent project for working with native libraries and has support for the Windows registry in the platform library (platform.jar) through Advapi32Util and Advapi32.


Update: Here's a snippet with some examples of how easy it is to use JNA to work with the Windows registry using JNA 3.4.1,


I've done this before using jRegistryKey. It is an LGPL Java/JNI library that can do what you need. Here's an example of how I used it to enabled Registry editing through regedit and also the "Show Folder Options" option for myself in Windows via the registry.


I've incremented the Pure java code originally posted by David to allow acessing the 32-bits section of the registry from a 64-bit JVM, and vice-versa. I don't think any of the other answers address this.


Here it is:


Yes, using the java.util.Preferences API, since the Windows implementation of it uses the Registry as a backend.


In the end it depends on what you're wanting to do: storing preferences for your app is what the Preferences does just great. If you're wanting to actually change registry keys not having to do with your app, you'll need some JNI app, as described by Mark (shameless steal here):


From a quick google:
  Check the WinPack for JNIWrapper. It has full Windows Registry access support including Reading and Writing.


The WinPack Demo has Registry Viewer implemented as an example.


Check at http://www.teamdev.com/jniwrapper/winpack/#registry_access


And...


There is also try JNIRegistry @ http://www.trustice.com/java/jnireg/


There is also the option of invoking an external app, which is responsible for reading / writing the registry.


From a quick google:


Check the WinPack for JNIWrapper. It
  has full Windows Registry access
  support including Reading and Writing.


The WinPack Demo has Registry Viewer
  implemented as an example.


Check at
  http://www.teamdev.com/jniwrapper/winpack/#registry_access


And...


There is also try JNIRegistry @
  http://www.trustice.com/java/jnireg/


There is also the option of invoking an external app, which is responsible for reading / writing the registry.


Here's a modified version of Oleg's solution.  I noticed that on my system (Windows server 2003), the output of "reg query" is not separated by tabs ('\t'), but by 4 spaces.


I also simplified the solution, as a thread is not required.


}


As has been noted, the Preferences API uses the registry to store preferences, but cannot be used to access the whole registry.


However, a pirate called David Croft has worked out that it's possible to use methods in Sun's implementation of the Preferences API for reading the Windows registry from Java without JNI. There are some dangers to that, but it is worth a look.


Thanks to original post. I have reskinned this utility class and come up over the flaws which it had earlier, thought it might help others so posting here. I have also added some extra utility methods. Now it is able to read any file in windows registry(including REG_DWORD, REG_BINARY, REG_EXPAND_SZ etc.). All the methods work like a charm. Just copy and paste it and it should work. Here is the reskinned and modified class:  


Sample of using the methods is as follows: 


Below method retrieves the value of the key from the given path:  


String hex = WinRegistry.valueForKey(WinRegistry.HKEY_LOCAL_MACHINE, "SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WindowsUpdate\\Auto Update", "AUOptions"); 


This method retrieves all data for the specified path(in form of keys and values) :  


Map<String, String> map = WinRegistry.valuesForPath(WinRegistry.HKEY_LOCAL_MACHINE, "SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\WSMAN"); 


This method retrieves value recursively for the key from the given path:  


String val = WinRegistry.valueForKeyPath(WinRegistry.HKEY_LOCAL_MACHINE, "System", "TypeID"); 


and this one retrieves all values recursively for a key from the given path:  


List<String> list = WinRegistry.valuesForKeyPath(
                       WinRegistry.HKEY_LOCAL_MACHINE,                  //HKEY                               "SOFTWARE\\Wow6432Node\\Microsoft\\Windows\\CurrentVersion\\Uninstall",   //path                 "DisplayName"         //Key
                );
Here in above code I retrieved all installed software names in windows system.
Note: See the documentation of these methods 


And this one retrieves all subkeys of the given path:
List<String> list3 = WinRegistry.subKeysForPath(WinRegistry.HKEY_CURRENT_USER, "Software"); 


Important Note: I have modified only reading purpose methods in this process, not the writing purpose methods like createKey, deleteKey etc. They still are same as I recieved them. 


The Preferences API approach does not give you access to all the branches of the registry. In fact, it only gives you access to where the Preferences API stores its, well, preferences. It's not a generic registry handling API, like .NET's


To read/write every key I guess JNI or an external tool would be the approach to take, as Mark shows.


There are few JNDI service providers to work with windows registry.


One could observe http://java.sun.com/products/jndi/serviceproviders.html.


You could try WinRun4J. This is a windows java launcher and service host but it also provides a library for accessing the registry.


(btw I work on this project so let me know if you have any questions)


The best way to write to the register probably is using the reg import native Windows command and giving it the file path to the .reg file which has been generated by exporting something from the registry.


Reading is done with the reg query command. Also see the documentation:
https://technet.microsoft.com/en-us/library/cc742028.aspx


Therefore the following code should be self-explanatory:


My previous edit to @David's answer was rejected.  Here is some useful information about it.


This "magic" works because Sun implements the Preferences class for Windows as part of JDK, but it is package private.  Parts of the implementation use JNI.


The implementation is selected at runtime using a factory method here: http://grepcode.com/file/repository.grepcode.com/java/root/jdk/openjdk/7-b147/java/util/prefs/Preferences.java#Preferences.0factory


The real question: Why doesn't OpenJDK expose this API to public?


Yet another library...


https://code.google.com/p/java-registry/


This one launches reg.exe under the covers, reading/writing to temporary files. I didn't end up using it, but it looks like a pretty comprehensive implementation. If I did use it, I might dive in and add some better management of the child processes.


The java.util.prefs package provides a way for applications to store and retrieve user and system preferences and data configuration. These preference data will be stored persistently in an implementation-dependent backing stored. For example in Windows operating system in will stored in Windows registry.


To write and read these data we use the java.util.prefs.Preferences class. Below code shows how to read and write to the HKCU and HKLM in the registry.


Although this is pretty old, but i guess the better utility to use on windows platform would be regini :


A single call to process: 


will do all the magic. I have tried it, while making jar as windows service using servany.exe which requires changes to made in registry for adding javaw.exe arguments and it works perfectly. You might want to read this: http://support.microsoft.com/kb/264584


This was crazy... I took the code from one of the posts here, failed to see there were 18 more comments in which one stated that it does not read a dword value...


In any case, I've refactored the hell of that code into something with less ifs and methods... 


The Enum could be refined a bit, but as soon as I've fought my way to read a numeric value or byte array and failed, I've given up...


So here it is:


NOTE: THIS DOES NOT READ ANYTHING ELSE BUT STRINGS!!!!!


The WinPack Demo has Registry Viewer
  implemented as an example.


Check at
  http://www.jniwrapper.com/winpack_features.jsp#registry


BTW, WinPack has been moved to the following address:


http://www.teamdev.com/jniwrapper/winpack/


I prefer using java.util.prefs.Preferences class.


A simple example would be 


In response to David answer - I would do some enhancements:


You can execute these "REG QUERY" command using java code.


Try to execute this from command prompt and execute command from java code.


HKEY_LOCAL_MACHINE "SOFTWARE\Microsoft\Windows NT\CurrentVersion"


To Search details like productname version etc.. use /v amd "name". 


HKEY_LOCAL_MACHINE "SOFTWARE\Microsoft\Windows NT\CurrentVersion" /v "ProductName"


This uses the same Java internal APIs as in in David's answer, but I've rewritten it completely. It's shorter now and nicer to use. I also added support for HKEY_CLASSES_ROOT and other hives. It still has some of the other limitations though (such as no DWORD support and no Unicode support) which are due to the underlying API and are sadly unavoidable with this approach. Still, if you only need basic string reading/writing and don't want to load a native DLL, it's handy.


I'm sure you can figure out how to use it.


Public domain. Have fun.


One day, Java will have a built-in foreign function interface for easy access to native APIs, and this sort of hack will be unnecessary.






I am designing a simple web based application. I am new to this web based domain.I needed your advice regarding the design patterns like how responsibility should be distributed among Servlets, criteria to make new Servlet, etc.


Actually I have few entities on my home page and corresponding to each one of them we have few options like add, edit and delete. Earlier I was using one Servlet per options like Servlet1 for add entity1, Servlet2 for edit entity1 and so on and in this way we ended up having a large number of servlets.


Now we are changing our design. My question is how you exactly choose how you choose the responsibility of a servlet. Should we have one Servlet per entity which will process all it's options and forward request to service layer.Or should we have one servlet for the whole page which will process the whole page request and then forward it to corresponding service layer.Also should the request object forwarded to service layer or not.


Please you guide us in choosing the best design.Also any pointer to a good design pattern material will be welcome.


A bit decent web application consists of a mix of design patterns. I'll mention only the most important ones.


The core (architectural) design pattern you'd like to use is the Model-View-Controller pattern. The Controller is to be represented by a Servlet which (in)directly creates/uses a specific Model and View based on the request. The Model is to be represented by Javabean classes. This is often further dividable in Business Model which contains the actions (behaviour) and Data Model which contains the data (information). The View is to be represented by JSP files which have direct access to the (Data) Model by EL (Expression Language). 


Then, there are variations based on how actions and events are handled. The popular ones are:


Request (action) based MVC: this is the simplest to implement. The (Business) Model works directly with HttpServletRequest and HttpServletResponse objects. You have to gather, convert and validate the request parameters (mostly) yourself. The View can be represented by plain vanilla HTML/CSS/JS and it does not maintain state across requests. This is how among others Spring MVC, Struts and Stripes works.


Component based MVC: this is harder to implement. But you end up with a simpler model and view wherein all the "raw" Servlet API is abstracted completely away. You shouldn't have the need to gather, convert and validate the request parameters yourself. The Controller does this task and sets the gathered, converted and validated request parameters in the Model. All you need to do is to define action methods which works directly with the model properties. The View is represented by "components" in flavor of JSP taglibs or XML elements which in turn generates HTML/CSS/JS. The state of the View for the subsequent requests is maintained in the session. This is particularly helpful for server-side conversion, validation and value change events. This is how among others JSF, Wicket and Play! works.


As a side note, hobbying around with a homegrown MVC framework is a very nice learning exercise, and I do recommend it as long as you keep it for personal/private purposes. But once you go professional, then it's strongly recommended to pick an existing framework rather than reinventing your own. Learning an existing and well-developed framework takes in long term less time than developing and maintaining a robust framework yourself.


In the below detailed explanation I'll restrict myself to request based MVC since that's easier to implement.


First, the Controller part should implement the Front Controller pattern (which is a specialized kind of Mediator pattern). It should consist of only a single servlet which provides a centralized entry point of all requests. It should create the Model based on information available by the request, such as the pathinfo or servletpath, the method and/or specific parameters. The Business Model is called Action in the below HttpServlet example.


Executing the action should return some identifier to locate the view. Simplest would be to use it as filename of the JSP. Map this servlet on a specific url-pattern in web.xml, e.g. /pages/*, *.do or even just *.html. 


In case of prefix-patterns as for example /pages/* you could then invoke URL's like http://example.com/pages/register, http://example.com/pages/login, etc and provide /WEB-INF/register.jsp, /WEB-INF/login.jsp with the appropriate GET and POST actions. The parts register, login, etc are then available by request.getPathInfo() as in above example. 


When you're using suffix-patterns like *.do, *.html, etc, then you could then invoke URL's like http://example.com/register.do, http://example.com/login.do, etc and you should change the code examples in this answer (also the ActionFactory) to extract the register and login parts by request.getServletPath() instead.


The Action should follow the Strategy pattern. It needs to be defined as an abstract/interface type which should do the work based on the passed-in arguments of the abstract method (this is the difference with the Command pattern, wherein the abstract/interface type should do the work based on the arguments which are been passed-in during the creation of the implementation).


You may want to make the Exception more specific with a custom exception like ActionException. It's just a basic kickoff example, the rest is all up to you.


Here's an example of a LoginAction which (as its name says) logs in the user. The User itself is in turn a Data Model. The View is aware of the presence of the User.


The ActionFactory should follow the Factory method pattern. Basically, it should provide a creational method which returns a concrete implementation of an abstract/interface type. In this case, it should return an implementation of the Action interface based on the information provided by the request. For example, the method and pathinfo (the pathinfo is the part after the context and servlet path in the request URL, excluding the query string).


The actions in turn should be some static/applicationwide Map<String, Action> which holds all known actions. It's up to you how to fill this map. Hardcoding:


Or configurable based on a properties/XML configuration file in the classpath: (pseudo)


Or dynamically based on a scan in the classpath for classes implementing a certain interface and/or annotation: (pseudo)


Keep in mind to create a "do nothing" Action for the case there's no mapping. Let it for example return directly the request.getPathInfo().substring(1) then.


Those were the important patterns so far. 


To get a step further, you could use the Facade pattern to create a Context class which in turn wraps the request and response objects and offers several convenience methods delegating to the request and response objects and pass that as argument into the Action#execute() method instead. This adds an extra abstract layer to hide the raw Servlet API away. You should then basically end up with zero import javax.servlet.* declarations in every Action implementation. In JSF terms, this is what the FacesContext and ExternalContext classes are doing. You can find a concrete example in this answer.


Then there's the State pattern for the case that you'd like to add an extra abstraction layer to split the tasks of gathering the request parameters, converting them, validating them, updating the model values and execute the actions. In JSF terms, this is what the LifeCycle is doing.


Then there's the Composite pattern for the case that you'd like to create a component based view which can be attached with the model and whose behaviour depends on the state of the request based lifecycle. In JSF terms, this is what the UIComponent represent. 


This way you can evolve bit by bit towards a component based framework.


In the beaten-up MVC pattern, the Servlet is "C" - controller.


Its main job is to do initial request evaluation and then dispatch the processing based on the initial evaluation to the specific worker. One of the worker's responsibilities may be to setup some presentation layer beans and forward the request to the JSP page to render HTML.  So, for this reason alone, you need to pass the request object to the service layer.


I would not, though, start writing raw Servlet classes.  The work they do is very predictable and boilerplate, something that framework does very well. Fortunately, there are many available, time-tested candidates ( in the alphabetical order ): Apache Wicket, Java Server Faces, Spring to name a few.


IMHO, there is not much difference in case of web application if you look at it from the angle of responsibility assignment. However, keep the clarity in the layer. Keep anything purely for the presentation purpose in the presentation layer, like the control and code specific to the web controls. Just keep your entities in the business layer and all features (like add, edit, delete) etc in the business layer. However rendering them onto the browser to be handled in the presentation layer. For .Net, the ASP.NET MVC pattern is very good in terms of keeping the layers separated. Look into the MVC pattern.


I have used the struts framework and find it fairly easy to learn. When using the struts framework each page of your site will have the following items.


1) An action which is used is called every time the HTML page is refreshed. The action should populate the data in the form when the page is first loaded and handles interactions between the web UI and the business layer. If you are using the jsp page to modify a mutable java object a copy of the java object should be stored in the form rather than the original so that the original data doesn't get modified unless the user saves the page.


2) The form which is used to transfer data between the action and the jsp page. This object should consist of a set of getter and setters for attributes that need to be accessible to the jsp file. The form also has a method to validate data before it gets persisted. 


3) A jsp page which is used to render the final HTML of the page. The jsp page is a hybrid of HTML and special struts tags used to access and manipulate data in the form. Although struts allows users to insert Java code into jsp files you should be very cautious about doing that because it makes your code more difficult to read. Java code inside jsp files is difficult to debug and can not be unit tested. If you find yourself writing more than 4-5 lines of java code inside a jsp file the code should probably be moved to the action.


BalusC excellent answer covers most of the patterns for web applications.


Some application may require Chain-of-responsibility_pattern


In object-oriented design, the chain-of-responsibility pattern is a design pattern consisting of a source of command objects and a series of processing objects. Each processing object contains logic that defines the types of command objects that it can handle; the rest are passed to the next processing object in the chain.


Use case to use this pattern:


When handler to process a request(command) is unknown and this request can be sent to multiple objects. Generally you set successor to object. If current object can't handle the request or process the request partially and forward the same request to successor object. 


Useful SE questions/articles:


Why would I ever use a Chain of Responsibility over a Decorator?


Common usages for chain of responsibility?


chain-of-responsibility-pattern from oodesign


chain_of_responsibility from sourcemaking 






Until today, I thought that for example:


is just a shortcut for:


But what if we try this:


Then i = i + j; will not compile but i += j; will compile fine.


Does it mean that in fact i += j; is a shortcut for something like this
i = (type of i) (i + j)?


As always with these questions, the JLS holds the answer. In this case §15.26.2 Compound Assignment Operators. An extract:


A compound assignment expression of the form E1 op= E2 is equivalent to E1 = (T)((E1) op (E2)), where T is the type of E1, except that E1 is evaluated only once.


An example cited from §15.26.2


[...] the following code is correct:


and results in x having the value 7 because it is equivalent to:


In other words, your assumption is correct.


A good example of this casting is using *= or /=


or


or


or


Very good question. The Java Language specification confirms your suggestion.


For example, the following code is correct:


and results in x having the value 7 because it is equivalent to:


Yes,


basically when we write


the compiler converts this to 


I just checked the .class file code.


Really a good thing to know


you need to cast from long to int explicitly in case of i = i + l  then it will compile and give correct output. like 


or


but in case of += it just works fine because the operator implicitly does the type casting from type of right variable to type of left variable so need not cast explicitly.


The problem here involves type casting.


When you add int and long, 


But += is coded in such a way that it does type casting. i=(int)(i+m)


In Java type conversions are performed automatically when the type of the expression on the right hand side of an assignment operation can be safely promoted to the type of the variable on the left hand side of the assignment. Thus we can safely assign:  


The same will not work the other way round. For example we cannot automatically convert a long to an int because the first requires more storage than the second and consequently information may be lost. To force such a conversion we must carry out an explicit conversion.
Type - Conversion


Sometimes, such a question can be asked at an interview.


For example, when you write:


there is no automatic typecasting. In C++ there will not be any error compiling the above code, but in Java you will get something like Incompatible type exception.


So to avoid it, you must write your code like this:


The main difference is that with a = a + b, there is no typecasting going on, and so the compiler gets angry at you for not typecasting. But with a += b, what it's really doing is typecasting b to a type compatible with a. So if you do 


What you're really doing is: 


Subtle point here...


There is an implicit typecast for 'i+j' when 'j' is a double and 'i' is an int.
Java ALWAYS converts an integer into a double when there is an operation between them.


To clarify 'i+=j' where i is an integer and j is a double can be described as


See: this description of implicit casting


You might want to typecast j to (int) in this case for clarity.


In the case of compound assignment operator, internal type casting will be performed automatically:


And in some cases, you will lose some values:






I have an image that is Base64 encoded. What is the best way to decode that in Java? Hopefully using only the libraries included with Sun Java 6.


As of v6, Java SE ships with JAXB. javax.xml.bind.DatatypeConverter has static methods that make this easy. See parseBase64Binary() and printBase64Binary().


As of Java 8, there is an officially supported API for Base64 encoding and decoding.
In time this will probably become the default choice.


The API includes the class java.util.Base64 and its nested classes. It supports three different flavors: basic, URL safe, and MIME.


Sample code using the "basic" encoding:


The documentation for java.util.Base64 includes several more methods for configuring encoders and decoders, and for using different classes as inputs and outputs (byte arrays, strings, ByteBuffers, java.io streams).


Here is a working example using Apache Commons codec:


Maven / sbt repo: commons-codec, commons-codec, 1.8.


No need to use commons--Sun ships a base64 encoder with Java.  You can import it as such:


And then use it like this:


Where encodedBytes is either a java.lang.String or a java.io.InputStream.  Just beware that the sun.* classes are not "officially supported" by Sun.


EDIT: Who knew this would be the most controversial answer I'd ever post?  I do know that sun.* packages are not supported or guaranteed to continue existing, and I do know about Commons and use it all the time.  However, the poster asked for a class that that was "included with Sun Java 6," and that's what I was trying to answer.  I agree that Commons is the best way to go in general.


EDIT 2: As amir75 points out below, Java 6+ ships with JAXB, which contains supported code to encode/decode Base64. Please see Jeremy Ross' answer below.


Specifically in Commons Codec: class Base64 to decode(byte[] array) or encode(byte[] array)


Guava now has Base64 decoding built in. 


Use BaseEncoding.base64().decode() 


As for dealing with possible whitespace in input the recommended way of doing that is the following way


BaseEncoding.base64().decode(CharMatcher.WHITESPACE.removeFrom(...));


See this discussion for more information


My solution is fastest and easiest.


Here's my own implementation, if it could be useful to someone : 


As an alternative to sun.misc.BASE64Decoder or non-core libraries, look at javax.mail.internet.MimeUtility.decode().


Jist: 


Link with full code: Encode/Decode to/from Base64


Given a test encode/decode example of javax.xml.bind.DatatypeConverter using methods parseBase64Binary() and printBase64Binary() referring to @jeremy-ross and @nightfirecat answer.


Result:


Another late answer, but my benchmarking shows that Jetty's implementation of Base64 encoder is pretty fast. Not as fast as MiGBase64 but faster than iHarder Base64.


I also did some benchmarks:


These are runs/sec so higher is better.


If You are prefering performance based solution then you can use "MiGBase64"


http://migbase64.sourceforge.net/


Hope this helps you:   


Or:


java.util.prefs.Base64 works on local rt.jar,


But it is not in The JRE Class White List


and not in Available classes not listed in the GAE/J white-list


What a pity!


PS. In android, it's easy because that android.util.Base64 has been included since Android API Level 8.


This is a late answer, but Joshua Bloch committed his Base64 class (when he was working for Sun, ahem, Oracle) under the java.util.prefs package. This class existed since JDK 1.4.


E.g.


You can write or download file from encoded Base64 string:


Worked for me and hopefully for you also...


If you are already adding AWS SDK for Java, you can use com.amazonaws.util.Base64.


The Java 8 implementation of java.util.Base64 has no dependencies on other Java 8 specific classes.


I am not certain if this will work for Java 6 project, but it is possible to copy and paste the Base64.java file into a Java 7 project and compile it with no modification other than importing java.util.Arrays and java.util.Objects.


Note the Base64.java file is covered by the GNU GPL2


I used android.util.base64 that works pretty good without any dependances: 


Usage:


package com.test;






I need to randomly shuffle the following Array:


Is there any function to do that?


Using Collections to shuffle an array of primitive types is a bit of an overkill...


It is simple enough to implement the function yourself, using for example the Fisher–Yates shuffle:


Here is a simple way using an ArrayList:


Here is a working and efficient Fisher–Yates shuffle array function:


or


Collections class has an efficient method for shuffling, that can be copied, so as not to depend on it:


Look at the Collections class, specifically shuffle(...).


Here is a complete solution using the Collections.shuffle approach:


Note that it suffers due to Java's inability to smoothly translate between int[] and Integer[] (and thus int[] and List<Integer>).


Using ArrayList<Integer> can help you solving the problem of shuffling without applying much of logic and consuming less time. Here is what I suggest:


You have a couple options here. A list is a bit different than an array when it comes to shuffling.


As you can see below, an array is faster than a list, and a primitive array is faster than an object array.


Below, are three different implementations of a shuffle. You should only use Collections.shuffle if you are dealing with a collection. There is no need to wrap your array into a collection just to sort it. The methods below are very simple to implement.


Simple utility methods to copy and convert arrays to lists and vice-versa.


Generates a range of values, similar to Python's range function.


The following code will achieve a random ordering on the array. 


from: http://www.programcreek.com/2012/02/java-method-to-shuffle-an-int-array-with-random-order/


Here is a Generics version for arrays:


Considering that ArrayList is basically just an array, it may be advisable to work with an ArrayList instead of the explicit array and use Collections.shuffle(). Performance tests however, do not show any significant difference between the above and Collections.sort():


The Apache Commons implementation MathArrays.shuffle is limited to int[] and the performance penalty is likely due to the random number generator being used.


By the way, I've noticed that this code returns a ar.length - 1 number of elements, so if your array has 5 elements, the new shuffled array will have 4 elements. This happens because the for loop says i>0. If you change to i>=0, you get all elements shuffled.


You can use java 8 now:


I'm weighing in on this very popular question because nobody has written a shuffle-copy version. Style is borrowed heavily from Arrays.java, because who isn't pillaging Java technology these days? Generic and int implementations included.


This is knuth shuffle algorithm.


There is another way also, not post yet


that way more easy, depended of the context


The most simple solution for this Random Shuffling in an Array.


Here is a solution using Apache Commons Math 3.x (for int[] arrays only):


http://commons.apache.org/proper/commons-math/javadocs/api-3.6.1/org/apache/commons/math3/util/MathArrays.html#shuffle(int[])


Alternatively, Apache Commons Lang 3.6 introduced new shuffle methods to the ArrayUtils class (for objects and any primitive type).


http://commons.apache.org/proper/commons-lang/javadocs/api-release/org/apache/commons/lang3/ArrayUtils.html#shuffle-int:A-


I saw some miss information in some answers so i decided to add a new one.


Java collections Arrays.asList takes var-arg of type T (T ...). If you pass a primitive array (int array), asList method will infer and generate a List<int[]>, which is a one element list (the one element is the primitive array). if you shuffle this one element list, it won`t change any thing.


So, first you have to convert you primitive array to Wrapper object array. for this you can use ArrayUtils.toObject method from apache.commons.lang. then pass the generated array to a List and finaly shuffle that.






I've been looking for a simple Java algorithm to generate a pseudo-random alpha-numeric string.  In my situation it would be used as a unique session/key identifier that would "likely" be unique over 500K+ generation (my needs don't really require anything much more sophisticated).  Ideally, I would be able to specify a length depending on my uniqueness needs. For example, a generated string of length 12 might look something like "AEYGF7K0DM1X".  


To generate a random string, concatenate characters drawn randomly from the set of acceptable symbols until the string reaches the desired length.


Here's some fairly simple and very flexible code for generating random identifiers. Read the information that follows for important application notes.


Create an insecure generator for 8-character identifiers:


Create a secure generator for session identifiers:


Create a generator with easy-to-read codes for printing. The strings are longer than full alphanumeric strings to compensate for using fewer symbols:


Generating session identifiers that are likely to be unique is not good enough, or you could just use a simple counter. Attackers hijack sessions when predictable identifiers are used.


There is tension between length and security. Shorter identifiers are easier to guess, because there are fewer possibilities. But longer identifiers consume more storage and bandwidth. A larger set of symbols helps, but might cause encoding problems if identifiers are included in URLs or re-entered by hand.


The underlying source of randomness, or entropy, for session identifiers should come from a random number generator designed for cryptography. However, initializing these generators can sometimes be computationally expensive or slow, so effort should be made to re-use them when possible.


Not every application requires security. Random assignment can be an efficient way for multiple entities to generate identifiers in a shared space without any coordination or partitioning. Coordination can be slow, especially in a clustered or distributed environment, and splitting up a space causes problems when entities end up with shares that are too small or too big.


Identifiers generated without taking measures to make them unpredictable should be protected by other means if an attacker might be able to view and manipulate them, as happens in most web applications. There should be a separate authorization system that protects objects whose identifier can be guessed by an attacker without access permission.


Care must be also be taken to use identifiers that are long enough to make collisions unlikely given the anticipated total number of identifiers. This is referred to as "the birthday paradox." The probability of a collision, p, is approximately n2/(2qx), where n is the number of identifiers actually generated, q is the number of distinct symbols in the alphabet, and x is the length of the identifiers. This should be a very small number, like 2‑50 or less.


Working this out shows that the chance of collision among 500k 15-character identifiers is about 2‑52, which is probably less likely than undetected errors from cosmic rays, etc.


According to their specification, UUIDs are not designed to be unpredictable, and should not be used as session identifiers.


UUIDs in their standard format take a lot of space: 36 characters for only 122 bits of entropy. (Not all bits of a "random" UUID are selected randomly.) A randomly chosen alphanumeric string packs more entropy in just 21 characters.


UUIDs are not flexible; they have a standardized structure and layout. This is their chief virtue as well as their main weakness. When collaborating with an outside party, the standardization offered by UUIDs may be helpful. For purely internal use, they can be inefficient.


Java supplies a way of doing this directly. If you don't want the dashes, they are easy to strip out. Just use uuid.replace("-", "")


Output:


If you're happy to use Apache classes, you could use org.apache.commons.text.RandomStringGenerator (commons-text).


Example:


Since commons-lang 3.6, RandomStringUtils is deprecated.


In one line:


http://mynotes.wordpress.com/2009/07/23/java-generating-random-string/


You can use Apache library for this: RandomStringUtils


using Dollar should be simple as:


it outputs something like that:


Here it is in Java:


Here's a sample run:


Surprising no-one here has suggested it but: 


Easy. 


Benefit of this is UUIDs are nice and long and guaranteed to be almost impossible to collide.


Wikipedia has a good explanation of it: 


" ...only after generating 1 billion UUIDs every second for the next 100 years, the probability of creating just one duplicate would be about 50%."


http://en.wikipedia.org/wiki/Universally_unique_identifier#Random_UUID_probability_of_duplicates


The first 4 bits are the version type and 2 for the variant so you get 122 bits of random. So if you want to you can truncate from the end to reduce the size of the UUID. It's not recommended but you still have loads of randomness, enough for your 500k records easy.


A short and easy solution, but uses only lowercase and numerics:


The size is about 12 digits to base 36 and can't be improved further, that way. Of course you can append multiple instances.


This is easily achievable without any external libraries.


First you need a cryptographic PRNG. Java has SecureRandom for that typically uses the best entropy source on the machine (e.g. /dev/random) . Read more here.


Note: SecureRandom is the slowest, but most secure way in Java of generating random bytes. I do however recommend NOT considering performance here since it usually has no real impact on your application unless you have to generate millions of tokens per second.


Next you have to decide "how unique" your token needs to be. The whole and only point of considering entropy is to make sure that the system can resist brute force attacks: the space of possible values must be so large that any attacker could only try a negligible proportion of the values in non-ludicrous time1. Unique identifiers such as random UUID have 122bit of entropy (ie. 2^122 = 5.3x10^36) - the chance of collision is "*(...) for there to be a one in a billion chance of duplication, 103 trillion version 4 UUIDs must be generated2". We will choose 128 bit since it fits exactly into 16 bytes and is seen as highly sufficient for being unique for basically every, but the most extreme, use cases and you don't have to think about duplicates. Here is a simple comparison table of entropy including simple analysis of the birthday problem.





For simple requirements 8 or 12 byte length might suffice, but with 16 bytes you are on the "safe side".


And that's basically it. Last thing is to think about encoding so it can be represented as a printable text (read, a String).


Typical encodings include:


Base64 every character encodes 6bit creating a 33% overhead. Unfortunatly there is no standard implementation in the JDK (there is in Android). But numerous libraries exist that add this. The downside is, that Base64 is not safe for eg. urls and as filename in most file systems requiring additional encoding (e.g. url encoding). Example encoding 16 bytes with padding: XfJhfv3C0P6ag7y9VQxSbw==


Base32 every character encodes 5bit creating a 40% overhead. This will use A-Z and 2-7 making it reasonably space efficient while being case-insensitive alpha-numeric. Like with Base64 there is no standard implementation in JDK. Example encoding 16 bytes without padding: WUPIL5DQTZGMF4D3NX5L7LNFOY


Base16 (hex) every character encodes 4bit requiring 2 characters per byte (ie. 16 byte create a string of length 32). Therefore hex is less space efficient than Base32 but is safe to use in most cases (url) since it only uses 0-9 and A to F. Example encoding 16 bytes: 4fa3dd0f57cb3bf331441ed285b27735. See a SO discussion about converting to hex here.


Additional encodings like Base85 and the exotic Base122 exist with better/worse space efficiency. You can create your own encoding (which basically most answers in this thread do) but I would advise against it, if you don't have very specific requirements. See more encoding schemes in the Wikipedia article.


Don't


If you want a ready-to-use cli tool you may use dice: https://github.com/patrickfav/dice


An alternative in Java 8 is:


So what this does is just add's the password into the string and ... yeah works good check it out... very simple. I wrote it


Using UUIDs is insecure, because parts of the UUID arn't random at all. The procedure of @erickson is very neat, but does not create strings of the same length. The following snippet should be sufficient:


Why choosing length*5. Let's assume the simple case of a random string of length 1, so one random character. To get a random character containing all digits 0-9 and characters a-z, we would need a random number between 0 and 35 to get one of each character. BigInteger provides a constructor to generate a random number, uniformly distributed over the range 0 to (2^numBits - 1). Unfortunately 35 is no number which can be received by 2^numBits - 1. So we have two options: Either go with 2^5-1=31 or 2^6-1=63. If we would choose 2^6 we would get a lot of "unnecesarry" / "longer" numbers. Therefore 2^5 is the better option, even if we loose 4 characters (w-z). To now generate a string of a certain length, we can simply use a 2^(length*numBits)-1 number. The last problem, if we want a string with a certain length, random could generate a small number, so the length is not met, so we have to pad the string to it's required length prepending zeros.


I found this solution that generates a random hex encoded string.  The provided unit test seems to hold up to my primary use case.  Although, it is slightly more complex than some of the other answers provided.


Change String characters as per as your requirements.


String is immutable. Here StringBuilder.append is more efficient than string concatenation.





You can use following code , if your password mandatory contains numbers alphabetic special characters:


Here is the one line code by AbacusUtil


Random doesn't mean it must be unique. to get unique strings, using:


You mention "simple", but just in case anyone else is looking for something that meets more stringent security requirements, you might want to take a look at jpwgen.  jpwgen is modeled after pwgen in Unix, and is very configurable.


Here it is a Scala solution:


using apache library it can be done in one line


here is doc http://commons.apache.org/lang/api-2.3/org/apache/commons/lang/RandomStringUtils.html


Maybe this is helpful


Best Random String Generator Method


Lots of use of StringBuilder above.  I guess it's easy, but requires a function call per char, growing an array, etc...
If using the stringbuilder, a suggestion is to specify the required capacity of the string ie.,


Here's a version that doesn't use a StringBuilder or String appending, and no dictionary.


You can create a character array which includes all the letters and numbers, then you can randomly select from this char array and create your own string password.






Consider the below code:


So, I want to copy the 'dum' to 'dumtwo' and I want to change 'dum' without affecting the 'dumtwo'. But the above code is not doing that. When I change something in 'dum', the same change is happening in 'dumtwo' also.


I guess, when I say dumtwo = dum, Java copies the reference only. So, is there any way to create a fresh copy of 'dum' and assign it to 'dumtwo'?


Create a copy constructor:


Every object has also a clone method which can be used to copy the object, but don't use it. It's way too easy to create a class and do improper clone method. If you are going to do that, read at least what Joshua Bloch has to say about it in Effective Java.


Basic: Object Copying in Java.


Let us Assume an object- obj1, that contains two objects, containedObj1 and containedObj2. 



shallow copying:
shallow copying creates a new instance of the same class and copies all the fields to the new instance and returns it. Object class provides a clone method and provides support for the shallow copying.



Deep copying:
A deep copy occurs when an object is copied along with the objects to which it refers. Below image shows obj1 after a deep copy has been performed on it. Not only has obj1 been copied, but the objects contained within it have been copied as well. We can use Java Object Serialization to make a deep copy. Unfortunately, this approach has some problems too(detailed examples). 



Possible Problems:
clone is tricky to implement correctly.
It's better to use Defensive copying, copy constructors(as @egaga reply) or static factory methods.


For example org.apache.commons.lang.SerializationUtils will have method for Deep clone using serialization(Source). If we need to clone Bean then there are couple of utility methods in org.apache.commons.beanutils (Source).


Just follow as below:


and wherever you want to get another object, simple perform cloning.
e.g: 


In the package import org.apache.commons.lang.SerializationUtils; there is a method:


Example:


Why is there no answer for using Reflection API?


It's really simple.


EDIT: Include child object via recursion


Yes, you are just making a reference to the object. You can clone the object if it implements Cloneable.


Check out this wiki article about copying objects.


Refer here: Object copying


I use Google's JSON library to serialize it then create a new instance of the serialized object. It does deep copy with a few restrictions:


there can't be any recursive references


it won't copy arrays of disparate types


arrays and lists should be typed or it won't find the class to instantiate


you may need to encapsulate strings in a class you declare yourself


I also use this class to save user preferences, windows and whatnot to be reloaded at runtime. It is very easy to use and effective.


Yes. You need to Deep Copy your object.


Add Cloneable and below code to your class


Use this  clonedObject = (YourClass) yourClassObject.clone();


To do that you have to clone the object in some way. Although Java has a cloning mechanism, don't use it if you don't have to. Create a copy method that does the copy work for you, and then do:


Here is some more advice on different techniques for accomplishing a copy.


Here's a decent explanation of clone() if you end up needing it...


Here: clone (Java method)


Use a deep cloning utility: 


This will deep copy any java object, check it out at https://github.com/kostaskougios/cloning


Other than explicitly copying, another approach is to make the object immutable (no set or other mutator methods). In this way the question never arises. Immutability becomes more difficult with larger objects, but that other side of that is that it pushes you in the direction of splitting into coherent small objects and composites.


Deep Cloning is your answer, which requires implementing the Cloneable interface and overriding the clone() method.


You will call it like this
DummyBean dumtwo = dum.clone();


This works too. Assuming model


First add
compile 'com.google.code.gson:gson:2.8.1' to your app>gradle & sync. Then


You can exclude using a field by using transient keyword after access modifier.


Note: This is bad practice. Also don't recommend to use Cloneable or JavaSerialization It's slow and broken. Write copy constructor for best performance ref.


Something like


Test stats of 90000 iteration:
Line UserAccount clone = gson.fromJson(gson.toJson(aO), UserAccount.class); takes 808ms


Line UserAccount clone = new UserAccount(aO); takes less than 1ms


Conclusion: Use gson if your boss is crazy and you prefer speed. Use second copy constructor if you prefer quality.


You can also use copy constructor code generator plugin in Android Studio.


You can deep copy automatically with XStream, from http://x-stream.github.io/:


XStream is a simple library to serialize objects to XML and back
  again.


Add it to your project (if using maven)


Then


With this you have a copy without the need to implement any cloning interface.


Pass the object whcih you wants to copy and get the object which you wants ,


Now parse the objDest to desigered object.


Happy Coding


You can try to implement Cloneable and use the clone() method; however, if you use the clone method you should - by standard - ALWAYS override Object's public Object clone() method.


If you can add an annotation to the source file, an annotation processor or code generator like this one can be used.


A class DummyBeanBuilders will be generates, which has a static method dummyBeanUpdater to create shallow copies, the same way as you would do it manually.






I need to concatenate two String arrays in Java.


What is the easiest way to do this?


I found a one-line solution from the good old Apache Commons Lang library. ArrayUtils.addAll(T[], T...)


Code:


Here's a method that will concatenate 2 arrays of type Foo (replace Foo in the code with your classname in question).


(source: Sun Forum )


Here is a version that works with generics:


Note like all generics it will not work with primitives but with Objects.


It's possible to write a fully generic version that can even be extended to concatenate any number of arrays. This versions require Java 6, as they use Arrays.copyOf()


Both versions avoid creating any intermediary List objects and use System.arraycopy() to ensure that copying large arrays is as fast as possible.


For two arrays it looks like this:


And for a arbitrary number of arrays (>= 1) it looks like this:


One-liner in Java 8:


Or:


Or with the beloved Guava:


Also, there are versions for primitive arrays:


Using the Java API:


A solution 100% old java and without System.arraycopy (not available in GWT client for example):


I've recently fought problems with excessive memory rotation. If a and/or b are known to be commonly empty, here is another adaption of silvertab's code (generified too):


(In either case, array re-usage behaviour shall be clearly JavaDoced!)


The Functional Java library has an array wrapper class that equips arrays with handy methods like concatenation.


...and then


To get the unwrapped array back out, call


Here's an adaptation of silvertab's solution, with generics retrofitted:


NOTE: See Joachim's answer for a Java 6 solution. Not only does it eliminate the warning; it's also shorter, more efficient and easier to read!


Another way with Java8 using Stream


If you use this way so you no need to import any third party class.


If you want concatenate String


Sample code for concate two String Array


If you want concatenate Int


Sample code for concate two Integer Array


Here is Main method


We can use this way also.


Please forgive me for adding yet another version to this already long list. I looked at every answer and decided that I really wanted a version with just one parameter in the signature. I also added some argument checking to benefit from early failure with sensible info in case of unexpected input.


You could try converting it into a Arraylist and use the addAll method then convert back to an array.


Here a possible implementation in working code of the pseudo code solution written by silvertab. 


Thanks silvertab!


Following next is the builder interface. 


Note: A builder is necessary because in java it is not possible to do 


new T[size] 


due to generic type erasure:


Here a concrete builder implementing the interface, building a Integer array:


And finally the application / test:


Wow! lot of complex answers here including some simple ones that depend on external dependencies. how about doing it like this:


This is a converted function for a String array:


How about simply    


And just do Array.concat(arr1, arr2). As long as arr1 and arr2 are of the same type, this will give you another array of the same type containing both arrays. 


Using only Javas own API:


Now, this code ist not the most efficient, but it relies only on standard java classes and is easy to understand. It works for any number of String[] (even zero arrays).


Here's my slightly improved version of Joachim Sauer's concatAll. It can work on Java 5 or 6, using Java 6's System.arraycopy if it's available at runtime. This method (IMHO) is perfect for Android, as it work on Android <9 (which doesn't have System.arraycopy) but will use the faster method if possible.


Another way to think about the question. To concatenate two or more arrays, one have to do is to list all elements of each arrays, and then build a new array. This sounds like create a List<T> and then calls toArray on it. Some other answers uses ArrayList, and that's fine. But how about implement our own? It is not hard:


I believe the above is equivalent to solutions that uses System.arraycopy. However I think this one has its own beauty. 


How about :


A simple variation allowing the joining of more than one array:


This works, but you need to insert your own error checking.



It's probably not the most efficient, but it doesn't rely on anything other than Java's own API.


A type independent variation (UPDATED - thanks to Volley for instantiating T):


If you'd like to work with ArrayLists in the solution, you can try this:


An easy, but inefficient, way to do this (generics not included):






Is there a limit to the number of elements a Java array can contain? If so, what is it?


Haven't seen the right answer, even though it's very easy to test.


In a recent HotSpot VM, the correct answer is Integer.MAX_VALUE - 5.  Once you go beyond that:


You get:


This is (of course) totally VM-dependent.


Browsing through the source code of OpenJDK 7 and 8 java.util.ArrayList, .Hashtable, .AbstractCollection,  .PriorityQueue, and .Vector, you can see this claim being repeated:


which is added by Martin Buchholz (Google) on 2010-05-09; reviewed by Chris Hegarty (Oracle).


So,  probably  we can say that the maximum "safe" number would be  2 147 483 639 (Integer.MAX_VALUE - 8) and "attempts to allocate larger arrays may result in OutOfMemoryError".


(Yes, Buchholz's standalone claim does not include backing evidence, so this is a calculated appeal to authority. Even within OpenJDK itself, we can see code like return (minCapacity > MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; which shows that MAX_ARRAY_SIZE does not yet have a real use.)


There are actually two limits.  One, the maximum element indexable for the array and, two, the amount of memory available to your application.  Depending on the amount of memory available and the amount used by other data structures, you may hit the memory limit before you reach the maximum addressable array element.


Going by this article http://en.wikipedia.org/wiki/Criticism_of_Java#Large_arrays:


Java has been criticized for not supporting arrays of more than 231−1 (about 2.1 billion) elements. This is a limitation of the language; the Java Language Specification, Section 10.4, states that:


Arrays must be indexed by int values... An attempt to access an array
    component with a long index value results in a compile-time error.


Supporting large arrays would also require changes to the JVM. This limitation manifests itself in areas such as collections being limited to 2 billion elements and the inability to memory map files larger than 2 GiB. Java also lacks true multidimensional arrays (contiguously allocated single blocks of memory accessed by a single indirection), which limits performance for scientific and technical computing.


Arrays are non-negative integer indexed , so maximum array size you can access would be Integer.MAX_VALUE. The other thing is how big array you can create. It depends on the maximum memory available to your JVM and the content type of the array. Each array element has it's size, example. byte = 1 byte, int = 4 bytes, Object reference = 4 bytes (on a 32 bit system) 


So if you have 1 MB memory available on your machine, you could allocate an array of byte[1024 * 1024] or Object[256 * 1024]. 


Answering your question - You can allocate an array of size (maximum available memory / size of array item).   


Summary - Theoretically the maximum size of an array will be Integer.MAX_VALUE. Practically it depends on how much memory your JVM has and how much of that has already been allocated to other objects.


Maximum number of elements of an array is (2^31)−1 or 2 147 483 647 


I tried to create a byte array like this


With this run configuration:


And java version:


Openjdk version "1.8.0_141" 


OpenJDK Runtime Environment (build 1.8.0_141-b16) 


OpenJDK 64-Bit Server VM (build 25.141-b16, mixed mode)


It only works for x >= 2 which means the maximum size of an array is Integer.MAX_VALUE-2


Values above that give


Exception in thread "main" java.lang.OutOfMemoryError: Requested array size exceeds VM limit
      at Main.main(Main.java:6)






What is the difference between a wait() and sleep() in Threads?


Is my understanding that a wait()-ing Thread is still in running mode and uses CPU cycles but a sleep()-ing does not consume any CPU cycles correct?


Why do we have both wait() and sleep(): how does their implementation vary at a lower level?


A wait can be "woken up" by another thread calling notify on the monitor which is being waited on whereas a sleep cannot. Also a wait (and notify) must happen in a block synchronized on the monitor object whereas sleep does not:


At this point the currently executing thread waits and releases the monitor. Another thread may do


(On the same mon object) and the first thread (assuming it is the only thread waiting on the monitor) will wake up. 


You can also call notifyAll if more than one thread is waiting on the monitor - this will wake all of them up. However, only one of the threads will be able to grab the monitor (remember that the wait is in a synchronized block) and carry on - the others will then be blocked until they can acquire the monitor's lock.


Another point is that you call wait on Object itself (i.e. you wait on an object's monitor) whereas you call sleep on Thread.


Yet another point is that you can get spurious wakeups from wait (i.e. the thread which is waiting resumes for no apparent reason). You should always wait whilst spinning on some condition as follows:  


One key difference not yet mentioned is that while sleeping a Thread does not release the locks it holds, while waiting releases the lock on the object that wait() is called on.


I found this link helpful (which references this post). It puts the difference between sleep(), wait(), and yield() in human terms. (in case the links ever go dead I've included the post below with additional markup)


It all eventually makes its way down to the OS’s scheduler, which
  hands out timeslices to processes and threads.


sleep(n) says “I’m done with my timeslice, and please don’t give me
  another one for at least n milliseconds.” The OS doesn’t even try to
  schedule the sleeping thread until requested time has passed.


yield() says “I’m done with my timeslice, but I still have work to
  do.” The OS is free to immediately give the thread another timeslice,
  or to give some other thread or process the CPU the yielding thread
  just gave up.


.wait() says “I’m done with my timeslice. Don’t give me another
  timeslice until someone calls notify().” As with sleep(), the OS won’t
  even try to schedule your task unless someone calls notify() (or one of
  a few other wakeup scenarios occurs).


Threads also lose the remainder of their timeslice when they perform
  blocking IO and under a few other circumstances. If a thread works
  through the entire timeslice, the OS forcibly takes control roughly as
  if yield() had been called, so that other processes can run.


You rarely need yield(), but if you have a compute-heavy app with
  logical task boundaries, inserting a yield() might improve system
  responsiveness (at the expense of time — context switches, even just
  to the OS and back, aren’t free). Measure and test against goals you
  care about, as always.


There are a lot of answers here but I couldn't find the semantic distinction mentioned on any.


It's not about the thread itself; both methods are required as they support very different use-cases.


sleep() sends the Thread to sleep as it was before, it just packs the context and stops executing for a predefined time. So in order to wake it up before the due time, you need to know the Thread reference. This is not a common situation in a multi-threaded environment. It's mostly used for time-synchronization (e.g. wake in exactly 3.5 seconds) and/or hard-coded fairness (just sleep for a while and let others threads work).


wait(), on the contrary, is a thread (or message) synchronization mechanism that allows you to notify a Thread of which you have no stored reference (nor care). You can think of it as a publish-subscribe pattern (wait == subscribe and notify() == publish). Basically using notify() you are sending a message (that might even not be received at all and normally you don't care).


To sum up, you normally use sleep() for time-syncronization and wait() for multi-thread-synchronization.


They could be implemented in the same manner in the underlying OS, or not at all (as previous versions of Java had no real multithreading; probably some small VMs doesn't do that either). Don't forget Java runs on a VM, so your code will be transformed in something different according to the VM/OS/HW it runs on.


There are some difference key notes i conclude after working on wait and sleep, first take a look on sample using wait() and sleep():


Example1: using wait() and sleep():


Let clarity some key notes:


you normally use sleep() for time-syncronization and wait() for
  multi-thread-synchronization.


Please correct me if i'm wrong.


Here are few important differences between wait() and sleep() methods.


wait() method needs to be called from a loop in order to deal with false alarm.


wait() method must be called from synchronized context (i.e.  synchronized method or block), otherwise  it will throw IllegalMonitorStateException


Ref: Difference between Wait and Sleep


Code snippet for calling wait and sleep method





Difference between wait() and sleep()


The fundamental difference is wait() is from Object and sleep() is static method of Thread.


The major difference is that wait() releases the lock while sleep() doesn’t releas any lock while waiting. 


The wait() is used for inter-thread communication while sleep() is used to introduce pause on execution, generally.


The wait() should call from inside synchronise or else we get IllegalMonitorStateException  while sleep()  can call anywhere.


Similarities which helps understand 


This is a very simple question, because both these methods have a totally different use. 


The major difference is to wait to release the lock or monitor while sleep doesn't release any lock or monitor while waiting. Wait is used for inter-thread communication while sleep is used to introduce pause on execution. 


This was just a clear and basic explanation, if you want more than that then continue reading.


In case of wait() method thread goes in waiting state and it won't come back automatically until we call the notify() method (or notifyAll() if you have more then one thread in waiting state and you want to wake all of those thread). And you need synchronized or object lock or class lock to access the wait() or notify() or notifyAll() methods. And one more thing, the wait() method is used for inter-thread communication because if a thread goes in waiting state you'll need another thread to wake that thread.


But in case of sleep() this is a method which is used to hold the process for few seconds or the time you wanted. Because you don't need to provoke any notify() or notifyAll() method to get that thread back. Or you don't need any other thread to call back that thread. Like if you want something should happen after few seconds like in a game after user's turn you want the user to wait until the computer plays then you can mention the sleep() method.


And one more important difference which is asked often in interviews: sleep() belongs to Thread class and wait() belongs to Object class.


These are all the differences between sleep() and wait().


And there is a similarity between both methods: they both are checked statement so you need try catch or throws to access these methods.


I hope this will help you.


source : http://www.jguru.com/faq/view.jsp?EID=47127


Thread.sleep() sends the current thread into the "Not Runnable" state
  for some amount of time. The thread keeps the monitors it has aquired
  -- i.e. if the thread is currently in a synchronized block or method no other thread can enter this block or method. If another thread calls t.interrupt() it will wake up the sleeping thread.


Note that sleep is a static method, which means that it always affects
  the current thread (the one that is executing the sleep method). A
  common mistake is to call t.sleep() where t is a different thread;
  even then, it is the current thread that will sleep, not the t thread.


t.suspend() is deprecated. Using it is possible to halt a thread other
  than the current thread. A suspended thread keeps all its monitors and
  since this state is not interruptable it is deadlock prone.


object.wait() sends the current thread into the "Not Runnable" state,
  like sleep(), but with a twist. Wait is called on an object, not a
  thread; we call this object the "lock object." Before lock.wait() is
  called, the current thread must synchronize on the lock object; wait()
  then releases this lock, and adds the thread to the "wait list"
  associated with the lock. Later, another thread can synchronize on the
  same lock object and call lock.notify(). This wakes up the original,
  waiting thread. Basically, wait()/notify() is like
  sleep()/interrupt(), only the active thread does not need a direct
  pointer to the sleeping thread, but only to the shared lock object.


Wait and sleep are two different things: 


sleep is a method of Thread, wait is a method of Object, so wait/notify is a technique of synchronizing shared data in Java (using monitor), but sleep is a simple method of thread to pause itself.


sleep() is a method which is used to hold the process for few seconds or the time you wanted but in case of wait() method thread goes in waiting state and it won’t come back automatically until we call the notify() or notifyAll().


The major difference is that wait() releases the lock or monitor while sleep() doesn’t releases any lock or monitor while waiting. Wait is used for inter-thread communication while sleep is used to introduce pause on execution, generally.


Thread.sleep() sends the current thread into the “Not Runnable” state for some amount of time. The thread keeps the monitors it has acquired — i.e. if the thread is currently in a synchronized block or method no other thread can enter this block or method. If another thread calls t.interrupt() it will wake up the sleeping thread. Note that sleep is a static method, which means that it always affects the current thread (the one that is executing the sleep method). A common mistake is to call t.sleep() where t is a different thread; even then, it is the current thread that will sleep, not the t thread.


object.wait() sends the current thread into the “Not Runnable” state, like sleep(), but with a twist. Wait is called on an object, not a thread; we call this object the “lock object.” Before lock.wait() is called, the current thread must synchronize on the lock object; wait() then releases this lock, and adds the thread to the “wait list” associated with the lock. Later, another thread can synchronize on the same lock object and call lock.notify(). This wakes up the original, waiting thread. Basically, wait()/notify() is like sleep()/interrupt(), only the active thread does not need a direct pointer to the sleeping thread, but only to the shared lock object.


Let categorize all above points :


Call on:


Synchronized:


Hold lock:


Wake-up condition:


Usage:


Ref:diff sleep and wait


wait and sleep methods are very different:


Come to think about it, the names are confusing in that respect; however sleep is a standard name and wait is like the WaitForSingleObject or WaitForMultipleObjects in the Win API.


In simple words, wait is wait Until some other thread invokes you whereas sleep is "dont execute next statement" for some specified period of time.


Moreover sleep is static method in Thread class and it operates on thread, whereas wait() is in Object class and called on an object.


Another point, when you call wait on some object, the thread involved synchronize the object and then waits. :)


From this post : http://javaconceptoftheday.com/difference-between-wait-and-sleep-methods-in-java/


1) The thread which calls wait() method releases the lock it holds.


2) The thread regains the lock after other threads call either notify() or notifyAll() methods on the same lock.


3) wait() method must be called within the synchronized block.


4) wait() method is always called on objects.


5) Waiting threads can be woken up by other threads by calling notify() or notifyAll() methods.


6) To call wait() method, thread must have object lock.


1) The thread which calls sleep() method doesn’t release the lock it holds.


2) sleep() method can be called within or outside the synchronized block.


3) sleep() method is always called on threads.


4) Sleeping threads can not be woken up by other threads. If done so, thread will throw InterruptedException.


5) To call sleep() method, thread need not to have object lock.


sleep


Wait


wait() is a method of Object class.
sleep() is a method of Thread class.


sleep() allows the thread to go to sleep state for x milliseconds. 
When a thread goes into sleep state it doesn’t release the lock. 


wait() allows thread to release the lock and goes to suspended state. 
This thread will be active when a notify() or notifAll() method is 
called  for the same object.


One potential big difference between sleep/interrupt and wait/notify is that


Generating an exception when not needed is inefficient.  If you have threads communicating with each other at a high rate, then it would be generating a lot of exceptions if you were calling interrupt all the time, which is a total waste of CPU.


You are correct - Sleep() causes that thread to "sleep" and the CPU will go off and process other threads (otherwise known as context switching) wheras I believe Wait keeps the CPU processing the current thread.


We have both because although it may seem sensible to let other people use the CPU while you're not using it, actualy there is an overhead to context switching - depending on how long the sleep is for, it can be more expensive in CPU cycles to switch threads than it is to simply have your thread doing nothing for a few ms.


Also note that sleep forces a context switch.  


Also - in general it's not possible to control context switching - during the Wait the OS may (and will for longer waits) choose to process other threads.


The methods are used for different things.


Thread.sleep(n) can be interrupted, but Object.wait() must be notified.
It's possible to specify the maximum time to wait: Object.wait(5000) so it would be possible to use wait to, er, sleep but then you have to bother with locks.


Neither of the methods uses the cpu while sleeping/waiting. 


The methods are implemented using native code, using similar constructs but not in the same way.


Look for yourself: Is the source code of native methods available? The file /src/share/vm/prims/jvm.cpp is the starting point...


Here wait() will be in the waiting state till it notify by another Thread but where as sleep() will be having some time..after that it will automatically transfer to the Ready state...


Wait() and sleep() Differences?


Thread.sleep()
     Once its work completed then only its release the lock to everyone. until its never release the lock to anyone.


Object.wait()
    When  its going to waiting stage, its will be release the key and its waiting for some of the seconds based on the parameter. 


For Example:


you are take the coffee in yours right hand, you can take another anyone of the same hand, when will your put down then only take another object same type here. also. this is sleep()
 you sleep time you didn't any work, you are doing only sleeping.. same here also.


wait(). when you are put down and take another one mean while you are waiting , that's wait


you are play movie or anything in yours system same as player you can't play more than one at a time right, thats its here, when you close and choose another anyone movie or song mean while is called wait


In my opinion, the main difference between both mechanisms is that sleep/interrupt is the most basic way of handling threads, whereas wait/notify is an abstraction aimed to do thread inter-communication easier. This means that sleep/interrupt can do anything, but that this specific task is harder to do.


Why is wait/notify more suitable? Here are some personal considerations:


It enforces centralization. It allows to coordinate the communication between a group of threads with a single shared object. This simplifies the work a lot.


It enforces synchronization. Because it makes the programmer wrap the call to wait/notify in a synchronized block.


It's independent of the thread origin and number. With this approach you can add more threads arbitrarily without editing the other threads or keeping a track of the existing ones. If you used sleep/interrupt, first you would need to keep the references to the sleeping threads, and then interrupt them one by one, by hand.


An example from the real life that is good to explain this is a classic restaurant and the method that the personnel use to communicate among them: The waiters leave the customer requests in a central place (a cork board, a table, etc.), ring a bell, and the workers from the kitchen come to take such requests. Once that there is any course ready, the kitchen personnel ring the bell again so that the waiters are aware and take them to the customers.


Example about sleep doesn’t release lock and wait does


Here there are two classes :


Singleton : This is singleton class with two static methods getInstance() and getInstance(boolean isWait).


and


Now run this example you will get below output :


Here Singleton instances created by threadA and threadB are same. It means threadB is waiting outside until threadA release it’s lock.


Now change the Singleton.java by commenting Thread.sleep(500); method and uncommenting Singleton.class.wait(500); . Here because of Singleton.class.wait(500); method threadA will release all acquire locks and moves into the “Non Runnable” state, threadB will get change to enter in synchronized block.


Now run again :


Here Singleton instances created by threadA and threadB are NOT same because of threadB got change to enter in synchronised block and after 500 milliseconds threadA started from it’s last position and created one more Singleton object.


Should be called from synchronized block : wait() method is always called from synchronized block i.e. wait() method needs to lock object monitor before object on which it is called.  But sleep() method can be called from outside synchronized block i.e. sleep() method doesn’t need any object monitor.


IllegalMonitorStateException : if wait() method is called without acquiring object lock than IllegalMonitorStateException is thrown at runtime, but sleep() method never throws such exception.


Belongs to which class : wait() method belongs to java.lang.Object class but sleep() method belongs to java.lang.Thread class.


Called on object or thread : wait() method is called on objects but sleep() method is called on Threads not objects.


Thread state : when wait() method is called on object, thread that holded object’s monitor goes from running to waiting state and can return to runnable state only when notify() or notifyAll() method is called on that object. And later thread scheduler schedules that thread to go from from runnable to running state. 
when sleep() is called on thread it goes from running to waiting state and can return to runnable state when sleep time is up.


When called from synchronized block : when wait() method is called thread leaves the object lock.  But sleep() method when called from synchronized block or method thread doesn’t leaves object lock.


For More Reference


From oracle documentation page on wait() method of Object:


This method throws


IllegalMonitorStateException - if the current thread is not the owner of the object's monitor.


InterruptedException - if any thread interrupted the current thread before or while the current thread was waiting for a notification. The interrupted status of the current thread is cleared when this exception is thrown.


From oracle documentation page on sleep() method of Thread class:


This method throws:


IllegalArgumentException - if the value of millis is negative


InterruptedException - if any thread has interrupted the current thread. The interrupted status of the current thread is cleared when this exception is thrown.


Other key difference:


wait() is a non-static method (instance method) unlike static method sleep() (class method). 


wait releases the lock and sleep doesn't. A thread in waiting state is eligible for waking up as soon as notify or notifyAll is called. But in case of sleep the thread keeps the lock and it'll only be eligible once the sleep time is over.


Lets assume you are hearing songs.


As long as the current song is running, the next song wont play, i.e Sleep() called by next song


If you finish the song it will stop and until you select play button(notify()) it wont play, i.e wait() called by current song.


In this both cases songs going to Wait states.


wait() is given inside a synchronized method 
whereas sleep() is given inside a non-synchronized method because wait() method release the lock on the object but sleep() or yield() does release the lock().


sleep() method causes the current thread to move from running state to block state for a specified time. If the current thread has the lock of any object then it keeps holding it, which means that other threads cannot execute any synchronized method in that class object.


wait() method causes the current thread to go into block state either for a specified time or until notify, but in this case the thread releases the lock of the object (which means that other threads can execute any synchronized methods of the calling object.






I am a Java programmer who is new to the corporate world. Recently I've developed an application using Groovy and Java. All through the code I wrote used quite a good number of statics. I was asked by the senior technical lot to cut down on the number of statics used. I've googled about the same, and I find that many programmers are fairly against using static variables.


I find static variables more convenient to use. And I presume that they are efficient too (please correct me if I am wrong), because if I had to make 10,000 calls to a function within a class, I would be glad to make the method static and use a straightforward Class.methodCall() on it instead of cluttering the memory with 10,000 instances of the class, right?


Moreover statics reduce the inter-dependencies on the other parts of the code. They can act as perfect state holders. Adding to this I find that statics are widely implemented in some languages like Smalltalk and Scala. So why is this oppression for statics prevalent among programmers (especially in the world of Java)?


PS: please do correct me if my assumptions about statics are wrong.


Static variables represent global state. That's hard to reason about and hard to test: if I create a new instance of an object, I can reason about its new state within tests. If I use code which is using static variables, it could be in any state - and anything could be modifying it.


I could go on for quite a while, but the bigger concept to think about is that the tighter the scope of something, the easier it is to reason about. We're good at thinking about small things, but it's hard to reason about the state of a million line system if there's no modularity. This applies to all sorts of things, by the way - not just static variables.


Its not very object oriented:
One reason statics might be considered "evil" by some people is they are contrary the object-oriented paradigm. In particular, it violates the principle that data is encapsulated in objects (that can be extended, information hiding, etc). Statics, in the way you are describing using them, are essentially to use them as a global variable to avoid dealing with issues like scope. However, global variables is one of the defining characteristics of procedural or imperative programming paradigm, not a characteristic of "good" object oriented code. This is not to say the procedural paradigm is bad, but I get the impression your supervisor expects you to be writing "good object oriented code" and you're really wanting to write "good procedural code". 


There are many gotchyas in Java when you start using statics that are not always immediately obvious. For example, if you have two copies of your program running in the same VM, will they shre the static variable's value and mess with the state of each other? Or what happens when you extend the class, can you override the static member? Is your VM running out of memory because you have insane numbers of statics and that memory cannot be reclaimed for other needed instance objects?


Object Lifetime:
Additionally, statics have a lifetime that matches the entire runtime of the program. This means, even once you're done using your class, the memory from all those static variables cannot be garbage collected. If, for example, instead, you made your variables non-static, and in your main() function you made a single instance of your class, and then asked your class to execute a particular function 10,000 times, once those 10,000 calls were done, and you delete your references to the single instance, all your static variables could be garbage collected and reused. 


Prevents certain re-use:
Also, static methods cannot be used to implement an interface, so static methods can prevent certain object oriented features from being usable.


Other Options:
If efficiency is your primary concern, there might be other better ways to solve the speed problem than considering only the advantage of invocation being usually faster than creation. Consider whether the transient or volatile modifiers are needed anywhere. To preserve the ability to be inlined, a method could be marked as final instead of static. Method parameters and other variables can be marked final to permit certain compiler optimiazations based on assumptions about what can change those variables. An instance object could be reused multiple times rather than creating a new instance each time.  There may be compliler optimization switches that should be turned on for the app in general. Perhaps, the design should be set up so that the 10,000 runs can be multi-threaded and take advantage of multi-processor cores. If portablity isn't a concern, maybe a native method would get you better speed than your statics do.


If for some reason you do not want multiple copies of an object, the singleton design pattern, has advantages over static objects, such as thread-safety (presuming your singleton is coded well), permitting lazy-initialization, guaranteeing the object has been properly initialized when it is used, sub-classing, advantages in testing and refactoring your code, not to mention, if at some point you change your mind about only wanting one instance of an object it is MUCH easier to remove the code to prevent duplicate instances than it is to refactor all your static variable code to use instance variables. I've had to do that before, its not fun, and you end up having to edit a lot more classes, which increases your risk of introducing new bugs...so much better to set things up "right" the first time, even if it seems like it has its disadvantages. For me, the re-work required should you decide down the road you need multiple copies of something is probably one of most compelling reasons to use statics as infrequently as possible. And thus I would also disagree with your statement that statics reduce inter-dependencies, I think you will end up with code that is more coupled if you have lots of statics that can be directly accessed, rather than an object that "knows how to do something" on itself. 


Evil is a subjective term.


You don't control statics in terms of creation and destruction. They live at the behest of the program loading and unloading.   


Since statics live in one space, all threads wishing to use them must go through access control that you have to manage. This means that programs are more coupled and this change is harder to envisage and manage (like J Skeet says). This leads to problems of isolating change impact and thus affects how testing is managed.


These are the two main issues I have with them.


No. Global states are not evil per se. But we have to see your code to see if you used it properly. It is quite possible that a newbie abuses global states; just like he would abuses every language feature.


Global states are absolute necessity. We cannot avoid global states. We cannot avoid reasoning about global states. - If we care to understand our application semantics. 


People who try to get rid of global states for the sake of it, inevitably end up with a much more complex system - and the global states are still there, cleverly/idiotically disguised under many layers of indirections; and we still have to reason about global states, after unwrapping all the indirections.


Like the Spring people who lavishly declare global states in xml and think somehow it's superior.


@Jon Skeet if I create a new instance of an object now you have two things to reason about - the state within the object, and the state of the environment hosting the object. 


There are 2 main problems with static variables:


If you are using the ‘static’ keyword without the ‘final’ keyword, this should be a signal to carefully consider your design. Even the presence of a ‘final’ is not a free pass, since a mutable static final object can be just as dangerous.


I would estimate somewhere around 85% of the time I see a ‘static’ without a ‘final’, it is WRONG. Often, I will find strange workarounds to mask or hide these problems.


Please don’t create static mutables. Especially Collections. In general, Collections should be initialized when their containing object is initialized and should be designed so that they are reset or forgotten about when their containing object is forgotten.


Using statics can create very subtle bugs which will cause sustaining engineers days of pain. I know, because I’ve both created and hunted these bugs.


If you would like more details, please read on…


Why Not Use Statics?


There are many issues with statics, including writing and executing tests, as well as subtle bugs that are not immediately obvious.


Code that relies on static objects can’t be easily unit tested, and statics can’t be easily mocked (usually).


If you use statics, it is not possible to swap the implementation of the class out in order to test higher level components. For example, imagine a static CustomerDAO that returns Customer objects it loads from the database. Now I have a class CustomerFilter, that needs to access some Customer objects. If CustomerDAO is static, I can’t write a test for CustomerFilter without first initializing my database and populating useful information.


And database population and initialization takes a long time. And in my experience, your DB initialization framework will change over time, meaning data will morph, and tests may break. IE, imagine Customer 1 used to be a VIP, but the DB initialization framework changed, and now Customer 1 is no longer VIP, but your test was hard-coded to load Customer 1…


A better approach is to instantiate a CustomerDAO, and pass it into the CustomerFilter when it is constructed. (An even better approach would be to use Spring or another Inversion of Control framework.


Once you do this, you can quickly mock or stub out an alternate DAO in your CustomerFilterTest, allowing you to have more control over the test,


Without the static DAO, the test will be faster (no db initialization) and more reliable (because it won’t fail when the db initialization code changes). For example, in this case ensuring Customer 1 is and always will be a VIP, as far as the test is concerned.


Executing Tests


Statics cause a real problem when running suites of unit tests together (for example, with your Continuous Integration server). Imagine a static map of network Socket objects that remains open from one test to another. The first test might open a Socket on port 8080, but you forgot to clear out the Map when the test gets torn down. Now when a second test launches, it is likely to crash when it tries to create a new Socket for port 8080, since the port is still occupied.  Imagine also that Socket references in your static Collection are not removed, and (with the exception of WeakHashMap) are never eligible to be garbage collected, causing a memory leak.


This is an over-generalized example, but in large systems, this problem happens ALL THE TIME. People don’t think of unit tests starting and stopping their software repeatedly in the same JVM, but it is a good test of your software design, and if you have aspirations towards high availability, it is something you need to be aware of.


These problems often arise with framework objects, for example, your DB access, caching, messaging, and logging layers. If you are using Java EE or some best of breed frameworks, they probably manage a lot of this for you, but if like me you are dealing with a legacy system, you might have a lot of custom frameworks to access these layers.


If the system configuration that applies to these framework components changes between unit tests, and the unit test framework doesn’t tear down and rebuild the components, these changes can’t take effect, and when a test relies on those changes, they will fail.


Even non-framework components are subject to this problem. Imagine a static map called OpenOrders. You write one test that creates a few open orders, and checks to make sure they are all in the right state, then the test ends. Another developer writes a second test which puts the orders it needs into the OpenOrders map, then asserts the number of orders is accurate. Run individually, these tests would both pass, but when run together in a suite, they will fail.


Worse, failure might be based on the order in which the tests were run.


In this case, by avoiding statics, you avoid the risk of persisting data across test instances, ensuring better test reliability.


Subtle Bugs


If you work in high availability environment, or anywhere that threads might be started and stopped, the same concern mentioned above with unit test suites can apply when your code is running on production as well.


When dealing with threads, rather than using a static object to store data, it is better to use an object initialized during the thread’s startup phase. This way, each time the thread is started, a new instance of the object (with a potentially new configuration) is created, and you avoid data from one instance of the thread bleeding through to the next instance.


When a thread dies, a static object doesn’t get reset or garbage collected. Imagine you have a thread called “EmailCustomers”, and when it starts it populates a static String collection with a list of email addresses, then begins emailing each of the addresses. Lets say the thread is interrupted or canceled somehow, so your high availability framework restarts the thread. Then when the thread starts up, it reloads the list of customers. But because the collection is static, it might retain the list of email addresses from the previous collection. Now some customers might get duplicate emails.


An Aside: Static Final


The use of “static final” is effectively the Java equivalent of a C #define, although there are technical implementation differences. A C/C++ #define is swapped out of the code by the pre-processor, before compilation. A Java “static final” will end up memory resident on the stack. In that way, it is more similar to a “static const” variable in C++ than it is to a #define.


Summary


I hope this helps explain a few basic reasons why statics are problematic up. If you are using a modern Java framework like Java EE or Spring, etc, you may not encounter many of these situations, but if you are working with a large body of legacy code, they can become much more frequent.


Since no one* has mentioned it: concurrency. Static variables can surprise you if you have multiple threads reading and writing to the static variable. This is common in web applications (e.g., ASP.NET) and it can cause some rather maddening bugs. For example, if you have a static variable that is updated by a page, and the page is requested by two people at "nearly the same time", one user may get the result expected by the other user, or worse.


statics reduce the inter-dependencies on the other parts of the code. They can act as perfect state holders


I hope you're prepared to use locks and deal with contention.


*Actually, Preet Sangha mentioned it.


if I had to make 10,000 calls to a function within a class, I would be
  glad to make the method static and use a straightforward
  class.methodCall() on it instead of cluttering the memory with 10,000
  instances of the class, Right?


You have to balance the need for encapsulating data into an object with a state, versus the need of simply computing the result of a function on some data.


Moreover statics reduce the inter-dependencies on the other parts of the code.


So does encapsulation. In large applications, statics tend to produce spaghetti code and don't easily allow refactoring or testing.


The other answers also provide good reasons against excessive use of statics.


Static variables are generally considered bad because they represent global state and are therefore much more difficult to reason about.  In particular, they break the assumptions of object-oriented programming.  In object-oriented programming, each object has its own state, represented by instance (non-static) variables.  Static variables represent state across instances which can be much more difficult to unit test.  This is mainly because it is more difficult to isolate changes to static variables to a single test.


That being said, it is important to make a distinction between regular static variables (generally considered bad), and final static variables (AKA constants; not so bad).


In my opinion it's hardly ever about performance, it's about design. I don't consider the use of static methods wrong as apposed of the use of static variables (but I guess you are actually talking about method calls). 


It's simply about how to isolate logic and give it a good place. Sometimes that justifies using static methods of which java.lang.Math is a good example. I think when you name most of your classes XxxUtil or Xxxhelper you'd better reconsider your design.


It might be suggested that in most cases where you use a static variable, you really want to be using the singleton pattern.


The problem with global states is that sometimes what makes sense as global in a simpler context, needs to be a bit more flexible in a practical context, and this is where the singleton pattern becomes useful.


Yet another reason: fragility.


If you have a class, most people expect to be able to create it and use it at will.


You can document it's not the case, or protect against it (singleton/factory pattern) - but that's extra work, and therefore an additional cost.
Even then, in a big company, chances are someone will try at some point to use your class without fully paying attention to all the nice comments or the factory.


If you're using static variables a lot, that will break. Bugs are expensive.


Between a .0001% performance improvement and robustness to change by potentially clueless developers, in a lot of cases robustness is the good choice.


Advantages:


Static members/methods are used as in helper classes say like Math or in constants classes. which helps other objects to utilize Strings or useful functions for which you do not need to create object but invoked using Class name.
Example – singleton objects are invoked using a static function.


Disadvantages:


Static members are part of class and thus remain in memory till application terminates and can’t be ever garbage collected. Using excess of static members sometime predicts that you fail to design your product and trying to cop of with static / procedural programming. It denotes that object oriented design is compromised. This can result in memory over flow.
Also there are certain disadvantages if you make any method static in Java for example you can not override any static method in Java so it makes testing harder you can not replace that method with mock. Since static method maintains global state they can create subtle bug in concurrent environment which is hard to detect and fix.


Things to remember:


The static variable will be part of the class definition rather than on the heap. However static variables are useful when you know there will be accesses to the object from multiple places. Access to static resources is not thread safe. You might get weird/unpredictable results in a threaded environment. But if your only reading the static value then using threads for it is fine.


How Static Breaks encapsulation:


The technical implementation of them is to allow state to be maintained across all instances of a class. The problem is that this is intrinsically not OOP because it disregards encapsulation. If a variable can be altered by any instance of a class then the fundamental principle behind encapsulation/information hiding is lost entirely: An object is no longer in complete control of its state. Its state now relies on variables which are essentially global. Which we know is bad. Even private static variables maintain state at a global level but simply limit its access. Any instance of the object can alter the static variable which causes ambiguity as individual instances of the object no longer have control over their own state. State changes can arbitrarily happen without knowledge of an object which relies on that state which is problematic because the object may not work correctly when this happens. Much as it’s often said that “Inheritance breaks encapsulation” statics do this in a far more severe way: By not just exposing internal implementation but also by exposing internal state.


Summarising few basic Advantages & Disadvantages of using Static methods in Java:


Advantages:


Disadvantages:


Static variables most importantly creates problem with security of data (any time changed,anyone can change,direct access without object, etc.)


For further info read this
Thanks.


I find static variables more convenient to use. And I presume that they are efficient too (Please correct me if I am wrong) because if I had to make 10,000 calls to a function within a class, I would be glad to make the method static and use a straightforward class.methodCall() on it instead of cluttering the memory with 10,000 instances of the class, Right? 


I see what you think, but a simple Singleton pattern will do the same without having to instantiate 10 000 objects.


static methods can be used, but only for functions that are related to the object domain and do not need or use internal properties of the object.


ex:


The issue of 'Statics being evil' is more of an issue about global state. The appropriate time for a variable to be static, is if it does not ever have more than one state; IE tools that should be accessible by the entire framework and always return the same results for the same method calls are never 'evil' as statics. As to your comment:


I find static variables more convenient to use. And I presume that they are efficient too


Statics are the ideal and efficient choice for variables/classes that do not ever change.


The problem with global state is the inherent inconsistency that it can create. Documentation about unit tests often address this issue, since any time there is a global state that can be accessed by more than multiple unrelated objects, your unit tests will be incomplete, and not 'unit' grained. As mentioned in this article about global state and singletons, if object A and B are unrelated (as in one is not expressly given reference to another), then A should not be able to affect the state of B.


There are some exceptions to the ban global state in good code, such as the clock. Time is global, and--in some sense--it changes the state of objects without having a coded relationship.


Seems to me that you're asking about static variables but you also point out static methods in your examples.


Static variables are not evil - they have its adoption as global variables like constants in most cases combined with final modifier, but as it said don't overuse them.


Static methods aka utility method. It isn't generally a bad practice to use them but major concern is that they might obstruct testing.


As a example of great java project that use a lot of statics and do it right way please look at Play! framework. There is also discussion about it in SO.


Static variables/methods combined with static import are also widely used in libraries that facilitate declarative programming in java like: make it easy or Hamcrest. It wouldn't be possible without a lot of static variables and methods.


So static variables (and methods) are good but use them wisely!


My $.02 is that several of these answers are confusing the issue, rather than saying "statics are bad" I think its better to talk about scoping and instances.


What I would say is that a static is a "class" variables - it represenst a value that is shared across all instances of that class. Typically it should be scoped that way as well (protected or private to class and its instances).


If you plan to put class-level behavior around it and expose it to other code, then a singleton may be a better solution to support changes in the future (as @Jessica suggested). This is because you can use interfaces at the instance/singleton level in ways that you can not use at the class level - in particular inheritance.


Some thoughts on why I think some of the aspects in other answers are not core to the question...


Statics are not "global". In Java scoping is controlled separately from static/instance. 


Concurrency is no less dangerous for statics than instance methods. It's still state that needs to be protected. Sure you may have 1000 instances with an instance variable each and only one static variable, but if the code accessing either isn't written in a thread-safe way you are still screwed - it just may take a little longer for you to realize it.


Managing life cycle is an interesting argument, but I think it's a less important one. I don't see why its any harder to manage a pair of class methods like init()/clear() than the creation and destroying of a singleton instance. In fact, some might say a singleton is a little more complicated due to GC.


PS, In terms of Smalltalk, many of its dialects do have class variables, but in Smalltalk classes are actually instances of Metaclass so they are really are variables on the Metaclass instance. Still, I would apply the same rule of thumb. If they are being used for shared state across instances then ok. If they are supporting public functionality you should look at a Singleton. Sigh, I sure do miss Smalltalk....


There's nothing wrong with static variables per se.  It's just the Java syntax that's broken.  Each Java class actually defines two structures- a singleton object which encapsulates static variables, and an instance.  Defining both in the same source block is pure evil, and results in a code that's hard to read.  Scala did that right.


I have just summarized some of the points made in the answers. If you find anything wrong please feel free to correct it.


Scaling: We have exactly one instance of a static variable per JVM. Suppose we are developing a library management system and we decided to put the name of book a static variable as there is only one per book. But if system grows and we are using multiple JVMs then we dont have a way to figure out which book we are dealing with?


Thread-Safety: Both instance variable and static variable need to be controlled when used in multi threaded environment. But in case of an instance variable it does not need protection unless it is explicitly shared between threads but in case of a static variable it is always shared by all the threads in the process. 


Testing: Though testable design does not equal to good design but we will rarely observe a good design that is not testable. As static variables represent global state and it gets very difficult to test them.


Reasoning about state: If I create a new instance of a class then we can reason about the state of this instance but if it is having static variables then it could be in any state. Why? Because it is possible that the static variable has been modified by some different instance as static variable is shared across instances. 


Serialization: Serialization also does not work well with them.


Creation and destruction: Creation and destruction of static variables can not be controlled. Usually they are created and destroyed at program loading and unloading time. It means they are bad for memory management and also add up the initialization time at start up.


But sometimes we may have a genuine need of them. If we really feel the need of many static variables that are shared across the application then one option is to make use of Singleton Design pattern which will have all these variables. Or we can create some object which will have these static variable and can be passed around.


Also if the static variable is marked final it becomes a constant and value assigned to it once cannot be changed. It means it will save us from all the problems we face due to its mutability.


If you have a small- to midsize-program, where the static variable Global.foo is accessed, the call to it normally comes from nowhere - there is no path, and therefore no timeline, how the variable comes to the place, where it is used. Now how do I know who set it to its actual value? How do I know, what happens, if I modify it right now? I have grep over the whole source, to collect all accesses, to know, what is going on. 


If you know how you use it, because you just wrote the code, the problem is invisible, but if you try to understand foreign code, you will understand. 


Static variables often prevent multiple programs of the same kind running in the same JVM with different values. You often don't foresee usages, where more than one instance of your program is useful, but if it evolves, or if it is useful for others, they might experience situations, where they would like to start more than one instance of your program. 


Only more or less useless code which will not be used by many people over a longer time in an intensive way might go well with static variables. 


There are two main questions in your post.


First, about static variables.
Static variables are completelly unnecesary and it's use can be avoided easily. In OOP languajes in general, and in Java particularlly, function parameters are pased by reference, this is to say, if you pass an object to a funciont, you are passing a pointer to the object, so you dont need to define static variables since you can pass a pointer to the object to any scope that needs this information. Even if this implies that yo will fill your memory with pointers, this will not necesary represent a poor performance because actual memory pagging systems are optimized to handle with this, and they will maintain in memory the pages referenced by the pointers you passed to the new scope; usage of static variables may cause the system to load the memory page where they are stored when they need to be accessed (this will happen if the page has not been accesed in a long time). A good practice is to put all that static stuf together in some little "configuration clases", this will ensure the system puts it all in the same memory page.


Second, about static methods.
Static methods are not so bad, but they can quickly reduce performance. For example, think about a method that compares two objects of a class and returns a value indicating which of the objects is bigger (tipical comparison method) this method can be static or not, but when invoking it the non static form will be more eficient since it will have to solve only two references (one for each object) face to the three references that will have to solve the static version of the same method (one for the class plus two, one for each object). But as I say, this is not so bad, if we take a look at the Math class, we can find a lot of math functions defined as static methods. This is really more eficient than putting all these methods in the class defining the numbers, because most of them are rarelly used and including all of them in the number class will cause the class to be very complex and consume a lot of resources unnecesarilly.


In concluson: Avoid the use of static variables and find the correct performance equilibrium when dealing with static or non static methods.


PS: Sorry for my english.


everything (can:) have its purpose, if you have bunch of threads that needs to share/cache data and also all accessible memory (so you dont split into contexts within one JVM) the static is best choice-> of course you can force just one instance, but why?
i find some of the comments in this thread evil, not the statics ;)


All the answers above show why statics are bad. The reason they are evil is because it gives the false impression that you are writing object oriented code, when in fact you are not.
That is just plain evil.


Static variables are not good nor evil. They represent attributes that describe the whole class and not a particular instance. If you need to have a counter for all the instances of a certain class, a static variable would be the right place to hold the value.


Problems appear when you try to use static variables for holding instance related values.


There are plenty of good answers here, adding to it, 


Memory:
 Static variables are live as long as the class loader lives[in general till VM dies], but this is only in-case of bulk objects/references stored as static.


Modularization:
consider concepts like IOC, dependencyInjection, proxy etc.. All are completely against tightly coupling/static implementations.


Other Con's: Thread Safety, Testability


Think that if you have an application with many users and you have define a static form, then every user will modify all other forms of other users too.


Static means global, whenever you mark a variable as static, you make it visible and shared between all instances of a class.


In multi-threaded environments, marking a variable as static would allow multiple threads to access and modify it concurrently and that's would leave it in inconsistent state and lead to several serious problems, the debugging of such problems is very harmful. 


Although developers normally tend to protect their static variables from concurrent modifications using for example Synchronized blocks, it is a time-consuming task to always surround each modification with a Synchronized block and there's a high possibility that the developer forget to protect some modification code by mistake.


The common usage of static variables is for defining constants, try to diminish the usage of them as much as you can unless you have a very specific business case which couldn't be solved better without static variable i.e. when you define an auto generated ID field in a class.


For much details, check Static keyword in java


I think excessive uses of global variables with static keyword will also leads to memory leakage at some point of instance in the applica






I have the following code example below. Whereby you can enter a command to the bash shell i.e. echo test and have the result echo'd back. However, after the first read. Other output streams don't work?


Why is this or am I doing something wrong? My end goal is to created a Threaded scheduled task that executes a command periodically to /bash so the OutputStream and InputStream would have to work in tandem and not stop working. I have also been experiencing the error java.io.IOException: Broken pipe any ideas?


Thanks.


Firstly, I would recommend replacing the line


with the lines


ProcessBuilder is new in Java 5 and makes running external processes easier.  In my opinion, its most significant improvement over Runtime.getRuntime().exec() is that it allows you to redirect the standard error of the child process into its standard output.  This means you only have one InputStream to read from.  Before this, you needed to have two separate Threads, one reading from stdout and one reading from stderr, to avoid the standard error buffer filling while the standard output buffer was empty (causing the child process to hang), or vice versa.


Next, the loops (of which you have two)


only exit when the reader, which reads from the process's standard output, returns end-of-file.  This only happens when the process exits.  It will not return end-of-file if there happens at present to be no more output from the process.  Instead, it will wait for the next line of output from the process and not return until it has this next line.


Since you're sending two lines of input to the process before reaching this loop, the first of these two loops will hang if the process hasn't exited after these two lines of input.  It will sit there waiting for another line to be read, but there will never be another line for it to read.


I compiled your source code (I'm on Windows at the moment, so I replaced /bin/bash with cmd.exe, but the principles should be the same), and I found that:


I have seen a trick that does something similar to what you seem to want, in a program I used to work on.  This program kept around a number of shells, ran commands in them and read the output from these commands.  The trick used was to always write out a 'magic' line that marks the end of the shell command's output, and use that to determine when the output from the command sent to the shell had finished.


I took your code and I replaced everything after the line that assigns to writer with the following loop:


After doing this, I could reliably run a few commands and have the output from each come back to me individually.


The two echo --EOF-- commands in the line sent to the shell are there to ensure that output from the command is terminated with --EOF-- even in the result of an error from the command.


Of course, this approach has its limitations.  These limitations include:


These points might not matter to you if whatever it is you're thinking of running as a scheduled task is going to be restricted to a command or a small set of commands which will never behave in such pathological ways.


EDIT: improve exit handling and other minor changes following running this on Linux.


I think you can use thread like demon-thread for reading your input and your output reader will already be in while loop in main thread so you can read and write at same time.You can modify your program like this:


and you can reader will be same as above i.e.


make your writer as final otherwise it wont be able to accessible by inner class. 


You have writer.close(); in your code. So bash receives EOF on its stdin and exits. Then you get Broken pipe when trying to read from the stdoutof the defunct bash.






This question already has an answer here:


I have been having trouble while attempting to use the nextLine() method from java.util.Scanner. 


Here is what I tried:


Example #1: This example works as intended. The line String sentence = scanner.nextLine(); waits for input to be entered before continuing on to System.out.print("Enter an index:\t");.


This produces the output:


Example #2: This example does not work as intended. This example uses a while loop and and if - else structure to allow the user to choose what to do. Once the program gets to String sentence = scanner.nextLine();, it does not wait for input but instead executes the line System.out.print("Enter an index:\t");.


This produces the output:


Which makes it impossible to enter a sentence.


Why does example #2 not work as intended? The only difference between Ex. 1 and 2 is that Ex. 2 has a while loop and an if-else structure. I don't understand why this affects the behavior of scanner.nextInt(). 


I think your problem is that


reads just the number, not the end of line or anything after the number.  When you


This read the remainder of the line with the number on it (with nothing after the number I suspect) 


Try placing a scanner.nextLine(); after each nextInt() if you intend to ignore the rest of the line.


Rather than placing an extra scanner.nextLine() each time you want to read something, since it seems you want to accept each input on a new line, you might want to instead changing the delimiter to actually match only newlines (instead of any whitespace, as is the default)


Thus, to read a line of input, you only need scanner.next() that has the same behavior delimiter-wise of next{Int, Double, ...} 


The difference with the "nextLine() every time" approach, is that the latter will accept, as an index also <space>3, 3<space> and 3<space>whatever while the former only accepts 3 on a line on its own


Don't try to scan text with nextLine(); AFTER using nextInt() with the same scanner! It doesn't work well with Java Scanner, and many Java developers opt to just use another Scanner for integers. You can call these scanners scan1 and scan2 if you want.


It's because when you enter a number then press Enter, input.nextInt() consumes only the number, not the "end of line". Primitive data types like int, double etc do not consume "end of line", therefore the "end of line" remains in buffer and When input.next() executes, it consumes the "end of line" from buffer from the first input. That's why, your String sentence = scanner.next() only consumes the "end of line" and does not wait to read from keyboard.


Tip: use scanner.nextLine() instead of scanner.next() because scanner.next() does not read white spaces from the keyboard. (Truncate the string after giving some space from keyboard, only show string before space.)


or






I have been doing Java SE for some years now and moving on to Java EE. However I have some trouble understanding some aspects of Java EE.


Is Java EE just a specification? What I mean is: Is EJB Java EE?  


Are EJB/Spring different implementations of Java EE?


I am sorry to ask but I have some difficulties to understand what Java EE is. Could someone explain what Java EE is? And EJB?


Is Java EE just a specification? What I mean is: Is EJB Java EE?


Java EE is indeed an abstract specification. Anybody is open to develop and provide a working implementation of the specification. The concrete implementations are the so-called application servers, like WildFly, TomEE, GlassFish, Liberty, WebLogic, etc. There are also servlet containers which implement only the JSP/Servlet part of the huge Java EE API, such as Tomcat, Jetty, etc.


We, Java EE developers, should write code utilizing the specification (i.e. import only javax.* classes in our code instead of implementation specific classes such as org.jboss.wildfly.*, com.sun.glassfish.*, etc) and then we'll be able to run our code on any implementation (thus, on any application server). If you're familiar with JDBC, it's basically the same concept as how JDBC drivers work. See also a.o. In simplest terms, what is a factory?


The Java EE SDK download from Oracle.com contains basically the GlassFish server along a bunch of documentation and examples and optionally also the NetBeans IDE. You don't need it if you want a different server and/or IDE.


EJB is part of the Java EE specification. Look, it's in the Java EE API. Full-fledged Java EE application servers support it out the box, but simple JSP/Servlet containers don't.


Are EJB/Spring different implementations of Java EE?


No, as said, EJB is part of Java EE. Spring is a standalone framework which substitutes and improves many parts of Java EE. Spring doesn't necessarily require Java EE to run. A barebones servletcontainer like Tomcat is already sufficient. Simply put, Spring is a competitor of Java EE. E.g. "Spring" (standalone) competes EJB/JTA, Spring MVC competes JSF/JAX-RS, Spring DI/IoC/AOP competes CDI, Spring Security competes JAAS/JASPIC, etc.


Back during the old J2EE/EJB2 times, the EJB2 API was terrible to implement and maintain. Spring was then a much better alternative to EJB2. But since EJB3 (Java EE 5), the EJB API was much improved based on lessons learnt from Spring. Since CDI (Java EE 6), there's not really a reason to look at again another framework like Spring to make the developers more easy as to developing among others the service layer.


Only when you're using a barebones servletcontainer such as Tomcat and can't move on to a Java EE server, then Spring is more attractive as it's easier to install Spring on Tomcat. It isn't possible to install e.g. an EJB container om Tomcat without modifying the server itself, you would basically be reinventing TomEE.


Java Enterprise Edition (Java EE) is an umbrella specification that references a number of other more detailed specifications, of which Enterprise JavaBeans (EJB) is one of the more important ones.


Read this - it explains the difference between Java EE and Spring


Thanks...


Source -- Java 2 Platform, Enterprise Edition (J2EE) defines the standard for developing component-based multitier enterprise applications. J2EE simplifies building enterprise applications that are portable, scalable, and that integrate easily with legacy applications and data .


Source -- Enterprise JavaBeans (EJB) technology is the server-side component architecture for Java Platform, Enterprise Edition (Java EE). EJB technology enables rapid and simplified development of distributed, transactional, secure and portable applications based on Java technology.


Is Java EE just a specification? What I mean is: Is EJB Java EE?


Java EE is a specification.


EJB is server side component architecture for Java EE


Are EJB/Spring different implementations of Java EE?


To put simply - JavaEE is a platform. 


It is made up of many specifications which are just APIs. The specific concrete implementations of these APIs are the so called 'Reference Implementation'


EJB is Enterprise Java Beans






What do the 3 dots in the following method mean?


It means that zero or more String objects (or an array of them) may be passed as the argument(s) for that method.


See the "Arbitrary Number of Arguments" section here: http://java.sun.com/docs/books/tutorial/java/javaOO/arguments.html#varargs


In your example, you could call it as any of the following:


Important Note: The argument(s) passed in this way is always an array - even if there's just one. Make sure you treat it that way in the method body.


Important Note 2: The argument that gets the ... must be the last in the method signature. So, myMethod(int i, String... strings) is okay, but myMethod(String... strings, int i) is not okay.


Thanks to Vash for the clarifications in his comment.


That feature is called varargs, and it's a feature introduced in Java 5. It means that function can receive multiple String arguments:


Then, you can use the String var as an array:


This answer borrows heavily from kiswa's and Lorenzo's... and also from the Graphain's comment.


This is the Java way to pass varargs (variable number arguments).


If you are familiar with C, this is similar to the ... syntax used it the printf function:


but in a type safe fashion: every argument has to comply with the specified type (in your sample, they should be all String).


This is a simple sample of how you can use varargs:


The ... argument is actually an array, so you could pass a String[] as the parameter.


Arguably, it is an example of syntactic sugar, since it is implemented as an array anyways (which doesn't mean it's useless) - I prefer passing an array to keep it clear, and also declare methods with arrays of given type. Rather an opinion than an answer, though.


The varargs short for variable-length arguments is a feature that allows the method to accept variable number of arguments (zero or more). With varargs it has become simple to create methods that need to take a variable number of arguments. The feature of variable argument has been added in Java 5.


Syntax of varargs


A vararg is secified by three ellipsis (three dots) after the data type, its general form is


Need for varargs


Prior to Java 5, in case there was a need of variable number of arguments, there were two ways to handle it


If the max number of arguments, a method can take was small and known, then overloaded versions of the method could be created.
If the maximum number of arguments a method could take was large or/and unknown then the approach was to put those arguments in an array and pass them to a method which takes array as a parameter.
These 2 approaches were error-prone - constructing an array of parameters every time and difficult to maintain - as the addition of new argument may result in writing a new overloaded method.


Advantages of varargs


Offers a much simpler option.
Less code as no need to write overloaded methods.


Example of varargs


It can be seen from the program that length is used here to find the number of arguments passed to the method. It is possible because varargs are implicitly passed as an array. Whatever arguments are passed as varargs are stored in an array which is referred by the name given to varargs. In this program array name is values.
Also note that method is called with different number of argument, first call with four arguments, then three arguments and then with zero arguments. All these calls are handled by the same method which takes varargs.


Restriction with varargs


It is possible to have other parameters with varargs parameter in a method, however in that case, varargs parameter must be the last parameter declared by the method.


Another restriction with varargs is that there must be only one varargs parameter.


Overloading varargs Methods


It is possible to overload a method that takes varargs parameter. 
Varargs method can be overloaded by -


Types of its vararg parameter can be different.
By adding other parameters.
Example of overloading varargs method


Varargs and overloading ambiguity


In some cases call may be ambiguous while we have overloaded varargs method.
Let's see an example


In this program when we make a call to displayData() method without any parameter it throws error, because compiler is not sure whether this method call is for displayData(String ... values) or displayData(int ... values)


Same way if we have overloaded methods where one has the vararg method of one type and another method has one parameter and vararg parameter of the same type, then also we have the ambiguity - 
As Exp - 
displayData(int ... values) and displayData(int a, int ... values)


These two overloaded methods will always have ambiguity.


Also to shed some light, it is important to know that var-arg parameters are limited to one and you can't have several var-art params. For example this is illigal:


Just think of it as the keyword params in C#, if you are coming from that background :)


String... is the same as String[]


A really common way to see a clear example of the use of the three dots it is present in one of the most famous methods in android AsyncTask ( that today is not used too much because of RXJAVA, not to mention the Google Architecture components), you can find thousands of examples searching for this term, and the best way to understand and never forget anymore the meaning of the three dots is that they express a ...doubt... just like in the common language. Namely it is not clear the number of parameters that have to be passed, could be 0, could be 1 could be more( an array)...






When I write System.out.println(0123); I get 83 however System.out.println((int)0123F); prints 123.


Why does it work that way?


0123 means octal 123, that is 1*8*8 + 2*8 + 3, which equals 83.
For some reason, octal floats are not available.


Creating 0123 means the integer 83.
Creating 0123F means the floating 123. When converted back to integer, it remains 123.


Just don't use the leading 0 if you don't mean octal. After all, they are not exactly useful(and programmers who do know about octal numbers will get confused when they see 09F).


Because integer literals starting with 0 are treated as octal numbers.


See section 3.10.1 of the JLS


Try this:


first one printed as 83 because java takes 0123 as octal number and it prints decimal equivalent of that number.


The octal (leading 0) and hexadecimal (leading 0x) were inherited from C.
For comparison, try


The numbers 1010L and 0101L are not in binary representation (just to avoid the confusion).
These numbers are in decimal representation.


Even as per the Regex patterns in Oracle docs,


\0n is the character with octal value 0n (0 <= n <= 7) 
  \xhh is the character with hexadecimal value 0xhh


Thus, your number 0101 be it in Integer or Long format is treated as an Octal representation of a number. 


printf will do it: http://java.sun.com/developer/technicalArticles/Programming/sprintf/


You could also make it "%0" + size + "%d" if you wanted to vary the length... though if the lengths were common I'd probably make constants like "%04d", "%012d", etc...


In Java integer literals with a leading zero are octal integers (base 8).


So do not use any number leading with 0, if you don't want to treated it as octal number.


Any number with suffix 'F' is then it is treated as Float number.


In given example (inf)0123F will prints 123  because 0123F treated as float (123) and converted to int value remains 123.






What is Double Brace initialization syntax ({{ ... }}) in Java?


Double brace initialisation creates an anonymous class derived from the specified class (the outer braces), and provides an initialiser block within that class (the inner braces). e.g.


Note that an effect of using this double brace initialisation is that you're creating anonymous inner classes. The created class has an implicit this pointer to the surrounding outer class. Whilst not normally a problem, it can cause grief in some circumstances e.g. when serialising or garbage collecting, and it's worth being aware of this.


Every time someone uses double brace initialisation, a kitten gets killed.


Apart from the syntax being rather unusual and not really idiomatic (taste is debatable, of course), you are unnecessarily creating two significant problems in your application, which I've just recently blogged about in more detail here.


Each time you use double brace initialisation a new class is made. E.g. this example:


... will produce these classes:


That's quite a bit of overhead for your classloader - for nothing! Of course it won't take much initialisation time if you do it once. But if you do this 20'000 times throughout your enterprise application... all that heap memory just for a bit of "syntax sugar"?


If you take the above code and return that map from a method, callers of that method might be unsuspectingly holding on to very heavy resources that cannot be garbage collected. Consider the following example:


The returned Map will now contain a reference to the enclosing instance of ReallyHeavyObject. You probably don't want to risk that:





Image from http://blog.jooq.org/2014/12/08/dont-be-clever-the-double-curly-braces-anti-pattern/


To answer your actual question, people have been using this syntax to pretend that Java has something like map literals, similar to the existing array literals:


Some people may find this syntactically stimulating.


tl;dr
 1. The first brace creates a new Anonymous Inner Class.
 2. The second set of brace creates an instance initializers like static block in Class.   


For example:


How it works 


first brace creates a new Anonymous Inner Class. These inner classes are capable of accessing the behavior of their parent class. So, in our case, we are actually creating a subclass of HashSet class, so this inner class is capable of using add() method.


And second set of braces are nothing but instance initializers. If you remind core java concepts then you can easily associate instance initializer blocks with static initializers due to similar brace like struct. Only difference is that static initializer is added with static keyword, and is run only once; no matter how many objects you create.


more


For a fun application of double brace initialization, see here Dwemthy’s Array in Java.


An excerpt


And now, be prepared for the BattleOfGrottoOfSausageSmells and … chunky bacon!


I'd like to point out that there is no such thing as double brace initialization. There is only normal traditional one brace initializaition block. Second braces block has nothing to do with initialization. Answers say that those two braces initialize something, but it is not like that.


Secondly, almost all answers talk that it is a thing used when creating anonymous inner classes. I think that people reading those answers will get the impression that this is only used when creating anonymous inner classes. But it is used in all classes. Reading those answers it looks like is some brand new special future dedicated to anonymous classes and I think that is misleading.


Going further, this question talks about situation when second opening bracket is just after first opening bracket. When used in normal class usually there is some code between two braces, but it is totally the same thing. So it is a matter of placing brackets. So I think we should not say that this is some new exciting thing, beacuse this is the thing which we all know, but just written with some code between brackets. We should not create new concept called "double brace initialization".


I don't agree with an argument that you create too many anonymous classes. You're not creating them because an initialization block, but just because you create them. They would be created even if you did not use two braces initialization so those problems would occur even without initialization... Initialization is not the factor which creates initialized object.


Additionally we should not talk about problem created by using this non-existent thing "double brace initialization" or even by normal one bracket initialization, because described problems exist only because of creating anonymous class so it has nothing to do with original question. But all answers with give the readers impression that it is not fault of creating anonymous classes, but this evil (non-existent) thing called "double brace initialization".


I think it's important to stress that there is no such thing as "Double Brace initialization" in Java. Oracle web-site doesn't have this term. In this example there are two features used together: anonymous class and initializer block. Seems like the old initializer block has been forgotten by developers and cause some confusion in this topic. Citation from Oracle docs:


Initializer blocks for instance variables look just like static initializer blocks, but without the static keyword:


It's - among other uses - a shortcut for initializing collections. Learn more ...


you mean something like this?


it's an array list initialization in creation time (hack)


You can put some Java statements as loop to initialize collection:


To avoid all negative effects of double brace initialization, such as:


do next things:


Example:


Usage:


Advantages:


Disadvantages:


And, as a result, we have simplest java builder pattern ever.


See all samples at github: java-sf-builder-simple-example


This would appear to be the same as the with keyword so popular in flash and vbscript. It's a method of changing what this is and nothing more. 






I've written a factory to produce java.sql.Connection objects:


I'd like to validate the parameters passed to DriverManager.getConnection, but I don't know how to mock a static method. I'm using JUnit 4 and Mockito for my test cases. Is there a good way to mock/verify this specific use-case?


Use PowerMockito on top of Mockito.


Example code:


More information:


The typical strategy for dodging static methods that you have no way of avoiding using, is by creating wrapped objects and using the wrapper objects instead.


The wrapper objects become facades to the real static classes, and you do not test those.


A wrapper object could be something like


Finally, your class under test can use this singleton object by, for example, 
having a default constructor for real life use:


And here you have a class that can easily be tested, because you do not  directly use a class with static methods.


If you are using CDI and can make use of the @Inject annotation then it is even easier.
Just make your Wrapper bean @ApplicationScoped, get that thing injected as a collaborator (you do not even need messy constructors for testing), and go on with the mocking.


As mentioned before you can not mock static methods with mockito. 


If changing your testing framework is not an option you can do the following:


Create an interface for DriverManager, mock this interface, inject it via some kind of dependency injection and verify on that mock. 


To mock static method you should use a Powermock look at:
https://github.com/powermock/powermock/wiki/MockStatic.
Mockito doesn't provide this functionality.


You can read nice a article about mockito:
http://refcardz.dzone.com/refcardz/mockito


I had a similar issue. The accepted answer did not work for me, until I made the change:  @PrepareForTest(TheClassYouWriteTestFor.class).


And I don't have to use BDDMockito. 


My class:


My test class:


You can do it with a little bit of refactoring:


Then you can extend your class MySQLDatabaseConnectionFactory to return a mocked connection, do assertions on the parameters, etc.


The extended class can reside within the test case, if it's located in the same package (which I encourage you to do)






This question already has an answer here:


What is the difference between 


and 


When you use a string literal the string can be interned, but when you use new String("...") you get a new string object.


In this example both string literals refer the same object:


Here, 2 different objects are created and they have different references:


In general, you should use the string literal notation when possible. It is easier to read and it gives the compiler a chance to optimize your code.


A String literal is a Java language concept. This is a String literal:


A String object is an individual instance of the java.lang.String class. 


All are valid, but have a slight difference. s1 will refer to an interned String object. This means, that the character sequence "abcde" will be stored at a central place, and whenever the same literal "abcde" is used again, the JVM will not create a new String object but use the reference of the cached String.


s2 is guranteed to be a new String object, so in this case we have:


The long answer is available here, so I'll give you the short one. 


When you do this:


You are calling the intern() method on String. This method references an internal pool of String objects. If the String you called intern() on already resides in the pool, then a reference to that String is assigned to str. If not, then the new String is placed in the pool, and a reference to it is then assigned to str.


Given the following code:


When you check for object identity by doing == (you are literally asking: do these two references point to the same object?), you get true. 


However, you don't need to intern() Strings. You can force the creation on a new Object on the Heap by doing this:


In this instance, str and str2 are references to different Objects, neither of which have been interned, so that when you test for Object identity using ==, you will get false.


In terms of good coding practice: do not use == to check for String equality, use .equals() instead.


As Strings are immutable, when you do:


while creating the string, the JVM searches in the pool of strings if there already exists a string value "xyz", if so 'a' will simply be a reference of that string and no new String object is created.


But if you say:


you force JVM to create a new String reference, even if "xyz" is in its pool.


For more information read this.


"abc" is a literal String. 


In Java, these literal strings are pooled internally and the same String instance of "abc" is used where ever you have that string literal declared in your code.  So "abc" == "abc" will always be true as they are both the same String instance.


Using the String.intern() method you can add any string you like to the internally pooled strings, these will be kept in memory until java exits.


On the other hand, using new String("abc") will create a new string object in memory, which is logically the same as the "abc" literal. 
"abc" == new String("abc") will always be false, as although they are logically equal they refer to different instances.


Wrapping a String constructor around a string literal is of no value, it just needlessly uses more memory than it needs to.


String is a class in Java different from other programming languages. So as for every class the object declaration and initialization is 


or


Here, st1, st2 and st3 are different objects.


That is:


Because st1, st2, st3 are referencing 3 different objects, and == checks for the equality in memory location, hence the result. 


But:


Here .equals() method checks for the content, and the content of st1 = "", st2 = "hello" and st3 = "hello". Hence the result.


And in the case of the String declaration 


Here, intern() method of String class is called, and checks if "hello" is in intern pool, and if not, it is added to intern pool, and if "hello" exist in intern pool, then st will point to the memory of the existing "hello". 


So in case of:


Here:


Because st3 and st4 pointing to same memory address. 


Also:


In the first case, there are two objects created.


In the second case, it's just one.


Although both ways str is referring to "abc".


Some disassembly is always interesting...


In addition to the answers already posted, also see this excellent article on javaranch.


According to String class documentation they are equivalent.


Documentation for String(String original) also says that: Unless an explicit copy of original is needed, use of this constructor is unnecessary since Strings are immutable.


Look for other responses, because it seems that Java documentation is misleading :(


The following are some comparisons:


When intern() is called the reference is changed.


There is a subtle differences between String object and string literal.


In this simple case, "abc" will go in the pool and s will refer to it.


In this case, because we used the new keyword, Java will create a new String object
in normal (non-pool) memory, and s will refer to it. In addition, the literal "abc" will
be placed in the pool.


String s = new String("FFFF") creates 2 objects: "FFFF" string and String object, which point to "FFFF" string, so it is like pointer to pointer (reference to reference, I am not keen with terminology).


It is said you should never use new String("FFFF")






What regex pattern would need I to pass to the java.lang.String.split() method to split a String into an Array of substrings using all whitespace characters (' ', '\t', '\n', etc.) as delimiters?


Something in the lines of


This groups all white spaces as a delimiter. 


So if I have the string:


"Hello[space][tab]World"


This should yield the strings "Hello" and "World" and omit the empty space between the [space] and the [tab].


As VonC pointed out, the backslash should be escaped, because Java would first try to escape the string to a special character, and send that to be parsed. What you want, is the literal "\s", which means, you need to pass "\\s". It can get a bit confusing.


The \\s is equivalent to [ \\t\\n\\x0B\\f\\r]


In most regex dialects there are a set of convenient character summaries you can use for this kind of thing - these are good ones to remember:


\w - Matches any word character. 


\W - Matches any nonword character. 


\s - Matches any white-space character. 


\S - Matches anything but white-space characters. 


\d - Matches any digit. 


\D - Matches anything except digits.


A search for "Regex Cheatsheets" should reward you with a whole lot of useful summaries.


To get this working in Javascript, I had to do the following:


"\\s+" should do the trick


Also you may have a UniCode non-breaking space xA0...


Apache Commons Lang has a method to split a string with whitespace characters as delimiters:


http://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.html#split(java.lang.String)


This might be easier to use than a regex pattern.


Since it is a regular expression, and i'm assuming u would also not want non-alphanumeric chars like commas, dots, etc that could be surrounded by blanks (e.g. "one , two" should give [one][two]), it should be:


you can split a string by line break by using the following statement :


you can split a string by Whitespace by using the following statement :


Study this code.. good luck






Consider:


Is this how you create a two-dimensional array with 5 rows and 10 columns?


I saw this code online, but the syntax didn't make sense.


Try the following:


... which is a short hand for something like this:


Note that every element will be initialized to the default value for int, 0, so the above are also equivalent to:


We can declare a two dimensional array and directly store elements at the time of its declaration as:


Here int represents integer type elements stored into the array and the array name is 'marks'. int is the datatype for all the elements represented inside the "{" and "}" braces because an array is a collection of elements having the same data type. 


Coming back to our statement written above: each row of elements should be written inside the curly braces. The rows and the elements in each row should be separated by a commas.


Now observe the statement: you can get there are 3 rows and 5 columns, so the JVM creates 3 * 5 = 15 blocks of memory. These blocks can be individually referred ta as:



NOTE:
If you want to store n elements then the array index starts from zero and ends at n-1.
Another way of creating a two dimensional array is by declaring the array first and then allotting memory for it by using new operator.


By combining the above two we can write:


You can create them just the way others have mentioned. One more point to add: You can even create a skewed two-dimensional array with each row, not necessarily having the same number of collumns, like this:


The most common idiom to create a two-dimensional array with 5 rows and 10 columns is:


Alternatively, you could use the following, which is more similar to what you have, though you need to explicitly initialize each row:


Try:


Note that in your code only the first line of the 2D array is initialized to 0.
Line 2 to 5 don't even exist. If you try to print them you'll get null for everyone of them.


In Java, a two-dimensional array can be declared as the same as a one-dimensional array. In a one-dimensional array you can write like


where int is a data type, array[] is an array declaration, and new array is an array with its objects with five indexes.


Like that, you can write a two-dimensional array as the following.


Here array is an int data type. I have firstly declared on a one-dimensional array of that types, then a 3 row and 4 column array is created.


In your code


means that you have created a two-dimensional array, with five rows. In 
the first row there are 10 columns. In Java you can select the column size for every row as you desire.


It is also possible to declare it the following way. It's not good design, but it works.


Enjoy!


Try this Way:


These types of Array known as Jagged Array in Java :


In this scenario each row of array holds the different-different no of columns. In above example first row will holds 3 columns and 2nd row will holds 2 columns and 3rd row holds 5 columns. you can initialize this array at compile time like below :


You can easily iterate all elements from your Array :






I have a custom class loader so that a desktop application can dynamically start loading classes from an AppServer I need to talk to. We did this since the amount of jars that are required to do this are ridiculous (if we wanted to ship them). We also have version problems if we don't load the classes dynamically at run time from the AppServer library.


Now, I just hit a problem where I need to talk to two different AppServers and found that depending on whose classes I load first I might break badly... Is there any way to force the unloading of the class without actually killing the JVM?


Hope this makes sense


The only way that a Class can be unloaded is if the Classloader used is garbage collected.  This means, references to every single class and to the classloader itself need to go the way of the dodo.


One possible solution to your problem is to have a Classloader for every jar file, and a Classloader for each of the AppServers that delegates the actual loading of classes to specific Jar classloaders.  That way, you can point to different versions of the jar file for every App server.


This is not trivial, though.  The OSGi platform strives to do just this, as each bundle has a different classloader and dependencies are resolved by the platform.  Maybe  a good solution would be to take a look at it.


If you don't want to use OSGI, one possible implementation could be to use one instance of JarClassloader class for every JAR file.


And create a new, MultiClassloader class that extends Classloader.  This class internally would have an array (or List) of JarClassloaders, and in the defineClass() method would iterate through all the internal classloaders until a definition can be found, or a NoClassDefFoundException is thrown.  A couple of accessor methods can be provided to add new JarClassloaders to the class. There is several possible implementations on the net for a MultiClassLoader, so you might not even need to write your own.


If you instanciate a MultiClassloader for every connection to the server, in principle it is possible that every server uses a different version of the same class.


I've used the MultiClassloader idea in a project, where classes that contained user-defined scripts had to be loaded and unloaded from memory and it worked quite well.


Yes there are ways to load classes and to "unload" them later on. The trick is to implement your own classloader which resides between high level class loader (the System class loader) and the class loaders of the app server(s), and to hope that the app server's class loaders do delegate the classloading to the upper loaders.


A class is defined by its package, its name, and the class loader it originally loaded. Program a "proxy" classloader which is the first that is loaded when starting the JVM. Workflow:


Done right there should not come a ClassCastException or LinkageError etc.


For more informations about class loader hierarchies (yes, that's exactly what you are implementing here ;- ) look at "Server-Based Java Programming" by Ted Neward - that book helped me implementing something very similar to what you want.


I wrote a custom classloader, from which it is possible to unload individual classes without GCing the classloader. Jar Class Loader


Classloaders can be a tricky problem.  You can especially run into problems if you're using multiple classloaders and don't have their interactions clearly and rigorously defined.  I think in order to actually be able to unload a class youlre going go have to remove all references to any classes(and their instances) you're trying to unload.


Most people needing to do this type of thing end up using OSGi.  OSGi is really powerful and surprisingly lightweight and easy to use,


You can unload a ClassLoader but you cannot unload specific classes.  More specifically you cannot unload classes created in a ClassLoader that's not under your control.


If possible, I suggest using your own ClassLoader so you can unload.


Classes have an implicit strong reference to their ClassLoader instance, and vice versa. They are garbage collected as with Java objects. Without hitting the tools interface or similar, you can't remove individual classes.


As ever you can get memory leaks. Any strong reference to one of your classes or class loader will leak the whole thing. This occurs with the Sun implementations of ThreadLocal, java.sql.DriverManager and java.beans, for instance.


If you're live watching if unloading class worked in JConsole or something, try also adding  java.lang.System.gc() at the end of your class unloading logic. It explicitly triggers Garbage Collector.






I'm wondering if there is a recommended way of doing deep clone/copy of instance in java.


I have 3 solutions in mind, but I can have miss some,  and I'd like to have your opinion


edit: include Bohzo propositon and refine question: it's more about deep cloning than shallow cloning.


code the clone by hand properties after properties and check that mutable instances are cloned too.
pro:
- control of what will be performed
- quick execution
cons:
- tedious to write and maintain
- bug prone (copy/paste failure, missing property, reassigned mutable property) 


With your own reflection tools or with an external helper (like jakarta common-beans) it is easy to write a generic copy method that will do the job in one line.
pro:
- easy to write
- no maintenance
cons:
- less control of what happens
- bug prone with mutable object if the reflection tool does not clone sub objects too
- slower execution


Use a framework that do it for you, like :
commons-lang SerializationUtils
Java Deep Cloning Library
Dozer
Kryo


pro:
- same as reflection
- more control over what will be exactly be cloned.
cons:
- every mutable instance is fully cloned, even at the end of the hierarchy
- could be very slow to execute


javassit, BCEL or cglib might be use to generate a dedicated cloner as fast as one hand writed. Someone knows a lib using one of these tools for this purpose ?


What I have missed here ?
Which one would you recommend ?


Thanks.


commons-lang SerializationUtils - using serialization - if all classes are in your control and you can force implementing Serializable.


Java Deep Cloning Library - using reflection - in cases when the classes or the objects you want to clone are out of your control (a 3rd party library) and you can't make them implement Serializable, or in cases you don't want to implement Serializable.


commons-beanutils BeanUtils - in most cases.


Spring BeanUtils - if you are already using spring and hence have this utility on the classpath.


I deliberately omitted the "do-it-yourself" option - the API's above provide a good control over what to and what not to clone (for example using transient, or String[] ignoreProperties), so reinventing the wheel isn't preferred.


Joshua Bloch's book has a whole chapter entitled "Item 10: Override Clone Judiciously" in which he goes into why overriding clone for the most part is a bad idea because the Java spec for it creates many problems.  


He provides a few alternatives:


Use a factory pattern in place of a constructor:


Use a copy constructor:


All of the collection classes in Java support the copy constructor (e.g. new ArrayList(l);)


Since version 2.07 Kryo supports shallow/deep cloning:


Kryo is fast, at the and of their page you may find a list of companies which use it in production.


Use XStream toXML/fromXML in memory.  Extremely fast and has been around for a long time and is going strong. Objects don't need to be Serializable and you don't have use reflection (although XStream does).  XStream can discern variables that point to the same object and not accidentally make two full copies of the instance. A lot of details like that have been hammered out over the years.  I've used it for a number of years and it is a go to. It's about as easy to use as you can imagine.


or


To clone,


More succinctly:


I'd recommend the DIY way which, combined with a good hashCode() and equals() method should be easy to proof in a unit test. 


I'd suggest to override Object.clone(), call super.clone() first and than call ref = ref.clone() on all references that you want to have deep copied. It's more or less Do it yourself approach but needs a bit less coding.


Depends.


For speed, use DIY.
For bulletproof, use reflection.


BTW, serialization is not the same as refl, as some objects may provide overridden serialization methods (readObject/writeObject) and they can be buggy


For complicated objects and when performance is not significant i use gson
to serialize the object to json text, then deserialize the text to get new object.


gson which based on reflection will works in most cases, except that transient fields will not be copied and objects with circular reference with cause StackOverflowError.






Consider this code:


When using the new keyword, Java will create the abc String again right?
Will this be stored on the regular heap or the String pool?
How many Strings will end in the String pool?


If you use the new keyword, a new String object will be created. Note that objects are always on the heap - the string pool is not a separate memory area that is separate from the heap.


The string pool is like a cache. If you do this:


then the Java compiler is smart enough to make just one String object, and s and p will both be referring to that same String object. If you do this:


then there will be one String object in the pool, the one that represents the literal "abc", and there will be a separate String object, not in the pool, that contains a copy of the content of the pooled object. Since String is immutable in Java, you're not gaining anything by doing this; calling new String("literal") never makes sense in Java and is unnecessarily inefficient.


Note that you can call intern() on a String object. This will put the String object in the pool if it is not already there, and return the reference to the pooled string. (If it was already in the pool, it just returns a reference to the object that was already there). See the API documentation for that method for more info.


See also String interning (Wikipedia).


In bytecode, the first assignment is:


whereas the second is:


So the first is in the pool (at position #2) whereas the second will be stored in the heap.


EDIT


Since the CONSTANT_String_info store the index as U2 (16 bits, unsigned) the pool can contain at max 2**16 = 65535 references. In the case you care here more limits of the JVM.


Each time your code create a string literal


for example: 


the JVM checks the string literal pool first. If the string already exists in the pool, a reference to the pooled instance returns. If the string does not exist in the pool, a new String object instantiates, then is placed in the pool. Java can make this optimization since strings are immutable and can be shared without fear of data corruption


The only time you should use new String(foo) is when you want to break ==, which is an odd case, or when foo is a substring of a much larger string that has a limited lifetime, such as


and


Both expression gives you String object, but there is subtle difference between them. When you create String object using new() operator, it always create a new object in heap memory. On the other hand, if you create object using String literal syntax e.g. "Java", it may return an existing object from String pool (a cache of String object in Perm gen space, which is now moved to heap space in recent Java release), if it's already exists. 






I read some articles written on "ClassCastException", but I couldn't get a good idea on that. Is there a good article or what would be a brief explanation?


Straight from the API Specifications for the ClassCastException:


Thrown to indicate that the code has
  attempted to cast an object to a
  subclass of which it is not an
  instance.


So, for example, when one tries to cast an Integer to a String, String is not an subclass of Integer, so a ClassCastException will be thrown.


It's really pretty simple: if you are trying to typecast an object of class A into an object of class B, and they aren't compatible, you get a class cast exception.


Let's think of a collection of classes.


It is an Exception which occurs if you attempt to downcast a class, but in fact the class is not of that type.


Consider this heirarchy:


Object -> Animal -> Dog


You might have a method called:


If called with this code:


It will compile just fine, but at runtime you will get a ClassCastException because o was in fact an Animal, not a Dog.


In later versions of Java you do get a compiler warning unless you do:


Consider an example,


At Another t5 = (Another) new Goat(): you will get a ClassCastException because you cannot create an instance of the Another class using Goat. 


Note: The conversion is valid only in cases where a class extends a parent class and the child class is casted to its parent class.


How to deal with the ClassCastException:


Source of the Note and the Rest


Do you understand the concept of casting? Casting is the process of type conversion, which is in Java very common because its a statically typed language. Some examples:


Cast the String "1" to an int -> no problem


Cast the String "abc" to an int -> raises a ClassCastException


Or think of a class diagram with Animal.class, Dog.class and Cat.class


You are trying to treat an object as an instance of a class that it is not.  It's roughly analogous to trying to press the damper pedal on a guitar (pianos have damper pedals, guitars don't).


A class cast exception is thrown by Java when you try to cast an Object of one data type to another.


Java allows us to cast variables of one type to another as long as the casting happens between compatible data types.


For example you can cast a String as an Object and similarly an Object that contains String values can be cast to a String.


Let us assume we have an HashMap that holds a number of ArrayList objects.


If we write code like this:


it would throw a class cast exception, because the value returned by the get method of the hash map would be an Array list, but we are trying to cast it to a String. This would cause the exception.


A very good example that I can give you for classcastException in Java is while using "Collection"


This above code will give you ClassCastException on runtime. Because you are trying to cast Integer to String, that will throw the exception.


You can better understand ClassCastException and casting once you realize that the JVM cannot guess the unknown. If B is an instance of A it has more class members and methods on the heap than A. The JVM cannot guess how to cast A to B since the mapping target is larger, and the JVM will not know how to fill the additional members.


But if A was an instance of B, it would be possible, because A is a reference to a complete instance of B, so the mapping will be one-to-one.


The following pseudocode will explain it in a better way.






I'm attracted to the neatness that a single file database provides. What driver/connector library is out there to connect and use SQLite with Java.


I've discovered a wrapper library, http://www.ch-werner.de/javasqlite, but are there other more prominent projects available?


The wiki lists some more wrappers:


I found your question while searching for information with SQLite and Java. Just thought I'd add my answer which I also posted on my blog.


I have been coding in Java for a while now. I have also known about SQLite but never used it… Well I have used it through other applications but never in an app that I coded. So I needed it for a project this week and it's so simple use!


I found a Java JDBC driver for SQLite. Just add the JAR file to your classpath and import java.sql.*


His test app will create a database file, send some SQL commands to create a table, store some data in the table, and read it back and display on console. It will create the test.db file in the root directory of the project.  You can run this example with java -cp .:sqlitejdbc-v056.jar Test.


I understand you asked specifically about SQLite, but maybe HSQL database would be a better fit with Java. It is written in Java itself, runs in the JVM, supports in-memory tables etc. and all that features make it quite usable for prototyping and unit-testing.


There is a new project SQLJet that is a pure Java implementation of SQLite. It doesn't support all of the SQLite features yet, but may be a very good option for some of the Java projects that work with SQLite databases.


David Crawshaw project(sqlitejdbc-v056.jar) seems out of date and last update was Jun 20, 2009,  source here


I would recomend Xerials fork of Crawshaw sqlite wrapper.  I replaced sqlitejdbc-v056.jar  with Xerials sqlite-jdbc-3.7.2.jar file without any problem. 


Uses same syntax as in Bernie's answer and is much faster and with latest sqlite library.


What is different from Zentus's SQLite JDBC?


The original Zentus's SQLite JDBC driver
  http://www.zentus.com/sqlitejdbc/ itself is an excellent utility for
  using SQLite databases from Java language, and our SQLiteJDBC library
  also relies on its implementation. However, its pure-java version,
  which totally translates c/c++ codes of SQLite into Java, is
  significantly slower compared to its native version, which uses SQLite
  binaries compiled for each OS (win, mac, linux).


To use the native version of sqlite-jdbc, user had to set a path to
  the native codes (dll, jnilib, so files, which are JNDI C programs) by
  using command-line arguments, e.g., -Djava.library.path=(path to the
  dll, jnilib, etc.), or -Dorg.sqlite.lib.path, etc. This process was
  error-prone and bothersome to tell every user to set these variables.
  Our SQLiteJDBC library completely does away these inconveniences.


Another difference is that we are keeping this SQLiteJDBC libray
  up-to-date to the newest version of SQLite engine, because we are one
  of the hottest users of this library. For example, SQLite JDBC is a
  core component of UTGB (University of Tokyo Genome Browser) Toolkit,
  which is our utility to create personalized genome browsers.


EDIT : As usual when you update something, there will be problems in some obscure place in your code(happened to me). Test test test =)


Bernie's post is very helpful. Couldn't vote up (don't have enough reputation :( ). But it Helped a lot. Just to reiterate!


http://www.zentus.com/sqlitejdbc/


Here you can find the latest SQLite JDBC jar. Just add the jar into you classpath and you are done! :) You can run Bernie's sample code to test if everything is fine. 


http://souptonuts.sourceforge.net/readme_sqlite_tutorial.html
http://www.sqlite.org/lang.html


Here you can find some help on SQL syntax for SQLite.
Cheers to SQLite :)


When you compile and run the code, you should set the classpath options value.
Just like the following:


Please pay attention to "." and the sparate ";"(win, the linux is ":")


sqlitejdbc code can be downloaded using git from https://github.com/crawshaw/sqlitejdbc. 


Note: Makefile requires curl binary to download sqlite libraries/deps.


The example code leads to a memory leak in Tomcat (after undeploying the webapp, the classloader still remains in memory) which will cause an outofmemory eventually. The way to solve it is to use the sqlite-jdbc-3.7.8.jar; it's a snapshot, so it doesn't appear for maven yet.


Typo: java -cp .:sqlitejdbc-v056.jar Test


should be: java -cp .:sqlitejdbc-v056.jar; Test


notice the semicolon after ".jar" i hope that helps people, could cause a lot of hassle 






Which set is short-circuiting, and what exactly does it mean that the complex conditional expression is short-circuiting?


The && and || operators "short-circuit", meaning they don't evaluate the right hand side if it isn't necessary.


The & and | operators, when used as logical operators, always evaluate both sides.


There is only one case of short-circuiting for each operator, and they are:


Let's compare the behaviour in a simple example:


The 2nd version uses the non-short-circuiting operator & and will throw a NullPointerException if input is null, but the 1st version will return false without an exception;


SET A uses short-circuiting boolean operators.


What 'short-circuiting' means in the context of boolean operators is that for a set of booleans b1, b2, ..., bn, the short circuit versions will cease evaluation as soon as the first of these booleans is true (||) or false (&&).


For example:


Short circuiting means the second operator will not be checked if the first operator decides the final outcome.


E.g. Expression is: True || False


In case of ||, all we need is one of the side to be True. So if the left hand side is true, there is no point in checking the right hand side, and hence that will not be checked at all.


Similarly, False && True


In case of &&, we need both sides to be True. So if the left hand side is False, there is no point in checking the right hand side, the answer has to be False. And hence that will not be checked at all.


This kind will short-circuit, meaning if (x < z) evaluates to false then the latter is not evaluated, a will be false, otherwise && will also evaluate (x == x).


& is a bitwise operator, but also a boolean AND operator which does not short-circuit.


You can test them by something as follows (see how many times the method is called in each case):


Java provides two interesting Boolean operators not found in most other computer languages. These secondary versions of AND and OR are known as short-circuit logical operators. As you can see from the preceding table, the OR operator results in true when A is true, no matter what B is.


Similarly, the AND operator results in false when A is false, no matter what B is. If you use the || and && forms, rather than the | and & forms of these operators, Java will not bother to evaluate the right-hand operand alone. This is very useful when the right-hand operand depends on the left one being true or false in order to function properly.


For example, the following code fragment shows how you can take advantage of short-circuit logical evaluation to be sure that a division operation will be valid before evaluating it:


Since the short-circuit form of AND (&&) is used, there is no risk of causing a run-time exception from dividing by zero. If this line of code were written using the single & version of AND, both sides would have to be evaluated, causing a run-time exception when denom is zero.


It is standard practice to use the short-circuit forms of AND and OR in cases involving Boolean logic, leaving the single-character versions exclusively for bitwise operations. However, there are exceptions to this rule. For example, consider the following statement:


Here, using a single & ensures that the increment operation will be applied to e whether c is equal to 1 or not.


In plain terms, short-circuiting means stopping evaluation once you know that the answer can no longer change. For example, if you are evaluating a chain of logical ANDs and you discover a FALSE in the middle of that chain, you know the result is going to be false, no matter what are the values of the rest of the expressions in the chain. Same goes for a chain of ORs: once you discover a TRUE, you know the answer right away, and so you can skip evaluating the rest of the expressions.


You indicate to Java that you want short-circuiting by using && instead of & and || instead of |. The first set in your post is short-circuiting.


Note that this is more than an attempt at saving a few CPU cycles: in expressions like this


short-circuiting means a difference between correct operation and a crash (in the case where mystring is null).


Logical OR :- returns true if at least one of the operands evaluate to true. Both operands are evaluated before apply the OR operator.


Short Circuit OR :- if left hand side operand returns true, it returns true without evaluating the right hand side operand. 


Since the short-circuit form of AND(&&) is used, there is no risk of causing a run-time exception when demon is zero.


Ref. Java 2 Fifth Edition by Herbert Schildt






I'm working now together with others in a grails project. I have to write some Java-classes. But I need access to an searchable object created with groovy. It seems, that this object has to be placed in the default-package. 


My question is: Is there a way to access this object in the default-package from a Java-class in a named package?


You can’t use classes in the default package from a named package.
(Technically you can, as shown in Sharique Abdullah's answer through reflection API, but classes from the unnamed namespace are not in scope in an import declaration)


Prior to J2SE 1.4 you could import classes from the default package using a syntax like this:


That's no longer allowed. So to access a default package class from within a packaged class requires moving the default package class into a package of its own.


If you have access to the source generated by groovy, some post-processing is needed to move the file into a dedicated package and add this "package" directive at its beginning.


Update 2014: bug 6975015, for JDK7 and JDK8, describe an even stricter prohibition against import from unnamed package.


The TypeName must be the canonical name of a class type, interface type, enum type, or annotation type.
  The type must be either a member of a named package, or a member of a type whose outermost lexically enclosing type is a member of a named package, or a compile-time error occurs.


In fact, you can. 


Using reflections API you can access any class so far. At least I was able to :)


Use jarjar to repackage the jar file with the following rule:


All classes in the default package of the source jar file will move to the target package, thus are able to access.


You can use packages in the Groovy code, and things will work just fine. 


It may mean a minor reorganization of code under grails-app and a little bit of a pain at first, but on a large grails project, it just make sense to organize things in packages.  We use the Java standard package naming convention com.foo.<app>.<package>.


Having everything in the default package becomes a hindrance to integration, as you're finding.


Controllers seem to be the one Grails artifact (or artefact) that resists being put in a Java package.  Probably I just haven't figured out the Convention for that yet.  ;-)






I have a Java process that opens a file using a FileReader. How can I prevent another (Java) process from opening this file, or at least notify that second process that the file is already opened? Does this automatically make the second process get an exception if the file is open (which solves my problem) or do I have to explicitly open it in the first process with some sort of flag or argument?


I have a Java app that lists a folder and opens each file in the listing for processing it. It processes each file after the other. The processing of each file consists of reading it and doing some calculations based on the contents and it takes about 2 minutes. I also have another Java app that does the same thing but instead writes on the file. What I want is to be able to run these apps at the same time so the scenario goes like this. ReadApp lists the folder and finds files A, B, C. It opens file A and starts the reading. WriteApp lists the folder and finds files A, B, C. It opens file A, sees that is is open (by an exception or whatever way) and goes to file B. ReadApp finishes file A and continues to B. It sees that it is open and continues to C. It is crucial that WriteApp doesn't write while ReadApp is reading the same file or vice versa. They are different processes.


FileChannel.lock is probably what you want.


(Disclaimer: Code not compiled and certainly not tested.)


Note the section entitled "platform dependencies" in the API doc for FileLock.


Don't use  the classes in thejava.io package, instead  use the java.nio package . The latter has a FileLock class. You can apply a lock to a FileChannel.


If you can use Java NIO (JDK 1.4 or greater), then I think you're looking for java.nio.channels.FileChannel.lock()


FileChannel.lock()


use java.nio.channels.FileLock in conjunction with java.nio.channels.FileChannel


This may not be what you are looking for, but in the interest of coming at a problem from another angle....


Are these two Java processes that might want to access the same file in the same application? Perhaps you can just filter all access to the file through a single, synchronized method (or, even better, using JSR-166)?  That way, you can control access to the file, and perhaps even queue access requests.


Use a RandomAccessFile, get it's channel, then call lock().  The channel provided by input or output streams does not have sufficient privileges to lock properly.  Be sure to call unlock() in the finally block (closing the file doesn't necessarily release the lock).


I found the same issue some years back when I wrote an application that required multiple users on MacOS/Windows to share the same data in multiple files.
File locking didn't work on MacOS so I created my own 'ioFile' class which maintained it's own register of file access - open r/o, open r/w, etc, and who 'owned' the lock.
This is the only way at the time I could control access from different users on different machines using different OS's.


Below is a sample snippet code to lock a file until it's process is done by JVM.  


If you put your file access in synchronized block, only one instance of thread can enter into it, others will wait, until one has finished it's work.


You an use java.nio.* APIs for locking a file. However that doesn't guarantee locking, It depends on if the underlying OS supports locking or not. As I understand Operating systems like Linux doens't support locking and hence you cannot lock even if you use these APIs






Starting from scratch without any previous Jersey 1.x knowledge, I'm having a hard time understanding how to setup dependency injection in my Jersey 2.0 project.  


I also understand that HK2 is available in Jersey 2.0, but I cannot seem to find docs that help with Jersey 2.0 integration.


pom.xml


I can get the container to start and serve up my resource, but as soon as I add @Inject to MyService, the framework throws an exception:



My starter project is available at GitHub: https://github.com/donaldjarmstrong/jaxrs


You need to define an AbstractBinder and register it in your JAX-RS application. The binder specifies how the dependency injection should create your classes.


When @Inject is detected on a parameter or field of type MyService.class it is instantiated using the class MyService. To use this binder, it need to be registered with the JAX-RS application. In your web.xml, define a JAX-RS application like this:


Implement the MyApplication class (specified above in the init-param).


The binder specifying dependency injection is registered in the constructor of the class, and we also tell the application where to find the REST resources (in your case, MyResource) using the packages() method call.


First just to answer a comment in the accepts answer.


"What does bind do? What if I have an interface and an implementation?"


It simply reads bind( implementation ).to( contract ). You can alternative chain .in( scope ). Default scope of PerLookup. So if you want a singleton, you can


There's also a RequestScoped available


Also, instead of bind(Class).to(Class), you can also bind(Instance).to(Class), which will be automatically be a singleton.


Adding to the accepted answer


For those trying to figure out how to register your AbstractBinder implementation in your web.xml (i.e. you're not using a ResourceConfig), it seems the binder won't be discovered through package scanning, i.e. 


Or this either


To get it to work, I had to implement a Feature:


The @Provider annotation should allow the Feature to be picked up by the package scanning. Or without package scanning, you can explicitly register the Feature in the web.xml


See Also:


and for general information from the Jersey documentation


Aside from the basic binding in the accepted answer, you also have factories, where you can have more complex creation logic, and also have access to request context information. For example


Then you can inject MyService into your resource class.


The selected answer dates from a while back. It is not practical to declare every binding in a custom HK2 binder.
I'm using Tomcat and I just had to add one dependency. Even though it was designed for Glassfish it fits perfectly into other containers. 


Make sure your container is properly configured too (see the documentation).


Oracle recommends to add the @Path annotation to all types to be injected when combining JAX-RS with CDI:
http://docs.oracle.com/javaee/7/tutorial/jaxrs-advanced004.htm
Though this is far from perfect (e.g. you will get warning from Jersey on startup), I decided to take this route, which saves me from maintaining all supported types within a binder.


Example:


Late but I hope this helps someone.


I have my JAX RS defined like this:


Then, in my code finally I can inject:


In my case, the SomeManagedBean is an ApplicationScoped bean.


Hope this helps to anyone.


If you prefer to use Guice and you don't want to declare all the bindings, you can also try this adapter:


guice-bridge-jit-injector






The Java official documentation states:


The string "boo:and:foo", for example, yields the following results with these expressions 
Regex   Result
:   


And that's the way I need it to work. However, if I run this:


it prints:


Which is far from what I would expect:


Why is this happening?


Thanks in advance


You need 


split uses regular expression and in regex | is a metacharacter representing the OR operator. You need to escape that character using \ (written in String as "\\" since \ is also a metacharacter in String literals and require another \ to escape it).


You can also use 


and let Pattern.quote create the escaped version of the regex representing |.


Use proper escaping: string.split("\\|")


Or the helper Pattern.quote() which has been created for exactly this purpose: 


which works with arbitrary input strings. Very useful when you need to quote / escape user input.


Use this code:


You can also use .split("[|]").


(I used this instead of .split("\\|"), which didn't work for me.)


You could also use the apache library and do this:


the split() method takes a regular expression as an argument






In Java, the hash code for a String object is computed as


s[0]*31^(n-1) + s[1]*31^(n-2) + ... + s[n-1]


using int arithmetic, where s[i] is the ith character of the string, n is the length of the string, and ^ indicates exponentiation.


Why is 31 used as a multiplier?


I understand that the multiplier should be a relatively large prime number. So why not 29, or 37, or even 97?


According to Joshua Bloch's Effective Java (a book that can't be recommended enough, and which I bought thanks to continual mentions on stackoverflow):


The value 31 was chosen because it is an odd prime. If it were even and the multiplication overflowed, information would be lost, as multiplication by 2 is equivalent to shifting. The advantage of using a prime is less clear, but it is traditional. A nice property of 31 is that the multiplication can be replaced by a shift and a subtraction for better performance: 31 * i == (i << 5) - i. Modern VMs do this sort of optimization automatically.


(from Chapter 3, Item 9: Always override hashcode when you override equals, page 48)


As Goodrich and Tamassia point out, If you take over 50,000 English words (formed as the union of the word lists provided in two variants of Unix), using the constants 31, 33, 37, 39, and 41 will produce less than 7 collisions in each case. Knowing this, it should come as no surprise that many Java implementations choose one of these constants. 


Coincidentally, I was in the middle of reading the section "polynomial hash codes" when I saw this question.


EDIT: here is link to the ~10mb PDF book i'm referring to above. See section 10.2 Hash Tables (page 413) of Data Structures and Algorithms in Java 


On (mostly) old processors, multiplying by 31 can be relatively cheap. On an ARM, for instance, it is only one instruction:


Most other processors would require a separate shift and subtract instruction. However, if your multiplier is slow this is still a win. Modern processors tend to have fast multipliers so it doesn't make much difference, so long as 32 goes on the correct side.


It's not a great hash algorithm, but it's good enough and better than the 1.0 code (and very much better than the 1.0 spec!).


By multiplying, bits are shifted to the left. This uses more of the available space of hash codes, reducing collisions.


By not using a power of two, the lower-order, rightmost bits are populated as well, to be mixed with the next piece of data going into the hash.


The expression n * 31 is equivalent to (n << 5) - n.


Neil Coffey explains why 31 is used under Ironing out the bias.


Basically using 31 gives you a more even set-bit probability distribution for the hash function.


Actually, 37 would work pretty well!  z := 37 * x can be computed as y := x + 8 * x; z := x + 4 * y.  Both steps correspond to one LEA x86 instructions, so this is extremely fast.  


In fact, multiplication with the even-larger prime 73 could be done at the same speed by setting y := x + 8 * x; z := x + 8 * y.


Using 73 or 37 (instead of 31) might be better, because it leads to denser code:  The two LEA instructions only take 6 bytes vs. the 7 bytes for move+shift+subtract for the multiplication by 31.  One possible caveat is that the 3-argument LEA instructions used here became slower on Intel's Sandy bridge architecture, with an increased latency of 3 cycles.


Moreover, 73 is Sheldon Cooper's favorite number.


You can read Bloch's original reasoning under "Comments" in http://bugs.java.com/bugdatabase/view_bug.do?bug_id=4045622. He investigated the performance of different hash functions in regards to the resulting "average chain size" in a hash table. P(31) was one of the common functions during that time which he found in K&R's book (but even Kernighan and Ritchie couldn't remember where it came from). In the end he basically had to chose one and so he took P(31) since it seemed to perform well enough. Even though P(33) was not really worse and multiplication by 33 is equally fast to calculate (just a shift by 5 and an addition), he opted for 31 since 33 is not a prime:


Of the remaining
  four, I'd probably select P(31), as it's the cheapest to calculate on a RISC
  machine (because 31 is the difference of two powers of two).  P(33) is
  similarly cheap to calculate, but it's performance is marginally worse, and
  33 is composite, which makes me a bit nervous.


So the reasoning was not as rational as many of the answers here seem to imply. But we're all good in coming up with rational reasons after gut decisions (and even Bloch might be prone to that).


I'm not sure, but I would guess they tested some sample of prime numbers and found that 31 gave the best distribution over some sample of possible Strings.


Bloch doesn't quite go into this, but the rationale I've always heard/believed is that this is basic algebra.  Hashes boil down to multiplication and modulus operations, which means that you never want to use numbers with common factors if you can help it.  In other words, relatively prime numbers provide an even distribution of answers.


The numbers that make up using a hash are typically:


You really only get to control a couple of these values, so a little extra care is due.


From JDK-4045622, where Joshua Bloch describes the reasons why that particular (new) String.hashCode() implementation was chosen


The table below summarizes the performance of the various hash
  functions described above, for three data sets:


1) All of the words and phrases with entries in Merriam-Webster's
         2nd Int'l Unabridged Dictionary (311,141 strings, avg length 10 chars).


2) All of the strings in /bin/, /usr/bin/, /usr/lib/, /usr/ucb/
         and /usr/openwin/bin/*  (66,304 strings, avg length 21 characters).


3) A list of URLs gathered by a web-crawler that ran for several
         hours last night (28,372 strings, avg length 49 characters).


The performance metric shown in the table is the "average chain size"
  over all elements in the hash table (i.e., the expected value of the
  number of key compares to look up an element).


Looking at this table, it's clear that all of the functions except for
  the current Java function and the two broken versions of Weinberger's
  function offer excellent, nearly indistinguishable performance.  I
  strongly conjecture that this performance is essentially the
  "theoretical ideal", which is what you'd get if you used a true random
  number generator in place of a hash function.


I'd rule out the WAIS function as its specification contains pages of random numbers, and its performance is no better than any of the
  far simpler functions.  Any of the remaining six functions seem like
  excellent choices, but we have to pick one.  I suppose I'd rule out
  Vo's variant and Weinberger's function because of their added
  complexity, albeit minor.  Of the remaining four, I'd probably select
  P(31), as it's the cheapest to calculate on a RISC machine (because 31
  is the difference of two powers of two).  P(33) is similarly cheap to
  calculate, but it's performance is marginally worse, and 33 is
  composite, which makes me a bit nervous.


Josh






I am studying a java tutorial and saw that the way to find the x/y indexes of a JButton inside a GridLayout is to traverse a bidimensional array of buttons b which is associated to the layout and checking if


b[i][j] == buttonReference.


Is there an easier way to get the X/Y indexes of a button?


Something like:


this being a GameWindow instance and ev the ActionEvent triggered when the user presses the button.





In this case it should get: x == 2, y == 1


@GameWindow.java:


@JavaSwingApplication.java:


This example shows how to create a grid button that knows its location on the grid. The method getGridButton() shows how to obtain a button reference efficiently based on its grid coordinates, and the action listener shows that the clicked and found buttons are identical.





You have saved an array of all JButtons; you could search for ae.getSource() and you have the position.


From JButtons


JButton#setName(String);


JBUtton#setActionCommand(String);


JBUtton#setAction(Action);


from/to Container


SwingUtilities#convert...


SwingUtilities#getDeepestComponentAt


You can use setName() to store within a JButton its location(ex. button.setName(i+" "+j);) when you create it; you can then access it by splitting the string you get from button.getName() around the space. It is not an especially efficient method, but it sounds a little like what you are (or were, by now) looking for.


this solution selects everything object between like them
first 
write method that get text or Everything needed for Jbuuton or jlable or....
second change under code






What is the difference between HashMap, LinkedHashMap and TreeMap in Java? 
I don't see any difference in the output as all the three has keySet and values. What are Hashtables?


All three classes implement the Map interface and offer mostly the same functionality. The most important difference is the order in which iteration through the entries will happen:


"Hashtable" is the generic name for hash-based maps. In the context of the Java API,
Hashtable is an obsolete class from the days of Java 1.1 before the collections framework existed. It should not be used anymore, because its API is cluttered with obsolete methods that duplicate functionality, and its methods are synchronized (which can decrease performance and is generally useless). Use ConcurrrentHashMap instead of Hashtable. 


I prefer visual presentation: 


All three represent mapping from unique keys to values, and therefore implement the Map interface.


HashMap is a map based on hashing of the keys. It supports O(1) get/put operations. Keys must have consistent implementations of hashCode() and equals() for this to work. 


LinkedHashMap is very similar to HashMap, but it adds awareness to the order at which items are added (or accessed), so the iteration order is the same as insertion order (or access order, depending on construction parameters).


TreeMap is a tree based mapping. Its put/get operations take O(log n) time. It requires items to have some comparison mechanism, either with Comparable or Comparator. The iteration order is determined by this mechanism.


See where each class is in the class hierarchy in the following diagram (bigger one). TreeMap implements SortedMap and NavigableMap while HashMap doesn't.


HashTable is obsolete and the corresponding ConcurrentHashMap class should be used.



Just some more input from my own experience with maps, on when I would use each one:


HashMap makes absolutely not guarantees about the iteration order. It
  can (and will) even change completely when new elements are added.
  TreeMap will iterate according to the "natural ordering" of the keys
  according to their compareTo() method (or an externally supplied
  Comparator). Additionally, it implements the SortedMap interface,
  which contains methods that depend on this sort order. LinkedHashMap
  will iterate in the order in which the entries were put into the map


Look at how performance varying..



Tree map which is an implementation of Sorted map. The complexity of the put, get and containsKey operation is O(log n) due to the Natural ordering


Let me put it simple:


@Amit: SortedMap is an interface whereas TreeMap is a class which implements the SortedMap interface. That means if follows the protocol which SortedMap asks its implementers to do.
A tree unless implemented as search tree, can't give you ordered data because tree can be any kind of tree. So to make TreeMap work like Sorted order, it implements SortedMap ( e.g, Binary Search Tree - BST, balanced BST like AVL and R-B Tree , even Ternary Search Tree - mostly used for iterative searches in ordered way ).


In NUT-SHELL
HashMap : gives data in O(1) , no ordering


TreeMap : gives data in O(log N), base 2. with ordered keys


LinkedHashMap : is Hash table with linked list (think of indexed-SkipList) capability to store data in the way it gets inserted in the tree. Best suited to implement LRU ( least recently used ).


These are different implementations of the same interface. Each implementation has some advantages and some disadvantages (fast insert, slow search) or vice versa.


For details look at the javadoc of TreeMap, HashMap, LinkedHashMap.


All three classes HashMap, TreeMap and LinkedHashMap implements java.util.Map interface, and represents mapping from unique key to values. 


HashMap


A HashMap contains values based on the key.


It contains only    unique elements. 


It may have one null key and multiple null values.


It maintains no order.


public class HashMap<K,V> extends AbstractMap<K,V> implements Map<K,V>, Cloneable, Serializable


LinkedHashMap


It is same as HashMap instead maintains insertion order. //See class deceleration below


public class LinkedHashMap<K,V> extends HashMap<K,V> implements Map<K,V>


TreeMap


It is same as HashMap instead maintains ascending order(Sorted using the natural order of its key.).


public class TreeMap<K,V> extends AbstractMap<K,V> implements NavigableMap<K,V>, Cloneable, Serializable 


Hashtable


It is a legacy class.


public class Hashtable<K,V> extends Dictionary<K,V> implements Map<K,V>, Cloneable, Serializable





Ref: http://javarevisited.blogspot.in/2015/08/difference-between-HashMap-vs-TreeMap-vs-LinkedHashMap-Java.html


All offer a key->value map and a way to iterate through the keys. The most important distinction between
these classes are the time guarantees and the ordering of the keys.


Imagine you passed an empty TreeMap, HashMap, and LinkedHashMap into the following function:


The output for each will look like the results below.


For HashMap, the output was, in my own tests, { 0, 1, -1}, but it could be any ordering. There is no guarantee on the
ordering.
Treemap,the output was,{ -1, 0, 1}
LinkedList,the output was,{ 1, -1, 0}


HashMap
can contain one null key.


HashMap maintains no order. 


TreeMap


TreeMap can not contain any null key.


TreeMap maintains ascending order.


LinkedHashMap


LinkedHashMap can be used to maintain insertion order, on which keys are inserted into Map or it can also be used to maintain an access order, on which keys are accessed.


Examples::


1) HashMap map = new HashMap();


2) TreeMap map = new TreeMap();


3) LinkedHashMap map = new LinkedHashMap();






I need to use certain font for my entire application. I have .ttf file for the same.
Is it possible to set this as default font, at application start up and then use it elsewhere in the application? When set, how do I use it in my layout XMLs?


Yes with reflection. This works (based on this answer):


(Note: this is a workaround due to lack of support for custom fonts, so if you want to change this situation please do star to up-vote the android issue here). Note: Do not leave "me too" comments on that issue, everyone who has stared it gets an email when you do that. So just "star" it please.


You then need to overload the few default fonts, for example in an application class:


Or course if you are using the same font file, you can improve on this to load it just once.


However I tend to just override one, say "MONOSPACE", then set up a style to force that font typeface application wide:


I've investigated the reports in the comments that it doesn't work and it appears to be incompatible with the theme android:Theme.Material.Light.


If that theme is not important to you, use an older theme, e.g.:


While this would not work for an entire application, it would work for an Activity and could be re-used for any other Activity. I've updated my code thanks to @FR073N to support other Views. I'm not sure about issues with Buttons, RadioGroups, etc. because those classes all extend TextView so they should work just fine. I added a boolean conditional for using reflection because it seems very hackish and might notably compromise performance.


Note: as pointed out, this will not work for dynamic content! For that, it's possible to call this method with say an onCreateView or getView method, but requires additional effort.


Then to use it you would do something like this:


Hope that helps.


There is a great library for custom fonts in android:Calligraphy


here is a sample how to use it. 


in Gradle you need to put this line into your app's build.gradle file:


and then make a class that extends Application and write this code:


and in the activity class put this method before onCreate:


and the last thing your manifest file should look like this:


and it will change the whole activity to your font! it's simple and clean! 


I would like to improve weston's answer for API 21 Android 5.0.


Under API 21, most of the text styles include fontFamily setting, like:


Which applys the default Roboto Regular font:


The original answer fails to apply monospace font, because android:fontFamily has greater priority to android:typeface attribute (reference). 
Using Theme.Holo.* is a valid workaround, because there is no android:fontFamily settings inside.


Since Android 5.0 put system typeface in static variable Typeface.sSystemFontMap (reference), we can use the same reflection technique to replace it:


In summary:


Option#1:  Use reflection to apply font (combining weston & Roger Huang's answer):


Usage in Application class:


set up a style to force that font typeface application wide (based on lovefish):


Pre-Lollipop:


Lollipop (API 21):


Option2:   Subclass each and every View where you need to customize font, ie. ListView, EditTextView, Button, etc. (Palani's answer):


Option 3:   Implement a View Crawler that traverses through the view hierarchy of your current screen:


Variation#1 (Tom's answer):


Usage :


Variation#2:   https://coderwall.com/p/qxxmaa/android-use-a-custom-font-everywhere.


Option #4:  Use 3rd Party Lib called Calligraphy.


Personally, I would recommend Option#4, as it saves a lot of headaches.


its very simple...
1.Download and put ur custom font in assets..then write one separate class for text view as follows:  here i used futura font


}


and do the following in xml :


I would also suggest extending TextView and other controls, but it would be better I consider to set up font in constructs.


I would like to improve weston's and Roger Huang's answers for over API 21 Android lollipop with theme "Theme.AppCompat".


Below Android 4.4


Over(equal) API 5.0


And the FontsOverride util file is same as what in weston's answer. 
I have tested in these phones:


Nexus 5(android 5.1 Primary Android System) 


ZTE V5(android 5.1 CM12.1) 


XIAOMI note(android 4.4 MIUI6)


HUAWEI C8850(android 2.3.5 UNKNOWN)



Working for Xamarin.Android:


Class:


Application Implementation:


Style:


A brilliant solution can be found here: https://coderwall.com/p/qxxmaa/android-use-a-custom-font-everywhere.


Simply extend activities from BaseActivity and write those methods. Also you should better cache fonts as described here: https://stackoverflow.com/a/16902532/2914140.


After some research I wrote code that works at Samsung Galaxy Tab A (Android 5.0). Used code of weston and Roger Huang as well as https://stackoverflow.com/a/33236102/2914140. Also tested on Lenovo TAB 2 A10-70L, where it doesn't work.
I inserted a font 'Comic Sans' here in order to see a difference.


To run the code in entire application you should write in some class like Application the following:


Create a folder 'fonts' inside 'assets' and put needed fonts there. A simple instruction may be found here: https://stackoverflow.com/a/31697103/2914140.


The Lenovo device also incorrectly gets a value of a typeface. In most times it returns Typeface.NORMAL, sometimes null. Even if a TextView is bold (in xml-file layout). See here: TextView isBold always returns NORMAL. This way a text on a screen is always in a regural font, not bold or italic. So I think it's a bug of a producer.


You can set custom fonts for every layout one by one ,with just one function call from every layout by passing its root View.First ,create a singelton approach for accessing font object like this 


You can define different fonts in above class, Now Define a font Helper class that will apply fonts : 


In the above code, I am applying fonts on textView and EditText only , you can apply fonts on other view elements as well similarly.You just need to pass the id of your root View group to the above apply font method. for example your layout is :


In the Above Layout the root parent id is "Main Parent " now lets apply font 


Cheers :) 


I would suggest extending TextView, and always using your custom TextView within your XML layouts or wherever you need a TextView. In your custom TextView, override setTypeface


As of Android O this is now possible to define directly from the XML and my bug is now closed!


See here for details


TL;DR:


First you must add your fonts to the project


Second you add a font family, like so:


Finally, you can use the font in a layout or style:


Enjoy!


Tom's solution works great, but only works with TextView and EditText.


If you want to cover most of the views (RadioGroup, TextView, Checkbox...), I created a method doing that : 


This method will get back the style of the view set in XML (bold, italic...) and apply them if they exists. 


For the ListView, I always create an adapter, and I set the font inside getView. 


I wrote a class assigning typeface to the views in the current view hierarchy and based os the current typeface properties (bold, normal, you can add other styles if you want):


Now in all fragments in onViewCreated or onCreateView, in all activities in onCreate and in all view adapters in getView or newView just invoke:


I would also like to improve weston's answer for API 21 Android 5.0.


I had the same issue on my Samsung s5, when using DEFAULT font. (with the others fonts it's working fine)


I managed to make it working by setting the typeface ("sans" for example) in XML files, for each Textview or Button


and in MyApplication Class :


Hope it helps.


This solution does not work correctly in some situations.
So I extend it:


FontsReplacer.java


https://gist.github.com/orwir/6df839e3527647adc2d56bfadfaad805


Calligraphy works pretty well, but it is not suitable for me, since it does not support different weights (bold, italic, etc) for a font-family.


So I tried Fontain, which allows you to define custom Views and apply them custom font families.


in order to use Fontain, you should add the following to your app module build.gradle:


Then, instead of using regular TextView, you should use FontTextView


Example of FontTextView with uppercase and bold content:


Yes, its possible to set the font to the entire application.


The easiest way to accomplish this is to package the desired font(s) with your application. 


To do this, simply create an assets/  folder in the project root, and put your fonts (in 
TrueType, or TTF, form) in the assets. 


You might, for example, create assets/fonts/  and put your TTF files in there.






JRE Version 1.7 Update 3


EXPECTED BEHAVIOUR


As I run the program, it works as expected, everything works smoothly. As when I click on STOP JButton the animation stops and the text on the same JButton changes to START. Now when i click on BALL COLOUR JButton, the colour of the BALL changes, as well as the colour of the BALL COLOUR JBUTTON, also changes, to that of the BALL. This whole behaviour works if I run my application as is without resizing.


UNEXPECTED BEHAVIOUR


But when i RESIZE my JFrame, by pulling the Right Side, that's when unexpected behaviour of my Application is shown, in the sense that if I press STOP JButton and then click on BALL COLOUR button, the text on the JButton clicked earlier whose text changed to START will change to STOP again when it should not be, as well as the colour of the BALL COLOUR JButton will remain unchanged or will turn to BLUE, when it should be changed to the colour of the ball. I am attaching the pics for more info. But if you will try to resize it back to it's original size or closer to that, then things will come back to normal. Why is this happening ? Any idea or clue will be much appreciated.


As My Application Runs with EXPECTED BEHAVIOUR as described above : 





And here the UNEXPECTED BEHAVIOUR





BOTTOM-LINE : 


Why the Application runs as usual as it should be, at the BEGINNING , but not when RESIZED by dragging it's RIGHT SIDE, but again if you bring it to it's original size or closer to it, things come back to normal, it works as expected ?


So considering the scenario, am I doing something wrong, in the program. Or is this exactly the situation, where I should be using the SwingWorker, Or Is this an issue with the Layout, or something hidden related to Content Pane. Please do put some light :-)


here is the code I am using, I had brought it down to the minimum, as I think to demonstrate my problem : 


**LATEST EDIT : **





The problem with your very nice example may be platform dependent, but I can offer a few observations:


You're not adding or removing components, so you don't need revalidate().


Because the background color is a bound property of the buttons, you don't need the subsequent calls to repaint().


You do need repaint() in your custom DrawingArea, but you may want to experiment with adding property change support, as suggested here.


Color.white can't be brighter() and Color.black can't be darker(); Color.darkGray.darker() is Color.black().


The variation below uses a Queue<Color> to simplify changing colors.





Seems like there is something wrong with BorderLayout.LINE_END thingy, only when I place the buttonPanel on LINE_END, I am getting undesirable results. I had tried to use only one JButton, instead of three as the latest measure, to sort out thingies. Now the problem that use to come as shown in this pic : 





has been sorted out by changing the position of the JButton Panel to LINE_START or using JRE version 1.6 update 31, in the pic as below : 





Here is the code used for this example : 


maybe will help you with two parts of, I think that Graphics/2D is designated to use Swing Timer exclusively, 


I am unsure whether I found a solution for your system, but adjusting the code to


works on my system (OS X with Java 1.7). Note the setOpaque call, which is needed so that the setBackground call has any effect as stated in the javadoc of that method:


Sets the background color of this component. The background color is used only if the component is opaque


On OS X, without that setOpaque call your code does not even work before a resize






lets assume this URL...


(Here id needs to be sent in a POST request)


I want to send the id = 10 to the server's page.php, which accepts it in a POST method.


How can i do this from within Java?


I tried this :


But I still can't figure out how to send it via POST


Since some of the classes, in the original answer, are deprecated in the newer version of Apache HTTP Components, I'm posting this update.


By the way, you can access the full documentation for more examples here.


I recommend to use Apache HttpClient. its faster and easier to implement.


for more information check this url: http://hc.apache.org/


Sending a POST request is easy in vanilla Java. Starting with a URL, we need t convert it to a URLConnection using url.openConnection();. After that, we need to cast it to a HttpURLConnection, so we can access its setRequestMethod() method to set our method. We finally say that we are going to send data over the connection.


We then need to state what we are going to send:


A normal POST coming from a http form has a well defined format. We need to convert our input to this format:


We can then attach our form contents to the http request with proper headers and send it.


We can also send json using java, this is also easy:


Remember that different servers accept different content-types for json, see this question.


Sending files can be considered more challenging to handle as the format is more complex. We are also going to add support for sending the files as a string, since we don't want to buffer the file fully into the memory.


For this, we define some helper methods:


We can then use these methods to create a multipart post request as follows:


The first answer was great, but I had to add try/catch to avoid Java compiler errors.
Also, I had troubles to figure how to read the HttpResponse with Java libraries.  


Here is the more complete code :


A simple way using Apache HTTP Components is


Take a look at the Fluent API


Posting code that can send form data in post requests and works even on Java 7


simplest way to send parameters with the post request:


You have done. now you can use responsePOST.
Get response content as string:


Call HttpURLConnection.setRequestMethod("POST") and HttpURLConnection.setDoOutput(true); Actually only the latter is needed as POST then becomes the default method.


I recomend use http-request built on apache http api.






I have "Hello World" kept in a String variable named hi.


I need to print it, but reversed.


How can I do this? I understand there is some kind of a function already built-in into Java that does that.


Related: Reverse each individual word of “Hello World” string with Java


You can use this:


Or, for versions earlier than JDK 1.5, use java.util.StringBuffer instead of StringBuilder — they have the same API. Thanks commentators for pointing out that StringBuilder is preferred nowadays.


For Online Judges problems that does not allow StringBuilder or StringBuffer, you can do it in place using char[] as following:


http://www.java2s.com/Code/Java/Language-Basics/ReverseStringTest.htm


I am doing this using following two ways:


Reverse string by CHARACTERS:


Reverse string by WORDS:


Here is an example using recursion:


Take a look at the Java 6 API under StringBuffer


Here is a low level solution:


I tried, just for fun, by using a Stack. Here my code:


Since the below method (using XOR) to reverse a string is not listed, I am attaching this method to reverse a string.


The Algorithm is based on :


1.(A XOR B) XOR B = A 


2.(A XOR B) XOR A = B


Code snippet:


Output:


keetarp


It is very simple in minimum code of lines


As others have pointed out the preferred way is to use:


new StringBuilder(hi).reverse().toString()


but if you want to implement this by youself, i'am afraid that the rest of responses have flaws.


The reason is that String represent a list of Unicode points, encoded in a char[] array according to the variable-length encoding: UTF-16. 


This means some code points use a single element of the array (one code unit) but others use two of them, so there might be pairs of characters that must be treated as a single unit (consecutive "high" and "low" surrogates)


This did the trick for me


I used this method to turn names backwards and into lower case.


One natural way to reverse a String is to use a StringTokenizer and a stack. Stack is a class that implements an easy-to-use last-in, first-out (LIFO) stack of objects.


Put it in the stack frontwards


Print the stack backwards


All above solution is too good but here I am making reverse string using recursive programming. 


This is helpful for who is looking recursive way of doing reverse string. 


If you want to use a simple for loop!


It gets the value you typed and returns it reversed ;)


}


public String reverseWords(String s) {


You can also try this:


1. Using Character Array:


2. Using StringBuilder:


OR


Reversing a String by Character:


Reversing a String by Word:


public class Main {


We can use split() to split the string .Then use reverse loop and add the characters.






Basically I would like to decode a given Html document, and replace all special chars, such as "&nbsp" -> " ", "&gt;" -> ">".


In .NET we can make use of HttpUtility.HtmlDecode. 


What's the equivalent function in Java?


I have used the Apache Commons StringEscapeUtils.unescapeHtml4() for this:


Unescapes a string containing entity
  escapes to a string containing the
  actual Unicode characters
  corresponding to the escapes. Supports
  HTML 4.0 entities.


I tried Apache Commons StringEscapeUtils.unescapeHtml3() in my project, but wasn't satisfied with its performance. Turns out, it does a lot of unnecessary operations. For one, it allocates a StringWriter for every call, even if there's nothing to unescape in the string.  I've rewritten that code differently, now it works much faster. Whoever finds this in google is welcome to use it.


Following code unescapes all HTML 3 symbols and numeric escapes (equivalent to Apache unescapeHtml3). You can just add more entries to the map if you need HTML 4.


The libraries mentioned in other answers would be fine solutions, but if you already happen to be digging through real-world html in your project, the Jsoup project has a lot more to offer than just managing "ampersand pound FFFF semicolon" things.


And you also get the convenient API for extracting and manipulating data, using the best of DOM, CSS, and jquery-like methods.  It's open source and MIT licence.


The following library can also be used for HTML escaping in Java: unbescape.


HTML can be unescaped this way:


A very simple but inefficient solution without any external library is:


This should be use only if you have only small count of string to decode.


This did the job for me,


Hope this helps :)


The most reliable way is with 


from org.apache.commons.lang3.StringEscapeUtils.


And to escape the whitespaces 


This will ensure that whitespaces due to copy and paste in web forms to not get persisted in DB.


Consider using the HtmlManipulator Java class. You may need to add some items (not all entities are in the list). 


The Apache Commons StringEscapeUtils as suggested by Kevin Hakanson did not work 100% for me; several entities like &#145 (left single quote) were translated into '222' somehow. I also tried org.jsoup, and had the same problem.


In my case i use the replace method by testing every entity in every variable, my code looks like this:


In my case this worked very well.


Incase you want to mimic what php function htmlspecialchars_decode does use php function get_html_translation_table() to dump the table and then use the java code like,






I have a generics class, Foo<T>. In a method of Foo, I want to get the class instance of type T, but I just can't call T.class.


What is the preferred way to get around it using T.class?


The short answer is, that there is no way to find out the runtime type of generic type parameters in Java. I suggest reading the chapter about type erasure in the Java Tutorial for more details.


A popular solution to this is to pass the Class of the type parameter into the constructor of the generic type, e.g.


I was looking for a way to do this myself without adding an extra dependency to the classpath. After some investigation I found that it is possible as long as you have a generic supertype. This was OK for me as I was working with a DAO layer with a generic layer supertype. If this fits your scenario then it's the neatest approach IMHO.


Most generics use cases I've come across have some kind of generic supertype e.g. List<T> for ArrayList<T> or GenericDAO<T> for DAO<T>, etc.


The article Accessing generic types at runtime in Java explains how you can do it using pure Java.


My project was using Spring which is even better as Spring has a handy utility method for finding the type. This is the best approach for me as it looks neatest. I guess if you weren't using Spring you could write your own utility method.


There is a small loophole however: if you define your Foo class as abstract.
That would mean you have to instantiate you class as:


(Note the double braces at the end.)


Now you can retrieve the type of T at runtime:


Note however that mySuperclass has to be the superclass of the class definition actually defining the final type for T.


It is also not very elegant, but you have to decide whether you  prefer new Foo<MyType>(){} or new Foo<MyType>(MyType.class); in your code.


For example:


Then:


A standard approach/workaround/solution is to add a class object to the constructor(s), like:


Imagine you have an abstract superclass that is generic:


And then you have a second class that extends Foo with a generic Bar that extends T:


You can get the class Bar.class in the Foo class by selecting the Type (from bert bruynooghe answer) and infering it using Class instance:


You have to note this operation is not ideal, so it is a good idea to cache the computed value to avoid multiple calculations on this. One of the typical uses is in generic DAO implementation. 


The final implementation:


The value returned is Bar.class when invoked from Foo class in other function or from Bar class.


Here is working solution!!!


NOTES:
Can be used only as superclass
1. Has to be extended with typed class  (Child extends Generic<Integer>)
OR
2. Has to be created as anonymous implementation (new Generic<Integer>() {};)   


You can't do it because of type erasure. See also Stack Overflow question Java generics - type erasure - when and what happens.


A better route than the Class the others suggested is to pass in an object that can do what you would have done with the Class, e.g., create a new instance.


I had this problem in an abstract generic class. In this particular case, the solution is simpler:


and later on the derived class:


It's possible:


You need two functions from svn/trunk/dao/src/main/java/com/googlecode/genericdao/dao/ DAOUtil.java.


For more explanations, see Reflecting generics.


If you are extending or implementing any class/interface that are using generics , you may get the Generic Type of parent class/interface, without modifying any existing class/interface at all.


There could be three possibilities, 


Case 1
When your class is extending a class that is using Generics


Case 2
When your class is implementing an interface that is using Generics


Case 3
When your interface is extending an interface that is using Generics


Actually, I suppose you have a field in your class of type T. If there's no field of type T, what's the point of having a generic Type? So, you can simply do an instanceof on that field.


In my case, I have a List<T> items; in my class, and I check if the class type is "Locality" by


Of course, this only works if the total number of possible classes is limited.


As explained in other answers, to use this ParameterizedType approach, you need to extend the class, but that seems like extra work to make a whole new class that extends it...


So, making the class abstract it forces you to extend it, thus satisfying the subclassing requirement. (using lombok's @Getter).


Now to extend it without defining a new class. (Note the {} on the end... extended, but don't overwrite anything - unless you want to).


I'm using workaround for this:






In java it's a bit difficult to implement a deep object copy function. What steps you take to ensure the original object and the cloned one share no reference? 


A safe way is to serialize the object, then deserialize.  This ensures everything is a brand new reference.


Here's an article about how to do this efficiently.


Caveats: It's possible for classes to override serialization such that new instances are not created, e.g. for singletons.  Also this of course doesn't work if your classes aren't Serializable.


A few people have mentioned using or overriding Object.clone(). Don't do it. Object.clone() has some major problems, and its use is discouraged in most cases. Please see Item 11, from "Effective Java" by Joshua Bloch for a complete answer. I believe you can safely use Object.clone() on primitive type arrays, but apart from that you need to be judicious about properly using and overriding clone. 


The schemes that rely on serialization (XML or otherwise) are kludgy.


There is no easy answer here. If you want to deep copy an object you will have to traverse the object graph and copy each child object explicitly via the object's copy constructor or a static factory method that in turn deep copies the child object. Immutables (e.g. Strings) do not need to be copied. As an aside, you should favor immutability for this reason.


You can make a deep copy with serialization without creating files.


Your object you wish to deep copy will need to implement serializable.  If the class isn't final or can't be modified, extend the class and implement serializable.


Convert your class to a stream of bytes:


Restore your class from a stream of bytes:


You can do a serialization-based deep clone using org.apache.commons.lang3.SerializationUtils.clone(T) in Commons Lang, but be careful--the performance is abysmal.


In general, it is best practice to write your own clone methods for each class of an object in the object graph needing cloning.  


One way to implement deep copy is to add copy constructors to each associated class. A copy constructor takes an instance of 'this' as its single argument and copies all the values from it. Quite some work, but pretty straightforward and safe.


EDIT: note that you don't need to use accessor methods to read fields. You can access all fields directly because the source instance is always of the same type as the instance with the copy constructor. Obvious but might be overlooked.


Example:


Edit: Note that when using copy constructors you need to know the runtime type of the object you are copying. With the above approach you cannot easily copy a mixed list (you might be able to do it with some reflection code). 


Apache commons offers a fast way to deep clone an object.


XStream is really useful in such instances. Here is a simple code to do cloning


You can use a library that has a simple API, and performs relatively fast cloning with reflection (should be faster than serialization methods).


One very easy and simple approach is to use Jackson JSON to serialize complex Java Object to JSON and read it back.


http://wiki.fasterxml.com/JacksonInFiveMinutes


Use XStream(http://x-stream.github.io/). You can even control which properties you can ignore through annotations or explicitly specifying the property name to XStream class. Moreover you do not need to implement clonable interface. 


Deep copying can only be done with each class's consent. If you have control over the class hierarchy then you can implement the clonable interface and implement the Clone method. Otherwise doing a deep copy is impossible to do safely because the object may also be sharing non-data resources (e.g. database connections). In general however deep copying is considered bad practice in the Java environment and should be avoided via the appropriate design practices.


I used Dozer for cloning java objects and it's great at that , Kryo library is another great alternative.


BeanUtils does a really good job deep cloning beans.


For Spring Framework users. Using class org.springframework.util.SerializationUtils:


1)


Here your MyPerson and MyAddress class must implement serilazable interface


For complicated objects and when performance is not significant i use a json library, like gson
to serialize the object to json text, then deserialize the text to get new object.


gson which based on reflection will works in most cases, except that transient fields will not be copied and objects with circular reference with cause StackOverflowError.






I've been programming in C# and Java recently and I am curious where the best place is to initialize my class fields.


Should I do it at declaration?:


or in a constructor?:


I'm really curious what some of you veterans think is the best practice. I want to be consistent and stick to one approach.


My rules:


In C# it doesn't matter. The two code samples you give are utterly equivalent. In the first example the C# compiler (or is it the CLR?) will construct an empty constructor and initialise the variables as if they were in the constructor.
If there is already a constructor then any initialisation "above" will be moved into the top of it.


In terms of best practice the former is less error prone than the latter as someone could easily add another constructor and forget to chain it.


The semantics of C# differs slightly from Java here. In C# assignment in declaration is performed before calling the superclass constructor. In Java it is done immediately after which allows 'this' to be used (particularly useful for anonymous inner classes), and means that the semantics of the two forms really do match.


If you can, make the fields final.


I think there is one caveat. I once committed such an error: Inside of a derived class, I tried to "initialize at declaration" the fields inherited from an abstract base class. The result was that there existed two sets of fields, one is "base" and another is the newly declared ones, and it cost me quite some time to debug.


The lesson: to initialize inherited fields, you'd do it inside of the constructor.


Assuming the type in your example, definitely prefer to initialize fields in the constructor. The exceptional cases are:


I always think of the field listing at the top of a class as the table of contents (what is contained herein, not how it is used), and the constructor as the introduction. Methods of course are chapters.


What if I told you, it depends?


I in general initialize everything and do it in a consistent way. Yes it's overly explicit but it's also a little easier to maintain. 


If we are worried about performance, well then I initialize only what has to be done and place it in the areas it gives the most bang for the buck.


In a real time system, I question if I even need the variable or constant at all.


And in C++ I often do next to no initialization in either place and move it into an Init() function. Why? Well, in C++ if you're initializing something that can throw an exception during object construction you open yourself to memory leaks.


In Java, an initializer with the declaration means the field is always initialized the same way, regardless of which constructor is used (if you have more than one) or the parameters of your constructors (if they have arguments), although a constructor might subsequently change the value (if it is not final). So using an initializer with a declaration suggests to a reader that the initialized value is the value that the field has in all cases, regardless of which constructor is used and regardless of the parameters passed to any constructor. Therefore use an initializer with the declaration only if, and always if, the value for all constructed objects is the same.


There are many and various situations.


I just need an empty list


The situation is clear. I just need to prepare my list and prevent an exception from being thrown when someone adds an item to the list.


I know the values


I exactly know what values I want to have by default or I need to use some other logic.


or


Empty list with possible values


Sometimes I expect an empty list by default with a possibility of adding values through another constructor.


There is a slight performance benefit to setting the value in the declaration.  If you set it in the constructor it is actually being set twice (first to the default value, then reset in the ctor).  


The design of C# suggests that inline initialization is preferred, or it wouldn't be in the language. Any time you can avoid a cross-reference between different places in the code, you're generally better off.


There is also the matter of consistency with static field initialization, which needs to be inline for best performance. The Framework Design Guidelines for Constructor Design say this:


✓ CONSIDER initializing static fields inline rather than explicitly using static constructors, because the runtime is able to optimize the performance of types that don’t have an explicitly defined static constructor.


"Consider" in this context means to do so unless there's a good reason not to. In the case of static initializer fields, a good reason would be if initialization is too complex to be coded inline.


Being consistent is important, but this is the question to ask yourself:
"Do I have a constructor for anything else?"


Typically, I am creating models for data transfers that the class itself does nothing except work as housing for variables.


In these scenarios, I usually don't have any methods or constructors. It would feel silly to me to create a constructor for the exclusive purpose of initializing my lists, especially since I can initialize them in-line with the declaration.


So as many others have said, it depends on your usage. Keep it simple, and don't make anything extra that you don't have to.


I normally try the constructor to do nothing but getting the dependencies and initializing the related instance members with them. This will make you life easier if you want to unit test your classes.


If the value you are going to assign to an instance variable does not get influenced by any of the parameters you are going to pass to you constructor then assign it at declaration time.


Consider the situation where you have more than one constructor. Will the initialization be different for the different constructors? If they will be the same, then why repeat for each constructor? This is in line with kokos statement, but may not be related to parameters. Let's say, for example, you want to keep a flag which shows how the object was created. Then that flag would be initialized differently for different constructors regardless of the constructor parameters. On the other hand, if you repeat the same initialization for each constructor you leave the possibility that you (unintentionally) change the initialization parameter in some of the constructors but not in others. So, the basic concept here is that common code should have a common location and not be potentially repeated in different locations. So I would say always put it in the declaration until you have a specific situation where that no longer works for you.






I was exploring the Java 8 source and found this particular part of code very surprising:


Is Math::max something like a method pointer? How does a normal static method get converted to IntBinaryOperator?


Usually, one would call the reduce method using Math.max(int, int) as follows:


That requires a lot of syntax for just calling Math.max. That's where lambda expressions come into play. Since Java 8 it is allowed to do the same thing in a much shorter way:


How does this work? The java compiler "detects", that you want to implement a method that accepts two ints and returns one int. This is equivalent to the formal parameters of the one and only method of interface IntBinaryOperator (the parameter of method reduce you want to call). So the compiler does the rest for you - it just assumes you want to implement IntBinaryOperator.


But as Math.max(int, int) itself fulfills the formal requirements of IntBinaryOperator, it can be used directly. Because Java 7 does not have any syntax that allows a method itself to be passed as an argument (you can only pass method results, but never method references), the :: syntax was introduced in Java 8 to reference methods:


Note that this will be interpreted by the compiler, not by the JVM at runtime! Although it produces different bytecodes for all three code snippets, they are semantically equal, so the last two can be considered to be short (and probably more efficient) versions of the IntBinaryOperator implementation above!


(See also Translation of Lambda Expressions)


:: is called Method Reference. It is basically a reference to a single method. i.e. it refers to an existing method by name.  


Short Explanation:
Below is an example of a reference to a static method:


square can be passed around just like object reference's and trigger when at need. In fact, it can be perfectly used as a reference to a normal method of an object and not just static ones. 


Function above is a functional interface. Well to fully explain ::, it is important to understand functional interface. Plainly, function interface is an interface with just one abstract method. 


For example: Runnable, Callable, ActionListener and so. 


Function above is a functional interface with just one method apply. It takes one argument and produces a result. 


The reason why :: are awesome is because:


Method references are expressions which have the same treatment as
  lambda's, but instead of providing a lambda body, they refer an existing method by name


i.e. Just like writing lambda body:


You can simply do:


At runtime they behave exactly the same. The bytecode may/not be the same (For above case, it generates the same bytecode (compile above and check javap -c))


The only major criteria to satisfy is: the method you provide should have a similar signature to method of the functional interface you use as object reference.


Below is illegal:


square expects an argument and returns a double. get method in Supplier expects an argument but doesn't return anything. So it is an error. 


Method Reference refers to a method of the functional interface (As mentioned, functional interface can only have one method). 


Some more examples: accept method in Consumer takes an input but doesn't return anything.


Above getRandom takes no argument and returns a double. So any functional interface that satisfies the criteria of: take no argument and return double can be used. 


Another example:


In case of Parameterized Types:


Method Reference can be obtained in different styles, but fundamentally they all mean the same and can simply be visualized as a lambda:


For further reference: http://cr.openjdk.java.net/~briangoetz/lambda/lambda-state-final.html


Yes, that true. The :: operator it is used for method referencing. So, one can extract static methods from classes by using it or methods from objects. The same operator can be used even for constructors. All cases mentioned here are exemplified in the code sample bellow.


The official documentation from Oracle can be found here.


You can have a better overview of the JDK 8 changes in this article. In the Method/Constructor referencing section a code example is also provided:


:: is a new operator included in Java 8 that is used to refer a method of an existing class. You can refer static methods and non-static methods of a class.


For referring static methods, the syntax is:


For referring non-static methods, the syntax is


And


The only prerequisite for referring a method is that method exists in a functional interface, which must be compatible with the method reference. 


Method references, when evaluated, create an instance of the functional interface. 


Found on: http://www.speakingcs.com/2014/08/method-references-in-java-8.html


This is a method reference in Java 8.  The oracle documentation is here.


As stated in the documentation...


The method reference Person::compareByAge is a reference to a static
  method.


The following is an example of a reference to an instance method of a
  particular object:


The method reference myComparisonProvider::compareByName invokes the method compareByName
  that is part of the object myComparisonProvider. The JRE infers the
  method type arguments, which in this case are (Person, Person).


It seems its little late but here are my two cents. A lambada expression is used to create anonymous methods. It does nothing but call an existing method, but it is clearer to refer to the method directly by its name. And method reference enables us to do that using method-reference operator :: .


Consider the following simple class where each employee has a name and grade.


Suppose we have a list of employees returned by some method and we want to sort the employees by their grade. We know we can make use of anonymous class as:


where getDummyEmployee() is some method as:  


Now we know that Comparable is a Functional Interface. A Functional Interface is the one with exactly one abstract method (though it may contain one or more default or static methods). So we can use lambada expression as:


It seems all good but what if the class Employee also provides similar method:


In this case using the method name itself will be more clear. Hence we can directly refer to method by using method reference as:


As per docs there are four kinds of method references:


:: Operator was introduced in java 8 for method references. A method reference is the shorthand syntax for a lambda expression that executes just ONE method. Here's the general syntax of a method reference:


We know that we can use lambda expressions instead of using an anonymous class. But sometimes, the lambda expression is really just a call to some method, for example:


To make the code clearer, you can turn that lambda expression into a method reference:


The :: is known as method references. Lets say  we want to call a calculatePrice method of class Purchase. Then we can write it as:


It can also be seen as short form of writing the lambda expression Because method references are converted into lambda expressions.


At runtime they behave a exactly the same.The bytecode may/not be same (For above Incase,it generates the same bytecode(complie above and check javaap  -c;))


At runtime they behave a exactly the same.method(math::max);,it generates the same math (complie above and check javap -c;))


return reduce(Math::max); is NOT EQUAL to return reduce(max());


But it means, something like this:


You can just save 47 keystrokes if you write like this


In java-8 Streams Reducer in simple works is a function which takes two values as input and returns result after some calculation. this result is fed in next iteration.


in case of Math:max function, method keeps returning max of two values passed and in the end you have largest number in hand.


Since many answers here explained well :: behaviour, additionally I would like to clarify that :: operator doesnt need to have exactly same signature as the referring Functional Interface if it is used for instance variables. Lets assume we need a BinaryOperator which has type of TestObject. In traditional way its implemented like this:


As you see in anonymous implementation it requires two TestObject argument and returns a TestObject object as well. To satisfy this condition by using :: operator we can start with a static method:


and then call:


Ok it compiled fine. What about if we need an instance method? Lets update TestObject with instance method:


Now we can access instance as below:


This code compiles fine, but below one not:


My eclipse tell me "Cannot make a static reference to the non-static method testInstance(TestObject, TestObject) from the type TestObject ..."


Fair enough its an instance method, but if we overload testInstance as below:


And call:


The code will just compile fine. Because it will call testInstance with single parameter instead of double one. Ok so what happened our two parameter? Lets printout and see:


Which will output:


Ok so JVM is smart enough to call param1.testInstance(param2). Can we use testInstance from another resource but not TestObject, i.e.:


And call:


It will just not compile and compiler will tell: "The type TestUtil does not define testInstance(TestObject, TestObject)". So compiler will look for a static reference if it is not the same type. Ok what about polymorphism? If we remove final modifiers and add our SubTestObject class:


And call:


It will not compile as well, compiler will still look for static reference. But below code will compile fine since it is passing is-a test:


*I am just studying so I have figured out by try and see, feel free to correct me if I am wrong


I found this source very interesting.


In fact, it is the Lambda that turns into a Double Colon.
The Double Colon is more readable.
We follow those steps:


STEP1:


STEP2:


STEP3:






I'm using Eclipse, I have the following line of code:


Eclipse marks this line as an error. I imported the required libraries:


But again, both of them are shown as errors. I found a similar post here: import sun.misc.BASE64Encoder results in error compiled in Eclipse


I used Apache Commons as the solution suggested by including:


and importing the JAR files downloaded from: http://commons.apache.org/codec/


But the problem still exists, Eclipse still shows the errors previously mentioned; please advise. 


You need to change the import of your Class.


probably somthing like this:


And then change your Class to use the BASE64 class.


here some example code:


Then read why you shouldn't use sun.* packages.


You can now java.util.Base64 with Java8. First, import it as you normally do:


Then use the Base64 static methods as follow:


See Javadocs for Base64 for more: https://docs.oracle.com/javase/8/docs/api/java/util/Base64.html


Use Java 8's never-too-late-to-join-in-the-fun class: java.util.Base64


You can also convert using base64 encoding. To do this you can use javax.xml.bind.DatatypeConverter#printBase64Binary method


For example:


In Java 8 it can be done as


Here is a short, self-contained complete example


gives output


Google Guava is a good choice to encode and decode base64 data:


POM config:


Sample code:


Eclipse gives you an error/warning because you are trying to use internal classes that are specific to a JDK vendor and not part of the public API. Jakarta Commons provides its own implementation of base64 codecs, which of course reside in a different package. Delete those imports and let Eclipse import the proper Commons classs for you.


To convert this you need Encoder & Decoder which you will get from http://www.source-code.biz/base64coder/java/. It is File Base64Coder.java you will need.


Now to access this class as per your requirement you will need class below:


In Android you can convert your Bitmap to Base64 for Uploading to Server/Web Service.


This “encodedImage” is text representation of your Image. You can use this for either uploading purpose or for diplaying directly into HTML Page as below (Reference):


Documentation: http://dwij.co.in/java-base64-image-encoder


apache commons has nice implementation of base64. you can do this as simply as 


you can find more details about base64 encoding at http://faisalbhagat.blogspot.com/2014/06/base64-encoding-using-java-and.html


For java 6-7 best option is to borrow code from Android repository. It has no dependencies.


https://github.com/android/platform_frameworks_base/blob/master/core/java/android/util/Base64.java


On Android, use the static methods of the android.util.Base64 utility class. The referenced documentation says that the Base64 class was added in API level 8 (Froyo).


Simple example with Java 8:


In Java 7 I coded this method


If you are using Spring framework at least version 4.1, you can use org.springframework.util.Base64Utils class:





It will delegate to Java 8's Base64, Apache Commons Codec or JAXB DatatypeConverter, depending on what is available.


I tried with the following code snippet. It worked well. :-)


If you are stuck to an earlier version of Java than 8 but already using AWS SDK for Java, you can use com.amazonaws.util.Base64.


it works for me in Android.






I'm putting together a Swing application where I often want to replace the contents of a JPanel. To do this, I'm calling removeAll(), then adding my new content, then calling revalidate().


However I'm finding that the old content is still actually visible (though obscured by the the new content). If I add a call to repaint() in addition to revalidate(), it works as expected.


I'm sure on other occasions I've experienced that just calling revalidate() is enough.


So basically my question is - should I need to call both functions and if not, when should I call each of them?


You need to call repaint() and revalidate(). The former tells Swing that an area of the window is dirty (which is necessary to erase the image of the old children removed by removeAll()); the latter tells the layout manager to recalculate the layout (which is necessary when adding components). This should cause children of the panel to repaint, but may not cause the panel itself to do so (see this for the list of repaint triggers).


On a more general note: rather than reusing the original panel, I'd recommend building a new panel and swapping them at the parent.


Any time you do a remove() or a removeAll(), you should call


after you have completed add()'ing the new components.


Calling validate() or revalidate() is mandatory when you do a remove() - see the relevant javadocs.


My own testing indicates that repaint() is also necessary. I'm not sure exactly why.


revalidate is called on a container once new components are added or old ones removed.  this call is an instruction to tell the layout manager to reset based on the new component list.  revalidate will trigger a call to repaint what the component thinks are 'dirty regions.'  Obviously not all of the regions on your JPanel are considered dirty by the RepaintManager.


repaint is used to tell a component to repaint itself.  It is often the case that you need to call this in order to cleanup conditions such as yours.


revalidate() just request to layout the container, when you experienced simply call revalidate() works, it could be caused by the updating of child components bounds triggers the repaint() when their bounds are changed during the re-layout. In the case you mentioned, only component removed and no component bounds are changed, this case no repaint() is "accidentally" triggered.


yes you need to call 
    repaint();
    revalidate();
when you call removeAll() then you have to call repaint() and revalidate()






I have the class name stored in a property file. I know that the classes store will implement IDynamicLoad. How do I instantiate the class dynamically?


Right now I have


Does the newInstance only load compiled .class files? How do I load a Java Class that is not compiled?


How do I load a Java Class that is not compiled?


You need to compile it first. This can be done programmatically with the javax.tools API. This only requires the JDK being installed at the local machine on top of JRE. 


Here's a basic kickoff example (leaving obvious exception handling aside):


Which yields like


Further use would be more easy if those classes implements a certain interface which is already in the classpath. 


Otherwise you need to involve the Reflection API to access and invoke the (unknown) methods/fields.


That said and unrelated to the actual problem:


Letting java.io.File rely on current working directory is recipe for portability trouble. Don't do that. Put that file in classpath and use ClassLoader#getResourceAsStream()  with a classpath-relative path. 


In the same vein as BalusC's answer, but a bit more automatic wrapper is here in this piece of code from my kilim distribution.
https://github.com/kilim/kilim/blob/master/src/kilim/tools/Javac.java


It takes a list of strings containing Java source, extracts the package and public class/interface names and creates the corresponding directory/file hierarchy in a tmp directory. It then runs the java compiler on it, and returns a list of name,classfile pairs (the ClassInfo structure). 


Help yourself to the code. It is MIT licensed.


Your commented code is correct if you know that the class has a public no-arg constructor. You just have to cast the result, as the compiler can't know that the class will in fact implement IDynamicLoad. So:


Of course the class has to be compiled and on the classpath for that to work.


If you are looking to dynamically compile a class from source code, that is a whole other kettle of fish.






When trying to convert a JPA object that has a bi-directional association into JSON, I keep getting 


All I found is this thread which basically concludes with recommending to avoid bi-directional associations. Does anyone have an idea for  a workaround for this spring bug?


------ EDIT 2010-07-24 16:26:22 -------


Codesnippets:


Business Object 1:


Business Object 2:


Controller:


JPA-implementation of the trainee DAO:


persistence.xml


You may use @JsonIgnore to break the cycle.


Since Jackson 1.6 you can use two annotations to solve the infinite recursion problem without ignoring the getters/setters during serialization: @JsonManagedReference and @JsonBackReference.


Explanation


For Jackson to work well, one of the two sides of the relationship should not be serialized, in order to avoid the infite loop that causes your stackoverflow error.


So, Jackson takes the forward part of the reference (your Set<BodyStat> bodyStats in Trainee class), and converts it in a json-like storage format; this is the so-called marshalling process. Then, Jackson looks for the back part of the reference (i.e. Trainee trainee in BodyStat class) and leaves it as it is, not serializing it. This part of the relationship will be re-constructed during the deserialization (unmarshalling) of the forward reference.


You can change your code like this (I skip the useless parts):


Business Object 1:


Business Object 2:


Now it all should work properly.


If you want more informations, I wrote an article about Json and Jackson Stackoverflow issues on Keenformatics, my blog.


EDIT: 


Another useful annotation you could check is @JsonIdentityInfo: using it, everytime Jackson serializes your object, it will add an ID (or another attribute of your choose) to it, so that it won't entirely "scan" it again everytime. This can be useful when you've got a chain loop between more interrelated objects (for example: Order -> OrderLine -> User -> Order and over again).


In this case you've got to be careful, since you could need to read your object's attributes more than once (for example in a products list with more products that share the same seller), and this annotation prevents you to do so. I suggest to always take a look at firebug logs to check the Json response and see what's going on in your code.


Sources:


Also, using Jackson 2.0+ you can use @JsonIdentityInfo.  This worked much better for my hibernate classes than @JsonBackReference and @JsonManagedReference, which had problems for me and did not solve the issue.  Just add something like:


and it should work.


the new annotation @JsonIgnoreProperties reslove all problems     


check this  it works just like I need 
documentation:
http://springquay.blogspot.com/2016/01/new-approach-to-solve-json-recursive.html


Also, Jackson 1.6 has support for handling bi-directional references... which seems like 
what you are looking for (this blog entry also mentions the feature)


And as of July 2011, there is also "jackson-module-hibernate" which might help in some aspects of dealing with Hibernate objects, although not necessarily this particular one (which does require annotations).


Now Jackson supports avoiding cycles without ignoring the fields:


Jackson - serialization of entities with birectional relationships (avoiding cycles)


This worked perfectly fine for me. 
Add the annotation @JsonIgnore on the child class where you mention the reference to the parent class. 


There's now a Jackson module (for Jackson 2) specifically designed to handle Hibernate lazy initialization problems when serializing.


https://github.com/FasterXML/jackson-datatype-hibernate


Just add the dependency (note there are different dependencies for Hibernate 3 and Hibernate 4):


and then register the module when intializing Jackson's ObjectMapper:


Documentation currently isn't great. See the Hibernate4Module code for available options.


In my case it was enough to change relation from:


to:


another relation stayed as it was:


Be sure you use com.fasterxml.jackson everywhere. I spent much time to find it out.


Then use @JsonManagedReference and @JsonBackReference.


Finally, you can serialize your model to JSON:


For me the best solution is to use @JsonView and create specific filters for each scenario. You could also use @JsonManagedReference and @JsonBackReference, however it is a hardcoded solution to only one situation, where the owner always references the owning side, and never the opposite. If you have another serialization scenario where you need to re-annotate the attribute differently, you will not be able to.


Lets use two classes, Company and Employee where you have a cyclic dependency between them:


And the test class that tries to serialize using ObjectMapper (Spring Boot):


If you run this code, you'll get the:


@JsonView enables you to use filters and choose what fields should be included while serializing the objects. A filter is just a class reference used as a identifier. So let's first create the filters:


Remember, the filters are dummy classes, just used for specifying the fields with the @JsonView annotation, so you can create as many as you want and need. Let's see it in action, but first we need to annotate our Company class:


and change the Test in order for the serializer to use the View:


Now if you run this code, the Infinite Recursion problem is solved, because you have explicitly said that you just want to serialize the attributes that were annotated with @JsonView(Filter.CompanyData.class).


When it reaches the back reference for company in the Employee, it checks that it's not annotated and ignore the serialization. You also have a powerful and flexible solution to choose which data you want to send through your REST APIs.


With Spring you can annotate your REST Controllers methods with the desired @JsonView filter and the serialization is applied transparently to the returning object.


Here are the imports used in case you need to check:


you can use DTO pattern 
create class TraineeDTO without any anotation hiberbnate and you can use jackson mapper to convert Trainee to TraineeDTO and bingo the error message disapeare :)


I had this problem, but I didn't want to use annotation in my entities, so I solved by creating a constructor for my class, this constructor must not have a reference back to the entities who references this entity. Let's say this scenario.


If you try to send to the view the class B or A with @ResponseBody it may cause an infinite loop. You can write a constructor in your class and create a query with your entityManager like this.


This is the class with the constructor.


However, there are some constrictions about this solution, as you can see, in the constructor I did not make a reference to List bs this is because Hibernate does not allow it, at least in version 3.6.10.Final, so when I need to show both entities in a view I do the following.


The other problem with this solution, is that if you add or remove a property you must update your constructor and all your queries.


In case you are using Spring Data Rest, issue can be resolved by creating  Repositories for every Entity involved in cyclical references.






I have always wondered if, in general, declaring a throw-away variable before a loop, as opposed to repeatedly inside the loop, makes any (performance) difference? 
A (quite pointless) example in Java:


a) declaration before loop:


b) declaration (repeatedly) inside loop:


Which one is better, a or b? 


I suspect that repeated variable declaration (example b) creates more overhead in theory, but that compilers are smart enough so that it doesn't matter. Example b has the advantage of being more compact and limiting the scope of the variable to where it is used. Still, I tend to code according example a.


Edit: I am especially interested in the Java case.


Which is better, a or b?


From a performance perspective, you'd have to measure it. (And in my opinion, if you can measure a difference, the compiler isn't very good).


From a maintenance perspective, b is better. Declare and initialize variables in the same place, in the narrowest scope possible. Don't leave a gaping hole between the declaration and the initialization, and don't pollute namespaces you don't need to.


Well I ran your A and B examples 20 times each, looping 100 million times.(JVM - 1.5.0)


A: average execution time: .074 sec


B: average execution time : .067 sec


To my surprise B was slightly faster.
As fast as computers are now its hard to say if you could accurately measure this.
I would code it the A way as well but I would say it doesn't really matter.


It depends on the language and the exact use. For instance, in C# 1 it made no difference. In C# 2, if the local variable is captured by an anonymous method (or lambda expression in C# 3) it can make a very signficant difference.


Example:


Output:


The difference is that all of the actions capture the same outer variable, but each has its own separate inner variable.


The following is what I wrote and compiled in .NET.


This is what I get from .NET Reflector when CIL is rendered back into code.


So both look exactly same after compilation. In managed languages code is converted into CL/byte code and at time of execution it's converted into machine language. So in machine language a double may not even be created on the stack. It may just be a register as code reflect that it is a temporary variable for WriteLine function. There are a whole set optimization rules just for loops. So the average guy shouldn't be worried about it, especially in managed languages. There are cases when you can optimize manage code, for example, if you have to concatenate a large number of strings using just string a; a+=anotherstring[i] vs using StringBuilder. There is very big difference in performance between both. There are a lot of such cases where the compiler cannot optimize your code, because it cannot figure out what is intended in a bigger scope. But it can pretty much optimize basic things for you.


This is a gotcha in VB.NET. The Visual Basic result won't reinitialize the variable in this example:


This will print 0 the first time (Visual Basic variables have default values when declared!) but i each time after that.


If you add a = 0, though, you get what you might expect:


It is language dependent - IIRC C# optimises this, so there isn't any difference, but JavaScript (for example) will do the whole memory allocation shebang each time.


I would always use A (rather than relying on the compiler) and might also rewrite to:


This still restricts intermediateResult to the loop's scope, but doesn't redeclare during each iteration.


I made a simple test:


vs 


I compiled these codes with gcc - 5.2.0. And then I disassembled the main ()
of these two codes and that's the result:


1º:


vs


2º


Which are exaclty the same asm result. isn't a proof that the two codes produce the same thing?


In my opinion, b is the better structure.  In a, the last value of intermediateResult sticks around after your loop is finished.


Edit:
This doesn't make a lot of difference with value types, but reference types can be somewhat weighty.  Personally, I like variables to be dereferenced as soon as possible for cleanup, and b does that for you,


I suspect a few compilers could optimize both to be the same code, but certainly not all.  So I'd say you're better off with the former.  The only reason for the latter is if you want to ensure that the declared variable is used only within your loop.


As a general rule, I declare my variables in the inner-most possible scope. So, if you're not using intermediateResult outside of the loop, then I'd go with B.


A co-worker prefers the first form, telling it is an optimization, preferring to re-use a declaration.


I prefer the second one (and try to persuade my co-worker! ;-)), having read that:


Anyway, it falls in the category of premature optimization that rely in quality of compiler and/or JVM.


There is a difference in C# if you are using the variable in a lambda, etc.  But in general the compiler will basically do the same thing, assuming the variable is only used within the loop.  


Given that they are basically the same: Note that version b makes it much more obvious to readers that the variable isn't, and can't, be used after the loop.  Additionally, version b is much more easily refactored.  It is more difficult to extract the loop body into its own method in version a. Moreover, version b assures you that there is no side effect to such a refactoring.


Hence, version a annoys me to no end, because there's no benefit to it and it makes it much more difficult to reason about the code...


Well, you could always make a scope for that:


This way you only declare the variable once, and it'll die when you leave the loop.


I've always thought that if you declare your variables inside of your loop then you're wasting memory.  If you have something like this:


Then not only does the object need to be created for each iteration, but there needs to be a new reference allocated for each object.  It seems that if the garbage collector is slow then you'll have a bunch of dangling references that need to be cleaned up.


However, if you have this:


Then you're only creating a single reference and assigning a new object to it each time.  Sure, it might take a bit longer for it to go out of scope, but then there's only one dangling reference to deal with.


I think it depends on the compiler and is hard to give a general answer.


My practice is following:  


if type of variable is simple (int, double, ...) I prefer variant b (inside).
Reason: reducing scope of variable.  


if type of variable is not simple (some kind of class or struct) I prefer variant a (outside).
Reason: reducing number of ctor-dtor calls.


From a performance perspective, outside is (much) better.


I executed both functions 1 billion times each. 
outside() took 65 milliseconds. inside() took 1.5 seconds.


this is the better form


1) in this way declared once time both variable, and not each for cycle.
2) the assignment it's fatser thean all other option.
3) So the bestpractice rule is any declaration outside the iteration for.


A) is a safe bet than B).........Imagine if you are initializing structure in loop rather than 'int' or 'float' then what?


like 


You are certainly bound to face problems with memory leaks!. Hence I believe 'A' is safer bet while 'B' is vulnerable to memory accumulation esp working close source libraries.You can check usinng 'Valgrind' Tool on Linux specifically sub tool 'Helgrind'. 


It's an interesting question. From my experience there is an ultimate question to consider when you debate this matter for a code:


Is there any reason why the variable would need to be global?


It makes sense to only declare the variable once, globally, as opposed to many times locally, because it is better for organizing the code and requires less lines of code. However, if it only needs to be declared locally within one method, I would initialize it in that method so it is clear that the variable is exclusively relevant to that method. Be careful not to call this variable outside the method in which it is initialized if you choose the latter option--your code won't know what you're talking about and will report an error.


Also, as a side note, don't duplicate local variable names between different methods even if their purposes are near-identical; it just gets confusing. 


I tested for JS with Node 4.0.0 if anyone is interested. Declaring outside the loop resulted in a ~.5 ms performance improvement on average over 1000 trials with 100 million loop iterations per trial. So I'm gonna say go ahead and write it in the most readable / maintainable way which is B, imo. I would put my code in a fiddle, but I used the performance-now Node module. Here's the code:


Even if I know my compiler is smart enough, I won't like to rely on it, and will use the a) variant.


The b) variant makes sense to me only if you desperately need to make the intermediateResult unavailable after the loop body. But I can't imagine such desperate situation, anyway....


EDIT: Jon Skeet made a very good point, showing that variable declaration inside a loop can make an actual semantic difference.






Maven2 is driving me crazy during the experimentation / quick and dirty mock-up phase of development.  


I have a pom.xml file that defines the dependencies for the web-app framework I want to use, and I can quickly generate starter projects from that file. However, sometimes I want to link to a 3rd party library that doesn't already have a pom.xml file defined, so rather than create the pom.xml file for the 3rd party lib by hand and install it, and add the dependency to my pom.xml, I would just like to tell Maven: "In addition to my defined dependencies, include any jars that are in /lib too."  


It seems like this ought to be simple, but if it is, I am missing something.


Any pointers on how to do this are greatly appreciated. Short of that, if there is a simple way to point maven to a /lib directory and easily create a pom.xml with all the enclosed jars mapped to a single dependency which I could then name / install and link to in one fell swoop would also suffice.


Most of the answers you'll find around the internet will suggest you to either install the dependency to your local repository or specify a "system" scope in the pom and distribute the dependency with the source of your project. But both of these solutions are actually flawed.


When you install a dependency to your local repository it remains there. Your distribution artifact will do fine as long as it has access to this repository. The problem is in most cases this repository will reside on your local machine, so there'll be no way to resolve this dependency on any other machine. Clearly making your artifact depend on a specific machine is not a way to handle things. Otherwise this dependency will have to be locally installed on every machine working with that project which is not any better.


The jars you depend on with the "System Scope" approach neither get installed to any repository or attached to your target packages. That's why your distribution package won't have a way to resolve that dependency when used. That I believe was the reason why the use of system scope even got deprecated. Anyway you don't want to rely on a deprecated feature.


After putting this in your pom:


for each artifact with a group id of form x.y.z Maven will include the following location inside your project dir in its search for artifacts:


To elaborate more on this you can read this blog post.


Instead of creating this structure by hand I recommend to use a Maven plugin to install your jars as artifacts. So, to install an artifact to an in-project repository under repo folder execute:


If you'll choose this approach you'll be able to simplify the repository declaration in pom to:


Since executing installation command for each lib is kinda annoying and definitely error prone, I've created a utility script which automatically installs all the jars from a lib folder to a project repository, while automatically resolving all metadata (groupId, artifactId and etc.) from names of files. The script also prints out the dependencies xml for you to copy-paste in your pom.


When you'll have your in-project repository created you'll have solved a problem of distributing the dependencies of the project with its source, but since then your project's target artifact will depend on non-published jars, so when you'll install it to a repository it will have unresolvable dependencies. 


To beat this problem I suggest to include these dependencies in your target package. This you can do with either the Assembly Plugin or better with the OneJar Plugin. The official documentaion on OneJar is easy to grasp.


For throw away code only


set scope == system and just make up a groupId, artifactId, and version


Note: system dependencies are not copied into resulted jar/war
(see How to include system dependencies in war built using maven)


You may create local repository on your project


For example if you have libs folder in project structure


In libs folder you should create directory structure like: /groupId/artifactId/version/artifactId-version.jar


In your pom.xml you should register repository


and add dependency as usual


That is all.


For detailed information: How to add external libraries in Maven


Note: When using the System scope (as mentioned on this page), Maven needs absolute paths.


If your jars are under your project's root, you'll want to prefix your systemPath values with ${basedir}.


You really ought to get a framework in place via a repository and identifying your dependencies up front. Using the system scope is a common mistake people use, because they "don't care about the dependency management." The trouble is that doing this you end up with a perverted maven build that will not show maven in a normal condition. You would be better off following an approach like this.


Maven install plugin has command line usage to install a jar into the local repository, POM is optional but you will have to specify the GroupId, ArtifactId, Version and Packaging (all the POM stuff).


This is what I have done, it also works around the package issue and it works with checked out code.


I created a new folder in the project in my case I used repo, but feel free to use src/repo


In my POM I had a dependency that is not in any public maven repositories


I then created the following directories repo/com/dovetail/zoslog4j/1.0.1 and copied the JAR file into that folder.


I created the following POM file to represent the downloaded file (this step is optional, but it removes a WARNING) and helps the next guy figure out where I got the file to begin with.


Two optional files I create are the SHA1 checksums for the POM and the JAR to remove the missing checksum warnings.


Finally I add the following fragment to my pom.xml that allows me to refer to the local repository


This is how we add or install a local jar


i gave some default groupId and artifactId because they are mandatory :)


Using <scope>system</scope> is a terrible idea for reasons explained by others, installing the file manually to your local repository makes the build unreproducible, and using <url>file://${project.basedir}/repo</url> is not a good idea either because (1) that may not be a well-formed file URL (e.g. if the project is checked out in a directory with unusual characters), (2) the result is unusable if this project’s POM is used as a dependency of someone else’s project.


Assuming you are unwilling to upload the artifact to a public repository, Simeon’s suggestion of a helper module does the job. But there is an easier way now…


Use non-maven-jar-maven-plugin. Does exactly what you were asking for, with none of the drawbacks of the other approaches.


I found another way to do this, see here from a Heroku post


To summarize (sorry about some copy & paste)


After having really long discussion with CloudBees guys about properly maven packaging of such kind of JARs, they made an interesting good proposal for a solution:


Creation of a fake Maven project which attaches a pre-existing JAR as a primary artifact, running into belonged POM install:install-file execution. Here is an example of such kinf of POM: 


But in order to implement it, existing project structure should be changed. First, you should have in mind that for each such kind of JAR there should be created different fake Maven project (module). And there should be created a parent Maven project including all sub-modules which are : all JAR wrappers and existing main project. The structure could be : 


root project (this contains the parent POM file includes all sub-modules with module XML element) (POM packaging)


JAR 1 wrapper Maven child project (POM packaging)


JAR 2 wrapper Maven child project (POM packaging)


main existing Maven child project (WAR, JAR, EAR .... packaging)


When parent running via mvn:install or mvn:packaging is forced and sub-modules will be executed. That could be concerned as a minus here, since project structure should be changed, but offers a non static solution at the end


The problem with systemPath is that the dependencies' jars won't get distributed along your artifacts as transitive dependencies. Try what I've posted here: Is it best to Mavenize your project jar files or put them in WEB-INF/lib?


Then declare dependencies as usual.


And please read the footer note.


If you want a quick and dirty solution, you can do the following (though I do not recommend this for anything except test projects, maven will complain in length that this is not proper).


Add a dependency entry for each jar file you need, preferably with a perl script or something similar and copy/paste that into your pom file.


A strange solution I found: 


using Eclipse 


cheers,
Balint


Even though it does not exactly fit to your problem, I'll drop this here. My requirements were:


Let's talk about (3) first: Just having the jars in a folder and somehow merging them into the final jar will not work for here, since the IDE will not understand this. This means all libraries have to be installed properly. However, I dont want to have everyone installing it using "mvn install-file".


In my project I needed metawidget. Here we go:


Every time you have a new library, just add a new execution and tell everyone to build the project again (you can improve this process with project hierachies).


What seems simplest to me is just configure your maven-compiler-plugin to include your custom jars. This example will load any jar files in a lib directory. 


A quick&dirty batch solution (based on Alex's answer):


libs.bat


Execute it like this: libs.bat > libs.txt.
Then open libs.txt and copy its content as dependencies.


In my case, I only needed the libraries to compile my code, and this solution was the best for that purpose.


To install the 3rd party jar which is not in maven repository use maven-install-plugin.


Below are steps:


mvn install:install-file -Dfile= -DgroupId=
  -DartifactId= -Dversion= -Dpackaging=


Below is the e.g one I used it for simonsite log4j


mvn install:install-file
  -Dfile=/Users/athanka/git/MyProject/repo/log4j-rolling-appender.jar -DgroupId=uk.org.simonsite -DartifactId=log4j-rolling-appender -Dversion=20150607-2059 -Dpackaging=jar


In the pom.xml include the dependency as below


Run the mvn clean install command to create your packaging


Below is the reference link:


https://maven.apache.org/guides/mini/guide-3rd-party-jars-local.html


For those that didn't find a good answer here, this is what we are doing to get a jar with all the necessary dependencies in it. This answer (https://stackoverflow.com/a/7623805/1084306) mentions to use the Maven Assembly plugin but doesn't actually give an example in the answer. And if you don't read all the way to the end of the answer (it's pretty lengthy), you may miss it. Adding the below to your pom.xml will generate target/${PROJECT_NAME}-${VERSION}-jar-with-dependencies.jar


This doesn't answer how to add them to your POM, and may be a no brainer, but would just adding the lib dir to your classpath work? I know that is what I do when I need an external jar that I don't want to add to my Maven repos. 


Hope this helps.


What works in our project is what Archimedes Trajano wrote, but we had in our .m2/settings.xml something like this:


and the * should be changed to central. So if his answer doesn't work for you, you should check your settings.xml


I alluded to some python code in a comment to the answer from @alex lehmann's , so am posting it here.


I just wanted a quick and dirty workaround... I couldn't run the script from Nikita Volkov: syntax error + it requires a strict format for the jar names.


I made this Perl script which works with whatever format for the jar file names, and it generates the dependencies in an xml so it can be copy pasted directly in a pom.


If you want to use it, make sure you understand what the script is doing, you may need to change the lib folder and the value for the groupId or artifactId...






According to this java.sun page == is the equality comparison operator for floating point numbers in Java.


However, when I type this code:


into my editor and run static analysis, I get: "JAVA0078 Floating point values compared with =="


What is wrong with using == to compare floating point values?  What is the correct way to do it? 


the correct way to test floats for 'equality' is:


where epsilon is a very small number like 0.00000001, depending on the desired precision.


Floating point values can be off by a little bit, so they may not report as exactly equal.  For example, setting a float to "6.1" and then printing it out again, you may get a reported value of something like "6.099999904632568359375".  This is fundamental to the way floats work; therefore, you don't want to compare them using equality, but rather comparison within a range, that is, if the diff of the float to the number you want to compare it to is less than a certain absolute value.


This article on the Register gives a good overview of why this is the case; useful and interesting reading.


Just to give the reason behind what everyone else is saying.


The binary representation of a float is kind of annoying.


In binary, most programmers know the correlation between 1b=1d, 10b=2d, 100b=4d, 1000b=8d


Well it works the other way too.


.1b=.5d, .01b=.25d, .001b=.125, ...


The problem is that there is no exact way to represent most decimal numbers like .1, .2, .3, etc.  All you can do is approximate in binary.  The system does a little fudge-rounding when the numbers print so that it displays .1 instead of .10000000000001 or .999999999999 (which are probably just as close to the stored representation as .1 is)


Edit from comment:  The reason this is a problem is our expectations.  We fully expect 2/3 to be fudged at some point when we convert it to decimal, either .7 or .67 or .666667..  But we don't automatically expect .1 to be rounded in the same way as 2/3--and that's exactly what's happening.


By the way, if you are curious the number it stores internally is a pure binary representation using a binary "Scientific Notation".  So if you told it to store the decimal number 10.75d, it would store 1010b for the 10, and .11b for the decimal.  So it would store .101011 then it saves a few bits at the end to say: Move the decimal point four places right.  


(Although technically it's no longer a decimal point, it's now a binary point, but that terminology wouldn't have made things more understandable for most people who would find this answer of any use.)


What is wrong with using == to compare floating point values?


Because it's not true that 0.1 + 0.2 == 0.3


I think there is a lot of confusion around floats (and doubles), it is good to clear it up.


There is nothing inherently wrong in using floats as IDs in standard-compliant JVM [*]. If you simply set the float ID to x, do nothing with it (i.e. no arithmetics) and later test for y == x, you'll be fine. Also there is nothing wrong in using them as keys in a HashMap. What you cannot do is assume equalities like x == (x - y) + y, etc. This being said, people usually use integer types as IDs, and you can observe that most people here are put off by this code, so for practical reasons, it is better to adhere to conventions. Note that there are as many different double values as there are long values, so you gain nothing by using double. Also, generating "next available ID" can be tricky with doubles and requires some knowledge of the floating-point arithmetic. Not worth the trouble.


On the other hand, relying on numerical equality of the results of two mathematically equivalent computations is risky. This is because of the rounding errors and loss of precision when converting from decimal to binary representation. This has been discussed to death on SO.


[*] When I said "standard-compliant JVM" I wanted to exclude certain brain-damaged JVM implementations. See this.


Foating point values are not reliable, due to roundoff error.


As such they should probably not be used for as key values, such as sectionID.  Use integers instead, or long if int doesn't contain enough possible values.


This is a problem not specific to java.  Using == to compare two floats/doubles/any decimal type number can potentially cause problems because of the way they are stored.
A single-precision float (as per IEEE standard 754) has 32 bits, distributed as follows:


1 bit - Sign (0 = positive, 1 = negative)
8 bits - Exponent (a special (bias-127) representation of the x in 2^x)
23 bits - Mantisa.  The actuall number that is stored.


The mantisa is what causes the problem.  It's kinda like scientific notation, only the number in base 2 (binary) looks like 1.110011 x 2^5 or something similar.
But in binary, the first 1 is always a 1 (except for the representation of 0)


Therefore, to save a bit of memory space (pun intended), IEEE deccided that the 1 should be assumed.  For example, a mantisa of 1011 really is 1.1011.


This can cause some issues with comparison, esspecially with 0 since 0 cannot possibly be represented exactly in a float.
This is the main reason the == is discouraged, in addition to the floating point math issues described by other answers.


Java has a unique problem in that the language is universal across many different platforms, each of which could have it's own unique float format.  That makes it even more important to avoid ==.


The proper way to compare two floats (not-language specific mind you) for equality is as follows:


where ACCEPTABLE_ERROR is #defined or some other constant equal to 0.000000001 or whatever precision is required, as Victor mentioned already.


Some languages have this functionality or this constant built in, but generally this is a good habit to be in.


In addition to previous answers, you should be aware that there are strange behaviours associated with -0.0f and +0.0f (they are == but not equals) and Float.NaN (it is equals but not ==) (hope I've got that right - argh, don't do it!).


Edit: Let's check!


Welcome to IEEE/754.


Here is a very long (but hopefully useful) discussion about this and many other floating point issues you may encounter: What Every Computer Scientist Should Know About Floating-Point Arithmetic


First of all, are they float or Float? If one of them is a Float, you should use the equals() method. Also, probably best to use the static Float.compare method.


You can use Float.floatToIntBits(). 


The following automatically uses the best precision:


Of course, you might choose more or less than 5 ULPs (‘unit in the last place’).


If you’re into the Apache Commons library, the Precision class has compareTo() and equals() with both epsilon and ULP.


you may want it to be ==, but 123.4444444444443 != 123.4444444444442


If you *have to* use floats, strictfp keyword may be useful.


http://en.wikipedia.org/wiki/strictfp


The correct way would be


Two different calculations which produce equal real numbers do not necessarily produce equal floating point numbers.  People who use == to compare the results of calculations usually end up being surprised by this, so the warning helps flag what might otherwise be a subtle and difficult to reproduce bug.


Are you dealing with outsourced code that would use floats for things named sectionID and currentSectionID? Just curious.


@Bill K: "The binary representation of a float is kind of annoying." How so? How would you do it better? There are certain numbers that cannot be represented in any base properly, because they never end. Pi is a good example. You can only approximate it. If you have a better solution, contact Intel.


As mentioned in other answers, doubles can have small deviations. And you could write your own method to compare them using an "acceptable" deviation. However ...


There is an apache class for comparing doubles: org.apache.commons.math3.util.Precision


It contains some interesting constants: SAFE_MIN and EPSILON, which are the maximum possible deviations of simple arithmetic operations.


It also provides the necessary methods to compare, equal or round doubles. (using ulps or absolute deviation)


In one line answer I can say, you should use:


To make you learned more about using related operators correctly, I am elaborating some cases here:
Generally, there are three ways to test strings in Java. You can use ==, .equals (), or Objects.equals ().


How are they different? == tests for the reference quality in strings meaning finding out whether the two objects are the same. On the other hand, .equals () tests whether the two strings are of equal value logically. Finally, Objects.equals () tests for any nulls in the two strings then determine whether to call .equals ().


Ideal operator to use


Well this has been subject to lots of debates because each of the three operators have their unique set of strengths and weaknesses. Example, == is often a preferred option when comparing object reference, but there are cases where it may seem to compare string values as well.


However, what you get is a falls value because Java creates an illusion that you are comparing values but in the real sense you are not. Consider the two cases below:


So, it’s way better to use each operator when testing the specific attribute it’s designed for. But in almost all cases, Objects.equals () is a more universal operator thus experience web developers opt for it.


Here you can get more details: http://fluentthemes.com/use-compare-strings-java/


As of today, the quick & easy way to do it is: 


However, the docs  do not clearly specify the value of the margin difference  (an epsilon  from @Victor 's answer) that is always present in calculations on floats, but it should be something reasonable as it is a part of the standard language library.  


Yet if a higher or customized precision is needed, then 


is another solution option. 


One way to reduce rounding error is to use double rather than float. This won't make the problem go away, but it does reduce the amount of error in your program and float is almost never the best choice. IMHO.






The method signature of a Java main() method is:


Is there a reason for this method to be static?


The method is static because otherwise there would be ambiguity: which constructor should be called?  Especially if your class looks like this:


Should the JVM call new JavaClass(int)?  What should it pass for x?


If not, should the JVM instantiate JavaClass without running any constructor method?  I think it shouldn't, because that will special-case your entire class - sometimes you have an instance that hasn't been initialized, and you have to check for it in every method that could be called.


There are just too many edge cases and ambiguities for it to make sense for the JVM to have to instantiate a class before the entry point is called.  That's why main is static.


I have no idea why main is always marked public though.


This is just convention.  In fact, even the name main(), and the arguments passed in are purely convention.


When you run java.exe (or javaw.exe on Windows), what is really happening is a couple of Java Native Interface (JNI) calls.  These calls load the DLL that is really the JVM (that's right - java.exe is NOT the JVM).  JNI is the tool that we use when we have to bridge between the virtual machine world, and the world of C, C++, etc...  The reverse is also true - it is not possible (at least to my knowledge) to actually get a JVM  running without using JNI.


Basically, java.exe is a super simple C application that parses the command line, creates a new String array in the JVM to hold those arguments, parses out the class name that you specified as containing main(), uses JNI calls to find the main() method itself, then invokes the main() method, passing in the newly created string array as a parameter.  This is very, very much like what you do when you use reflection from Java - it just uses confusingly named native function calls instead.


It would be perfectly legal for you to write your own version of java.exe (the source is distributed with the JDK), and have it do something entirely different.  In fact, that's exactly what we do with all of our Java based apps.


Each of our Java apps has its own launcher.  We primarily do this so we get our own icon and process name, but it has come in handy in other situations where we want to do something besides the regular main() call to get things going (For example, in one case we are doing COM interoperability, and we actually pass a COM handle into main() instead of a string array).


So, long and short:  the reason it is static is b/c that's convenient.  The reason it's called 'main' is because it had to be something, and main() is what they did in the old days of C (and in those days, the name of the function was important).  I suppose that java.exe could have allowed you to just specify a fully qualified main method name, instead of just the class (java com.mycompany.Foo.someSpecialMain) - but that just makes it harder on IDEs to auto-detect the 'launchable' classes in a project.


The main() method in C++, C# and Java are static because they can then be invoked by the runtime engine without having to instantiate an instance of the parent class.


This is how Java Language is designed and Java Virtual Machine is designed and written.


Check out Chapter 12 Execution - Section 12.1.4 Invoke Test.main:


Finally, after completion of the initialization for class Test (during which other consequential loading, linking, and initializing may have occurred), the method main of Test is invoked.


The method main must be declared public, static, and void. It must accept a single argument that is an array of strings. This method can be declared as either


or


Check out Chapter 2 Java Programming Language Concepts - Section 2.17 Execution:


The Java virtual machine starts execution by invoking the method main of some specified class and passing it a single argument, which is an array of strings. This causes the specified class to be loaded (§2.17.2), linked (§2.17.3) to other types that it uses, and initialized (§2.17.4). The method main must be declared public, static, and void.


Download and extract the source jar and see how JVM is written, check out ../launcher/java.c, which contains native C code behind command java [-options] class [args...]:


Let's simply pretend, that static would not be required as the application entry point.


A application class would then look like this:


The distinction between constructor code and main method is necessary, because in OO speak a constructor shall only make sure, that an instance is initialized properly. After initialization the instance can be used for the intended "service". Putting the complete application code into the constructor would spoil that.


So this approach would force three different contracts upon the application:


The static approach on the other hand only requires one contract: 


Here neither abstract nor multiple constructors matter.


Since Java was designed to be a simple language for the user it is not surprising that also the application entry point has been designed in a simple way using one contract and not in a complex way using three independent and brittle contracts.


Please note: This argument is not about simplicity inside the JVM or inside the JRE. This argument is about simplicity for the user. 



1Here the complete signature counts as only one contract.


If it wasn't, which constructor should be used if there are more than one?


There is more information on the initialization and execution of Java programs available in the Java Language Specification.


Because otherwise, it would need an instance of the object to be executed. But it must be called from scratch, without constructing the object first, since it is usually the task of the main() function (bootstrap), to parse the arguments and construct the object, usually by using these arguments/program parameters.


Before the main method is called, no objects are instantiated. Having the static keyword means the method can be called without creating any objects first.


What is the meaning of public static void main(String args[])?


static allows main() to be called before an object of the class has been created. This is neccesary because main() is called by the JVM before any objects are made. Since it is static it can be directly invoked via the class.


Similarly, we use static sometime for user defined methods so that we need not to make objects.


void indicates that the main() method being declared 
does not return a value.


String[] args specifies the only parameter in the main() method.


args - a parameter which contains an array of objects of class type String.


Let me explain these things in a much simpler way:


All Java applications, except applets, start their execution from main().


The keyword public is an access modifier which allows the member to be called from outside the class.


static is used because it allows main() to be called without having to instantiate a particular instance of that class.


void indicates that main() does not return any value.


Applets, midlets, servlets and beans of various kinds are constructed and then have lifecycle methods called on them. Invoking main is all that is ever done to the main class, so there is no need for state to be held in an object that is called multiple times. It's quite normal to pin main on another class (although not a great idea), which would get in the way of using the class to create a main object.


It's just a convention, but probably more convenient than the alternative. With a static main, all you need to know to invoke a Java program is the name and location of a class. If it weren't static, you'd also have to know how to instantiate that class, or require that the class have an empty constructor.


If the main method would not be static, you would need to create an object of your main class from outside the program. How would you want to do that?


When you execute the Java Virtual Machine (JVM) with the java command, 


When you execute your application, you specify its class name as an argument to the java command, as above


the JVM attempts to invoke the main method of the class you specify 


—at this point, no objects of the class have been created.


Declaring main as static allows the JVM to invoke main without creating
  an instance of the class.


let's back to the command 


ClassName is a command-line argument to the JVM that tells it which class to execute. Following the ClassName, you can also specify a list of Strings (separated by spaces) as command-line arguments that the JVM will pass to your application. -Such arguments might be used to specify options (e.g., a filename) to run the application- this is why there is a parameter called String[] args in the main 


References:Java™ How To Program (Early Objects), Tenth Edition 


I think the keyword 'static' makes the main method a class method, and class methods have only one copy of it and can be shared by all, and also, it does not require an object for reference. So when the driver class is compiled the main method can be invoked. (I'm just in alphabet level of java, sorry if I'm wrong)


main() is static because; at that point in the application's lifecycle, the application stack is procedural in nature due to there being no objects yet instantiated.


It's a clean slate. Your application is running at this point, even without any objects being declared (remember, there's procedural AND OO coding patterns). You, as the developer, turn the application into an object-oriented solution by creating instances of your objects and depending upon the code compiled within.


Object-oriented is great for millions of obvious reasons. However, gone are the days when most VB developers regularly used keywords like "goto" in their code. "goto" is a procedural command in VB that is replaced by its OO counterpart: method invocation.


You could also look at the static entry point (main) as pure liberty. Had Java been different enough to instantiate an object and present only that instance to you on run, you would have no choice BUT to write a procedural app. As unimaginable as it might sound for Java, it's possible there are many scenarios which call for procedural approaches.


This is probably a very obscure reply. Remember, "class" is only a collection of inter-related code. "Instance" is an isolated, living and breathing autonomous generation of that class.


The protoype public static void main(String[]) is a convention defined in the JLS :


The method main must be declared public, static, and void. It must specify a formal parameter (§8.4.1) whose declared type is array of String. 


In the JVM specification 5.2. Virtual Machine Start-up  we can read:


The Java virtual machine starts up by creating an initial class, which is specified in an implementation-dependent manner, using the bootstrap class loader (§5.3.1). The Java virtual machine then links the initial class, initializes it, and invokes the public class method void main(String[]). The invocation of this method drives all further execution. Execution of the Java virtual machine instructions constituting the main method may cause linking (and consequently creation) of additional classes and interfaces, as well as invocation of additional methods.


Funny thing, in the JVM specification it's not mention that the main method has to be static.
But the spec also says that the Java virtual machine perform 2 steps before :


Initialization of a class or interface consists of executing its class or interface initialization method.


In 2.9. Special Methods :


A class or interface initialization method is defined :


A class or interface has at most one class or interface initialization method and is initialized (§5.5) by invoking that method. The initialization method of a class or interface has the special name <clinit>, takes no arguments, and is void.


And a class or interface initialization method is different from an instance initialization method defined as follow :


At the level of the Java virtual machine, every constructor written in the Java programming language (JLS §8.8) appears as an instance initialization method that has the special name <init>. 


So the JVM initialize a class or interface initialization method and not an instance initialization method that is actually a constructor.
So they don't need to mention that the main method has to be static in the JVM spec because it's implied by the fact that no instance are created before calling the main method.


Recently, similar question has been posted at Programmers.SE


Looking for a definitive answer from a primary or secondary source for why did (notably) Java and C# decide to have a static method as their entry point – rather than representing an application instance by an instance of an Application class, with the entry point being an appropriate constructor?


TL;DR part of the accepted answer is,


In Java, the reason of public static void main(String[] args) is that





 
  For C#, the reasoning is transitively similar so to speak. Language designers kept the program entry point syntax familiar for programmers coming from Java. As C# architect Anders Hejlsberg puts it,


...our approach with C# has simply been to offer an alternative... to Java programmers...


...


It is just a convention. The JVM could certainly deal with non-static main methods if that would have been the convention. After all, you can define a static initializer on your class, and instantiate a zillion objects before ever getting to your main() method.


The true entry point to any application is a static method. If the Java language supported an instance method as the "entry point", then the runtime would need implement it internally as a static method which constructed an instance of the object followed by calling the instance method.


With that out of the way, I'll examine the rationale for choosing a specific one of the following three options:


static void main()


void main()


new ClassName()


I'll go in reverse order for this one.


Keep in mind that one of the design goals of Java was to emphasize (require when possible) good object-oriented programming practices. In this context, the constructor of an object initializes the object, but should not be responsible for the object's behavior. Therefore, a specification that gave an entry point of new ClassName() would confuse the situation for new Java developers by forcing an exception to the design of an "ideal" constructor on every application.


By making main() an instance method, the above problem is certainly solved. However, it creates complexity by requiring the specification to list the signature of the entry class's constructor as well as the signature of the main() method.


In summary, specifying a static void main() creates a specification with the least complexity while adhering to the principle of placing behavior into methods. Considering how straightforward it is to implement a main() method which itself constructs an instance of a class and calls an instance method, there is no real advantage to specifying main() as an instance method.


The public keyword is an access modifier, which allows the programmer to control
the visibility of class members. When a class member is preceded by public, then that
member may be accessed by code outside the class in which it is declared.


The opposite of public is private, which prevents a member from being used by code defined outside of its class.


In this case, main() must be declared as public, since it must be called
by code outside of its class when the program is started.


The keyword static allows
main() to be called without having to instantiate a particular instance of the class. This is necessary since main() is called by the Java interpreter before any objects are made.


The keyword void simply tells the compiler that main() does not return a value.


static - When the JVM makes a call to the main method there is no object that exists for the class being called therefore it has to have static method to allow invocation from class.


Static methods don't require any object.  It runs directly so main runs directly.


The static key word in the main method is used because there isn't any instantiation that take place in the main method. 
But object is constructed rather than invocation as a result we use the static key word in the main method.
In jvm context memory is created when class loads into it.And all static members are present in that memory. if we make the main static now it will be in memory and can be accessible to jvm (class.main(..)) so we can call the main method with out need of even need for heap been created.


It is just a convention as we can see here:


The method must be declared public and static, it must not return any
  value, and it must accept a String array as a parameter. By default,
  the first non-option argument is the name of the class to be invoked.
  A fully-qualified class name should be used. If the -jar option is
  specified, the first non-option argument is the name of a JAR archive
  containing class and resource files for the application, with the
  startup class indicated by the Main-Class manifest header.


http://docs.oracle.com/javase/1.4.2/docs/tooldocs/windows/java.html#description


The public static void keywords mean the Java virtual machine (JVM) interpreter can call the program's main method to start the program (public) without creating an instance of the class (static), and the program does not return data to the Java VM interpreter (void) when it ends.


Source:
Essentials, Part 1, Lesson 2: Building Applications


I don't know if the JVM calls main method before the objects are instantiated... But there is far more powerful reason why the main() method is static... When JVM calls the main method of the class (say Person)... it invokes it by "Person.main()" .... You see, the JVM invokes it by the class name. That is why the main() method is supposed to be static and public, so that it can be accessed by the JVM.


Hope it helped... :) ... If it did, let me know by commenting..! :D


Basically we make those DATA MEMBERS and MEMBER FUNCTIONS as STATIC which are not performing any task related to an object. And in case of main method, we are making it as an STATIC because it is nothing to do with object, as the main method always run whether we are creating an object or not.


Any method declared as static in Java belongs to the class itself .
Again  static method of a particular class can be accessed only by referring to the class like Class_name.method_name();


So a class need not to be instantiated before accessing a static method.


So the main() method is declared as static so that it can be accessed without creating an object of that class.


Since we save the program with the name of the class where the main method is present( or from where the program should begin its execution, applicable for classes without a main() method()(Advanced Level)). So by the above mentioned way:


the main method can be accessed.


In brief when the program is compiled it searches for the main() method having String arguments like: main(String args[]) in the class mentioned(i.e. by the name of the program), and since at the the beginning it has no scope to instantiate that class, so the main() method is declared as static.


there is the simple reason behind it that is because object is not required to call static method , if It were non-static method, java virtual machine creates object first then call main() method that will lead to the problem of extra memory allocation.






Does anyone know of a good library for SSH login from Java.


The Java Secure Channel (JSCH) is a very popular library, used by maven, ant and eclipse. It is open source with a BSD style license.


Update: The GSOC project and the code there isn't active, but this is:
https://github.com/hierynomus/sshj


hierynomus took over as maintainer since early 2015.  Here is the older, no longer maintained, Github link:


https://github.com/shikhar/sshj


There was a GSOC project: 


http://code.google.com/p/commons-net-ssh/


Code quality seem to be better than JSch, which, while a complete and working implementation, lacks documentation. Project page spots an upcoming beta release, last commit to the repository was mid-august.


Compare the APIs:


http://code.google.com/p/commons-net-ssh/


http://www.jcraft.com/jsch/


I just discovered sshj, which seems to have a much more concise API than JSCH (but it requires Java 6).  The documentation is mostly by examples-in-the-repo at this point, and usually that's enough for me to look elsewhere, but it seems good enough for me to give it a shot on a project I just started.


Take a look at the very recently released SSHD, which is based on the Apache MINA project.


There is a brand new version of Jsch up on github: https://github.com/vngx/vngx-jsch Some of the improvements include: comprehensive javadoc, enhanced performance, improved exception handling, and better RFC spec adherence. If you wish to contribute in any way please open an issue or send a pull request. 


I took miku's answer and jsch example code. I then had to download multiple files during the session and preserve original timestamps. This is my example code how to do it, probably many people find it usefull. Please ignore filenameHack() function its my own usecase.


http://code.google.com/p/connectbot/, Compile src\com\trilead\ssh2 on windows linux or android , it can create Local Port Forwarder or create Dynamic Port Forwarder or other else






Is there any way to accept only numeric values in a JTextField?  Is there any special method for this?


As this question re-appears quite often, I put some more effort in this answer then I would usually do.


My vote goes to the JFormattedTextField. IMO each Swing developer should have an improved version of that class in his/her toolkit as it allows to validate almost anything you can think of by the correct choice of Format. Examples for which I already used it:


It also allows for visual feedback when the input is invalid which is for example not the case with the InputVerifier. It still allows to user to input anything, but that value is simply not accepted when not valid and that value never leaves the UI. I think (but again, that is my opinion) that it is better to allow the user to type invalid input that just removing that automatically with e.g. a DocumentFilter. I would suspect a bug when a type a character in a text field and it does not appear.


Let me illustrate this with some code (quite some code actually). First the small demo application. This application just shows a JFormattedTextField for numbers. Just using another format allows to reuse that component for completely different validations.





which just shows an ImprovedFormattedTextField and a JButton which is only enabled when the input is valid (aha, eat that DocumentFilter solution). It also shows a JTextArea in which the value is printed each time a new valid value is encountered. Pressing the button shows the value.


The code for the ImprovedFormattedTextField can be found below, together with the ParseAllFormat on which it depends


The ParseAllFormat class:


Possible improvements:


This question was cited as an 'exact duplicate' of another question that has since been closed.  The answers to this question were so poor that I was inspired to help out anybody that might find it later, by linking to a much better answer for this use case.


It is an answer to the closed question & can be summed up as.. 


Although there is the pure evil JFormattedTextField there isn't a trivial way to do it using only the Swing library. The best way to implement this sort of feature is with a DocumentFilter.


Some code I prepared earlier. A bit of description.


A quick solution:


The problem with the above solution is that the user cannot use the Delete, Left Arrow, Right Arrow, or Backspace keys in the text field, so I suggest using this solution:


A simple approach is to subclass JTextField and override createDefaultModel() by returning customised PlainDocument subclass. Example - a textfield for integers only:


Process input in insertString() any way.


Also, consider using an InputVerifier.


Concidering the number of views this question is getting, i found none of the above solution suitable for my problem. I decided to make a custom PlainDocument to fit my needs.
This solution also makes a beep sound when the maximum number of characters used is reached, or the inserted text is not an integer.


implented as follows:


A very easy solution is to use a action listener.


You Can use it for Double as well:


Look at JFormattedTextField.


write this code into key typed


Try this out in the key pressed event for the related JTextField.


Use formatter to format text field.


numberField = new JFormattedTextField(NumberFormat.getInstance());


Formatted text field tutorial


You would like to take a look at JFormattedTextField


Formatted text fields provide a way for developers to specify the valid set of characters that can be typed in a text field


This is a subclass of JTextField, so you can use it like this:


I think it is the best solution:


You can create a beautiful text field in java that accepts or allows only numeric values.. You can even set the precision for the float values... check the code in zybocodes






Is it possible to force garbage collection in Java, even it is tricky to do? I know about System.gc(); and Runtime.gc(); but they only suggest to do GC. How can I force GC?


Your best option is to call System.gc() which simply is a hint to the garbage collector that you want it to do a collection.  There is no way to force and immediate collection though as the garbage collector is non-deterministic.


The jlibs library has a good utility class for garbage collection. You can force garbage collection using a nifty little trick with WeakReference objects.


RuntimeUtil.gc() from the jlibs:


The best (if not only) way to force a GC would be to write a custom JVM.  I believe the Garbage collectors are pluggable so you could probably just pick one of the available implementations are tweak it.


Note:  This is NOT the easy answer.


Using the Java™ Virtual Machine Tool Interface (JVM TI), the function


will "Force the VM to perform a garbage collection." The JVM TI is part of the JavaTM Platform Debugger Architecture (JPDA).


YES it is almost possible to forced you have to call to methods in the same order and at the same time this ones are:


even if is just one object to clean the use of this two methods at the same time force the garbage collector to use the finalise() method of unreachable object freeing the memory assigned and doing what the finalize() method states.


HOWEVER it is a terrible practice to use the garbage collector because the use of it could introduce an over load to the software that may be even worst than on the memory, the garbage collector has his own thread which is not possible to control plus depending on the algorithm used by the gc could take more time and is consider very inefficient, you should check your software if it worst with the help of the gc because it is definitely broke, a good solution must not depend on the gc.


NOTE: just to keep on mind this will works only if in the finalize method is not a reassignment of the object, if this happens the object will keep alive an it will have a resurrection which is technically possible.


Under the documentation for OutOfMemoryError it declares that it will not be thrown unless the VM has failed to reclaim memory following a full garbage collection.  So if you keep allocating memory until you get the error, you will have already forced a full garbage collection. 


Presumably the question you really wanted to ask was "how can I reclaim the memory I think I should be reclaiming by garbage collection?"


To manually Request GC (not from System.gc()) : 


.gc is a candidate for elimination in future releases - a Sun Engineer once commented that maybe fewer than twenty people in the world actually know how to use .gc() - I did some work last night for a few hours on a central / critical data-structure using SecureRandom generated data, at somewhere just past 40,000 objects the vm would slow down as though it had run out of pointers. Clearly it was choking down on 16-bit pointer tables and exhibited classic "failing machinery" behavior.


I tried -Xms and so on, kept bit twiddling until it would run to about 57,xxx something. Then it would run gc going from say 57,127 to 57,128 after a gc() - at about the pace of code-bloat at camp Easy Money.


Your design needs fundamental re-work, probably a sliding window approach. 


JVM specification doesn't say anything specific about garbage collection. Due to this, vendors are free to implement GC in their way.


So this vagueness causes uncertainty in garbage collection behavior. You should check your JVM details to know about the garbage collection approaches/algorithms. Also there are options to customize behavior as well.


It would be better if you would describe the reason why you need garbage collection. If you are using SWT, you can dispose resources such as Image and Font to free memory. For instance:


There are also tools to determine undisposed resources.


If you need to force garbage collection, perhaps you should consider how you're managing resources. Are you creating large objects that persist in memory? Are you creating large objects (e.g., graphics classes) that have a Disposable interface and not calling dispose() when done with it? Are you declaring something at a class level that you only need within a single method?


Useful for batch/crontab:


jdk1.7.0/bin/jcmd  GC.run


Really, I don't get you. But to be
  clear about "Infinite Object Creation"
  I meant that there is some piece of
  code at my big system do creation of
  objects whom handles and alive in
  memory, I could not get this piece of
  code actually, just gesture!!


This is correct, only gesture. You have pretty much the standard answers already given by several posters. Let's take this one by one:


Correct, there is no actual jvm - such is only a specification, a bunch of computer science describing a desired behaviour ... I recently dug into initializing Java objects from native code. To get what you want, the only way is to do what is called aggressive nulling. The mistakes if done wrong are so bad doing that if it is done wrong that we have to limit ourselves to the original scope of the question: 


Most of the posters here will assume you are saying you are working to an interface, if such we would have to see if you are being handed the entire object or one item at a time.


If you no longer need an object, you can assign null to the object but if you get it wrong there is a null pointer exception generated. I bet you can achieve better work if you use NIO


Any time you or I or anyone else gets: "Please I need that horribly." it is almost universal precursor to near total destruction of what you are trying to work on .... write us a small sample code, sanitizing from it any actual code used and show us your question.


Do not get frustrated. Often what this resolves to is your dba is using a package bought somewhere and the original design is not tweaked for massive data structures. 


That is very common.


If you are running out of memory and getting an OutOfMemoryException you can try increasing the amount of heap space available to java by starting you program with java -Xms128m -Xmx512m instead of just java. This will give you an initial heap size of 128Mb and a maximum of 512Mb, which is far more than the standard 32Mb/128Mb.


(Sorry I can't add this as a comment as I don't have enough reputation points.)


I once interviewed at an image processing company for a Java job (even though I didn't have any/much java experience.)


Their tale of woe that was interesting to me, was their program would allocate a HUGE buffer for image.  Once, they were done with the image and memory, they would deference it.  Knowing that they really needed to recover the memory sooner than later, they tried to use an explicit call to Java gc() during a quiet time of the program.  Unfortunately, gc() is merely a suggestion to the Java runtime and had no effect.


As I recall, they ended up having to recycle the memory themselves.


FYI


The method call System.runFinalizersOnExit(true) guarantees that finalizer methods
are called before Java shuts down. However, this method is inherently unsafe
and has been deprecated. An alternative is to add “shutdown hooks” with the method
Runtime.addShutdownHook.


Masarrat Siddiqui


The best (if not only) way to force a GC would be to write a custom JVM. I believe the Garbage collectors are pluggable so you could probably just pick one of the available implementations are tweak it.


There is some indirect way for forcing garbage collector. You just need to fill heap with temporary objects until the point when garbage collector will execute. I've made class which forces garbage collector in this way:


Usage:


I don't know how much this method is useful, because it fills heap constantly, but if you have mission critical application which MUST force GC - when this may be the Java portable way to force GC.


I would like to add some thing here. Please not that Java runs on Virtual Machine and not actual Machine. The virtual machine has its own way of communication with the machine. It may varry from system to system. Now When we call the GC we ask the Virtual Machine of Java to call the Garbage Collector. 


Since the Garbage Collector is with Virtual Machine , we can not force it to do a cleanup there and then. Rather that we queue our request with the Garbage Collector. It depends on the Virtual Machine, after particular time (this may change from system to system, generally when the threshold memory allocated to the JVM is full) the actual machine will free up the space. :D


The following code is taken from the assertGC(...) method. It tries to force the nondeterministic garbage collector to collect.


Source (I added some comments for clarity): NbTestCase Example






My Java standalone application gets a URL (which points to a file) from the user and I need to hit it and download it. The problem I am facing is that I am not able to encode the HTTP URL address properly...


Example: 


returns me:


But, what I want is


(space replaced by %20)


I guess URLEncoder is not designed to encode HTTP URLs... The JavaDoc says "Utility class for HTML form encoding"... Is there any other way to do this?


The java.net.URI class can help; in the documentation of URL you find


Note, the URI class does perform escaping of its component fields in certain circumstances. The recommended way to manage the encoding and decoding of URLs is to use an URI


Use one of the constructors with more than one argument, like:


(the single-argument constructor of URI does NOT escape illegal characters) 


EDIT: added fully qualified class name to avoid confusion with other URI classes (like apaches httpclient)


EDIT 2:
Only illegal characters get escaped by above code - it does NOT escape non-ASCII characters (see fatih's comment).
The toASCIIString method can be used to get a String only with US-ASCII characters:  


EDIT 3:
For an URL with a query like http://www.google.com/ig/api?weather=São Paulo, use the 5-parameter version of the constructor:  


Please be warned that most of the answers above are INCORRECT.


The URLEncoder class, despite is name, is NOT what needs to be here.  It's unfortunate that Sun named this class so annoyingly.  URLEncoder is meant for passing data as parameters, not for encoding the URL itself.


In other words, "http://search.barnesandnoble.com/booksearch/first book.pdf" is the URL. Parameters would be, for example, "http://search.barnesandnoble.com/booksearch/first book.pdf?parameter1=this&param2=that".  The parameters are what you would use URLEncoder for.


The following two examples highlights the differences between the two.


The following produces the wrong parameters, according to the HTTP standard. Note the ampersand (&) and plus (+) are encoded incorrectly.


The following will produce the correct parameters, with the query properly encoded. Note the spaces, ampersands, and plus marks.


-Matt


I'm going to add one suggestion here aimed at Android users.  You can do this which avoids having to get any external libraries.  Also, all the search/replace characters solutions suggested in some of the answers above are perilous and should be avoided.  


Give this a try:


You can see that in this particular URL, I need to have those spaces encoded so that I can use it for a request.  


This takes advantage of a couple features available to you in Android classes.  First, the URL class can break a url into its proper components so there is no need for you to do any string search/replace work.  Secondly, this approach takes advantage of the URI class feature of properly escaping components when you construct a URI via components rather than from a single string.


The beauty of this approach is that you can take any valid url string and have it work without needing any special knowledge of it yourself.  


a solution i developed and much more stable than any other:


If you have a URL, you can pass url.toString() into this method.  First decode, to avoid double encoding (for example, encoding a space results in %20 and encoding a percent sign results in %25, so double encoding will turn a space into %2520).  Then, use the URI as explained above, adding in all the parts of the URL (so that you don't drop the query parameters).


Yeah URL encoding is going to encode that string so that it would be passed properly in a url to a final destination.  For example you could not have http://stackoverflow.com?url=http://yyy.com.  UrlEncoding the parameter would fix that parameter value.


So i have two choices for you:


Do you have access to the path separate from the domain?  If so you may be able to simply UrlEncode the path. However, if this is not the case then option 2 may be for you.


Get commons-httpclient-3.1.  This has a class URIUtil:


System.out.println(URIUtil.encodePath("http://example.com/x y", "ISO-8859-1"));


This will output exactly what you are looking for, as it will only encode the path part of the URI.


FYI, you'll need commons-codec and commons-logging for this method to work at runtime.


Nitpicking: a string containing a whitespace character by definition is not a URI. So what you're looking for is code that implements the URI escaping defined in Section 2.1 of RFC 3986.


Unfortunately, org.apache.commons.httpclient.util.URIUtil is deprecated, and the replacement org.apache.commons.codec.net.URLCodec does coding suitable for form posts, not in actual URL's. So I had to write my own function, which does a single component (not suitable for entire query strings that have ?'s and &'s)


URLEncoding can encode HTTP URLs just fine, as you've unfortunately discovered.  The string you passed in, "http://search.barnesandnoble.com/booksearch/first book.pdf", was correctly and completely encoded into a URL-encoded form.  You could pass that entire long string of gobbledigook that you got back as a parameter in a URL, and it could be decoded back into exactly the string you passed in.


It sounds like you want to do something a little different than passing the entire URL as a parameter.  From what I gather, you're trying to create a search URL that looks like "http://search.barnesandnoble.com/booksearch/whateverTheUserPassesIn".  The only thing that you need to encode is the "whateverTheUserPassesIn" bit, so perhaps all you need to do is something like this:


That should produce something rather more valid for you.


There is still a problem if you have got an encoded "/" (%2F) in your URL.


RFC 3986 - Section 2.2 says: "If data for a URI component would conflict with a reserved character's purpose as a delimiter, then the conflicting data must be percent-encoded before the URI is formed." (RFC 3986 - Section 2.2)


But there is an Issue with Tomcat: 


http://tomcat.apache.org/security-6.html - Fixed in Apache Tomcat 6.0.10


important: Directory traversal CVE-2007-0450


Tomcat permits '\', '%2F' and '%5C'
  [...] . 


The following Java system properties
  have been added to Tomcat to provide
  additional control of the handling of
  path delimiters in URLs (both options
  default to false):


Due to the impossibility to guarantee
  that all URLs are handled by Tomcat as
  they are in proxy servers, Tomcat
  should always be secured as if no
  proxy restricting context access was
  used.


Affects: 6.0.0-6.0.9


So if you have got an URL with the %2F character, Tomcat returns: "400 Invalid URI: noSlash"


You can switch of the bugfix in the Tomcat startup script:


I read the previous answers to write my own method because I could not have something properly working using the solution of the previous answers, it looks good for me but if you can find URL that does not work with this, please let me know.


I agree with Matt. Indeed, I've never seen it well explained in tutorials, but one matter is how to encode the URL path, and a very different one is how to encode the parameters which are appended to the URL (the query part, behind the "?" symbol). They use similar encoding, but not the same.


Specially for the encoding of the white space character. The URL path needs it to be encoded as %20, whereas the query part allows %20 and also the "+" sign. The best idea is to test it by ourselves against our Web server, using a Web browser.


For both cases, I ALWAYS would encode COMPONENT BY COMPONENT, never the whole string. Indeed URLEncoder allows that for the query part. For the path part you can use the class URI, although in this case it asks for the entire string, not a single component.


Anyway, I believe that the best way to avoid these problems is to use a personal non-conflictive design. How? For example, I never would name directories or parameters using other characters than a-Z, A-Z, 0-9 and _ . That way, the only need is to encode the value of every parameter, since it may come from an user input and the used characters are unknown.


If anybody doesn't want to add a dependency to their project, these functions may be helpful.


We pass the 'path' part of our URL into here.  You probably don't want to pass the full URL in as a parameter (query strings need different escapes, etc).


And tests:


In addition to the Carlos Heuberger's reply:
if a different than the default (80) is needed, the 7 param constructor should be used:


Maybe can try UriUtils in org.springframework.web.util


You can also use GUAVA and path escaper:
UrlEscapers.urlFragmentEscaper().escape(relativePath)


I had the same problem. Solved this by unsing: 


It encodes the string but skips ":" and "/".


I've created a new project to help construct HTTP URLs. The library will automatically URL encode path segments and query parameters.


You can view the source and download a binary at https://github.com/Widen/urlbuilder


The example URL in this question:


produces


http://search.barnesandnoble.com/booksearch/first%20book.pdf


I develop a library that serves this purpose: galimatias. It parses URL the same way web browsers do. That is, if a URL works in a browser, it will be correctly parsed by galimatias.


In this case:


Will give you: http://search.barnesandnoble.com/booksearch/first%20book.pdf. Of course this is the simplest case, but it'll work with anything, way beyond java.net.URI.


You can check it out at: https://github.com/smola/galimatias


You can use a function like this. Complete and modify it to your need :


Example of use :


The result is : http://www.growup.com/folder/int%C3%A9rieur-%C3%A0_vendre?o=4


String url=""http://search.barnesandnoble.com/booksearch/;


This will be constant i guess and only filename changes dyamically so get filename


String filename;
// get the file name


String urlEnc=url+fileName.replace(" ","%20");


How about:


public String UrlEncode(String in_) {


}






If I have the value "foo", and a HashMap<String> ftw for which ftw.containsValue("foo") returns true, how can I get the corresponding key? Do I have to loop through the hashmap? What is the best way to do that?


If you choose to use the Commons Collections library instead of the standard Java Collections API, you can achieve this with ease.


The BidiMap interface in the Collections library is a bi-directional map, allowing you to map a key to a value (like normal maps), and also to map a value to a key, thus allowing you to perform lookups in both directions. Obtaining a key for a value is supported by the getKey() method.


There is a caveat though, bidi maps cannot have multiple values mapped to keys, and hence unless your data set has 1:1 mappings between keys and values, you cannot use bidimaps.


Update


If you want to rely on the Java Collections API, you will have to ensure the 1:1 relationship between keys and values at the time of inserting the value into the map. This is easier said than done.


Once you can ensure that, use the entrySet() method to obtain the set of entries (mappings) in the Map. Once you have obtained the set whose type is Map.Entry, iterate through the entries, comparing the stored value against the expected, and obtain the corresponding key.


Update #2


Support for bidi maps with generics can be found in Google Guava and the refactored Commons-Collections libraries (the latter is not an Apache project). Thanks to Esko for pointing out the missing generic support in Apache Commons Collections. Using collections with generics makes more maintainable code.


If your data structure has many-to-one mapping between keys and values you should iterate over entries and pick all suitable keys:


In case of one-to-one relationship, you can return the first matched key:


In Java 8:


Also, for Guava users, BiMap may be useful. For example:


Some additional info... May be useful to you


Above method may not be good if your hashmap is really big. If your hashmap contain unique key to unique value mapping, you can maintain one more hashmap that contain mapping from Value to Key.


That is you have to maintain two hashmaps


In that case you can use second hashmap to get key.


You could insert both the key,value pair and its inverse into your map structure


Using map.get("theValue") will then return "theKey".


It's a quick and dirty way that I've made constant maps, which will only work for a select few datasets:


I think your choices are


To find all the keys that map to that value, iterate through all the pairs in the hashmap, using map.entrySet().


There is no unambiguous answer, because multiple keys can map to the same value.  If you are enforcing unique-ness with your own code, the best solution is to create a class that uses two Hashmaps to track the mappings in both directions.


Decorate map with your own implementation


I think this is best solution, original address: Java2s


An easy usage: 
if you put all data in hasMap and you have item = "Automobile", so you are looking its key in hashMap. that is good solution. 


I'm afraid you'll just have to iterate your map. Shortest I could come up with:


It sounds like the best way is for you to iterate over entries using map.entrySet() since map.containsValue() probably does this anyway.


If you build the map in your own code, try putting the key and value in the map together:


Then when you have a value, you also have the key.


Using Java 8:


For Android development targeting API < 19, Vitalii Fedorenko one-to-one relationship solution doesn't work because Objects.equals isn't implemented. Here's a simple alternative:


You can get the key using values using following code..


You can use the below:


Yes, you have to loop through the hashmap, unless you implement something along the lines of what these various answers suggest.  Rather than fiddling with the entrySet, I'd just get the keySet(), iterate over that set, and keep the (first) key that gets you your matching value.  If you need all the keys that match that value, obviously you have to do the whole thing.


As Jonas suggests, this might already be what the containsValue method is doing, so you might just skip that test all-together, and just do the iteration every time (or maybe the compiler will already eliminate the redundancy, who knows).


Also, relative to the other answers, if your reverse map looks like


you can deal with non-unique key->value mappings, if you need that capability (untangling them aside).  That would incorporate fine into any of the solutions people suggest here using two maps.


Use a thin wrapper: HMap


My 2 cents. 
You can get the keys in an array and then loop through the array. This will affect performance of this code block if the map is pretty big , where in you are getting the keys in an array first which might consume some time and then you are looping. Otherwise for smaller maps it should be ok.


In java8


It's important to note that since this question, Apache Collections supports Generic BidiMaps.  So a few of the top voted answers are no longer accurate on that point.


For a Serialized BidiMap that also supports duplicate values ( 1-to-many scenario ) also consider MapDB.org.


If you want to get key from value, its best to use bidimap (bi-directional maps) , you can get key from value in O(1) time.


But, the drawback with this is you can only use unique keyset and valueset.


There is a data structure called Table in java, which is nothing but map of maps like


Table< A, B , C > == map < A , map < B, C > >


Here you can get map<B,C> by querying T.row(a);, and you can also get map<A,C> by querying T.column(b);


In your special case, insert C as some constant.


So, it like  < a1, b1, 1 > 
  < a2, b2 , 1 > , ...


So, if you find via T.row(a1) ---> returns map of  --> get keyset  this returned map.


If you need to find key value then, T.column(b2) --> returns map of  --> get keyset of returned map.


Advantages over the previous case : 






As per my understanding I think:


Am I correct?


Now if am correct, I have the following question:
The HashMap internally uses the hashcode of the object. So if two objects can have the same hashcode, then how can the HashMap track which key it uses?


Can someone explain how the HashMap internally uses the hashcode of the object?


A hashmap works like this (this is a little bit simplified, but it illustrates the basic mechanism):


It has a number of "buckets" which it uses to store key-value pairs in. Each bucket has a unique number - that's what identifies the bucket. When you put a key-value pair into the map, the hashmap will look at the hash code of the key, and store the pair in the bucket of which the identifier is the hash code of the key. For example: The hash code of the key is 235 -> the pair is stored in bucket number 235. (Note that one bucket can store more then one key-value pair).


When you lookup a value in the hashmap, by giving it a key, it will first look at the hash code of the key that you gave. The hashmap will then look into the corresponding bucket, and then it will compare the key that you gave with the keys of all pairs in the bucket, by comparing them with equals().


Now you can see how this is very efficient for looking up key-value pairs in a map: by the hash code of the key the hashmap immediately knows in which bucket to look, so that it only has to test against what's in that bucket.


Looking at the above mechanism, you can also see what requirements are necessary on the hashCode() and equals() methods of keys:


If two keys are the same (equals() returns true when you compare them), their hashCode() method must return the same number. If keys violate this, then keys that are equal might be stored in different buckets, and the hashmap would not be able to find key-value pairs (because it's going to look in the same bucket).


If two keys are different, then it doesn't matter if their hash codes are the same or not. They will be stored in the same bucket if their hash codes are the same, and in this case, the hashmap will use equals() to tell them apart.


Your third assertion is incorrect.


It's perfectly legal for two unequal objects to have the same hash code. It's used by HashMap as a "first pass filter" so that the map can quickly find possible entries with the specified key. The keys with the same hash code are then tested for equality with the specified key.


You wouldn't want a requirement that two unequal objects couldn't have the same hash code, as otherwise that would limit you to 232 possible objects. (It would also mean that different types couldn't even use an object's fields to generate hash codes, as other classes could generate the same hash.)





HashMap is an array of Entry objects.


Consider HashMap as just an array of objects.


Have a look at what this Object is:


Each Entry object represents a key-value pair. The field next refers to another Entry object if a bucket has more than one Entry.


Sometimes it might happen that hash codes for 2 different objects are the same. In this case, two objects will be saved in one bucket and will be presented as a linked list. 
The entry point is the more recently added object. This object refers to another object with the next field and so on. The last entry refers to null.


When you create a HashMap with the default constructor


The array is created with size 16 and default 0.75 load balance.


If the bucket already has at least one element, a new one gets added and placed in the first position of the bucket. Its next field refers to the old element.


You can find excellent information at http://javarevisited.blogspot.com/2011/02/how-hashmap-works-in-java.html


To Summarize: 


HashMap works on the principle of hashing


put(key, value): HashMap stores both key and value object as Map.Entry. Hashmap applies hashcode(key) to get the bucket. if there is collision ,HashMap uses LinkedList to store object. 


get(key): HashMap uses Key Object's hashcode to find out bucket location and then call keys.equals() method to identify correct node in LinkedList and return associated value object for that key in Java HashMap.


Here is a rough description of HashMap mechanism, for Java 8 version, (it might be slightly different from Java 6).


HashMap.Node
Linked list version of node,


It could represent:


capacity, means hashtable's bucket count, it could be get from table.length, also could be calculated via threshold and loadFactor, thus no need to be defined as a class field.


capacity(): Get effective capacity.


The hashcode determines which bucket for the hashmap to check.  If there is more than one object in the bucket then a linear search is done to find which item in the bucket equals the desired item (using the equals()) method.


In other words, if you have a perfect hashcode then hashmap access is constant, you will never have to iterate through a bucket (technically you would also have to have MAX_INT buckets, the Java implementation may share a few hash codes in the same bucket to cut down on space requirements).  If you have the worst hashcode (always returns the same number) then your hashmap access becomes linear since you have to search through every item in the map (they're all in the same bucket) to get what you want.


Most of the time a well written hashcode isn't perfect but is unique enough to give you more or less constant access.


You're mistaken on point three.  Two entries can have the same hash code but not be equal.  Take a look at the implementation of HashMap.get from the OpenJdk.  You can see that it checks that the hashes are equal and the keys are equal.  Were point three true, then it would be unnecessary to check that the keys are equal.  The hash code is compared before the key because the former is a more efficient comparison.  


If you're interested in learning a little more about this, take a look at the Wikipedia article on Open Addressing collision resolution, which I believe is the mechanism that the OpenJdk implementation uses.  That mechanism is subtly different than the "bucket" approach one of the other answers mentions.  


This is a Most Confusing Question for many of us in Interviews.But its not that complex.


We know


HashMap stores key-value pair in Map.Entry (we all know)


HashMap works on hashing algorithm and uses hashCode() and equals() method in put() and get() methods. (even we know this)


When we call put method by passing key-value pair, HashMap uses Key **hashCode()** with hashing to **find out the index** to store the key-value pair. (this is important) 


The Entry is **stored in the LinkedList**, so if there are already existing entry, it uses **equals() method to check if the passed key already exists** (even this is important)


if yes it overwrites the value else it creates a new entry and store this key-value Entry.


When we call get method by passing Key, again it uses the hashCode() to find the index in the array and then use equals() method to find the correct Entry and return it’s value. (now this is obvious)


THIS IMAGE WILL HELP YOU UNDERSTAND: 


Edit Sept 2017:
here we see how hash value if used along with equals after we find bucket.





So here we see that if both the objects S1 and S2 have different content, then we are pretty sure that our overridden Hashcode method will generate different Hashcode(116232,11601) for both objects. NOW since there are different hash codes, so it won't even bother to call EQUALS method. Because a different Hashcode GUARANTEES DIFFERENT content in an object.


Hash map works on the principle of hashing 


HashMap get(Key k) method calls hashCode method on the key object and applies returned hashValue to its own static hash function to find a bucket location(backing array) where keys and values are stored in form of a nested class called Entry (Map.Entry) . So you have concluded that from the previous line that Both key and value is stored in the bucket as a form of  Entry object . So thinking that Only value is stored  in the bucket is not correct and will not give a good impression on the interviewer .


If key is null , then Null keys always map to hash 0, thus index 0.


If key is not null then , it will call hashfunction on the key object , see line 4 in above method i.e. key.hashCode()  ,so after key.hashCode() returns hashValue , line 4 looks like


and now ,it applies returned hashValue into its own hashing function .


We might wonder why we are calculating the hashvalue again using hash(hashValue). Answer is It defends against poor quality hash functions.


Now final  hashvalue is used to find the bucket location at which the Entry object is stored . Entry object stores in the bucket like this (hash,key,value,bucketindex) 


Each Entry object represents key-value pair. Field next refers to other Entry object if a bucket has more than 1 Entry.


Sometimes it might happen that hashCodes for 2 different objects are the same. In this case 2 objects will be saved in one bucket and will be presented as LinkedList. The entry point is more recently added object. This object refers to other object with next field and so one. Last entry refers to null.
When you create HashMap with default constructor


Array is gets created with size 16 and default 0.75 load balance.


 


(Source)


I will not get into the details of how HashMap works, but will give an example so we can remember how HashMap works by relating it to reality.


We have Key, Value ,HashCode and bucket.


For sometime, we will relate each of them with the following:


Using Map.get(key) :


Stevie wants to get to his friend's(Josse) house who lives in a villa in a VIP society, let it be JavaLovers Society. 
Josse's address is his SSN(which is different for everyone).
There's an index maintained in which we find out the Society's name based on SSN.
This index can be considered to be an algorithm to find out the HashCode.


Using Map.put(key,Value)


This finds a suitable society for this Value by finding the HashCode and then the value is stored.


I hope this helps and this is open for modifications.


In a summerized form of How hashMap works in java?


HashMap works on the principle of hashing, we have put() and get() method for storing and retrieving object from HashMap. When we pass both key and value to put() method to store on HashMap, it uses key object hashcode() method to calculate hashcode and they by applying hashing on that hashcode, it identifies bucket location for storing value object. While retrieving, it uses key object equals method to find out correct key value pair and return value object associated with that key. HashMap  uses linked list in case of collision and object will be stored in next node of linked list.
Also HashMap stores both key+value tuple in every node of linked list.


two objects are equal, implies that they have same hashcode, but not vice versa


Java 8 update in HashMap-


you do this operation in your code - 


so, suppose your hashcode returned for both keys "old" and "very-old" is same. Then what will happen.


myHashMap is a HashMap, and suppose that initially you didn't specify its capacity. So default capacity as per java is 16. So now as soon as you initialised hashmap using the new keyword, it created 16 buckets. now when you executed first statement-


then hashcode for "old" is calculated, and because the hashcode could be very large integer too, so, java internally did this - (hash is hashcode here and >>> is right shift)


so to give as a bigger pictureit will return some index, which would be between 0 to 15. Now your key value pair "old" and "key-value-pair" would be converted to Entry object's key and value instance variable. and then this entry object will be stored in the bucket, or you can say that at a particular index, this entry object would be stored.


FYI- Entry is a class in Map interface- Map.Entry, with these signature/definition


now when you execute next statement - 


and "very-old" gives same hashcode as "old", so this new key value pair is again sent to the same index or the same bucket. But since this bucket is not empty, then the next variable of the Entry object is used to store this new key value pair.


and this will be stored as linked list for every object which have the same hashcode, but a TRIEFY_THRESHOLD is specified with value 6. so after this reaches, linked list is converted to the balanced tree(red-black tree) with first element as the root.


As it is said, a picture is worth 1000 words. I say: some code is better than 1000 words. Here's the source code of HashMap. Get method:


So it becomes clear that hash is used to find the "bucket" and the first element is always checked in that bucket. If not, then equals of the key is used to find the actual element in the linked list.


Let's see the put() method:


It's slightly more complicated, but it becomes clear that the new element is put in the tab at the position calculated based on hash:


i = (n - 1) & hash here i is the index where the new element will be put (or it is the "bucket"). n is the size of the tab array (array of "buckets").


First, it is tried to be put as the first element of in that "bucket". If there is already an element, then append a new node to the list.


It gonna be a long answer , grab a drink and read on …


Hashing is all about storing a key-value pair in memory that can be read and written faster. It stores keys in an array  and  values in a LinkedList .


Lets Say I want to store 4 key value pairs -


So to store the keys we need an array of 4 element . Now how do I map one of these 4 keys to 4 array indexes (0,1,2,3)? 


So java finds the hashCode of individual keys and map them to a particular array index . 
Hashcode Formulae is - 


Hash and girl !! I know what you are thinking. Your fascination about that wild duet might made you miss an important thing . 


Why java multiply it with 31 ?


It’s because, 31 is an odd prime in the form 2^5 – 1 . And odd prime reduces the chance of Hash Collision


Now how this hash code is mapped to an array index? 


answer is , Hash Code % (Array length -1)  . So “girl” is mapped to (3173020 % 3) = 1 in our case . which is second element of the array . 


and the value “ahhan”  is stored in a LinkedList associated with array index 1 .


HashCollision -  If you try to find hasHCode of the keys “misused” and  “horsemints” using the formulae described above you’ll see both giving us same 1069518484. Whooaa !! lesson learnt -


2 equal objects must have same hashCode but there is no guarantee if
  the hashCode matches then the objects are equal . So it should store
  both values corresponding to “misused” and “horsemints” to bucket 1
  (1069518484 % 3) .


Now the hash map looks like –


Now if some body tries to find the value for the key “horsemints” , java quickly will find the hashCode of it , module it and start searching for it’s value in the LinkedList corresponding index 1 . So this way we need not search all the 4 array indexes thus making data access faster.


But , wait , one sec .   there are 3 values in that linkedList corresponding Array index 1, how it finds out which one was was the value for key “horsemints” ? 


Actually I lied , when I said HashMap just stores values in LinkedList .


It stores both key value pair as map entry. So actually Map looks like this . 


Now you can see While traversing through the linkedList corresponding to ArrayIndex1 it actually compares key of each entry to of that LinkedList to “horsemints” and when it finds one it just returns the value of it .


Hope you had fun while reading it :)






I am trying to get my first taste of Android development using Eclipse. I ran into this problem when trying to run Eclipse, having installed version 4.2 only minutes ago.


After first trying to start Eclipse without any parameters to specify the Java VM, I got an error message saying it couldn't find a Java VM called javaw.exe inside the Eclipse folder, so I found where Java was installed and specified that location as the parameter in the shortcut's target. Now I get a different error, "Java was started but returned exit code=13".


Similar questions seem to indicate that it's a 32-bit/64-bit conflict, but I'm 99% positive that I downloaded 64-bit versions of both Eclipse and Java (RE 7u5), which I chose because I have 64-bit Windows 7. 


Shortcut Target: "C:\Program Files\Eclipse-SDK-4.2-win32-x86_64\eclipse\eclipse.exe" -vm "C:\Program Files (x86)\Java\jre7\bin\javaw.exe"


Full error code...:


Working combinations of OS, JDK and eclipse bitness. In my case, I was using 64-bit JDK with 32-bit eclipse in a 64-bit OS. After downgrading JDK to 32-bit eclipse started working.
Kindly use 1 of the following combinations.


Hope this helps you.


Your version of Eclipse is 64-bit, based on the paths and filenames.
However, the version of Java that it's picking up is 32-bit, as indicated by where it is coming from, indicated on this line:


Program Files (x86) is the folder where 64-bit Windows places 32-bit programs.


Program Files is the folder where 64-bit Windows places 64-bit programs.


This can happen when a system has more than one JVM installed, as is often the case on Windows 64-bit (for example, the JRE download page uses the bit-ness of the browser to determine what bit-ness download to offer you, and many people use(d) 32-bit browsers even though they run 64-bit Windows).


The best way to fix this, assuming you do in fact have 64-bit JRE or JDK on your system, is to specify in eclipse.ini exactly which JVM you want it to use. The instructions are detailed in the Eclipse wiki page, but basically you have to specify the -vm option in the ini file - make sure to read the wiki page carefully as the format is very specific.


Specifying the JVM path in eclipse.ini is strongly recommended because doing so isolates Eclipse from any potential changes to your system PATH that some program installers might make (I'm talking to you, Oracle!).


Another option would be to download and use 32-bit Eclipse instead of 64-bit, but it's still strongly recommended to specify the path to the JVM in eclipse.ini.


Left for historical reference:


To check your version of Java, run 


in a console (command prompt). On Windows 7 with 64-bit Java 6 I get:


Note the 3rd line, which shows that this is a 64-bit version. 


On a 32-bit version you'll get something like:


I got this error and found that my PATH variable (on Windows) was probably changed. First in my PATH was this entry:


...and Eclipse ran "C:\ProgramData\Oracle\Java\javapath\javaw" - which gave the error. I suspect that this is something that came along with an installation of Java 8.


I have several Java versions installed (6,7 and 8), so I removed that entry from the PATH and tried to restart Eclipse again, which worked fine.


Instructions on how to edit PATH variable


If you have recently installed Java 8 and uninstalled Java 7, install JDK 8 and retry.


For me the solution was to go into (on Windows 8.1):


Under 'System variables' in the 'Path' variable there was the following first:


I removed this and Eclipse worked again!


I had the same issue, Java was started but returned exit code=13.


My solution was to create an environment variable to Windows properties variable name = PATH variable value = C:\Program Files\Java\jdk1.7.0_02\bin, not to C:\Program Files (x86)\Java\jre7\bin.


Next I added a line to file eclipse.ini → C:\Program Files\Java\jdk1.7.0_02\bin\javaw.exe.


That worked for me.





The issue was fixed by doing the following steps.


Eclipse finds the JAVA executables from
'C:\ProgramData\Oracle\Java\javapath'


The folder structure will contain shortcuts to the below executables, 
i. java.exe 
ii. javaw.exe 
iii. javaws.exe


For me the executable paths were pointing to my Program Files(x86) (home for 32 bit applications) folder location


I corrected it to Program Files (which homes 64-bit applications) and the issue got resolved


Please find the screenshot for the same.


The strangest fix ever. Look at your Eclipse path, and make sure you do not have strange characters (like !, #, and @). It worked for me.


Adding vm argument to .ini file worked for me


I had this message when I had forgot to install the JDK.


I uninstalled Java update 25, and the issue was solved.


A clean reinstall of the Java JDK did the trick in my case. I am running Eclipse 4.4 (Luna) like a charm now.


The solution is simple: Put the "eclipse" folder on "c:/Program Files". If it does not work, put it in "c:/Program Files (x86)".


It turned out I only had the 32-bit Java runtime installed.


All Eclipse really wanted was for me to install the 64-bit Java runtime. <= SOLVED


http://www.oracle.com/technetwork/java/javase/downloads/jre8-downloads-2133155.html


Locate eclipse.ini:


Often at C:\Users\xxx\eclipse\jee-neon\eclipse, add 


after


I had the same problem. I was using Windows 8 with a 64-bit OS. I just changed the path to Program Files (x86) and then it started work. I put this line in the eclipse.ini file:


If you install a 64-bit Eclipse version on a PC with a 32-bit JRE this is guaranteed to occur.


So the solution is quite straightforward: You need to synchronise them by updating either one. This shall happen when downloading Oracle Fusion middleware and Eclipse expects a 32-bit environment while your JRE is 64-bit and your JAVA home is pointing to a 64-bit JDK.


I had this issue.  I installed Java 8 update 25 via Chrome, and therafter attempting to start Eclipse gave the mentioned error.


Uninstalled that update, and Eclipse works again.


Make sure you don't have special characters (%, $, #, etc.) at Eclipse path.


I tried some of the solutions, but not worked for me.


Finally, I found another way, ...


Go to Environment Variables → System Variables


Set C:\Program Files\Java\jdk1.7.0_02\bin\javaw.exe to the path in the system variables.


Try it. It worked for me...


The best answer here is too long. I cannot comment so I added my answer.


I have just solved the same issue upon setting up my Windows 8.1 PC. Exactly like @George Papatheodorou mentioned above (sorry I cannot add a comment), Eclipse and JRE must be both 64 bit or 32 bit.


However, it seems for Windows 8/8.1 environment, you are going to get 32-bit JRE by default (and I do not know where to change that default for the download), as explained here: http://java.com/en/download/faq/win8_faq.xml


I was using 64-bit Eclipse so there was a discrepancy. I then installed 32-bit Eclipse and everything works fine this time.


So before bothering changing any environment variables, check your JRE and Eclipse version.


Of course you can use 64-bit JRE with 64-bit Eclipse. Just make sure they match because Windows 8.1 will give you 32-bit by default.


I tried the following solution:


I created a shortcut of javaw.exe from path C:\Program Files\Java\jdk1.7.0_71\bin and pasted it into the path C:\ProgramData\Oracle\Java\javapath.


After that, I launched Eclipse, and it worked for me.


I had the same issue after I upgraded my JDK from 1.7 to 1.8. I'm using Eclipse 4.4 (Luna). The error is gone after I degrade JDK to 1.7.


I also encountered the same issue. It turned out that the environment variable Path was pointing to an incorrect Java version.


Please check the environment variable and point it to the correct Java. For example: 


To check the environment variable, go to:


It could be due to less memory. You can modify the eclipse.ini file to increase the memory. Something like this might help you: FAQ How do I increase the heap size available to Eclipse? 


This might happen if you have several versions of Java on the same machine. To fix this I did the following:


I had an x64 bit JDK. There was nothing in my path settings. So I installed the x86 JDK. This solved my problem perfectly.


I had a similar error after installing Java 8 on my Windows 7 system, 64 bit system. 


Changing environment variables, etc. did not help. So I tried to remove the Java Update 8, but that too did not help. Downloading and installing the 64-bit version of Java 8 SDK fixed my problem. I hope this helps.


This type of errors occur basically due to use of different versions of Java with different version of Eclipse.


Suppose you are installing the 64-bit JDK on your system. Then make sure you install the 64-bit versioned Eclipse with it.


And if you are installing the 32-bit JDK on your system then make sure you install 32-bit versioned Eclipse with it.


I had the similar problem. I have installed the 32-bit JDK and was trying to use 64-bit Eclipse.


But when I installed the 64-bit JDK on my system then Eclipse started working without any problem.


It is advised to better install the 32-bit version of Java along with the 32-bit version Eclipse on a system with a 32-bit configuration and similarly for 64-bit systems.


This helps to increase performance of the system.






I realized that Android has no built-in method of displaying PDF files. 


How can I render a PDF file using Java on Android?


Taken from my blog:


Since API Level 21 (Lollipop) Android provides a PdfRenderer class:


For more information see the sample app.


For older APIs I recommend Android PdfViewer library, it is very fast and easy to use, licensed under Apache License 2.0:


I have made a hybrid approach from some of the answers given to this and other similar posts:


This solution checks if a PDF reader app is installed and does the following:
- If a reader is installed, download the PDF file to the device and start a PDF reader app
- If no reader is installed, ask the user if he wants to view the PDF file online through Google Drive


NOTE! This solution uses the Android DownloadManager class, which was introduced in API9 (Android 2.3 or Gingerbread). This means that it doesn't work on Android 2.2 or earlier.


I wrote a blog post about it here, but I've provided the full code below for completeness:


I finally was able to modify butelo's code to open any PDF file in the Android filesystem using pdf.js. The code can be found on my GitHub


What I did was modified the pdffile.js to read HTML argument file like this: 


So what you need to do is just append the file path after the index.html like this:


Update the path variable to point to a valid PDF in the Adroid filesystem.


Download the source code here (Display PDF file inside my android application)


Add this dependency in your Grade:
compile 'com.github.barteksc:android-pdf-viewer:2.0.3'


activity_main.xml


MainActivity.java


To add a little light to this, I would have to go with the pdf.js solution from Mozilla. Here is the link to an already well written implementation of this: https://bitbucket.org/butelo/pdfviewer/.


Here are the edits that I added in my Android Activity:


Here are the edits I made in pdffile.js:


I used the below code to open and print the PDF using Wi-Fi. I am sending my whole code, and I hope it is helpful.






In the following snippet:


What does / in the method getRealPath() represent? When should I use it?


The ServletContext#getRealPath() is intented to convert a web content path (the path in the expanded WAR folder structure on the server's disk file system) to an absolute disk file system path.


The "/" represents the web content root. I.e. it represents the web folder as in the below project structure:


So, passing the "/" to getRealPath() would return you the absolute disk file system path of the /web folder of the expanded WAR file of the project. Something like /path/to/server/work/folder/some.war/ which you should be able to further use in File or FileInputStream.


Note that most starters don't seem to see/realize that you can actually pass the whole web content path to it and that they often use


instead of


Also note that even though you can write new files into it using FileOutputStream, all changes (e.g. new files or edited files) will get lost whenever the WAR is redeployed; with the simple reason that all those changes are not contained in the original WAR file. So all starters who are attempting to save uploaded files in there are doing it wrong. 


Moreover, getRealPath() will always return null or a completely unexpected path when the server isn't configured to expand the WAR file into the disk file system, but instead into e.g. memory as a virtual file system. 


Use getRealPath() carefully. There are actually no sensible real world use cases for it. If all you actually need is to get an InputStream of the web resource, better use ServletContext#getResourceAsStream() instead, this will work regardless of the way how the WAR is expanded. So, if you for example want an InputStream of index.jsp, then do not do:


But instead do:


Or if you intend to obtain a list of all available web resource paths, use ServletContext#getResourcePaths() instead.


You can obtain an individual resource as URL via ServletContext#getResource(). This will return null when the resource does not exist.


Or if you intend to save an uploaded file, or create a temporary file, then see the below "See also" links.


A web application's context path is the directory that contains the web application's WEB-INF directory. It can be thought of as the 'home' of the web app. Often, when writing web applications, it can be important to get the actual location of this directory in the file system, since this allows you to do things such as read from files or write to files.


This location can be obtained via the ServletContext object's getRealPath() method. This method can be passed a String parameter set to File.separator to get the path using the operating system's file separator ("/" for UNIX, "\" for Windows). 


There is also a change between Java 7 and Java 8.  Admittedly it involves the a deprecated call, but I hae aWe had to add a "/" to get our program working!  Here is the link discussing it Why does servletContext.getRealPath returns null on tomcat 8?






I seem to have a problem with my very simple implementation of a file chooser dialogue that requires me to minimize Netbeans each time in order to get to it, and it gets pretty frustrating specially now with testing.


I have seen a few solutions online including SO yet none seem to do the trick, while some other seem very lengthy and complicated for my current level.  


Some of my try's include using;


Is there a particular attribute/method I can set in order to solve the problem?


The API for showOpenDialog() refers to showDialog(), which says, "If the parent is null, then the dialog depends on no visible window, and it's placed in a look-and-feel-dependent position such as the center of the screen."


The example below positions the chooser in the center of the screen on my L&F. You might see how it compares to yours.


package gui;


I'm not sure what your problem actually is (it's probably your Netbeans.... who knows), but have you tried overriding the createDialog method?


Example: 


This is merely a hack solution, you should not need to do that ordinarily.


Of course, this must be a Component of some sort (the JFrame or JPanel of your main interface).
All dialogs need to have a parent component if you wish them to come to the front.






When creating a new Java project in IntelliJ IDEA, the following directories and files are created:


I want to configure IntelliJ IDEA to include my dependency JARs in ./lib/*.jar to the project. What is the correct way to achieve this in IntelliJ IDEA?


Steps for adding external jars in IntelliJ IDEA:


File > Project Structure... 





or press Ctrl + Alt + Shift + S


Project Settings > Modules > Dependencies > "+" sign > JARs or directories...





Select the jar file and click on OK, then click on another OK button to confirm








You can view the jar file in the "External Libraries" folder





Just copy-paste the .jar under the libs folder, right click on it and select 'Add as library' option from the list. It will do the rest...


You add them as libraries to your module.  


I usually have a /lib directory in my source.   I put all the JARs I need there, add /lib as a library, and make it part of my module dependencies.


UPDATE: Starting to use Maven to manage dependencies.  No need to copy JARs that way - just add them to your pom.xml.


I'm up to IntelliJ 14.1 as of 29-Jan-2015.


Libraries cannot be directly used in any program if not properly added to the project gradle files.


This can easily be done in smart IDEs like inteli J.


1) First as a convention add a folder names 'libs' under your project src file. (this can easily be done using the IDE itself)


2) then copy or add your library file (eg: .jar file) to the folder named 'libs'


3) now you can see the library file inside the libs folder. Now right click on the file and select 'add as library'. And this will fix all the relevant files in your program and library will be directly available for your use.


Please note:


Whenever you are adding libraries to a project, make sure that the project supports the library


Some great help found here. However, I still could not make it to work despite loading JAR properly. I found out later that I accidentally created module in the file structure instead of regular folder and this very module was pre-selected in the project setting.


Here is the footprint:


File -> Project Structure -> Modules -> (select proper module if you have more) -> Dependencies -> + -> JAR or Libraries


While I agree with the previous answers, it's important to note how to access the code of those external libraries. 


For example to access a class in the external library, you will want to use the import keyword followed by the external library's name, continued with dot notation until the desired class is reached. 


Look at the image below to see how I import CodeGenerationException class from the quickfixj library. 





I use this method and it works well:


1- Copy And paste the .jar files under the libs folder.


2- Add compile fileTree(dir: 'libs', include: '*.jar') to dependencies in build.gradle then all the jars in the libs folder will be included..


3- Right click on libs folder and select 'Add as library' option from the list.






This question already has an answer here:


I was looking over some code the other day and I came across:


Coming from C++, I had no idea why that was there. Its not an error because the code compiled fine. What is this "static" block of code?


It's a static initializer. It's executed when the class is loaded (or initialized, to be precise, but you usually don't notice the difference).


It can be thought of as a "class constructor".


Note that there are also instance initializers, which look the same, except that they don't have the static keyword. Those are run in addition to the code in the constructor when a new instance of the object is created.


It is a static initializer. It's executed when the class is loaded and a good place to put initialization of static variables.


From http://java.sun.com/docs/books/tutorial/java/javaOO/initial.html


A class can have any number of static initialization blocks, and they can appear anywhere in the class body. The runtime system guarantees that static initialization blocks are called in the order that they appear in the source code. 


If you have a class with a static look-up map it could look like this


It's useful since the above static field could not have been initialized using labels = .... It needs to call the put-method somehow.


It's a block of code which is executed when the class gets loaded by a classloader. It is meant to do initialization of static members of the class.


It is also possible to write non-static initializers, which look even stranger:


Static block can be used to show that a program can run without main function also.


A static block executes once in the life cycle of any program, 
another property of static block is that it executes before the main method.


Static blocks are used for initializaing the code and  will be executed when JVM loads the class.Refer to the below link which gives the detailed explanation.
http://www.jusfortechies.com/java/core-java/static-blocks.php


yes, static block is used for initialize the code and it will load at the time JVM start for execution.


static block is used in previous versions of java but in latest version it doesn't work.






I've always been told never to represent money with double or float types, and this time I pose the question to you: why? 


I'm sure there is a very good reason, I simply do not know what it is.


Because floats and doubles cannot accurately represent the base 10 multiples we use for money. This issue isn't just for Java, it's for any programming language that uses native floating-point types, as it stems from how computers handle floating-point numbers by default.


This is how an IEEE-754 floating-point number works: it dedicates a bit for the sign, a few bits to store an exponent for the base, and the rest for a multiple of that elevated base. This leads to numbers like 10.25 being represented in a form similar to 1025 * 10-2; except that instead of the base being 10, for floats and doubles, it's two, so that would be 164 * 2-4. (That's still not exactly how they are represented in hardware, but this is simple enough and the math holds the same way.)


Even in base 10, this notation cannot accurately represent most simple fractions. For instance, with most calculators, 1/3 results in a repeating 0.333333333333, with as many 3's as the digital display allows, because you just can't write 1/3 in decimal notation. However, for the purpose of money (at least for countries whose money value is within an order of magnitude of the US dollar), in most scenarios all you need is to be able to store multiples of 10-2, so we don't really care if 1/3 doesn't have an exact representation as an integer times a power of 10, and even the cheapest calculators handle cents just fine.


The problem with floats and doubles is that the vast majority of money-like numbers don't have an exact representation as a integer times a power of two. In fact, the only fractions of a hundred between 0/100 and 100/100 (which are significant when dealing with money because they're integer cents) that can be represented exactly as an IEEE-754 binary floating-point number are 0, 0.25, 0.5, 0.75 and 1. All the others are off by a small amount.


Representing money as a double or float will probably look good at first as the software rounds off the tiny errors, but as you perform more additions, subtractions, multiplications and divisions on inexact numbers, you'll lose more and more precision as the errors add up. This makes floats and doubles inadequate for dealing with money, where perfect accuracy for multiples of base 10 powers is required.


A solution that works in just about any language is to use integers instead, and count cents. For instance, 1025 would be $10.25. Several languages also have built-in types to deal with money. Among others, Java  has the BigDecimal class, and C# has the decimal type.


From Bloch, J., Effective Java, 2nd ed, Item 48:


The float and double types are
  particularly ill-suited for monetary
  calculations because it is impossible
  to represent 0.1 (or any other
  negative power of ten) as a float or
  double exactly.


For example, suppose you have $1.03
  and you spend 42c. How much money do
  you have left?


prints out 0.6100000000000001.


The right way to solve this problem is
  to use BigDecimal, int or long
  for monetary calculations.


This is not a matter of accuracy, nor is it a matter of precision.  It is a matter of meeting the expectations of humans who use base 10 for calculations instead of base 2.  For example, using doubles for financial calculations does not produce answers that are "wrong" in a mathematical sense, but it can produce answers that are not what is expected in a financial sense.


Even if you round off your results at the last minute before output, you can still occasionally get a result using doubles that does not match expectations.


Using a calculator, or calculating results by hand, 1.40 * 165 = 231 exactly.  However, internally using doubles, on my compiler / operating system environment, it is stored as a binary number close to 230.99999... so if you truncate the number, you get 230 instead of 231.  You may reason that rounding instead of truncating would have given the desired result of 231.  That is true, but rounding always involves truncation.  Whatever rounding technique you use, there are still boundary conditions like this one that will round down when you expect it to round up.  They are rare enough that they often will not be found through casual testing or observation.  You may have to write some code to search for examples that illustrate outcomes that do not behave as expected.


Assume you want to round something to the nearest penny.  So you take your final result, multiply by 100, add 0.5, truncate, then divide the result by 100 to get back to pennies.  If the internal number you stored was 3.46499999.... instead of 3.465, you are going to get 3.46 instead 3.47 when you round the number to the nearest penny.  But your base 10 calculations may have indicated that the answer should be 3.465 exactly, which clearly should round up to 3.47, not down to 3.46.  These kinds of things happen occasionally in real life when you use doubles for financial calculations.  It is rare, so it often goes unnoticed as an issue, but it happens.


If you use base 10 for your internal calculations instead of doubles, the answers are always exactly what is expected by humans, assuming no other bugs in your code.


I'm troubled by some of these responses.  I think doubles and floats have a place in financial calculations.  Certainly, when adding and subtracting non-fractional monetary amounts there will be no loss of precision when using integer classes or BigDecimal classes.  But when performing more complex operations, you often end up with results that go out several or many decimal places, no matter how you store the numbers.  The issue is how you present the result.


If your result is on the borderline between being rounded up and rounded down, and that last penny really matters, you should be probably be telling the viewer that the answer is nearly in the middle - by displaying more decimal places.


The problem with doubles, and more so with floats, is when they are used to combine large numbers and small numbers.  In java,


results in


Floats and doubles are approximate. If you create a BigDecimal and pass a float into the constructor you see what the float actually equals:


this probably isn't how you want to represent $1.01.


The problem is that the IEEE spec doesn't have a way to exactly represent all fractions, some of them end up as repeating fractions so you end up with approximation errors. Since accountants like things to come out exactly to the penny, and customers will be annoyed if they pay their bill and after the payment is processed they owe .01 and they get charged a fee or can't close their account, it's better to use exact types like decimal (in C#) or java.math.BigDecimal in Java.


It's not that the error isn't controllable if you round: see this article by Peter Lawrey. It's just easier not to have to round in the first place. Most applications that handle money don't call for a lot of math, the operations consist of adding things or allocating amounts to different buckets. Introducing floating point and rounding just complicates things.


The result of floating point number is not exact, which makes them unsuitable for any financial calculation which requires exact result and not approximation. float and double are designed for engineering and scientific calculation and many times doesn’t produce exact result also result of floating point calculation may vary from JVM to JVM. Look at below example of BigDecimal and double primitive which is used to represent money value, its quite clear that floating point calculation may not be exact and one should use BigDecimal for financial calculations.


Output:


While it's true that floating point type can represent only approximatively decimal data, it's also true that if one rounds numbers to the necessary precision before presenting them, one obtains the correct result. Usually.


Usually because the double type has a precision less than 16 figures. If you require better precision it's not a suitable type. Also approximations can accumulate.


It must be said that even if you use fixed point arithmetic you still have to round numbers, were it not for the fact that BigInteger and BigDecimal give errors if you obtain periodic decimal numbers. So there is an approximation also here.


For example COBOL, historically used for financial calculations, has a maximum precision of 18 figures. So there is often an implicit rounding.


Concluding, in my opinion the double is unsuitable mostly for its 16 digit precision, which can be insufficient, not because it is approximate.


Consider the following output of the subsequent program. It shows that after rounding double give the same result as BigDecimal up to precision 16.


As said earlier "Representing money as a double or float will probably look good at first as the software rounds off the tiny errors, but as you perform more additions, subtractions, multiplications and divisions on inexact numbers, you’ll lose more and more precision as the errors add up. This makes floats and doubles inadequate for dealing with money, where perfect accuracy for multiples of base 10 powers is required."


Finally Java has a standard way to work with Currency And Money!


JSR 354: Money and Currency API


JSR 354 provides an API for representing, transporting, and performing comprehensive calculations with Money and Currency. You can download it from this link: 


JSR 354: Money and Currency API Download


The specification consists of the following things:


Sample Examples of JSR 354: Money and Currency API:


An example of creating a MonetaryAmount and printing it to the console looks like this::


When using the reference implementation API, the necessary code is much simpler:


The API also supports calculations with MonetaryAmounts:


CurrencyUnit and MonetaryAmount


MonetaryAmount has various methods that allow accessing the assigned currency, the numeric amount, its precision and more:


MonetaryAmounts can be rounded using a rounding operator:


When working with collections of MonetaryAmounts, some nice utility methods for filtering, sorting and grouping are available.


Custom MonetaryAmount operations


Resources: 


Handling money and currencies in Java with JSR 354


Looking into the Java 9 Money and Currency API (JSR 354)


See Also: JSR 354 - Currency and Money


I'll risk being downvoted, but I think the unsuitability of floating point numbers for currency calculations is overrated. As long as you make sure you do the cent-rounding correctly and have enough significant digits to work with in order to counter the binary-decimal representation mismatch explained by zneak, there will be no problem.


People calculating with currency in Excel have always used double precision floats (there is no currency type in Excel) and I have yet to see anyone complaining about rounding errors.


Of course, you have to stay within reason; e.g. a simple webshop would probably never experience any problem with double precision floats, but if you do e.g. accounting or anything else that requires adding a large (unrestricted) amount of numbers, you wouldn't want to touch floating point numbers with a ten foot pole.


If your computation involves various steps, arbitrary precision arithmetic won't cover you 100%.


The only reliable way to use perfect representation of results(Use a custom Fraction data type that will batch division operations to the last step) and only convert to a decimal notation in last step.


Arbitrary precision won't help because there always can be numbers that has so much decimal places, or some results such as 0.6666666... No arbitrary representation will cover the last example. So you will have small errors in each step.


This errors will add-up, may eventually become not easy to ignore anymore. This is called Error Propagation.


Some example... this works (actually don't work as expected), on almost any programming language... I've tried with Delphi, VBScript, Visual Basic, JavaScript and now with Java/Android:


OUTPUT:


round problems?: current total: 0.9999999999999999
 round problems?: current total: 2.7755575615628914E-17
 round problems?: is total equal to ZERO? NO... thats why you should not use Double for some math!!!


I prefer using Integer or Long to represent currency.  BigDecimal junks up the source code too much.


You just have to know that all your values are in cents.  Or the lowest value of whatever currency you're using.


Many of the answers posted to this question discuss IEEE and the standards surrounding floating-point arithmetic.


Coming from a non-computer science background (physics and engineering), I tend to look at problems from a different perspective. For me, the reason why I wouldn't use a double or float in a mathematical calculation is that I would lose too much information.


What are the alternatives? There are many (and many more of which I am not aware!).


BigDecimal in Java is native to the Java language.
Apfloat is another arbitrary-precision library for Java.


The decimal data type in C# is Microsoft's .NET alternative for 28 significant figures.


SciPy (Scientific Python) can probably also handle financial calculations (I haven't tried, but I suspect so).


The GNU Multiple Precision Library (GMP) and the GNU MFPR Library are two free and open-source resources for C and C++.


There are also numerical precision libraries for JavaScript(!) and I think PHP which can handle financial calculations.


There are also proprietary (particularly, I think, for Fortran) and open-source solutions as well for many computer languages.


I'm not a computer scientist by training. However, I tend to lean towards either BigDecimal in Java or decimal in C#. I haven't tried the other solutions I've listed, but they are probably very good as well.


For me, I like BigDecimal because of the methods it supports. C#'s decimal is very nice, but I haven't had the chance to work with it as much as I'd like. I do scientific calculations of interest to me in my spare time, and BigDecimal seems to work very well because I can set the precision of my floating point numbers. The disadvantage to BigDecimal? It can be slow at times, especially if you're using the divide method.


You might, for speed, look into the free and proprietary libraries in C, C++, and Fortran.






I learnt from Google that Internationalization is the process by which I can make my 
web application to use all languages. I want to understand Unicode for the process of internationalization, so I learnt about Unicode from here and there.


I am able to understand about Unicode that how a charset set in encoded to bytes and again bytes decoded to charset. But I don't know how to move forward further. I want to learn how to compare strings and I need to know how to implement internationalization in my web application. Any Suggestions Please? Please guide me. 


My Objective:


My main objective is to develop a Web Application for Translation (English to Arabic & vice versa). I want to follow Internationalization. I wish to run my web Application for translation in all the three browsers namely FF, Chrome, IE. How do I achieve this?


In case of a basic JSP/Servlet webapplication, the basic approach would be using JSTL fmt taglib in combination with resource bundles. Resource bundles contain key-value pairs where the key is a constant which is the same for all languages and the value differs per language. Resource bundles are usually properties files which are loaded by ResourceBundle API. This can however be customized so that you can load the key-value pairs from for example a database.


Here's an example how to internationalize the login form of your webapplication with properties file based resource bundles.


Create the following files and put them in some package, e.g. com.example.i18n (in case of Maven, put them in the package structure inside src/main/resources).


text.properties (contains key-value pairs in the default language, usually English)


text_nl.properties (contains Dutch (nl) key-value pairs)


text_es.properties (contains Spanish (es) key-value pairs)


The resource bundle filename should adhere the following pattern name_ll_CC.properties. The _ll part should be the lowercase ISO 693-1 language code. It is optional and only required whenever the _CC part is present. The _CC part should be the uppercase ISO 3166-1 Alpha-2 country code. It is optional and often only used to distinguish between country-specific language dialects, like American English (_en_US) and British English (_en_GB).


If not done yet, install JSTL. If you're running on a Servlet 2.5 container or newer (Tomcat 6.0 and so on) and your web.xml is declared conform the Servlet 2.5 specification, then just put jstl-1.2.jar in webapp's /WEB-INF/lib folder.


Create the following example JSP file and put it in web content folder.


login.jsp


The <c:set var="language"> manages the current language. If the language was supplied as request parameter (by language dropdown), then it will be set. Else if the language was already previously set in the session, then stick to it instead. Else use the user supplied locale in the request header.


The <fmt:setLocale> sets the locale for resource bundle. It's important that this line is before the <fmt:setBundle>.


The <fmt:setBundle> initializes the resource bundle by its base name (that is, the full qualified package name until with the sole name without the _ll_CC specifier).


The <fmt:message> retrieves the message value by the specified bundle key.


The <html lang="${language}"> informs the searchbots what language the page is in so that it won't be marked as duplicate content (thus, good for SEO).


The language dropdown will immediately submit by JavaScript when another language is chosen and the page will be refreshed with the newly chosen language.


You however need to keep in mind that properties files are by default read using ISO-8859-1 character encoding. You would need to escape them by unicode escapes. This can be done using the JDK-supplied native2ascii.exe tool. See also this article section for more detail. 


A theoretical alternative would be to supply a bundle with a custom Control to load those files as UTF-8, but that's unfortunately not supported by the basic JSTL fmt taglib. You would need to manage it all yourself with help of a Filter. There are (MVC) frameworks which can handle this in a more transparent manner, like JSF, see also this article.


In addition to what BalusC said, you have to take care about directionality (since English is written Left-To-Right and Arabic the other way round). The easiest way would be to add dir attribute to html element of your JSP web page and externalize it, so the value comes from properties file (just like with other elements or attributes):


Also, there are few issues with styling such application - you should to say the least avoid absolute positioning. If you cannot avoid that for some reason, you could either use different stylesheets per (each?) language or do something that is verboten, that is use tables for managing layout. If you want to use div elements, I'd suggest to use relative positioning with "symmetric" left and right style attributes (both having the same value), since this is what makes switching directionality work.


You could find more about Bi-Directional websites here.


based on this tutorial, I am using the following on GAE - Google's App Engine:


A jsp file as follows: 


And adding the files named: app.properties (default) and app_fr.properties (and so on for every language). Each of these files should contain the strings you need as follows: key:value_in_language, e.g. app_fr.properties contains: 


app.properties contains:


That's all






How do you write (and run) a correct micro-benchmark in Java?


I'm looking here for code samples and comments illustrating various things to think about.


Example: Should the benchmark measure time/iteration or iterations/time, and why?


Related: Is stopwatch benchmarking acceptable?


Tips about writing micro benchmarks from the creators of Java HotSpot:


Rule 0: Read a reputable paper on JVMs and micro-benchmarking. A good one is Brian Goetz, 2005. Do not expect too much from micro-benchmarks; they measure only a limited range of JVM performance characteristics.


Rule 1: Always include a warmup phase which runs your test kernel all the way through, enough to trigger all initializations and compilations before timing phase(s). (Fewer iterations is OK on the warmup phase. The rule of thumb is several tens of thousands of inner loop iterations.)


Rule 2: Always run with -XX:+PrintCompilation, -verbose:gc, etc., so you can verify that the compiler and other parts of the JVM are not doing unexpected work during your timing phase.


Rule 2.1: Print messages at the beginning and end of timing and warmup phases, so you can verify that there is no output from Rule 2 during the timing phase.


Rule 3: Be aware of the difference between -client and -server, and OSR and regular compilations. The -XX:+PrintCompilation flag reports OSR compilations with an at-sign to denote the non-initial entry point, for example: Trouble$1::run @ 2 (41 bytes). Prefer server to client, and regular to OSR, if you are after best performance.


Rule 4: Be aware of initialization effects. Do not print for the first time during your timing phase, since printing loads and initializes classes. Do not load new classes outside of the warmup phase (or final reporting phase), unless you are testing class loading specifically (and in that case load only the test classes). Rule 2 is your first line of defense against such effects.


Rule 5: Be aware of deoptimization and recompilation effects. Do not take any code path for the first time in the timing phase, because the compiler may junk and recompile the code, based on an earlier optimistic assumption that the path was not going to be used at all. Rule 2 is your first line of defense against such effects.


Rule 6: Use appropriate tools to read the compiler's mind, and expect to be surprised by the code it produces. Inspect the code yourself before forming theories about what makes something faster or slower.


Rule 7: Reduce noise in your measurements. Run your benchmark on a quiet machine, and run it several times, discarding outliers. Use -Xbatch to serialize the compiler with the application, and consider setting -XX:CICompilerCount=1 to prevent the compiler from running in parallel with itself.


Rule 8: Use a library for your benchmark as it is probably more efficient and was already debugged for this sole purpose. Such as JMH, Caliper or Bill and Paul's Excellent UCSD Benchmarks for Java.  


I know this question has been marked as answered but I wanted to mention two libraries that enable us to write micro benchmarks


Caliper from Google


Getting started tutorials


JMH from OpenJDK


Getting started tutorials


Important things for Java benchmarks are:


I'm just in the process of blogging about the design of a benchmarking framework in .NET. I've got a couple of earlier posts which may be able to give you some ideas - not everything will be appropriate, of course, but some of it may be.


jmh is a recent addition to OpenJDK and has been written by some performance engineers from Oracle. Certainly worth having a look.


The jmh is a Java harness for building, running, and analysing nano/micro/macro benchmarks written in Java and other languages targetting the JVM.


Very interesting pieces of information buried in the sample tests comments.


See also:


Should the benchmark measure time/iteration or iterations/time, and why?


It depends on what you are trying to test.  If you are interested in latency, use time/iteration and if you are interested in throughput use iterations/time.


Make sure you somehow use results which are computed in benchmarked code. Otherwise your code can be optimized away.


If you are trying to compare two algorithms, do at least two benchmarks on each, alternating the order.  i.e.:


I have found some noticeable differences (5-10% sometimes) in the runtime of the same algorithm in different passes..


Also, make sure that n is very large, so that the runtime of each loop is at the very least 10 seconds or so.  The more iterations, the more significant figures in your benchmark time and the more reliable that data is.


There are many possible pitfalls for writing micro-benchmarks in Java.


First: You have to calculate with all sorts of events that take time more or less random: Garbage collection, caching effects (of OS for files and of CPU for memory), IO etc.


Second: You cannot trust the accuracy of the measured times for very short intervals.


Third: The JVM optimizes your code while executing. So different runs in the same JVM-instance will become faster and faster.


My recommendations: Make your benchmark run some seconds, that is more reliable than a runtime over milliseconds. Warm up the JVM (means running the benchmark at least once without measuring, that the JVM can run optimizations). And run your benchmark multiple times (maybe 5 times) and take the median-value. Run every micro-benchmark in a new JVM-instance (call for every benchmark new Java) otherwise optimization effects of the JVM can influence later running tests. Don't execute things, that aren't executed in the warmup-phase (as this could trigger class-load and recompilation).


It should also be noted that it might also be important to analyze the results of the micro benchmark when comparing different implementations. Therefore a significance test should be made.


This is because implementation A might be faster during most of the runs of the benchmark than implementation B. But A might also have a higher spread, so the measured performance benefit of A won't be of any significance when compared with B.


So it is also important to write and run a micro benchmark correctly, but also to analyze it correctly.


http://opt.sourceforge.net/ Java Micro Benchmark - control tasks required to determine the comparative performance characteristics of the computer system on different platforms. Can be used to guide optimization decisions and to compare different Java implementations.


To add to the other excellent advice, I'd also be mindful of the following:


For some CPUs (e.g. Intel Core i5 range with TurboBoost), the temperature (and number of cores currently being used, as well as thier utilisation percent) affects the clock speed. Since CPUs are dynamically clocked, this can affect your results. For example, if you have a single-threaded application, the maximum clock speed (with TurboBoost) is higher than for an application using all cores. This can therefore interfere with comparisons of single and multi-threaded performance on some systems. Bear in mind that the temperature and volatages also affect how long Turbo frequency is maintained.


Perhaps a more fundamentally important aspect that you have direct control over: make sure you're measuring the right thing! For example, if you're using System.nanoTime() to benchmark a particular bit of code, put the calls to the assignment in places that make sense to avoid measuring things which you aren't interested in. For example, don't do:


Problem is you're not immediately getting the end time when the code has finished. Instead, try the following:






I'm adding three different objects to an ArrayList, but the list contains three copies of the last object I added. 


For example:


Expected:


Actual:


What mistake have I made?


Note: this is designed to be a canonical Q&A for the numerous similar issues that arise on this site.


This problem has two typical causes:


Static fields used by the objects you stored in the list


Accidentally adding the same object to the list


If the objects in your list store data in static fields, each object in your list will appear to be the same because they hold the same values. Consider the class below:


In that example, there is only one int value which is shared between all instances of Foo because it is declared static. (See "Understanding Class Members" tutorial.)


If you add multiple Foo objects to a list using the code below, each instance will return 3 from a call to getValue():


The solution is simple - don't use the static keywords for fields in your class unless you actually want the values shared between every instance of that class.


If you add a temporary variable to a list, you must create a new instance each time you loop. Consider the following erroneous code snippet:


Here, the tmp object was constructed outside the loop. As a result, the same object instance is being added to the list three times. The instance will hold the value 2, because that was the value passed during the last call to setValue().


To fix this, just move the object construction inside the loop:


Your problem is with the type static which requires a new initialization every time a loop is iterated. If you are in a loop it is better to keep the concrete initialization inside the loop.


Instead of:


Here tag is a variable in SomeStaticClass to check the validity of the above snippet; you can have some other implementation based on your use case.


Every time you add an object to an ArrayList, make sure you add a new object and not already used object. What is happening is that when you add the same 1 copy of object, that same object is added to different positions in an ArrayList. And when you make change to one, because the same copy is added over and over again, all the copies get affected. 
For example,
Say you have an ArrayList like this:


Now if you add this Card c to list, it will be added no problem. It will be saved at location 0. But, when you save the same Card c in the list, it will be saved at location 1. So remember that you added same 1 object to two different locations in a list. Now if you make a change that Card object c, the objects in a list at location 0 and 1 will also reflect that change, because they are the same object. 


One solution would be to make a constructor in Card class, that accepts another Card object. Then in that constructor, you can set the properties like this:


And lets say you have the same 1 copy of Card, so at the time of adding a new object, you can do this:


Had the same trouble with the calendar instance.


Wrong code:


You have to create a NEW object of the calendar, which can be done with calendar.clone();






I downloaded Android Studio and attempted to launch the program.


This is running on Windows 7 64-bit with Java 1.7. During the installation my Java 1.7 is detected, and the rest of the installation goes through just fine. However, when attempting to launch the application from the desktop icon, nothing happens. Looking at the task manager, a new process from the CMD is loaded. This is because it's attempting to run the batch file studio.bat.


When I execute via CMD, I get the following error:


ERROR: cannot start Android Studio. No JDK found. Please validate
  either ANDROID_STUDIO_JDK, or JDK_HOME or JAVA_HOME points to valid
  JDK installation. ECHO is off. Press any key to continue . . .


I've attempted to open the idea properties file to see if there was something I could configure for this ANDROID_STUDIO_JDK or something like that. However, I found nothing. I hope some of you can let me know if you were able to install this or if you are having problems as well.


Adding a system variable JDK_HOME with value c:\Program Files\Java\jdk1.7.0_21\ worked for me. The latest Java release can be downloaded here.


Additionally, make sure the variable JAVA_HOME is also set with the above location. Steps are here. For Video


OK, I figured out how fix this nasty bug.


Go to your Android Studio installation folder and locate the bin folder. Inside the bin folder, you will find studio.bat. Execute the file, and it'll show the error. If it is about the Java path then follow the tip 1.


When you set the path JAVA_HOME, etc., make sure not to include bin at the end of the path. This solved the issue for me.


JAVA_HOME => C:\Program Files\Java\jdk1.7.0_21


path => C:\Program Files\Java\jdk1.7.0_21\bin


It works fine with JDK 1.7 (I tried with 32 bit).


If you do so, you can see the initial screen as below.





Are you getting the below error message?


Your Android SDK is out of date or is missing templates. Please ensure
  you are using SDK version 22 or later.


This error probably occurs, because you have reference to your older SDK (that you downloaded with Eclipse) in your path variable. Go to Environment variables and remove any reference to the old SDK folder and point it to new SDK folder that is found inside the Android Studio installation folder.


Save and restart Studio, things should work as expected now. 


If you hate messing around with the path variable as given above by removing old references, simply follow the following steps to refer to new SDK path that comes with Studio.


*Project Defaults* -> *Project Structure* -> Click "New" -> Select "Android SDK" -> Select the SDK folder inside the studio installation.


With the last update of Androd Studio I have two versions of the IDE's launcher


One is called studio.exe and the other studio64.exe they are both on:


You have to launch the one that matches your Java version 64 or 32 bit


I had the same issue. I got resolved setting up correctly the environment variables in windows, for instance:


I've tried so many of the answers here but none of them works, so I decided to mix some of the answers here and I am successful!





Step 1: Go to the system properties by right-clicking on My Computer or by pressing windows button on typing This PC and right clicking on it and selecting Properties.





Step 2: Click the advanced system settings or Environment Variables


Step 3: Take note that there are 2 different variable. What you need to create is system variables not user variables, when you clicked new type the following


Variable name: JAVA_HOME


Variable value: C:\Program Files\Java\jdk1.8.0_25\ (Note: Please check if the path is right, sometimes it is C:\Program Files (x86)\Java\jdk1.8.0_25)


Step 4: Run the android studio, no need to restart.


Note:


*C:\Program Files\Java\jdk1.8.0_25\ depends entirely on the installation path of your JDK not JRE so don't be confused if you see something like the picture below. Just enter the location of your jdk, in my case it is C:\Program Files\Java\jdk1.8.0_25\.


*Do not include the bin folder when you enter the Variable value.








Edit: For Windows 8 and 10 Users:  Try to run C:\Program Files\Android\Android Studio\bin\studio.exe instead of C:\Program Files\Android\Android Studio\binstudio64.exe


The path for latest JDK. It worked very well.





I had the same issue. I am having 64 bit windows 8. I downloaded the android studio which worked on 32 bit machine but not on my 64 bit.


The solution for me was pretty simple. I navigated to 


C:\Program Files (x86)\Android\android-studio\bin


there I saw 2 exe files studio.exe and studio64.exe. Normally in my start menu was pointing to studio64.exe which alwasys kept on giving me "The enviournmental variable JDK_HOME does not point to valid JVM". So then I clicked studio.exe and it worked :)


I hope this may help someone facing same problem like me


If you are getting message "Your Android SDK is out of date…" — click "Configure" —> "Project Defaults" —> "Project Structure", pick "SDKs" —> "Android SDK" and in a "Build Target" choose "Android 4.2.2". Click "OK". Now it should work fine.


I got the problem that the installation stopped by "$(^name) has stopped working" error. I have installed Java SE Development kit already, also set both SDK_HOME and JAVA_HOME that point to "C:\Program Files\Java\jdk1.7.0_21\" 


My laptop installed with Windows 7 64 bits


So I tried to install the 32 bit version of Java SE Developement kit, set my JAVA_HOME to "C:\Program Files (x86)\Java\jdk1.7.0_21", restart and the installation worked OK.


This problem has been fixed in Android Studio v0.1.1, so just update Android Studio and it should work.


Sometimes you can resolve this type of issue by setting environment variables so the process looks for the JDK in the right spot.


Another approach is to figure out where the process is looking, then put your JDK there.


I've had lots of success using Process Monitor from Sysinternals:


This will filter down to all the file system operations taking place on your machine.


You could try filtering based on the result of the File System operation:


You can also quite easily filter based on the process name, either from the Filter... menu option or by right clicking on the Process Name column and selecting Include 'process.exe'.


Once you find the file system operation that's failing, the Path column will tell you where to put your JDK.


I've found this to be very empowering. Especially compared to the frustrating process of changing environment variables by trial and error.


My issue was caused because I have an & character in my Windows user name, so when installed in the default path I was getting the following error after running bin/studio.bat


So I uninstalled and reinstalled it to program files and it launches fine now.


I couldn't get this to work no matter which environment variables I set. So I simply put a copy of the JDK into my Android Studio installation folder.


Copy the contents of the JDK installation (for example, C:\Program Files (x86)\Java\jdk1.7.0_21)


Paste them into the installation directory of the Android Studio (for example, C:\Program Files (x86)\Android\android-studio)


I somewhat assumed that the issue was caused by having the x64 version of the JDK installed. But what was especially confusing was the fact that I could start Android Studio just fine when I started the studio.bat as an Administrator (even though the environment variables were set for my personal user account).


studio.bat will look for several valid options when determining which JDK to use.


:: Locate a JDK installation directory which will be used to run the IDE.
:: Try (in order): ANDROID_STUDIO_JDK, ..\jre, JDK_HOME, JAVA_HOME.


As explained above, I picked the ..\jre option.


Today I found another situation when this problem occures - when you have several JDK, defined in JAVA_PATH. I have:


So I received this problem with Android Studio setup


But when I've removed one of JDK - problem has been solved:


Installation wisard found my jdk and i had a nice night to study studio. 


But unfortunatelly even installed studio doesn't work with several jdk.
Does anybody know how to fix it?


I hope I've helped someone


MAKE SURE YOU RESTART ANDROID STUDIO


Even though i should know better and swear i did, make sure you restart studio after making these changes as it clearly does not check them on every build (which to me makes sense that system/user variables should only be read once on startup)


Anyway, yea... Make sure you restart after you make these changes..


Path = to the bin folder in the jdk folder (path already exists)


JAVA_HOME = to the jdk folder


Windows 64 bit, JDK 64 bit (Solution that worked for me)
Tried all the above solutions, None of them worked, I have been trying to solve it from past few days and now i done it successfully.For me the problem was, when i first installed Android Studio my JDK version was 1.7, then after installing i updated the JDK to 1.8,then i removed old JDK folder and everything was messed up, even uninstalling and reinstalling android studio randomly didn't solved the issue.


Below is the solution that worked for me


1) Uninstall Android Studio.


2) clean temp files and android studio C:\Users\Username.AndroidStudio1.5


3) Uninstall JDK.


4) Now without JDK try to install Android Studio and now it will show 
message that it cant find any JDK. Stop installation


5) Install JDK 1.7 or 1.8 (Set JAVA_HOME,JDK_HOME,path Environment variables as explained by everybody above)


6) Install Android Studio.


7) Done. Enjoy and happy coding. 


In my experience, I was unable (even after adding JDK_HOME) to launch Studio via either the shortcut or studio.exe itself.  I had to first run bin/studio.bat (mentioned in the original question).  After the first successful launch, I'm able to start it by the shortcut.


Install the latest JDK in your system from JDK 7 and JRE 7 Installation Guide. 


If you have a 64 bit windows OS, pointing the JAVA_HOME system variable to


Will work when 


fails to work. 


You need 1.7 JDK installed on your system. Add a system variable with:


name: ANDROID_STUDIO_JDK


path: your JDK path (for example, C:\Program Files\Java\jdk1.7.0_21)


TRY TO INSTALL 32BIT JDK


if you have jdk installed and had set up the System Varibles such as JAVA_HOME or JDK_HOME
and tried click back and then next ,you might have installed the 64bit JDK,just download the 32bit jdk and install it.


I downloaded the latest jdk version


JAVA_HOME to C:\Program Files\Java\jdk1.8.0_11\bin
Set the PATH to C:\Program Files\Java\jdk1.8.0_11\bin


I restarted the STUDIO and it worked.


On Windows 10, restarting the installer and running as admin worked for me.


To complete this stack of possible solutions: For me the problem was, that I did not execute the Android-Studio-Setup as administrator. Running it as administrator then made me able to install Android-Studio.


For me, the problem was that I had changed the GC vm arg to -XX:+UseParallelGC in the C:\Users\<username>\.AndroidStudio2.1\studio64.exe.vmoptions file.  That's what I use in Eclipse and I was trying various things to get AndroidStudio half way as efficent as Eclipse.  I restored the GC to -XX:+UseConcMarkSweepGC.


The answer to the original question is that, might be you are opening android studio from 32 bit shortcut icon of android studio, try to open from icon "studio64" located under .../bin/ where android studio setup is install.






I'm developing an application which displays images, and plays sounds from a database. I'm trying to decide whether or not to use a separate JFrame to add images to the database from the GUI. 


I'm just wondering whether it is good practice to use multiple JFrame windows?


I'm just wondering whether it is good practice to use multiple JFrames?


Bad (bad, bad) practice.  


There are any number of ways of displaying many elements in one GUI, e.g.:


But if those strategies do not work for a particular use-case, try the following.  Establish a single main JFrame, then have JDialog or JOptionPane instances appear for the rest of the free-floating elements, using the frame as the parent for the dialogs.


In this case where the multiple elements are images, it would be better to use either of the following instead:





The multiple JFrame approach has been something I've implemented since I began programming Swing apps. For the most part, I did it in the beginning because I didn't know any better. However, as I matured in my experience and knowledge as a developer and as began to read and absorb the opinions of so many more experienced Java devs online, I made an attempt to shift away from the multiple JFrame approach (both in current projects and future projects) only to be met with... get this... resistance from my clients! As I began implementing modal dialogs to control "child" windows and JInternalFrames for separate components, my clients began to complain! I was quite surprised, as I was doing what I thought was best-practice! But, as they say, "A happy wife is a happy life." Same goes for your clients. Of course, I am a contractor so my end-users have direct access to me, the developer, which is obviously not a common scenario.


So, I'm going to explain the benefits of the multiple JFrame approach, as well as myth-bust some of the cons that others have presented.


I've written a lot and I feel like I could write more. Anyways, I hope I don't get down-voted simply because it's an unpopular opinion. The question is clearly a valuable one and I hope I've provided a valuable answer, even if it isn't the common opinion.


A great example of multiple frames/single document per frame (SDI) vs single frame/multiple documents per frame (MDI) is Microsoft Excel. Some of MDI benefits:


SDI (Single-Document Interface, i.e., every window can only have a single document):





MDI (Multiple-Document Interface, i.e., every window can have multiple documents):





I'd like to counter the "not user friendly" argument with an example that I have just been involved with.


In our application we have a main window where the users run various 'programs' as separate tabs. As much as possible we have tried to keep our application to this single window.


One of the 'programs' they run presents a list of reports that have been generated by the system, and the user can click on an icon on each line to pop open a report viewer dialog. This viewer is showing the equivalent of the portrait/landscape A4 page(s) of the report, so the users like this window to be quite big, almost filling their screens.


A few months ago we started getting requests from our customers to make these report viewer windows modeless, so that they could have multiple reports open at the same time.


For some time I resisted this request as I did not think this was a good solution. However, my mind was changed when I found out how the users were getting around this 'deficiency' of our system.


They were opening a viewer, using the 'Save As' facility to save the report as a PDF to a specific directory, using Acrobat Reader to open the PDF file, and then they would do the same with the next report. They would have multiple Acrobat Readers running with the various report outputs that they wanted to look at.


So I relented and made the viewer modeless. This means that each viewer has a task-bar icon.


When the latest version was released to them last week, the overwhelming response from them is that they LOVE it. It's been one of our most popular recent enhancements to the system.


So you go ahead and tell your users that what they want is bad, but ultimately it won't do you any favours.


SOME NOTES:


Make an jInternalFrame into main frame and make it invisible. Then you can use it for further events.


It's been a while since the last time i touch swing but in general is a bad practice to do this. Some of the main disadvantages that comes to mind: 


It's more expensive: you will have to allocate way more resources to draw a JFrame that other kind of window container, such as Dialog or JInternalFrame.


Not user friendly: It is not easy to navigate into a bunch of JFrame stuck together, it will look like your application is a set of applications inconsistent and poorly design.


It's easy to use JInternalFrame This is kind of retorical, now it's way easier and other people smarter ( or with more spare time) than us have already think through the Desktop and JInternalFrame pattern, so I would recommend to use it.


Bad practice definitely. One reason is that it is not very 'user-friendly' for the fact that every JFrame shows a new taskbar icon. Controlling multiple JFrames will have you ripping your hair out.


Personally, I would use ONE JFrame for your kind of application. Methods of displaying multiple things is up to you, there are many. Canvases, JInternalFrame, CardLayout, even JPanels possibly.


Multiple JFrame objects = Pain, trouble, and problems.


i think using multiple Jframes is not a good idea.


Instead we can use jpanels more than one or more jpanel in the same jframe.


also we can switch between this jpanels .so it give us freedom to display more than on thing in the jframe.


for each jpanel we can design different things and all this jpanel can be displayed on the single jframe one at a time.


To switch between this jpanels use menubar with menuitems for each jpanel or jbutton for each jpanel.


more than one jframe is not a good practice.but there is nothing wrong if we want more than one jframe.
but its better to change one jframe for our different needs rather than having multiple jframes.


If the frames are going to be the same size, why not create the frame and pass the frame then as a reference to it instead. 


When you have passed the frame you can then decide how to populate it. It would be like having a method for calculating the average of a set of figures. Would you create the method over and over again? 


It is not a good practice but even though you wish to use it you can use the singleton pattern as its good. I have used the singleton patterns in most of my project its good.






I have;


Is there a (easy) way to retrieve the generic type of the list?


If those are actually fields of a certain class, then you can get them with a little help of reflection:


You can also do that for parameter types and return type of methods.


But if they're inside the same scope of the class/method where you need to know about them, then there's no point of knowing them, because you already have declared them yourself.


Short answer: no.


This is probably a duplicate, can't find an appropriate one right now.


Java uses something called type erasure, which means at runtime both objects are equivalent. The compiler knows the lists contain integers or strings, and as such can maintain a type safe environment. This information is lost (on an object instance basis) at runtime, and the list only contain 'Objects'.


You CAN find out a little about the class, what types it might be parametrized by, but normally this is just anything that extends "Object", i.e. anything. If you define a type as


AClass.class will only contain the fact that the parameter A is bounded by MyClass, but more than that, there's no way to tell.


You can do the same for method parameters as well:


If you need to get the generic type of a returned type, I used this approach when I needed to find methods in a class which returned a Collection and then access their generic types:


This outputs:


Generic type is class java.lang.String


Expanding on Steve K's answer:


At runtime, no, you can't.


However via reflection the type parameters are accessible. Try


The method getGenericType() returns a Type object. In this case, it will be an instance of ParametrizedType, which in turn has methods getRawType() (which will contain List.class, in this case) and getActualTypeArguments(), which will return an array (in this case, of length one, containing either String.class or Integer.class).


The generic type of a collection should only matter if it actually has objects in it, right? So isn't it easier to just do:


There's no such thing as a generic type in runtime, but the objects inside at runtime are guaranteed to be the same type as the declared generic, so it's easy enough just to test the item's class before we process it.


For finding generic type of one field:


As others have said, the only correct answer is no, the type has been erased.


If the list has a non-zero number of elements, you could investigate the type of the first element ( using it's getClass method, for instance ). That won't tell you the generic type of the list, but it would be reasonable to assume that the generic type was some superclass of the types in the list.


I wouldn't advocate the approach, but in a bind it might be useful.


Generally impossible, because List<String> and List<Integer> share the same runtime class.


You might be able to reflect on the declared type of the field holding the list, though (if the declared type does not itself refer to a type parameter whose value you don't know).


The type is erased so you will not be able to. See http://en.wikipedia.org/wiki/Type_erasure and http://en.wikipedia.org/wiki/Generics_in_Java#Type_erasure


Had the same problem, but I used instanceof instead. Did it this way:


This involves using unchecked casts so only do this when you know it is a list, and what type it can be. 


Use Reflection to get the Field for these then you can just do: field.genericType to get the type that contains the information about generic as well.






Use of java.net.URLConnection is asked about pretty often here, and the Oracle tutorial is too concise about it. 


That tutorial basically only shows how to fire a GET request and read the response. It doesn't explain anywhere how to use it to among others perform a POST request, set request headers, read response headers, deal with cookies, submit a HTML form, upload a file, etc. 


So, how can I use java.net.URLConnection to fire and handle "advanced" HTTP requests?


First a disclaimer beforehand: the posted code snippets are all basic examples. You'll need to handle trivial IOExceptions and RuntimeExceptions like NullPointerException, ArrayIndexOutOfBoundsException and consorts yourself.


We first need to know at least the URL and the charset. The parameters are optional and depend on the functional requirements.


The query parameters must be in name=value format and be concatenated by &. You would normally also URL-encode the query parameters with the specified charset using URLEncoder#encode().


The String#format() is just for convenience. I prefer it when I would need the String concatenation operator + more than twice.


It's a trivial task. It's the default request method.


Any query string should be concatenated to the URL using ?. The Accept-Charset header may hint the server what encoding the parameters are in. If you don't send any query string, then you can leave the Accept-Charset header away. If you don't need to set any headers, then you can even use the URL#openStream() shortcut method.


Either way, if the other side is a HttpServlet, then its doGet() method will be called and the parameters will be available by HttpServletRequest#getParameter().


For testing purposes, you can print the response body to stdout as below:


Setting the URLConnection#setDoOutput() to true implicitly sets the request method to POST. The standard HTTP POST as web forms do is of type application/x-www-form-urlencoded wherein the query string is written to the request body.


Note: whenever you'd like to submit a HTML form programmatically, don't forget to take the name=value pairs of any <input type="hidden"> elements into the query string and of course also the name=value pair of the <input type="submit"> element which you'd like to "press" programmatically (because that's usually been used in the server side to distinguish if a button was pressed and if so, which one).


You can also cast the obtained URLConnection to HttpURLConnection and use its HttpURLConnection#setRequestMethod() instead. But if you're trying to use the connection for output you still need to set URLConnection#setDoOutput() to true.


Either way, if the other side is a HttpServlet, then its doPost() method will be called and the parameters will be available by HttpServletRequest#getParameter().


You can fire the HTTP request explicitly with URLConnection#connect(), but the request will automatically be fired on demand when you want to get any information about the HTTP response, such as the response body using URLConnection#getInputStream() and so on. The above examples does exactly that, so the connect() call is in fact superfluous.


HTTP response status:


You need a HttpURLConnection here. Cast it first if necessary.


HTTP response headers:


HTTP response encoding:


When the Content-Type contains a charset parameter, then the response body is likely text based and we'd like to process the response body with the server-side specified character encoding then.


The server side session is usually backed by a cookie. Some web forms require that you're logged in and/or are tracked by a session. You can use the CookieHandler API to maintain cookies. You need to prepare a CookieManager with a CookiePolicy of ACCEPT_ALL before sending all HTTP requests.


Note that this is known to not always work properly in all circumstances. If it fails for you, then best is to manually gather and set the cookie headers. You basically need to grab all Set-Cookie headers from the response of the login or the first GET request and then pass this through the subsequent requests.


The split(";", 2)[0] is there to get rid of cookie attributes which are irrelevant for the server side like expires, path, etc. Alternatively, you could also use cookie.substring(0, cookie.indexOf(';')) instead of split().


The HttpURLConnection will by default buffer the entire request body before actually sending it, regardless of whether you've set a fixed content length yourself using connection.setRequestProperty("Content-Length", contentLength);. This may cause OutOfMemoryExceptions whenever you concurrently send large POST requests (e.g. uploading files). To avoid this, you would like to set the HttpURLConnection#setFixedLengthStreamingMode().


But if the content length is really not known beforehand, then you can make use of chunked streaming mode by setting the HttpURLConnection#setChunkedStreamingMode() accordingly. This will set the HTTP Transfer-Encoding header to chunked which will force the request body being sent in chunks. The below example will send the body in chunks of 1KB.


It can happen that a request returns an unexpected response, while it works fine with a real web browser. The server side is probably blocking requests based on the User-Agent request header. The URLConnection will by default set it to Java/1.6.0_19 where the last part is obviously the JRE version. You can override this as follows:


Use the User-Agent string from a recent browser.


If the HTTP response code is 4nn (Client Error) or 5nn (Server Error), then you may want to read the HttpURLConnection#getErrorStream() to see if the server has sent any useful error information.


If the HTTP response code is -1, then something went wrong with connection and response handling. The HttpURLConnection implementation is in older JREs somewhat buggy with keeping connections alive. You may want to turn it off by setting the http.keepAlive system property to false. You can do this programmatically in the beginning of your application by:


You'd normally use multipart/form-data encoding for mixed POST content (binary and character data). The encoding is in more detail described in RFC2388.


If the other side is a HttpServlet, then its doPost() method will be called and the parts will be available by HttpServletRequest#getPart() (note, thus not getParameter() and so on!). The getPart() method is however relatively new, it's introduced in Servlet 3.0 (Glassfish 3, Tomcat 7, etc). Prior to Servlet 3.0, your best choice is using Apache Commons FileUpload to parse a multipart/form-data request. Also see this answer for examples of both the FileUpload and the Servelt 3.0 approaches.


Sometimes you need to connect a HTTPS URL, perhaps because you're writing a web scraper. In that case, you may likely face a javax.net.ssl.SSLException: Not trusted server certificate on some HTTPS sites who doesn't keep their SSL certificates up to date, or a java.security.cert.CertificateException: No subject alternative DNS name matching [hostname] found or javax.net.ssl.SSLProtocolException: handshake alert: unrecognized_name on some misconfigured HTTPS sites.


The following one-time-run static initializer in your web scraper class should make HttpsURLConnection more lenient as to those HTTPS sites and thus not throw those exceptions anymore.


The Apache HttpComponents HttpClient is much more convenient in this all :)


If all you want is parsing and extracting data from HTML, then better use a HTML parser like Jsoup


When working with HTTP it's almost always more useful to refer to HttpURLConnection rather than the base class URLConnection (since URLConnection is an abstract class when you ask for URLConnection.openConnection() on a HTTP URL that's what you'll get back anyway).


Then you can instead of relying on URLConnection#setDoOutput(true) to implicitly set the request method to POST instead do httpURLConnection.setRequestMethod("POST") which some might find more natural (and which also allows you to specify other request methods such as PUT, DELETE, ...).


It also provides useful HTTP constants so you can do:


Inspired by this and other questions on SO, I've created a minimal open source basic-http-client that embodies most of the techniques found here.


google-http-java-client is also a great open source resource.


There are 2 options you can go with HTTP URL Hits : GET / POST


GET Request :-


POST request :-


I was also very inspired by this response.


I am often on projects where I need to do some HTTP, and I may not want to bring in a lot of 3rd party dependencies (which bring in others and so on and so on, etc.)


I started to write my own utilities based on some of this conversation (not any where done):


Then there are just a bunch or static methods.


Then post...


Well you get the idea....


Here are the tests:


You can find the rest here:


https://github.com/RichardHightower/boon


My goal is to provide the common things one would want to do in a bit more easier way then....


I suggest you take a look at the code on kevinsawicki/http-request, its basically a wrapper on top of HttpUrlConnection it provides a much simpler API in case you just want to make the requests right now or you can take a look at the sources (it's not too big) to take a look at how connections are handled.


Example: Make a GET request with content type application/json and some query parameters:


Initially I was misled by this article which favours HttpClient. 


Later I have been realized that HttpURLConnection is going to stay from this article


As per the Google blog:


Apache HTTP client has fewer bugs on Eclair and Froyo. It is the best choice for these releases. For Gingerbread , HttpURLConnection is the best choice. Its simple API and small size makes it great fit for Android.


Transparent compression and response caching reduce network use, improve speed and save battery. New applications should use HttpURLConnection; it is where we will be spending our energy going forward.


After reading this article and some other stack over flow questions, I am convinced that HttpURLConnection is going to stay for longer durations.


Some of the SE questions favouring HttpURLConnections:


On Android, make a POST request with URL Encoded Form data without using UrlEncodedFormEntity


HttpPost works in Java project, not in Android


You can also use JdkRequest from jcabi-http (I'm a developer), which does all this work for you, decorating HttpURLConnection, firing HTTP requests and parsing responses, for example:


Check this blog post for more info: http://www.yegor256.com/2014/04/11/jcabi-http-intro.html


In Java 9, you can send a GET request like:


Then you can examine the returned HttpResponse:


Since this new HTTP Client is in java.httpclient module, you should declare this dependency in your module-info.java file:


There is also OkHttp, which is an HTTP client that’s efficient by default:


First create an instance of OkHttpClient:


Then, prepare your GET request:


finally, use OkHttpClient to send prepared Request:


For more details, you can consult the OkHttp's documentation


if you are using http get please remove this line
 urlConnection.setDoOutput(true);


I recomend http-request built on apache http api. (I'm a developer)


Perform HTTP GET request


or


Perform HTTP POST request


Replace HttpRequestBuilder.createGet to HttpRequestBuilder.createPost


Add headers


Convert response to type


let's say response is JSON and you know it


{"name":"myname","lastname":"mylastname","age":25}


You must create class User:


Note: You don't need to worry about Exceptions. All exceptions is wrapped.






This question already has an answer here:


I'm currently working on a simple game in Java with several different modes. I've extended a main Game class to put the main logic within the other classes. Despite this, the main game class is still pretty hefty.


After taking a quick look at my code the majority of it was Getters and Setters (60%) compared to the rest that is truly needed for the logic of the game.


A couple of Google searches have claimed that Getters and Setters are evil, whilst others have claimed that they are necessary for good OO practice and great programs.


So what should I do? Which should it be? Should I be changing my Getters and Setters for my private variables, or should I stick with them?


There is also the point of view that most of the time, using setters still breaks encapsulation by allowing you to set values that are meaningless. As a very obvious example, if you have a score counter on the game that only ever goes up, instead of


it should be


This is perhaps a bit of a facile example. What I'm trying to say is that discussing getter/setters vs public fields often obscures bigger problems with objects manipulating each others' internal state in an intimate manner and hence being too closely coupled.


The idea is to make methods that directly do things you want to do. An example would be how to set enemies' "alive" status. You might be tempted to have a setAlive(boolean alive) method. Instead you should have:


The reason for this is that if you change the implementation that things no longer have an "alive" boolean but rather a "hit points" value, you can change that around without breaking the contract of the two methods you wrote earlier:


It really depends on the situation though - sometimes you really do just want a dumb data object.


You've already had a lot of good answers on this, so I'll just give my two cents. Getters and setters are very, very evil. They essentially let you pretend to hide your object's internals when most of the time all you've done is tossed in redundant code that does nothing to hide internal state. For a simple POJO, there's no reason why getName() and setName() can't be replaced with obj.name = "Tom". 


If the method call merely replaces assignment, then all you've gained by preferring the method call is code bloat. Unfortunately, the language has enshrined the use of getters and setters in the JavaBeans specification, so Java programmers are forced to use them, even when doing so makes no sense whatsoever. 


Fortunately, Eclipse (and probably other IDEs as well) lets you automatically generate them. And for a fun project, I once built a code-generator for them in XSLT. But if there's one thing I'd get rid of in Java, its the over-dependence on getters and setters.


Getters and setters enforce the concept of encapsulation in object-oriented programming.


By having the states of the object hidden from the outside world, the object is truly in charge of itself, and cannot be altered in ways that aren't intended. The only ways the object can be manipulated are through exposed public methods, such as getters and setters.


There are a few advantages for having getters and setters:


1. Allowing future changes without modification to code that uses the modified class.


One of the big advantage of using a getter and setter is that once the public methods are defined and there comes a time when the underlying implementation needs to be changed (e.g. finding a bug that needs to be fixed, using a different algorithm for improving performance, etc.), by having the getters and setters be the only way to manipulate the object, it will allow existing code to not break, and work as expected even after the change.


For example, let's say there's a setValue method which sets the value private variable in an object:


But then, there was a new requirement which needed to keep track of the number of times value was changed. With the setter in place, the change is fairly trivial:


If the value field were public, there is no easy way to come back later and add a counter that keeps track of the number of times the value was changed. Therefore, having getters and setters are one way to "future-proof" the class for changes which may come later.


2. Enforcing the means by which the object can be manipulated.


Another way getters and setters come in handy is to enforce the ways the object can be manipulated, therefore, the object is in control of its own state. With public variables of an object exposed, it can easily be corrupted.


For example, an ImmutableArray object contains an int array called myArray. If the array were a public field, it just won't be immutable:


To implement a truly immutable array, a getter for the array (getArray method) should be written so it returns a copy of its array:


And even if the following occurs:


The ImmutableArray is indeed immutable. Exposing the variables of an object will allow it to be manipulated in ways which aren't intended, but only exposing certain ways (getters and setters), the object can be manipulated in intended ways.


I suppose having getters and setters would be more important for classes which are part of an API that is going to be used by others, as it allows keeping the API intact and unchanged while allowing changes in the underlying implementation.


With all the advantages of getters and setters said, if the getter is merely returning the value of the private variable and the setter is merely accepting a value and assigning it to a private variable, it seems the getters and setter are just extraneous and really a waste. If the class is going to be just for internal use by an application that is not going to be used by others, using getters and setters extensively may not be as important as when writing a public API.


They absolutely are evil.


@coobird unfortunately they absolutely do not "enforce the concept of encapsulation", all they do is make you think you're encapsulating data when in fact you're exposing data via a property with delusions of method grandeur. Anything a getter/setter does a public field does better.


First, if you want public data, make it public, get rid of the getter & setter methods to reduce the number of methods the client has to wade through and make it cognitively simpler for the client to change it's value by eg.


instead of the more cognitively intense


where the client must now check the getter/setter method to see if it has any side-effects.


Second, if you really need to do something else in the method, why call it a get/set method when it's got more responsibilities than simply getting or setting?
Either follow the SRP or call the method something that actually tells you what the whole method does like Zarkonnen's examples he mentioned eg.


instead of


where does the setAlive(boolean) method tell the client that as a side-effect it'll remove the object from the world? Why should the client have any knowledge about the isAlive field? Plus what happens when the object is re-added to the world, should it be re-initialised? why would the client care about any of that?


IMHO the moral is to name methods to say exactly what they do, follow the SRP and get rid of getters/setters.
If there's problems without getters/setters, tell objects to do their own dirty work inside their own class instead of trying to do things with them in other classes.


here endeth my rant, sorry about that ;)


It's a slippery slope.


A simple Transfer object (or Parameter object) may have the sole purpose of holding some fields and providing their values on demand. However, even in that degenerate case one could argue that the object should be immutable -- configured in the constructor and exposing only get... methods.


There's also the case of a class that exposes some "control knobs"; your car radio's UI probably can be understood as exposing something like getVolume, setVolume, getChannel, and setChannel, but its real functionality is receiving signals and emitting sound. But those knobs don't expose much implementation detail; you don't know from those interface features whether the radio is transistors, mostly-software, or vacuum tubes.


The more you begin to think of an object as an active participant in a problem-domain task, the more you'll think in terms of asking it to do something instead of asking it to tell you about its internal state, or asking it for its data so other code can do something with those values.


So... "evil"? Not really. But every time you're inclined to put in a value and expose both get... and set... methods on that value, ask yourself why, and what that object's reponsibility really is. If the only answer you can give yourself is, "To hold this value for me", then maybe something besides OO is going on here.


Your Game class is probably following the god object antipattern if it exposes that many variables. There's nothing wrong with getters and setters (though their verbosity in Java can be a bit annoying); in a well-designed app where each class has a clearly separated functionality, you will not need dozens of them in a single class.


Edit: If the main point for the getters and setters is to "configure" the game classe (I understand your comment that way), then your probably don't need the getters (it's perfectly fine for a class to access its own private variables without using get methods), and you can probably collapse many of the setters into "group setters" that set several variables which belong together conceptually.


My opinion is that getters and setters are a requirement for good programs. Stick with them, but don't write unnecessary getters/setters - it's not always necessary to directly deal with all variables.


The presence of getter and setters tends to indicate (a "smell" if you are into that sort of primary school language) that there is a design problem. Trivial getters and setters are barely distinguishable from public fields. Typically the code operating on the data will be in a different class - poor encapsulation, and what you would expect from programmers not at ease with OO.


In some cases getters and setters are fine. But as a rule a type with both getters and setters indicates design problems. Getters work for immutability; setters work for "tell don't ask". Both immutability and "tell don't ask" are good design choices, so long as they are not applied in an overlapping style.


I don't really think they are evil.  But I would love to live in a world where I never had to use them unless I really needed to.


One example I read above was future-proofing your code.  For example:


Then, the requirements change and you need to track how many times the value was set.


So:


This is beautiful.  I get it.  However, in Ruby, would the following not serve the same purpose?


Later, you need to track the number of times my_value was set.  Well then, could you not just override the setter THEN and only THEN?


I'm all for beautiful code but I have to admit, looking through the mountains of Java classes we have and seeing literally thousands and thousands of lines of code that are NOTHING but basic getter/setters is ugly and annoying.


When I was developing in C# full time, we used public properties all the time and did custom getters/setters only when needed.  Worked like a charm and it didn't break anything.


As always the only answer is: it depends. If you are the only peron touching the code, you can do anything you're comfortable with, including taking shortcuts.


One of the benefits of using setters is that checks need to be performed at only one location in your code.


You might want to pay some closer attention to what is actually being get and set by these methods. If you're using them to provide access to constant values you are probably better off by using constants.


This depends on the programming language in question. Your question is framed in the context of Java, where it seems that getters and setters are generally thought of as a good thing. 


In contrast, in the Python world, they are generally considered as bad style: they add lines to the code without actually adding functionality. When Python programmers need to, they can use metaprogramming to catch getting and/or setting of object attributes. 


In Java (at least the version of Java I learned slightly a decade ago), that was not possible. Thus, in Java it is usually best to use getters and setters religiously, so that if you need to, you can override access to the variables.


(This doesn't make Python necessarily better than Java, just different.)


Just FYI: In addition to all the excellent answers in this thread, remember that of all reasons you can come up with for or against getters/setters, performance isn't one (as some might believe). The JVM is smart enough to inline trivial getters/setters (even non-final ones, as long as they aren't actually overridden).


You may want to replace some of your classes by value classes. This will allow you to remove the getter and avoid problems when the content is changed from under you.


If you need external access to individual values of fields, use getters and/ or setters. If not, don't. Never use public fields. It's as simple as that! (Ok, it's never that simple, but it's a good rule of thumb).


In general you should also find that you need to supply a setter much less often than a getter - especially if you are trying to make your objects immutable - which is a Good Thing (but not always the best choice) - but even if not.


I've been programming in java for few monts ago, and I've learned that we should use getters & setters only when it's necessary for the application


have fun :)






I am developing an application, and everytime I run it, I get the message:


Unfortunately, MyApp has stopped.


What can I do to solve this?


About this question - obviously inspired by What is a stack trace, and how can I use it to debug my application errors?, there are lots of questions stating that their application has crashed, without any further detail. This question aims to instruct novice Android programmers on how to try and fix their problems themselves, or ask the right questions.


This answer describes the process of retrieving the stack trace. Already have the stack trace? Read up on stack traces in "What is a stack trace, and how can I use it to debug my application errors?"


Your application quit because an uncaught RuntimeException was thrown.
The most common of these is the NullPointerException.


Every time an Android application crashes (or any Java application for that matter), a Stack trace is written to the console (in this case, logcat). This stack trace contains vital information for solving your problem.





In the bottom bar of the window, click on the Android button. Alternatively, you can press alt+6. Make sure your emulator or device is selected in the Devices panel. Next, try to find the stack trace, which is shown in red. There may be a lot of stuff logged into logcat, so you may need to scroll a bit. An easy way to find the stack trace is to clear the logcat (using the recycle bin on the right), and let the app crash again.





In the top right corner, click the DDMS button. If it is not there, you might need to add it first using the Open Perspective button to the left of the Java button. You will find the logcat pane at the bottom. First, make sure your device is selected in the topleft devices panel. Next, try to find the stack trace, which is shown in red. Again, there may be a lot of stuff logged into logcat, so you may need to scroll a bit. An easy way to find the stack trace here is to clear the logcat (using the clear log button on the top right), and let the app crash again. You should also click on the package name of your app, if it is not already selected. This will filter out only the log message made by your app.


Yay! You're halfway to solving your problem.
You only need to find out what exactly made your application crash, by analyzing the stack trace.


Read up on stack traces in "What is a stack trace, and how can I use it to debug my application errors?"


If you've found your Exception and the line where it occurred, and still cannot figure out how to fix it, don't hesitate to ask a question on StackOverflow.  


Try to be as concise as possible: post the stack trace, and the relevant code (e.g. a few lines up to the line which threw the Exception).


You can use Google's ADB tool to get Logcat file to analyze the issue.


open logcat.txt file and search for your application name. There should be information on why it failed, the line number ,Class name etc.


Just check the error in log cat. 


You get the log cat option from in eclipse:


window->show view->others->Android->Logcat


Log cat contains error.


Other wise you can also check the error by executing an application in debug mode.
Firstly set breakpoint after that by doing:


right click on project->debug as->Android application


First you check which point your app has crashed (Unfortunately, MyApp has stopped.). For this you can use Log.e("TAG","Message");, using this line you can see you app log in logcat.


After that you find which point your app has stopped its very easy to solve at your side. 


Note: This answer is using Android Studio 2.2.2


You can use any of these tools:


adb logcat


adb logcat > logs.txt (you can use editors to open and search errors.)


eclipse logcat (If not visible in eclipse, Go to Windows->Show View->Others->Android->LogCat)





I suggest to use Android Debug Monitor, it is good. Because eclipse hangs when too many logs are there, and through adb logcat filter and all difficult.


This popup shows only when you get a fatal exception in your code which stops the execution of the app. It could be any exception NullPointerException, OutOfMemoryException etc.


Best way to check is through Logcat if you are still developing the app in Android studio which is quick way to read stack trace and check the cause of the app.


If your app is already live, then you can not use logcat. So, for that you can implement Crashlytics to provide you bug reports of any exception that occurs.


Check your Logcat message and see your Manifest file. There should be something missing like defining the Activity,User permission`, etc.


You have to check the Stack trace


How to do that?


on Your IDE Check the windows form LOGCAT 


If you cant see the logcat windows go to this path and open it 


if you are using Google-Api go to this path 


adb logcat > logcat.txt


Use the LogCat and try to find what is causing the app to crash.


To see Logcat if you use Android Studio then Press ALT + 6
or


if you use Eclipse then 
Window -> Open Perspective -> Other - LogCat 


Go to the LogCat, from the drop down menu select error. This will contain all the required information to help you debug. If that doesn't help, post the LogCat as an edit to your question and somebody will help you out.


Let me share a basic Logcat analysis for when you meet a Force Close (when app stops working).


DOCS


Basic tool from Android to collect/analyse logs is the logcat. 


HERE is the Android's page about logcat


If you use android Studio, you can also check this LINK.


Capturing


Basically, you can MANUALLY capture logcat with following command (or just check AndroidMonitor window in AndroidStudio):


There's a lot of parameters you can add to command which helps you to filter and display the message that you want... This is personal...  I always use the command below to get the message timestamp:


You can redirect the output to a file and analyze it in a Text Editor.


Analyzing


If you app is Crashing, you'll get something like:


This part of the log shows you a lot of information:


It is important to check when the issue happened... You may find several errors in a log... you must be sure that you are checking the proper messages :)


This way, you know which app crashed (to be sure that you are checking the logs about your message)


A NULL Pointer Exception error


You tried to call method onBackPressed() from a FragmentActivity object. However, that object was null when you did it.


Stack Trace: Stack Trace shows you the method invocation order... Sometimes, the error happens in the calling method (and not in the called method).


at com.example.khan.abc.AudioFragment$1.onClick(AudioFragment.java:125)


Error happened in file com.example.khan.abc.AudioFragment.java, inside onClick() method at line: 125 (stacktrace shows the line that error happened)


It was called by:


Which was called by:


which was called by:


etc....


Overview


This was just an overview... Not all logs are simple etc... It is just to share the idea and provide a entry-level information to you... 


I hope I could help you someway...
Regards


In below showToast() method you have to pass another parameter for context or application context by doing so you can try it.


You can also get this error message on its own, without any stack trace or any further error message.


In this case you need to make sure your Android manifest is configured correctly (including any manifest merging happening from a library and any activity that would come from a library), and pay particular attention to the first activity displayed in your application in your manifest files.


If your app for some reason crashes without good stacktrace. Try debug it from first line, and go line by line until crash. Then you will have answer, which line is causing you trouble. Proably you could then wrapp it into try catch block and print error output.


Alternative Solution for Handling Unfortunately App crash.


We get this message whenever our App forced closed by any exceptions that is not handled in android or in our application.


So we just need to take care of it when we are writing the code that will save a lots of time in tracking any type of exceptions in android.


Steps to track the exceptions in App :- 


1.Open the Logcat and view the Exception.


If you cant see the logcat windows go to this path and open it


We Use the LogCat and try to find, what is causing the app to crash.


2. Try to handle the exception which is shown in the logcat, and also check the other case's which may cause the exception .


3. Add an Uncaught Exception Handler in your Application to haldle all other exception . 


I).Create a class MyExceptionHandler which implementsThread.UncaughtExceptionHandler 


}


II).Handle exception in any class or activity or fragment.


It will restart the same Activity again if the app got crashed.






Is it possible in Hibernate to print generated SQL queries with real values instead of question marks?


How would you suggest to print queries with real values if it is not possible with Hibernate API?


You need to enable logging for the the following categories:


So a log4j configuration could look like:


The first is equivalent to hibernate.show_sql=true legacy property, the second prints the bound parameters among other things.


Another solution (non hibernate based) would be to use a JDBC proxy driver like P6Spy.


Just for convenience, here is the same configuration example for Logback (SLF4J)


The output in your sql.log (example) then looks like this:


Change hibernate.cfg.xml to:


Include log4j and below entries in "log4j.properties":


Log4JDBC is a nice solution which prints the exact SQL going to the database with parameters in place rather than the most popular answer here which does not do this. One major convenience of this is that you can copy the SQL straight to your DB front-end and execute as is.


http://log4jdbc.sourceforge.net/


https://code.google.com/p/log4jdbc-remix/


The latter also outputs a tabular representation of query results.


Sample Output showing generated SQL with params in place together with result set table from query:


Most recently I have now been using log4jdbc-log4j2 (https://code.google.com/archive/p/log4jdbc-log4j2/ ) with SLF4j and logback. Maven dependencies required for my set-up are as below:


The Driver and DB Urls then look like:


My logback.xml configuration file looks like the below: this outputs all SQL statements with parameters plus the resultset tables for all queries.


Finally, I had to create a file named log4jdbc.log4j2.properties at the root of the classpath e.g. src/test/resources or src/main/resources in a Mevn project.  This file has one line which is the below:


The above will depend on your logging library. See the docs at https://code.google.com/archive/p/log4jdbc-log4j2 for further info


Sample Output:


You can add category lines to log4j.xml:


and add hibernate properties: 


turn on the org.hibernate.type Logger to see how the actual parameters are bind to the question marks.


In case of spring boot is being used , just config this :


aplication.yml


aplication.properties


and nothing more.


HTH


You can do it using the datasource-proxy, as I described in this post.


Assuming your application expects a dataSource bean (e.g. via @Resource), this is how you can configure datasource-proxy:


Now the Hibernate output vs datasource-proxy:


The datasource-proxy queries contain parameter values and you can even add custom JDBC statement interceptors so that you can catch N+1 query issues right from your integration tests.


add following properties and values to your log4j or logback configuration:


This answer is a little variance for the question.
Sometimes, we only need the sql only for debug purposes in runtime.
In that case, there are a more easy way, using debug on editors.


This is for hibernate 3. I'm not sure that this work on other versions.


The solution is correct but logs also all bindings for the result objects.
To prevent this it's possibile to create a separate appender and enable filtering, for example:


I like this for log4j:












Using Hibernate 4 and slf4j/log4j2 , I tried adding the following in my log4j2.xml configuration :


But without success.


I found out through this thread that the jboss-logging framework used by hibernate needed to be configured in order to log through slf4j. I added the following argument to the VM arguments of the application:


And it worked like a charm.


if you are using hibernate 3.2.xx
use 


instead of 


You can log this:


Output example:


Log4Jdbc plugin would be best for your requirement. It shows following-


Refer below link to configure Log4Jdbc-


Logging works but not exactly you want or i wanted some time ago, but P6Spy does work perfectly, 


here is the simple tutorial to implement as well MKYONG tutorial for P6Spy.


for me it worked like charm.


Get the “p6spy-install.jar“


Extract the p6spy-install.jar file, look for p6spy.jar and spy.properties


Add p6spy.jar into your project library dependency


Modify your database configuration file. You need to replace your existing JDBC driver with P6Spy JDBC driver – com.p6spy.engine.spy.P6SpyDriver


Original is MySQL JDBC driver – com.mysql.jdbc.Driver


Changed it to P6Spy JDBC driver – com.p6spy.engine.spy.P6SpyDriver


Replace the real driver with your existing MySQL JDBC driver


Change the Log file location
Change the log file location in logfile property, all SQL statements will log into this file.


Windows


*nix


Copy “spy.properties” to your project root folder, make sure your project can locate “spy.properties”, else it will prompt “spy.properties” file not found exception.


Use Wireshark or something similar:


None of the above mentioned answers will print sql with parameters properly or is a pain. I achieved this by using WireShark, which captures all sql/commands being send from the application to Oracle/Mysql etc with the queries.












All of the answers here are helpful, but if you're using a Spring application context XML to setup your session factory, setting the log4j SQL level variable only gets you part of the way there, you also have to set the hibernate.show_sql variable in the app context itself to get Hibernate to start actually showing the values.


ApplicationContext.xml has:


And your log4j file needs


mysql jdbc driver has already provide a convenient to meet this requirement, you must at least the have the jar version >= mysql-connect-jar-5.1.6.jar


step 1: [configure your jdbc.url to add logger and custom logging]


now, it is using slf4j logging, if your default logging is log4j, you must add slf4j-api, slf4j-log4j12 dependencies to use slf4j logging


step 2: [write your custom logging]


Here is what worked for me, set below property in the log4j.file:


Hibernate properties settings :






I need to append text repeatedly to an existing file in Java. How do I do that?


Are you doing this for logging purposes?  If so there are several libraries for this. Two of the most popular are Log4j and Logback.


If you just need to do this one time, the Files class makes this easy:


Careful: The above approach will throw a NoSuchFileException if the file does not already exist. It also does not append a newline automatically (which you often want when appending to a text file). Steve Chambers's answer covers how you could do this with Files class.


However, if you will be writing to the same file many times, the above has to open and close the file on the disk many times, which is a slow operation. In this case, a buffered writer is better:


Notes:


If you need robust exception handling for older Java, it gets very verbose:


You can use fileWriter with a flag set to true , for appending.


Shouldn't all of the answers here with try/catch blocks have the .close() pieces contained in a finally block?


Example for marked answer:


Also, as of Java 7, you can use a try-with-resources statement. No finally block is required for closing the declared resource(s) because it is handled automatically, and is also less verbose:


Edit - as of Apache Commons 2.1, the correct way to do it is:


I adapted @Kip's solution to include properly closing the file on finally:





It's a bit alarming how many of these answers leave the file handle open in case of an error. The answer https://stackoverflow.com/a/15053443/2498188 is on the money but only because BufferedWriter() cannot throw. If it could then an exception would leave the FileWriter object open. 


A more general way of doing this that doesn't care if BufferedWriter() can throw:


As of Java 7, the recommended way is to use "try with resources" and let the JVM deal with it:


In Java-7 it also can be done such kind:


//---------------------


Sample, using Guava:


This can be done in one line of code. Hope this helps :)


I just add small detail:


2.nd parameter (true) is a feature (or, interface) called appendable (http://docs.oracle.com/javase/7/docs/api/java/lang/Appendable.html). It is responsible for being able to add some content to the end of particular file/stream. This interface is implemented since Java 1.5. Each object (i.e. BufferedWriter, CharArrayWriter, CharBuffer, FileWriter, FilterWriter, LogStream, OutputStreamWriter, PipedWriter, PrintStream, PrintWriter, StringBuffer, StringBuilder, StringWriter, Writer) with this interface can be used for adding content


In other words, you can add some content to your gzipped file, or some http process


Using java.nio.Files along with java.nio.file.StandardOpenOption


This creates a BufferedWriter using Files, which accepts StandardOpenOption parameters, and an auto-flushing PrintWriter from the resultant BufferedWriter. PrintWriter's println() method, can then be called to write to the file.


The StandardOpenOption parameters used in this code: opens the file for writing, only appends to the file, and creates the file if it does not exist.


Paths.get("path here") can be replaced with new File("path here").toPath().
And Charset.forName("charset name") can be modified to accommodate the desired Charset.


Try with bufferFileWriter.append, it works with me.


To slightly expand on Kip's answer,
here is a simple Java 7+ method to append a new line to a file, creating it if it doesn't already exist:


Note: The above uses the Files.write overload that writes lines of text to a file (i.e. similar to a println command). To just write text to the end (i.e. similar to a print command), an alternative Files.write overload can be used, passing in a byte array (e.g. "mytext".getBytes(StandardCharsets.UTF_8)).


this will do what you intend for..


If we are using Java 7 and above and also know the content to be added (appended) to the file we can make use of newBufferedWriter method in NIO package.


There are few points to note:


Though OP has not asked but just in case we want to search for lines having some specific keyword e.g. confidential we can make use of stream APIs in Java:


Then catch an IOException somewhere upstream.


Create a function anywhere in your project and simply call that function where ever you need it.


Guys you got to remember that you guys are calling active threads that you are not calling asynchronously and since it would likely be a good 5 to 10 pages to get it done right.
Why not spend more time on your project and forget about writing anything already written.
Properly


three lines of code two really since the third actually appends text. :P


Library


Code


You can also try this :


Better to use try-with-resources then all that pre-java 7 finally business


This code will fulifil your need:


the true allows to append the data in the existing file. If we will write


It will overwrite the existing file. So go for first approach.


I might suggest the apache commons project. This project already provides a framework for doing what you need (i.e. flexible filtering of collections). 


The following method let's you append text to some file:


Alternatively using FileUtils:


It is not efficient but works fine. Line breaks are handled correctly and a new file is created if one didn't exist yet.


My answer:


In case you want to ADD SOME TEXT IN SPECIFIC LINES you can first read the whole file, append the text wherever you want and then overwrite everything like in the code below:


You can use the follong code to append the content in the file:






I've been using the == operator in my program to compare all my strings so far.
However, I ran into a bug, changed one of them into .equals() instead, and it fixed the bug.


Is == bad? When should it and should it not be used? What's the difference?


== tests for reference equality (whether they are the same object).


.equals() tests for value equality (whether they are logically "equal"). 


Objects.equals() checks for nulls before calling .equals() so you don't have to (available as of JDK7, also available in Guava).


Consequently, if you want to test whether two strings have the same value you will probably want to use Objects.equals().


You almost always want to useObjects.equals(). In the rare situation where you know you're dealing with interned strings, you can use ==.


From JLS 3.10.5. String Literals:


Moreover, a string literal always refers to the same instance of class String. This is because string literals - or, more generally, strings that are the values of constant expressions (§15.28) - are "interned" so as to share unique instances, using the method String.intern.


Similar examples can also be found in JLS 3.10.5-1.


== tests object references, .equals() tests the string values.  


Sometimes it looks as if == compares values, because Java does some behind-the-scenes stuff to make sure identical in-line strings are actually the same object.


For example:  


But beware of nulls! 


== handles null strings fine, but calling .equals() from a null string will cause an exception:  


== compares Object reference.


.equals() compares String value.


Sometimes == gives illusions of comparing String values, as in following cases:


This is a because when you create any String literal, the JVM first searches for that literal in String pool, and if it finds a match, that same reference will be given to the new String. because of this, we get 


(a==b) ===> true


However, == fails in following case


in this case for new String("test") the statement new String will be created in heap that reference will be given to b, so b will be given reference in heap not in String Pool.
Now a is pointing to String in String pool while b is pointing to String in heap, because of that we are getting  


if(a==b) ===> false.


While .equals() always compares value of String so it gives true in both cases


So using .equals() is always better.


Hope this will help.


The == operator checks to see if the two strings are exactly the same object.


The .equals() method will check if the two strings have the same value.


String in java are immutable that means whenever you try to change/modify the string you get a new instance. You cannot change the original string. This has been done so that these string instances can be cached. A typical program contains a lot of string references and caching these instances can decrease the memory footprint and increase the performance of the program.


When using == operator for string comparison you are not comparing the contents of the string but are actually comparing the memory address, if they are both equal it will return true and false otherwise. Whereas equals in string compares the string contents.


So the question is if all the strings are cached in the system how come == returns false whereas equals return true. Well this is possible. If you make a new string like String str = new String("Testing") you end up creating a new string in the cache even if the cache already contains a string having the same content. In short "MyString" == new String("MyString") will always return false.


Java also talks about the function intern() that can be used on a string to make it part of the cache so "MyString" == new String("MyString").intern() will return true.


Note: == operator is much faster that equals just because you are comparing two memory addresses, but you need to be sure that the code isn't creating new String instances in the code otherwise you will encounter bugs.


Make sure you understand why.  It's because the == comparison only compares references; the equals() method does a character-by-character comparison of the contents.


When you call new for a and b, each one gets a new reference that points to the "foo" in the string table.  The references are different, but the content is the same.


Yea, it's bad...


"==" means that your two string references are exactly the same object. You may have heard that this is the case because Java keeps sort of a literal table (which it does), but that is not always the case. Some strings are loaded in different ways, constructed from other strings, etc., so you must never assume that two identical strings are stored in the same location.


Equals does the real comparison for you. 


Java is having a String pool under which java manages the memory allocation for the String objects. See String Pools in java


What happens is when you check(compare) two objects using == operator it compares the address equality into the string-pool. If two String objects having same address references then it returns true otherwise false. But if you want to compare the contents of two String objects then you must override equals method.


equals is actually the method of Object class but is Overridden into the String class and new definition is given which compares the contents of object. 


But mind it respects the case of String. If you want Case insensitive compare then you must go for equalsIgnoreCase method of the String class. 


Yes, == is bad for comparing Strings (any objects really, unless you know they're canonical).  == just compares object references.  .equals() tests for equality. For Strings, often they'll be the same but as you've discovered, that's not guaranteed always.


== compares object references in Java, and that is no exception for String objects.


For comparing the actual contents of objects (including String), one must use the equals method.


If a comparison of two String objects using == turns out to be true, that is because the String objects were interned, and the Java Virtual Machine is having multiple references point to the same instance of String. One should not expect that comparing one String object containing the same contents as another String object using == to evaluate as true.


.equals() compares the data in a class (assuming the function is implemented).
== compares pointer locations (location of the object in memory).


== returns true if both objects (NOT TALKING ABOUT PRIMITIVES) point to the SAME object instance.
.equals() returns true if the two objects contain the same data equals() Versus == in Java


That may help you.


== performs a reference equality check, whether the 2 objects (strings in this case) refer to the same object in the memory.


The equals() method will check whether the contents or the states of 2 objects are the same.


Obviously == is faster, but will (might) give false results in many cases if you just want to tell if 2 Strings hold the same text.


Definitely the use of equals() method is recommended.


Don't worry about the performance. Some things to encourage using String.equals():


When all is said and done, even if we have guarantee that the strings are interns, using the equals() method is still not that overhead that one might think, definitely the recommended way. If you want efficient reference check, then use enums where it is guaranteed by the language specification and implementation that the same enum value will be the same object (by reference).


I agree with the answer from zacherates.


But what you can do is to call intern() on your non-literal strings.


From zacherates example:


If you intern the non-literal String equality is true


If you're like me, when I first started using Java, I wanted to use the "==" operator to test whether two String instances were equal, but for better or worse, that's not the correct way to do it in Java.


In this tutorial I'll demonstrate several different ways to correctly compare Java strings, starting with the approach I use most of the time. At the end of this Java String comparison tutorial I'll also discuss why the "==" operator doesn't work when comparing Java strings.


Option 1: Java String comparison with the equals method
Most of the time (maybe 95% of the time) I compare strings with the equals method of the Java String class, like this:


This String equals method looks at the two Java strings, and if they contain the exact same string of characters, they are considered equal.


Taking a look at a quick String comparison example with the equals method, if the following test were run, the two strings would not be considered equal because the characters are not the exactly the same (the case of the characters is different):


But, when the two strings contain the exact same string of characters, the equals method will return true, as in this example:


Option 2: String comparison with the equalsIgnoreCase method


In some string comparison tests you'll want to ignore whether the strings are uppercase or lowercase. When you want to test your strings for equality in this case-insensitive manner, use the equalsIgnoreCase method of the String class, like this:


Option 3: Java String comparison with the compareTo method


There is also a third, less common way to compare Java strings, and that's with the String class compareTo method. If the two strings are exactly the same, the compareTo method will return a value of 0 (zero). Here's a quick example of what this String comparison approach looks like:


While I'm writing about this concept of equality in Java, it's important to note that the Java language includes an equals method in the base Java Object class. Whenever you're creating your own objects and you want to provide a means to see if two instances of your object are "equal", you should override (and implement) this equals method in your class (in the same way the Java language provides this equality/comparison behavior in the String equals method).


You may want to have a look at this ==, .equals(), compareTo(), and compare()


Function:


Test:


== operator check if the two references point to the same object or not. .equals() check for the actual string content (value).


Note that .equals() method belongs to Class Object (Super class of all classes). You need to override it as per you class requirement but for String it is already implemented and it checks whether two string have same value or not.


Case 1


Reason:  String literals created without null are stores in String pool in permgen area of heap. So both s1 and s2 point to same object in the pool.


Case 2


Reason: If you create String object using new keyword separate space is allocated to it on heap.


== compares the reference value of objects whereas the equals() method present in the java.lang.String class compares the contents of the String object (to another object).


I think that when you define a String you define an object. So you need to use .equals(). When you use primitive data types you use == but with String (and any object) you must use .equals().


always == operator meant for object reference comparison,where as String class .equals() method is overridden for content comparison


equals() method is present in the java.lang.Object class and it is expected to check for the equivalence of the state of objects!. That means, the contents of the objects. Whereas the == operator is expected to check the actual object instances are same or not.


Example


Consider two different reference variables str1 and str2 


if you use the equals()


You will get the output as TRUE


if you use ==


Now you will get the FALSE as output because both str1 and str2 are pointing to two different objects even though both of them share the same string content. It is because of new String() everytime a new object is created.


You can also use compareTo() method to compare two Strings. If the compareTo result is 0, then the two strings are equal, otherwise the strings being compared are not equal. 


The == compares the references and does not compare the actual strings. If you did create every string using new String(somestring).intern() then you can use the == operator to compare two strings, otherwise equals() or compareTo methods can only be used.


All objects are guaranteed to have a .equals() method since Object contains a method .equals() that returns a boolean. It is the subclass' job to override this method if a further defining definition is required.  Without it(i.e. using ==) only memory addresses are checked between two objects for equality.   String overrides this .equals() method and instead of using the memory address it returns the comparison of strings at the character level for equality. 


A key note is that strings are stored in one lump pool so once a string is created it is forever stored in a program at the same address. Strings do not change, they are immutable. This is why it is a bad idea to use regular string concatenation if you have a serious of amount of string processing to do. Instead you would use the StringBuilder classes provided. Remember the pointers to this string can change and if you were interested to see if two pointers were the same == would be a fine way to go. Strings themselves do not.


In Java, when the “==” operator is used to compare 2 objects, it checks to see if the objects refer to the same place in memory. In other words, it checks to see if the 2 object names are basically references to the same memory location. 


The Java String class actually overrides the default equals() implementation in the Object class – and it overrides the method so that it checks only the values of the strings, not their locations in memory.
 This means that if you call the equals() method to compare 2 String objects, then as long as the actual sequence of characters is equal, both objects are considered equal.


The == operator checks if the two strings are exactly the same object.


The .equals() method  check if the two strings have the same value.






What is the best way of searching the whole classpath for an annotated class?


I'm doing a library and I want to allow the users to annotate their classes, so when the Web application starts I need to scan the whole classpath for certain annotation.


Do you know a library or a Java facility to do this?


Edit: I'm thinking about something like the new functionality for Java EE 5 Web Services or EJB's. You annotate your class with @WebService or @EJB and the system finds these classes while loading so they are accessible remotely.


Use org.springframework.context.annotation.ClassPathScanningCandidateComponentProvider 


API


A component provider that scans the classpath from a base package. It then applies exclude and include filters to the resulting classes to find candidates. 


And another solution is Google reflections.


Quick review: 


I just released an uber-fast and lightweight classpath scanner (git repo here) that does not call the classloader to load classes on the classpath in order to determine subclasses, superclasses, annotations etc., but rather reads the classfile binary headers directly (inspired by, but simpler than, rmueller's classpath scanner, linked in another comment).


My classpath scanner can find classes on the classpath that extend a given superclass, that implement a given interface, or that have a given class annotation, and can find files within the classpath of any type whose path matches a given regular expression.


Here is an example of usage:


The scanner also records the latest last-modified timestamp of any file or directory encountered, and you can see if that latest last-modified timestamp has increased (indicating that something on the classpath has been updated) by calling:


This can be used to enable dynamic class-reloading if something on the classpath is updated, for example to support hot-replace of route handler classes in a webserver. The above call is several times faster than the original call to scan(), since only modification timestamps need to be checked.


If you want a really light weight (no dependencies, simple API, 15 kb jar file) and very fast solution, take a look at annotation-detector found at https://github.com/rmuller/infomas-asl 


Disclaimer: I am the author.


You can use Java Pluggable Annotation Processing API to write annotation processor which will be executed during the compilation process and will collect all annotated classes and build the index file for runtime use.


This is the fastest way possible to do annotated class discovery because you don't need to scan your classpath at runtime, which is usually very slow operation. Also this approach works with any classloader and not only with URLClassLoaders usually supported by runtime scanners.


The above mechanism is already implemented in ClassIndex library.


To use it annotate your custom annotation with @IndexAnnotated meta-annotation. This will create at compile time an index file: META-INF/annotations/com/test/YourCustomAnnotation listing all annotated classes. You can acccess the index at runtime by executing:


Use the ServiceLoader, or implement your own if you are not in Java 6.


Perhaps an annotation processor could produce the necessary files under META-INF/services at compile-time.


Try Scannotation.


It can be used to search the classpath or your web application lib directory for specific annotations.


You might want to use http://code.google.com/p/annovention/ 


Slightly offtopic, but Spring also does something similar, using <context:component-scan>, which you could perhaps study the source code of?


Spring provides the capability of automatically detecting 'stereotyped' classes [...]. To autodetect these classes and register the corresponding beans requires the inclusion of the  [context:component-scan element].


I'm not sure if it will help you or not, but you could look into the apache commons-discovery project.


discovery project


With Spring you can also just write the following using AnnotationUtils class. i.e.:


For more details and all different methods check official docs: 
https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/core/annotation/AnnotationUtils.html


Java does not have "Discovery".  The only way I know of is to scan the directory that the .class files should be in, parse the names and use that.  Horribly ugly, maybe there is a better package these days--I haven't looked in a few years.


Usually this problem used to be addressed by including a properties file or a .xml file with the classnames in it.


I'd be interested in hearing a better answer as well.


The Classloader API doesn't have an "enumerate" method, because class loading is an "on-demand" activity -- you usually have thousands of classes in your classpath, only a fraction of which will ever be needed (the rt.jar alone is 48MB nowadays!).


So, even if you could enumerate all classes, this would be very time- and memory-consuming. 


The simple approach is to list the concerned classes in a setup file (xml or whatever suits your fancy); if you want to do this automatically, restrict yourself to one JAR or one class directory. 


Google Reflections seems to be much faster than Spring. Found this feature request that adresses this difference: http://www.opensaga.org/jira/browse/OS-738


This is a reason to use Reflections as startup time of my application is really important during development. Reflections seems also to be very easy to use for my use case (find all implementers of an interface).


If you want a Scala library, use Sclasner:
https://github.com/ngocdaothanh/sclasner






What are Null Pointer Exceptions (java.lang.NullPointerException) and what causes them?


What methods/tools can be used to determine the cause so that you stop the exception from causing the program to terminate prematurely?


When you declare a reference variable (i.e. an object) you are really creating a pointer to an object. Consider the following code where you declare a variable of primitive type int:


In this example the variable x is an int and Java will initialize it to 0 for you. When you assign it to 10 in the second line your value 10 is written into the memory location pointed to by x.


But, when you try to declare a reference type something different happens. Take the following code:


The first line declares a variable named num, but, it does not contain a primitive value. Instead it contains a pointer (because the type is Integer which is a reference type). Since you did not say as yet what to point to Java sets it to null, meaning "I am pointing at nothing".


In the second line, the new keyword is used to instantiate (or create) an object of type Integer and the pointer variable num is assigned this object. You can now reference the object using the dereferencing operator . (a dot).  


The Exception that you asked about occurs when you declare a variable but did not create an object. If you attempt to dereference num BEFORE creating the object you get a NullPointerException. In the most trivial cases the compiler will catch the problem and let you know that "num may not have been initialized" but sometimes you write code that does not directly create the object.


For instance you may have a method as follows:


in which case you are not creating the object obj, rather assuming that is was created before the doSomething method was called. Unfortunately it is possible to call the method like this:


in which case obj is null. If the method is intended to do something to the passed-in object, it is appropriate to throw the NullPointerException because it's a programmer error and the programmer will need that information for debugging purposes.


Alternatively, there may be cases where the purpose of the method is not solely to operate on the passed in object, and therefore a null parameter may be acceptable. In this case, you would need to check for a null parameter and behave differently. You should also explain this in the documentation. For example, doSomething could be written as:


Finally, How to pinpoint the exception location & cause using Stack Trace


NullPointerExceptions are exceptions that occur when you try to use a reference that points to no location in memory (null) as though it were referencing an object.  Calling a method on a null reference or trying to access a field of a null reference will trigger a NullPointerException.  These are the most common, but other ways are listed on the NullPointerException javadoc page.


Probably the quickest example code I could come up with to illustrate a NullPointerException would be:


On the first line inside main I'm explicitly setting the Object reference obj equal to null.  This means I have a reference, but it isn't pointing to any object.  After that, I try to treat the reference as though it points to an object by calling a method on it.  This results in a NullPointerException because there is no code to execute in the location that the reference is pointing.


(This is a technicality, but I think it bears mentioning: A reference that points to null isn't the same as a C pointer that points to an invalid memory location.  A null pointer is literally not pointing anywhere, which is subtly different than pointing to a location that happens to be invalid.)


A good place to start is the JavaDocs. They have this covered:


Thrown when an application attempts to use null in a case where an
  object is required. These include:


Applications should throw instances of this class to indicate other
  illegal uses of the null object.


It is also the case that if you attempt to use a null reference with synchronized, that will also throw this exception, per the JLS:


So you have a NullPointerException, how do you fix it? Let's take a simple example which throws a NullPointerException


Identify the null values


The first step is identifying exactly which values are causing the exception. For this we need to do some debugging. It's important to learn to read a stacktrace. This will show you where the exception was thrown:


Here, we see that the exception is thrown on line 13 (in the printString method). Look at line and check which values are null by
adding logging statements or using a debugger. We find out that s is null, and calling the length
method on it throws the exception. We can see that the program stops throwing the exception when
s.length() is removed from the method.


Trace where these values come from


Next check where this value comes from. By following the callers of the method, we see that s is
passed in with printString(name) in the print() method, and this.name is null.


Trace where these values should be set


Where is this.name set? In the setName(String) method. With some more debugging, we can see that this method isn't called at all. If the method was called, make sure to check the order that these methods are called, and the set method isn't called after the print method.


This is enough to give us a solution: add a call to printer.setName() before calling printer.print().


The variable can have a default value (and setName can prevent it being set to null):


Either the print or printString method can check for null, for example:


Or you can design the class so that name always has a non-null value:


See also:


If you tried to debug the problem and still don't have a solution, you can post a question for more help, but make sure to include what you've tried so far. At a minimum, include the stacktrace in the question, and mark the important line numbers in the code. Also, try simplifying the code first (see SSCCE).


As you should know, Java types are divided into primitive types (boolean, int etc) and reference types.  Reference types in Java allow you to use the special value null which is the Java way of saying "no object".


A NullPointerException is thrown at runtime whenever your program attempts to use a null as if it was a real reference.  For example, if you write this:


the statement labelled "HERE" is going to attempt to run the length() method on a null reference, and this will throw a NullPointerException.


There are many ways that you could use a null value that will result in a NullPointerException.  If fact, the only things that you can do with a null without causing an NPE are:


Suppose that I compile and run the program above:


First observation: the compilation succeeds!  The problem in the program is NOT a compilation error.  It is a runtime error.  (Some IDEs may warn your program will always throw an exception ... but the standard javac compiler doesn't.)


Second observation: when I run the program, it outputs two lines of "gobbledy-gook".  WRONG!!  That's not gobbledy-gook.  It is a stacktrace ... and it provides vital information that will help you track down the error in your code, if you take the time to read it carefully.


So lets look at what is says:


The first line of the stack trace tells you a number of things:


The second line is the most important one in diagnosing an NPE. 


This tells us a number of things:


And if you count the lines in the file above, line 4 is the one that I labelled with the "HERE" comment.


Note that in a more complicated example, there will be lots of lines in the NPE stack trace.  But you can be sure that the second line (the first "at" line) will tell you where the NPE was thrown1.


In short the stacktrace will tell us unambiguously which statement of the program has thrown the NPE.


1 - Not quite true.  There are things called nested exceptions ...


This is the hard part.  The short answer is to apply logical inference to the evidence provided by the stack trace, the source code and the relevant API documentation.


Lets illustrate with the simple example (above) first.  We start by looking at the line that the stacktrace has told us is where the NPE happened:


How can that throw an NPE?  


In fact there is only one way: it can only happen if foo has the value null.  We then try to run the length() method on null and .... BANG!


But (I hear you say) what if the NPE was thrown inside the length() method call?


Well if that happened, the stacktrace would look different.  The first "at" line would say that the exception was thrown in some line in the java.lang.String class, and line 4 of Test.java would be the second "at" line.


So where did that null come from?  In this case it is obvious and it is obvious what we need to do to fix it.  (Assign a non-null value to foo)


OK, so lets try a slightly more tricky example.  This will require some logical deduction.


So now we have 2 "at" lines.  The first one is for this line:


and the second one is for this line:


So looking at the first line, how could that throw an NPE?  In fact, there are two ways:


So next we need to figure out which of those scenarios explains what is actually happening.  Lets start by exploring the first one:


Where does bar come from?   It is a parameter to the test method call, and if we look at how test was called, we can see that it comes from the foo static variable.  And we can see clearly that we initialized foo to a non-null value.  That is sufficient to tentatively dismiss this explanation.  (In theory, something else could change foo to null ... but that's not happening here.)


So what about our 2nd scenario?  Well we can see that pos is 1, so that means that foo[1] must be null.  Is that possible?


Indeed it is!  And that is the problem.  When we initialize like this:


we allocate a String[] with two elements that are initialized to null.  And then we didn't change the contents of foo ... so foo[1] will still be null.


A null pointer exception is caused when you dereference a variable that is pointing to null. See the following code:


Null pointer exception is thrown when an application attempts to use null in a case where an object is required. These include:


Applications should throw instances of this class to indicate other illegal uses of the null object. 


Reference : http://docs.oracle.com/javase/8/docs/api/java/lang/NullPointerException.html


A NULL pointer is one that points to nowhere.  When you dereference a pointer p, you say "give me the data at the location stored in "p".  When p is a null pointer, the location stored in p is nowhere, you're saying "give me the data at the location 'nowhere'".  Obviously it can't do this, so it throws a NULL pointer exception.


In general, it's because something hasn't been initialized properly.


A lot of explanations are already present to explain how it happens and how to fix it but you should also follow best practices to avoid NullPointerException at all.


See also:
A good list of best practices


I would add, very important, make a good use of the final modifier.
Using "final" modifier whenever applicable in java


Summary:


In Java every things is in the form of class.


If you want to use any object then you have two phases


Example:


Same for Array concept


If you not given Initialization section then the NullpointerException arise. 


A null pointer exception is an indicator that you are using Object without initialize it.


e.g below is a student class which will use in our code.


below code give you null pointer exception .


Because you are using Obj_Student but you forgot to initialize it like wise
correct code is shown below


In Java all the variables you declare are actually "references" to the objects (or primitives) and not the objects themselves.


When you attempt to execute one object method, the reference ask the living object to execute that method. But if the reference is referencing NULL (nothing, zero, void, nada)  then there is no way the method gets executed. Then the runtime let you know this by throwing a NullPointerException.


Your reference is "pointing" to null, thus "Null -> Pointer".


The object lives in the VM memory space and the only way to access it is using this references. Take this example:


This an important thing to know - when there are no more references to an object (in the example above when "reference" and "otherReference" point to null) then the object is "unreachable". There is no way we can work with it, so this object is marked for to be  garbage collected, and at some point the VM will free the memory used by this object and will allocate another.


Another occurrence of a NullPointerException occurs when one declares an object array, then immediately tries to dereference elements inside of it.


This particular NPE can be avoided if the comparison order is reversed; namely, use .equals on a guaranteed non-null object.


All elements inside of an array are initialized to their common initial value; for any type of object array, that means that all elements are null.


You must initialize the elements in the array before accessing or derefencing them.






Sometimes when I run my application it gives me an error that looks like:


People have referred to this as a "stack trace". What is a stack trace? What can it tell me about the error that's happening in my program?


About this question - quite often I see a question come through where a novice programmer is "getting an error", and they simply paste their stack trace and some random block of code without understanding what the stack trace is or how they can use it. This question is intended as a reference for novice programmers who might need help understanding the value of a stack trace.


In simple terms, a stack trace is a list of the method calls that the application was in the middle of when an Exception was thrown.


Simple Example


With the example given in the question, we can determine exactly where the exception was thrown in the application. Let's have a look at the stack trace:


This is a very simple stack trace. If we start at the beginning of the list of "at ...", we can tell where our error happened. What we're looking for is the topmost method call that is part of our application. In this case, it's:


To debug this, we can open up Book.java and look at line 16, which is:


This would indicate that something (probably title) is null in the above code.


Example with a chain of exceptions


Sometimes applications will catch an Exception and re-throw it as the cause of another Exception.  This typically looks like:


This might give you a stack trace that looks like:


What's different about this one is the "Caused by". Sometimes exceptions will have multiple "Caused by" sections. For these, you typically want to find the "root cause", which will be one of the lowest "Caused by" sections in the stack trace. In our case, it's:


Again, with this exception we'd want to look at line 22 of Book.java to see what might cause the NullPointerException here.


More daunting example with library code


Usually stack traces are much more complex than the two examples above. Here's an example (it's a long one, but demonstrates several levels of chained exceptions):


In this example, there's a lot more. What we're mostly concerned about is looking for methods that are from our code, which would be anything in the com.example.myproject package. From the second example (above), we'd first want to look down for the root cause, which is:


However, all the method calls under that are library code. So we'll move up to the "Caused by" above it, and look for the first method call originating from our code, which is:


Like in previous examples, we should look at MyEntityService.java on line 59, because that's where this error originated (this one's a bit obvious what went wrong, since the SQLException states the error, but the debugging procedure is what we're after).


I am posting this answer so the topmost answer (when sorted by activity) is not one that is just plain wrong.


What is a Stacktrace?


A stacktrace is a very helpful debugging tool. It shows the call stack (meaning, the stack of functions that were called up to that point) at the time an uncaught exception was thrown (or the time the stacktrace was generated manually). This is very useful because it doesn't only show you where the error happened, but also how the program ended up in that place of the code.
This leads over to the next question:


What is an Exception?


An Exception is what the runtime environment uses to tell you that an error occurred. Popular examples are NullPointerException, IndexOutOfBoundsException or ArithmeticException. Each of these are caused when you try to do something that is not possible. For example, a NullPointerException will be thrown when you try to dereference a Null-object:


How should I deal with Stacktraces/Exceptions?


At first, find out what is causing the Exception. Try googleing the name of the exception to find out, what is the cause of that exception. Most of the time it will be caused by incorrect code. In the given examples above, all of the exceptions are caused by incorrect code. So for the NullPointerException example you could make sure that a is never null at that time. You could, for example, initialise a or include a check like this one:


This way, the offending line is not executed if a==null. Same goes for the other examples.


Sometimes you can't make sure that you don't get an exception. For example, if you are using a network connection in your program, you cannot stop the computer from loosing it's internet connection (e.g. you can't stop the user from disconnecting the computer's network connection). In this case the network library will probably throw an exception. Now you should catch the exception and handle it. This means, in the example with the network connection, you should try to reopen the connection or notify the user or something like that. Also, whenever you use catch, always catch only the exception you want to catch, do not use broad catch statements like catch (Exception e) that would catch all exceptions. This is very important, because otherwise you might accidentally catch the wrong exception and react in the wrong way.


Why should I not use catch (Exception e)?


Let's use a small example to show why you should not just catch all exceptions:


What this code is trying to do is to catch the ArithmeticException caused by a possible division by 0. But it also catches a possible NullPointerException that is thrown if a or b are null. This means, you might get a NullPointerException but you'll treat it as an ArithmeticException and probably do the wrong thing. In the best case you still miss that there was a NullPointerException. Stuff like that makes debugging much harder, so don't do that.


TLDR


If 1. is not possible, catch the specific exception and handle it.


To add on to what Rob has mentioned.  Setting break points in your application allows for the step-by-step processing of the stack.  This enables the developer to use the debugger to see at what exact point the method is doing something that was unanticipated.


Since Rob has used the NullPointerException (NPE) to illustrate something common, we can help to remove this issue in the following manner:  


if we have a method that takes parameters such as:  void (String firstName) 


In our code we would want to evaluate that firstName contains a value, we would do this like so: if(firstName == null || firstName.equals(""))  return;


The above prevents us from using firstName as an unsafe parameter.  Therefore  by doing null checks before processing we can help to ensure that our code will run properly.  To expand on an example that utilizes an object with methods we can look here:  


if(dog == null || dog.firstName == null)  return;


The above is the proper order to check for nulls, we start with the base object, dog in this case, and then begin walking down the tree of possibilities to make sure everything is valid before processing.  If the order were reversed a NPE could potentially be thrown and our program would crash.


There is one more stacktrace feature offered by Throwable family - the possibility to manipulate stack trace information.


Standard behavior:


Stack trace:


Manipulated stack trace:


Stack trace:


To understand the name: A stack trace is a a list of Exceptions( or you can say a list of "Cause by"), from the most surface Exception(e.g. Service Layer Exception) to the deepest one (e.g. Database Exception). Just like the reason we call it 'stack' is because stack is First in Last out (FILO), the deepest exception was happened in the very beginning, then a chain of exception was generated a series of consequences, the surface Exception was the last one happened in time, but we see it in the first place.


Key 1:A tricky and important thing here need to be understand is : the deepest cause may not be the "root cause", because if you write some "bad code", it may cause some exception underneath which is deeper than its layer. For example, a bad sql query may cause SQLServerException connection reset in the bottem instead of syndax error, which may just in the middle of the stack.


-> Locate the root cause in the middle is your job.



Key 2:Another tricky but important thing is inside each "Cause by" block, the first line was the deepest layer and happen first place for this block. For instance,


Book.java:16 was called by Auther.java:25 which was called by Bootstrap.java:14, Book.java:16 was the root cause.
Here attach a diagram sort the trace stack in chronological order.



Just to add to the other examples, there are inner(nested) classes that are displayed using $ sign. For example:


Will result in this stack trace:


The other posts describe what a stack trace is, but it can still be hard to work with.


If you get a stack trace and want to trace the cause of the exception, a good start point in understanding it is to use the Java Stack Trace Console in Eclipse. If you use another IDE there may be a similar feature, but this answer is about Eclipse.


First, ensure that you have all of your Java sources accessible in an Eclipse project.


Then in the Java perspective, click on the Console tab (usually at the bottom). If the Console view is not visible, go to the menu option Window -> Show View and select Console.


Then in the console window, click on the following button (on the right)





and then select Java Stack Trace Console from the drop-down list.


Paste your stack trace into the console. It will then provide a list of links into your source code and any other source code available.


This is what you might see (image from the Eclipse documentation):





The most recent method call made will be the top of the stack, which is the top line (excluding the message text). Going down the stack goes back in time. The second line is the method that calls the first line, etc.


If you are using open-source software, you might need to download and attach to your project the sources if you want to examine. Download the source jars, in your project, open the Referenced Libraries folder to find your jar for your open-source module (the one with the class files) then right click, select Properties and attach the source jar.






How can I upload files to server using JSP/Servlet? I tried this:


However, I only get the file name, not the file content. When I add  enctype="multipart/form-data" to the <form>, then request.getParameter() returns null. 


During research I stumbled upon Apache Common FileUpload. I tried this:


Unfortunately, the servlet threw an exception without a clear message and cause. Here is the stacktrace:


To browse and select a file for upload you need a HTML <input type="file"> field in the form. As stated in the HTML specification you have to use the POST method and the enctype attribute of the form has to be set to "multipart/form-data".


After submitting such a form, the binary multipart form data is available in the request body in a different format than when the enctype isn't set.


Before Servlet 3.0, the Servlet API didn't natively support multipart/form-data. It supports only the default form enctype of application/x-www-form-urlencoded. The request.getParameter() and consorts would all return null when using multipart form data. This is where the well known Apache Commons FileUpload came into the picture.


You can in theory parse the request body yourself based on ServletRequest#getInputStream(). However, this is a precise and tedious work which requires precise knowledge of RFC2388. You shouldn't try to do this on your own or copypaste some homegrown library-less code found elsewhere on the Internet. Many online sources have failed hard in this, such as roseindia.net. See also uploading of pdf file. You should rather use a real library which is used (and implicitly tested!) by millions of users for years. Such a library has proven its robustness.


If you're using at least Servlet 3.0 (Tomcat 7, Jetty 9, JBoss AS 6, GlassFish 3, etc), then you can just use standard API provided HttpServletRequest#getPart() to collect the individual multipart form data items (most Servlet 3.0 implementations actually use Apache Commons FileUpload under the covers for this!). Also, normal form fields are available by getParameter() the usual way.


First annotate your servlet with @MultipartConfig in order to let it recognize and support multipart/form-data requests and thus get getPart() to work:


Then, implement its doPost() as follows:


Note the Path#getFileName(). This is a MSIE fix as to obtaining the file name. This browser incorrectly sends the full file path along the name instead of only the file name.


In case you have a <input type="file" name="file" multiple="true" /> for multi-file upload, collect them as below (unfortunately there is no such method as request.getParts("file")):


Note that Part#getSubmittedFileName() was introduced in Servlet 3.1 (Tomcat 8, Jetty 9, WildFly 8, GlassFish 4, etc). If you're not on Servlet 3.1 yet, then you need an additional utility method to obtain the submitted file name.


Note the MSIE fix as to obtaining the file name. This browser incorrectly sends the full file path along the name instead of only the file name.


If you're not on Servlet 3.0 yet (isn't it about time to upgrade?), the common practice is to make use of Apache Commons FileUpload to parse the multpart form data requests. It has an excellent User Guide and FAQ (carefully go through both). There's also the O'Reilly ("cos") MultipartRequest, but it has some (minor) bugs and isn't actively maintained anymore for years. I wouldn't recommend using it. Apache Commons FileUpload is still actively maintained and currently very mature.


In order to use Apache Commons FileUpload, you need to have at least the following files in your webapp's /WEB-INF/lib: 


Your initial attempt failed most likely because you forgot the commons IO. 


Here's a kickoff example how the doPost() of your UploadServlet may look like when using Apache Commons FileUpload:


It's very important that you don't call getParameter(), getParameterMap(), getParameterValues(), getInputStream(), getReader(), etc on the same request beforehand. Otherwise the servlet container will read and parse the request body and thus Apache Commons FileUpload will get an empty request body. See also a.o. ServletFileUpload#parseRequest(request) returns an empty list.


Note the FilenameUtils#getName(). This is a MSIE fix as to obtaining the file name. This browser incorrectly sends the full file path along the name instead of only the file name.


Alternatively you can also wrap this all in a Filter which parses it all automagically and put the stuff back in the parametermap of the request so that you can continue using request.getParameter() the usual way and retrieve the uploaded file by request.getAttribute(). You can find an example in this blog article.


Note that Glassfish versions older than 3.1.2 had a bug wherein the getParameter() still returns null. If you are targeting such a container and can't upgrade it, then you need to extract the value from getPart() with help of this utility method:


Head to the following answers for detail on properly saving the obtained InputStream (the fileContent variable as shown in the above code snippets) to disk or database:


Head to the following answers for detail on properly serving the saved file from disk or database back to the client:


Head to the following answers how to upload using Ajax (and jQuery). Do note that the servlet code to collect the form data does not need to be changed for this! Only the way how you respond may be changed, but this is rather trivial (i.e. instead of forwarding to JSP, just print some JSON or XML or even plain text depending on whatever the script responsible for the Ajax call is expecting).


Hope this all helps :)


If you happen to use Spring MVC, this is how to: 
(I'm leaving this here in case someone find it useful).


Use a form with enctype attribute set to "multipart/form-data" (Same as BalusC's Answer)


In your controller, map the request parameter file to MultipartFile type as follows:


You can get the filename and size using MultipartFile's getOriginalFilename() and getSize().


I've tested this with Spring version 4.1.1.RELEASE.


You need the common-io.1.4.jar file to be included in your lib directory, or if you're working in any editor, like NetBeans, then you need to go to project properties and just add the JAR file and you will be done. 


To get the common.io.jar file just google it or just go to the Apache Tomcat website where you get the option for a free download of this file. But remember one thing: download the binary ZIP file if you're a Windows user.


I am Using common Servlet for every Html Form whether it has attachments or not.
This Servlet returns a TreeMap where the keys are jsp name Parameters and values are User Inputs and saves all attachments in fixed directory and later you rename the directory of your choice.Here Connections is our custom interface having connection object. I think this will help you


Without component or external Library in Tomcat 6 o 7


Enabling Upload in the web.xml file:


http://joseluisbz.wordpress.com/2014/01/17/manually-installing-php-tomcat-and-httpd-lounge/#Enabling%20File%20Uploads.


AS YOU CAN SEE:


Uploading Files using JSP. Files:


In the html file


In the JSP File or Servlet


Edit your code to servlet requirements, like max-file-size, max-request-size  and other options that you can to set...


Another source of this problem occurs if you are using Geronimo with its embedded Tomcat. In this case, after many iterations of testing commons-io and commons-fileupload, the problem arises from a parent classloader handling the commons-xxx jars. This has to be prevented. The crash always occurred at: 


Note that the List type of fileItems has changed with the current version of commons-fileupload to be specifically List<FileItem> as opposed to prior versions where it was generic List. 


I added the source code for commons-fileupload and commons-io into my Eclipse project to trace the actual error and finally got some insight. First, the exception thrown is of type Throwable not the stated FileIOException nor even Exception (these will not be trapped). Second, the error message is obfuscatory in that it stated class not found because axis2 could not find commons-io.  Axis2 is not used in my project at all but exists as a folder in the Geronimo repository subdirectory as part of standard installation.


Finally, I found 1 place that posed a working solution which successfully solved my problem. You must hide the jars from parent loader in the deployment plan. This was put into geronimo-web.xml with my full file shown below.


For Spring MVC
I have been trying for hours to do this
and managed to have a simpler version that worked for taking form input both data and image.


Controller to handle 


Hope it helps :)


Here's an example using apache commons-fileupload:


you can upload file using jsp /servlet.


on the other hand server side.
use following code.


from this object you have to get file items and fields then yo can store into server like followed


Sending multiple file for file we have to use enctype="multipart/form-data"
and to send multiple file use  multiple="multiple" in input tag  


HTML PAGE


SERVLET FILE


web.xml


Compile above servlet UploadServlet and create required entry in web.xml file as follows.






I want to add JTable into JPanel whose layout is null.  JPanel contains other components. I have to add JTable at proper position.


The Java Tutorial has comprehensive information on using layout managers. See the Laying Out Components Within a Container lesson for further details.


One aspect of layouts that is not covered well by the tutorial is that of nested layouts, putting one layout inside another to get complex effects.


The following code puts a variety of components into a frame to demonstrate how to use nested layouts.  All the layouts that are explicitly set are shown as a titled-border for the panel on which they are used.


Notable aspects of the code are:














Don't use a null layout.  Learn to use LayoutManagers:


http://download.oracle.com/javase/tutorial/uiswing/layout/using.html


LayoutManagers allow you to properly handle things window resizing or dynamic component counts.  They might seem intimidating at first, but they are worth the effort to learn.


As I can remember, the null layout means an absolute position so it will be pretty hard you to count the X point for your JTable left upper corner location. But if you just want to have all panel components one by one you can use FlowLayout() manager as


or if you need to fill the panel you should use GridLayout() as...


Good luck


If you are using null layout manager you always need to set the bounds of a component.
That is the problem in your case.


You should do what everyone suggest here and go and use some layout manager believe they save time.
Go and check out the tutorial in @jzd's post.


Enjoy, Boro.


JTable should be added into the JScrollPane which actually should be added into the JPanel.


The JPanel should have some layout manager.


If you don't care about the precision of components size you can use pure BorderLayout and combine it with FlowLayout and GridLayout. if you need precision - use jgoodies FormLayout.


The FormLayout is really tricky one, but you can play a little with WindowBuilder (which is embedded into Eclipse) and a look at the code it generates. It may look complicated but it is just an ignorance.


Good luck. 


First, you should seriously consider other Layout managers, for example the BorderLayoutManager (new JPanel(new BorderLayout())) is a good start. 


Also when designing your dialog, remember that you can and should nest your layouts: one JPanel inside another JPanel (e.g. a GridLayout inside a BorderLayout). Please note: a 'good' dialog should resize properly, so that if the user resizes your Frame, you want to automatically extend your information objects such as your table, and not show large areas of JPanel background. That's something you cannot achieve with a NullLayout.


But there are probably cases - somewhere in this big world - where a NullLayout is just the thing. So here's an example:


You can make use of the following code. To add JTable to JPanel.


Hope this helps.


table model depends on your requirement


Try this.


When a component have a "null" layout, you have to manage the layout by yourself, that means you have to calculate the dimensions and locations for the children of the component to decide where they are drawn. Quite tedious unless it is absolutely necessary.


If you really want that fine-grained control, maybe try GridBagLayout first before going mudding with the UI arrangement.






I am trying to write a simple application that gets updated. For this I need a simple function that can download a file and show the current progress in a ProgressDialog. I know how to do the ProgressDialog, but I'm not sure how to display the current progress and how to download the file in the first place.


There are many ways to download files. Following I will post most common ways; it is up to you to decide which method is better for your app.


This method will allow you to execute some background processes and update the UI at the same time (in this case, we'll update a progress bar).


This is an example code:


The AsyncTask will look like this:


The method above (doInBackground) runs always on a background thread. You shouldn't do any UI tasks there. On the other hand, the onProgressUpdate and onPreExecute run on the UI thread, so there you can change the progress bar:


For this to run, you need the WAKE_LOCK permission.


The big question here is: how do I update my activity from a service?. In the next example we are going to use two classes you may not be aware of: ResultReceiver and IntentService. ResultReceiver is the one that will allow us to update our thread from a service; IntentService is a subclass of Service which spawns a thread to do background work from there (you should know that a Service runs actually in the same thread of your app; when you extends Service, you must manually spawn new threads to run CPU blocking operations).


Download service can look like this:


Add the service to your manifest:


And the activity will look like this:


Here is were ResultReceiver comes to play:


Groundy is a library that basically helps you run pieces of code in a background service, and it is based on the ResultReceiver concept shown above. This library is deprecated at the moment. This is how the whole code would look like:


The activity where you are showing the dialog...


A GroundyTask implementation used by Groundy to download the file and show the progress:


And just add this to the manifest:


It couldn't be easier I think. Just grab the latest jar from Github and you are ready to go. Keep in mind that Groundy's main purpose is to make calls to external REST apis in a background service and post results to the UI with easily. If you are doing something like that in your app, it could be really useful.


GingerBread brought a new feature, DownloadManager, which allows you to download files easily and delegate the hard work of handling threads, streams, etc. to the system.


First, let's see a utility method:


Method's name explains it all. Once you are sure DownloadManager is available, you can do something like this:


Download progress will be showing in the notification bar.


First and second methods are just the tip of the iceberg. There are lots of things you have to keep in mind if you want your app to be robust. Here is a brief list:


Unless you need detailed control of the download process, then consider using DownloadManager (3) because it already handles most of the items listed above.


But also consider that your needs may change. For example, DownloadManager does no response caching. It will blindly download the same big file multiple times. There's no easy way to fix it after the fact. Where if you start with a basic HttpURLConnection (1, 2), then all you need is to add an HttpResponseCache. So the initial effort of learning the basic, standard tools can be a good investment.


Don't forget to add permissions to your manifest file if you're gonna be downloading stuff from the internet!


Yes the code above will work .But if you are updating your progressbar in onProgressUpdate of Asynctask  and you press back button or finish your activity AsyncTask looses its track with your UI .And when you go back to your activity, even if  download is running in background you will see no update on progressbar. So on OnResume() try to run a thread like runOnUIThread with   a timer task that updates ur progressbar with values updating from the AsyncTask running background.


Don't forget to Destroy the thread when ur activity is not visible.


I have modified AsyncTask class to handle creation of progressDialog at the same context .I think following code will be more reusable.
(it can be called from any activity just pass context,target File,dialog message)


I'd recommend you to use my Project Netroid, It base on Volley which Google IO 2013 presentation, I extend it, add some features such as multi-events callback, file download management, I think that's what you looking for.


Do not forget to replace "/sdcard..." by new File("/mnt/sdcard/...") otherwise you will get a FileNotFoundException


I found this blog post very helpful, Its using loopJ to download file, it has only one Simple function, will be helpful to some new android guys.


My personal advice is to use Progress Dialog and build up before execution , or initiate at OnPreExecute() , publish progress often if you use horizontal style of progress bar of the progress dialog. The remaining part is to optimize the algorithm of doInBackground.


While I was starting to learn android development, I had learnt that ProgressDialog is the way to go. There is the setProgress method of ProgressDialog which can be invoked to update the progress level as the file gets downloaded.


The best I have seen in many apps is that they customize this progress dialog's attributes to give a better look and feel to the progress dialog than the stock version. Good to keeping the user engaged with some animation of like frog, elephant or cute cats/puppies. Any animation with in the progress dialog attracts users and they don't feel like being kept waiting for long.


I will write a blog post on ProgressDialog and share here soon.


Edit:
Show Progress Bar when downloading a file in android


Use Android Query library, very cool indeed.You can change it to use ProgressDialog as you see in other examples, this one will show progress view from your layout and hide it after completion.


Permissions


Using HttpURLConnection


I am adding another answer for other solution I am using now because Android Query is so big and unmaintained to stay healthy. So i moved to this https://github.com/amitshekhariitbhu/Fast-Android-Networking.






This question already has an answer here:


The very common beginner mistake is when you try to use a class property "statically" without making an instance of that class. It leaves you with the mentioned error message.


You can either make the non static method static or make an instance of that class to use its properties.


Why? I am not asking for solutions. I would be grateful to know what's the reason behind it. The very core reason!


You can't call something that doesn't exist.  Since you haven't created an object, the non-static method doesn't exist yet.  A static method (by definition) always exists.


The method you are trying to call is an instance-level method; you do not have an instance.


static methods belong to the class, non-static methods belong to instances of the class.


The essence of object oriented programming is encapsulating logic together with the data it operates on. 


Instance methods are the logic, instance fields are the data. Together, they form an object.


What could possibly be the result of running the above program?


Without an object, there is no instance data, and while the instance methods exist as part of the class definition, they need an object instance to provide data for them.


In theory, an instance method that does not access any instance data could work in a static context, but then there isn't really any reason for it to be an instance method. It's a language design decision to allow it anyway rather than making up an extra rule to forbid it.


I just realized, I think people shouldn't be exposed to the concept of "static" very early.


Static methods should probably be the exception rather than the norm. Especially early on anyways if you want to learn OOP. (Why start with an exception to the rule?) That's very counter-pedagogical of Java, that the "first" thing you should learn is the public static void main thing. (Few real Java applications have their own main methods anyways.)


I think it is worth pointing out that by the rules of the Java language the Java compiler inserts the equivalent of "this." when it notices that you're accessing instance methods or instance fields without an explicit instance.  Of course, the compiler knows that it can only do this from within an instance method, which has a "this" variable, as static methods don't.


Which means that when you're in an instance method the following are equivalent:


and these are also equivalent:


The compiler is effectively inserting the "this." when you don't supply a specific instance.  


This (pun intended) bit of "magic help" by the compiler can confuse novices: it means that instance calls and static calls sometimes appear to have the same syntax while in reality are calls of different types and underlying mechanisms.


The instance method call is sometimes referred to as a method invocation or dispatch because of the behaviors of virtual methods supporting polymorphism; dispatching behavior happens regardless of whether you wrote an explicit object instance to use or the compiler inserted a "this.".


The static method call mechanism is simpler, like a function call in a non-OOP language.


Personally, I think the error message misleading, it could read "non-static method cannot be referenced from a static context without specifying an explicit object instance"


The answers so far describe why, but here is a something else you might want to consider: 


You can can call a method from an instantiable class by appending a method call to its constructor, 


or


This is useful it you only wish to use a method of an instantiable class once within a single scope.  If you are calling multiple methods from an instantiable class within a single scope, definitely create a referable instance.


The compiler actually adds an argument to non-static methods. It adds a this pointer/reference. This is also the reason why a static method can not use this, because there is no object.


A static method relates an action to a type of object, whereas the non static method relates an action to an instance of that type of object.  Typically it is a method that does something with relation to the instance.


Ex:


class Car might have a wash method, which would indicate washing a particular car, whereas a static method would apply to the type car.


if a method is not static, that "tells" the compiler that the method requires access to instance-level data in the class, (like a non-static field).  This data would not be available unless an instance of the class has been created.  So the compiler throws an error if you try to call the method from a static method.. If in fact the method does NOT reference any non-static member of the class, make the method static.


In Resharper, for example, just creating a non-static method that does NOT reference any static member of the class generates a warning message "This method can be made static" 


If we try to access an instance method from a static context , the compiler has no way to guess which instance method ( variable for which object ), you are referring to. Though, you can always access it using an object reference.


The simple reason behind this is that Static data members of parent class
can be accessed (only if they are not overridden) but for instance(non-static)
data members or methods we need their reference and so they can only be
called through an object.


So you are asking for a very core reason? 


Well, since you are developing in Java, the compiler generates an object code that the Java Virtual Machine can interpret. The JVM anyway is a binary program that run in machine language (probably the JVM’s version specific for your operating system and hardware was previously compiled by another programming language like C in order to get a machine code that can run in your processor). At the end, any code is translated to machine code. So, create an object (an instance of a class) is equivalent to reserve a memory space (memory registers that will be processor registers when the CPU scheduler of the operating system put your program at the top of the queue in order to execute it) to have a data storage place that can be able to read and write data. If you don’t have an instance of a class (which happens on a static context), then you don’t have that memory space to read or write the data. In fact, like other people had said, the data don’t exist (because from the begin you never had written neither had reserved the memory space to store it).


Sorry for my english! I'm latin!


A non-static method is dependent on the object. It is recognized by the program once the object is created.  


Static methods can be called even before the creation of an object. Static methods are great for doing comparisons or operations that aren't dependent on the actual objects you plan to work with.






I am using Scanner methods nextInt() and nextLine() for reading input. Basically, it looks like this:


The problem is that after entering the numerical value, the first input.nextLine() is skipped and the second input.nextLine() is executed, so that my output looks like this:


I tested my application and it looks like the problem lies in using input.nextInt(). If I delete it, then both string1 = input.nextLine() and string2 = input.nextLine() are executed as I want them to be.


That's because the Scanner.nextInt method does not consume the last newline character of your input, and thus that newline is consumed in the next call to Scanner.nextLine.


You will encounter the similar behaviour when you use Scanner.nextLine after Scanner.next() or any Scanner.nextFoo method (except nextLine itself).


Workaround:


Either fire a blank Scanner.nextLine call after Scanner.nextInt or Scanner.nextFoo to consume rest of that line including newline 


Or, it would be even better, if you read the input through Scanner.nextLine and convert your input to the proper format you need. For examples, to an integer using Integer.parseInt(String) method.


The problem is with the input.nextInt() command it only reads the int value. So when you continue reading with input.nextLine() you receive the "\n" Enter key. So to skip this you have to add the input.nextLine(). Hope this should be clear now.


Try it like that:


It's because when you enter a number then press Enter, input.nextInt() consumes only the number, not the "end of line". When input.nextLine() executes, it consumes the "end of line" still in the buffer from the first input.


Instead, use input.nextLine() immediately after input.nextInt()


There seem to be many questions about this issue with java.util.Scanner. I think a more readable/idiomatic solution would be to call scanner.skip("[\r\n]+") to drop any newline characters after calling nextInt().


EDIT: as @PatrickParker noted below, this will cause an infinite loop if user inputs any whitespace after the number. See their answer for a better pattern to use with skip: https://stackoverflow.com/a/42471816/143585


It does that because input.nextInt(); doesn't capture the newline. you could do like the others proposed by adding an input.nextLine(); underneath.
Alternatively you can do it C# style and parse a nextLine to an integer like so:  


Doing this works just as well, and it saves you a line of code.


Things you need to know:


text which represents few lines also contains non-printable characters between lines (we call them line separators) like 


when you are reading data from console, it allows user to type his response and when he is done he needs to somehow confirm that fact. To do so, user is required to press "enter"/"return" key on keyboard.  


What is important is that this key beside ensuring placing user data to standard input (represented by System.in which is read by Scanner) also sends OS dependant line separators (like for Windows \r\n) after it. 


So when you are asking user for value like age, and user types 42 and presses enter, standard input will contain "42\r\n".


Scanner#nextInt (and other Scanner#nextType methods) doesn't allow Scanner to consume these line separators. It will read them from System.in (how else Scanner would know that there are no more digits from user which represent age value than facing whitespace?) which will remove them from standard input, but it will also cache those line separators internally. What we need to remember, is that all of Scanner methods are always scanning starting from cached text.  


Now Scanner#nextLine() simply collects and returns all characters until it finds line separators (or end of stream). But since line separators after reading number from console are found immediately in Scanner's cache, it returns empty String, meaning that Scanner was not able to find any character before those line separators (or end of stream).
BTW nextLine also consumes those line separators.  


So when you want to ask for number and then for entire line and avoid that empty string as result of nextLine, either 


BTW: Scanner#nextType methods can skip delimiters (by default all whitespaces like tabs, line separators) including those cached by scanner, until they will find next non-delimiter value (token). Thanks to that for input like "42\r\n\r\n321\r\n\r\n\r\nfoobar" code 


will be able to properly assign num1=42 num2=321 name=foobar.


Instead of input.nextLine() use input.next(), that should solve the problem.


Modified code:


In order to avoid the issue, use nextLine(); immediately after nextInt(); as it helps in clearing out the buffer. When you press ENTER the nextInt(); does not capture the new line and hence, skips the Scanner code later. 


If you want to scan input fast without getting confused into Scanner class nextLine() method , Use Custom Input Scanner for it . 


ScanReader sc = new ScanReader(System.in);

3. Import necessary Classes : 


import java.io.BufferedInputStream;
import java.io.IOException;
import java.io.InputStream;
 
4. Throw IOException from your main method to handle Exception
5. Use Provided Methods.
6. Enjoy


If you want to read both strings and ints, a solution is to use two Scanners:


Why not use a new Scanner for every reading? Like below. With this approach you will not confront your problem.


sc.nextLine() is better as compared to parsing the input.
Because performance wise it will be good.






I wanted to clarify if I understand this correctly:


Am I correct in my understanding ?


In general, the answer to  your question is "yes", but...


With respect to the String class:


The equals() method compares the "value" inside String instances (on the heap) irrespective if the two object references refer to the same String instance or not. If any two object references of type String refer to the same String instance then great! If the two object references refer to two different String instances .. it doesn't make a difference. Its the "value" (that is: the contents of the character array) inside each String instance that is being compared.


On the other hand, the "==" operator compares the value of two object references to see whether they refer to the same String instance. If the value of both object references "refer to" the same String instance then the result of the boolean expression would be "true"..duh. If, on the other hand, the value of both object references "refer to" different String instances (even though both String instances have identical "values", that is, the contents of the character arrays of each String instance are the same) the result of the boolean expression would be "false".


As with any explanation, let it sink in.


I hope this clears things up a bit.


There are some small differences depending whether you are talking about "primitives" or "Object Types"; the same can be said if you are talking about "static" or "non-static" members; you can also mix all the above...


Here is an example (you can run it):


You can compare the explanations for "==" (Equality Operator) and ".equals(...)" (method in the java.lang.Object class) through these links:


Difference between == and equals confused me for sometime until I decided to have a closer look at it.
Many of them say that for comparing string you should use equals and not ==. Hope in this answer I will be able to say the difference.


The best way to answer this question will be by asking few question to yourself. so lets start:


What is the output for the below program:


if you say, 


I will say you are right but why did you said that?
and If you say the output is,


I will say you are wrong but I will still ask you, why you think that is right?


Ok, Lets try to answer this one:


What is the output for the below program:


Now If you say,


I will say you are wrong but why is it wrong now?
the correct output for this program is


Please compare the above program and try to think on it.


Ok. Now this might help (please read this : print the address of object - not possible but still we can use it.)


can you just try to think for the output of last three lines in above code:
for me ideone printed this out (you can check the code here):


Oh! Now you see the identityHashCode(mango) is equal to identityHashCode(mango2) But it is not equal to identityHashCode(mango3)


Even though all the string variables - mango,mango2 and mango3 has the same value of "mango". But still identityHashCode() for all is not same.


Now try to uncomment this line // mango2 = "mang"; and run it again this time you will see all three identityHashCode() are different.
Hmm that is a helpful hint


we know that if hashcode(x)=N and hashcode(y)=N => x is equal to y


I am not sure how java works internally, But I assume this is what happened when I said:


java created a string "mango" and which was pointed(referenced) by variable mango something like this


Now in the next line when I said:


It actually reused the same string "mango" which looks something like this


Both mango and mango2 pointing to the same reference
Now when I said 


It actually created a completely new reference(string) for "mango". which looks something like this,


and thats why when I outputted the values for mango == mango2, it outputted true. and when I outputted the value for mango3 == mango2, it outputted false (even when the value were same).


and when you uncommented the line // mango2 = "mang";
It actually created a string "mang" and which turned our graph like this:


and this is why the identityHashCode is not same for all.


Hope this help you guys.
Actually I wanted to generate a testcase where == fails and equals() pass.
Please feel free to comment and let me know If I am wrong.


The == operator tests whether two variables have the same references
  (aka pointer to a memory address).


Whereas the equals() method tests whether two variables refer to objects
  that have the same state (values).


Cheers :-)


You will have to override the equals function (along with others) to use this with custom classes.


The equals method compares the objects.


The == binary operator compares memory addresses.


Both == and .equals() refers to the same object if you don't override .equals(). 


Its your wish  what you want to do once you override .equals(). You can compare the invoking object's state with the passed in object's state or you can just call super.equals()


"==" is an operator and "equals" is a method.
operators are used for primitive type comparisons and so "==" is used for memory address comparison."equals" method is used for comparing objects. 


Just remember that .equals(...) has to be implemented by the class you are trying to compare. Otherwise, there isn't much of a point; the version of the method for the Object class does the same thing as the comparison operation: Object#equals.


The only time you really want to use the comparison operator for objects is wen you are comparing Enums. This is because there is only one instance of an Enum value at a time. For instance, given the enum


You will never have more than one instance of A at a time, and the same for B and C. This means that you can actually write a method like so:


And you will have no problems whatsoever.


The == operator:


The == is a relational operator in Java that is used to compare two operands. It is used to determine whether the two operands are equal or not. Using the == operator, you can compare any primitive type such as int, char, float and Booleans. After comparison, the == operator returns a boolean value. If the two operands are equal, the == operator returns a true value. However, if the two operands are not equal, it returns a false value.
When used with objects, the == operator compares the two object references and determines whether they refer to the same instance.


The .equals() Method


equals() is a method available in the String class that is used to compare two strings and determine whether they are equal. This method returns a boolean value as a result of the comparison. If the two strings contain the same characters in the same order, the equals() method returns true. Otherwise, it returns a false value.


For Examples:


http://goo.gl/Sa3q5Y


When you evaluate the code, it is very clear that (==) compares according to memory address, while equals(Object o)  compares hashCode() of the instances. 
That's why it is said do not break the contract between equals() and  hashCode() if you do not face surprises later. 


== can be used in many object types but you can use Object.equals for any type , especially Strings and Google Map Markers.


Also note that .equals() normally contains == for testing as this is the first thing you would wish to test for if you wanted to test if two objects are equal. 


And == actually does look at values for primitive types, for objects it checks the reference.


== operator always reference is compared. But in case of 


equals() method


it's depends's on implementation if we are overridden equals method than it compares object on basic of implementation given in overridden method. 


in above code both obj and obj1 object contains same data but reference is not same so equals return false and == also.
but if we overridden equals method than


know check out it will return true and false for same case only we overridden 


equals method .


it compare object on basic of content(id) of object


but ==


still compare references of object.


----Output-----
   true
   false
   true


It may be worth adding that for wrapper objects for primitive types - i.e. Int, Long, Double - == will return true if the two values are equal.


To contrast, putting the above two Longs into two separate ArrayLists, equals sees them as the same, but == doesn't.


Since Java doesn’t support operator overloading, == behaves identical
  for every object but equals() is method, which can be overridden in
  Java and logic to compare objects can be changed based upon business
  rules.


Main difference between == and equals in Java is that "==" is used to
  compare primitives while equals() method is recommended to check
  equality of objects.


String comparison is a common scenario of using both == and equals method. Since java.lang.String class override equals method, It
  return true if two String object contains same content but == will
  only return true if two references are pointing to same object.


Here is an example of comparing two Strings in Java for equality using == and equals() method which will clear some doubts:


The String pool (aka interning) and Integer pool blur the difference further, and may allow you to use == for objects in some cases instead of .equals


This can give you greater performance (?), at the cost of greater complexity.


E.g.:


Complexity tradeoff: the following may surprise you:


I advise you to stay away from such micro-optimization, and always use .equals for objects, and == for primitives:


Basically, == compares if two objects have the same reference on the heap, so unless two references are linked to the same object, this comparison will be false.


equals() is a method inherited from Object class. This method by default compares if two objects have the same referece. It means:


object1.equals(object2) <=> object1 == object2


However, if you want to establish equality between two objects of the same class you should override this method. It is also very important to override the method hashCode() if you have overriden equals().


Implement hashCode() when establishing equality is part of the Java Object Contract. If you are working with collections, and you haven't implemented hashCode(), Strange Bad Things could happen:


null will be printed after executing the previous code if you haven't implemented hashCode().


The major difference between == and equals() is


1) == is used to compare primitives.


For example : 


2) equals() is used to compare objects.
For example :


"==" are actually comparing the two object references to see if they point to the same object.


"equals" which is a “deep comparison” that compares the actual string values. 






I am having a error for my GUI. Trying to set title bar icon then be included in a Runnable JAR.


Here is the error I am getting:


The image is in the correct directory which "resources" folder is the root of the 
project file


First of all, change this line : 


to this : 


More info, on as to where lies the difference between the two approaches, can be found on this thread - Different ways of loading a Resource


For Eclipse: 


For NetBeans: 


For IntelliJ IDEA:


Use the last link to check how to access this file now in Java code. Though for this example, one would be using 


getClass().getResource("/resources/images/myImage.imageExtension");


Press Shift + F10, to make and run the project. The resources and images folders, will be created automatically inside the out folder.


If you are doing it manually : 


QUICK REFERENCE CODE EXAMPLE(though for more detail consider, A little extra clarification link):


The image files must be in the directory resources/ in your JAR, as shown in How to Use Icons and this example for the directory named images/.


There's a much easier way to load and set an image as a frame icon:


And thats all :)! You don't even have to use a try-catch block because ImageIcon does not throw any declared exceptions. And due to getClass().getResource(), it works both from file system and from a jar depending how you run your application.


If you need to check whether the image is available, you can check if the URL returned by getResource() is null:






Consider:


What would the equivalent for loop look like without using the for each syntax?


Note that if you need to use i.remove(); in your loop, or access the actual iterator in some way, you cannot use the for ( : ) idiom, since the actual iterator is merely inferred.


As was noted by Denis Bueno, this code works for any object that implements the Iterable interface.


Also, if the right-hand side of the for (:) idiom is an array rather than an Iterable object, the internal code uses an int index counter and checks against array.length instead. See the Java Language Specification.


for each is also valid for arrays. e.g.


which is essentially equivalent of


So, overall summary:
[nsayer]The following is the longer form of what is happening:


Note that if you need to use
  i.remove(); in your loop, or access
  the actual iterator in some way, you
  cannot use the for( : ) idiom, since
  the actual Iterator is merely
  inferred.


[Denis Bueno]


It's implied by nsayer's answer, but
  it's worth noting that the OPs for(..)
  syntax will work when "someList" is
  anything that implements
  java.lang.Iterable -- it doesn't have
  to be a list, or some collection from
  java.util. Even your own types,
  therefore, can be used with this
  syntax.


Here is an answer which does not assume knowledge of Java Iterators. It is less precise but is useful for education. 


While programming we often write code that looks like the following: 


The foreach syntax allows this common pattern to be written in a more natural and less syntactically noisy way.


Additionally this syntax is valid for objects such as Lists or Sets which do not support array indexing but which do implement the Java Iterable interface. 


The foreach loop, added in Java 5 (also called the "enhanced for loop"), is equivalent to using a java.util.Iterator--it's syntactic sugar for the same thing. Therefore, when reading each element, one by one and in order, a foreach should always be chosen over an iterator, as it is more convenient and concise.


The foreach loop, added in Java 5 (also called the "enhanced for loop"), is equivalent to using a java.util.Iterator--it's syntactic sugar for the same thing. Therefore, when reading each element, one by one and in order, a foreach should always be chosen over an iterator, as it is more convenient and concise.


foreach


Iterator


There are situations where you must use an Iterator directly. For example, attempting to delete an element while using a foreach can (will?) result in a ConcurrentModificationException.


There are situations where you must use an Iterator directly. For example, attempting to delete an element while using a foreach can (will?) result in a ConcurrentModificationException.


foreach vs. for: Basic differences


The only practical difference between for and foreach is that, in the case of indexable objects, you do not have access to the index. An example when the basic for loop is required:


The only practical difference between for and foreach is that, in the case of indexable objects, you do not have access to the index. An example when the basic for loop is required:


Although you could manually create a separate index int-variable with foreach


Although you could manually create a separate index int-variable with foreach


it is not recommended, since variable-scope is not ideal, and the basic for loop is simply the standard and expected format for this use-case.
foreach vs. for: Performance
When accessing collections, a foreach is significantly faster than the basic for loop's array access. When accessing arrays, however--at least with primitive and wrapper-arrays--access via indexes is dramatically faster.
Timing the difference between iterator and index access for primitive int-arrays
Indexes are 23-40 percent faster than iterators when accessing int or Integer arrays. Here is the output from the testing class at the bottom of this post, which sums the numbers in a 100-element primitive-int array (A is iterator, B is index):
[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 358,597,622 nanoseconds
Test B: 269,167,681 nanoseconds
B faster by 89,429,941 nanoseconds (24.438799231635727% faster)

[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 377,461,823 nanoseconds
Test B: 278,694,271 nanoseconds
B faster by 98,767,552 nanoseconds (25.666236154695838% faster)

[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 288,953,495 nanoseconds
Test B: 207,050,523 nanoseconds
B faster by 81,902,972 nanoseconds (27.844689860906513% faster)

[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 375,373,765 nanoseconds
Test B: 283,813,875 nanoseconds
B faster by 91,559,890 nanoseconds (23.891659337194227% faster)

[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 375,790,818 nanoseconds
Test B: 220,770,915 nanoseconds
B faster by 155,019,903 nanoseconds (40.75164734599769% faster)

[C:\java_code\]java TimeIteratorVsIndexIntArray 1000000
Test A: 326,373,762 nanoseconds
Test B: 202,555,566 nanoseconds
B faster by 123,818,196 nanoseconds (37.437545972215744% faster)

I also ran this for an Integer array, and indexes are still the clear winner, but only between 18 and 25 percent faster.
For collections, iterators are faster than indexes
For a List of Integers, however, iterators are the clear winner. Just change the int-array in the test-class to
List<Integer> intList = Arrays.asList(new Integer[] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100});

and make the necssary changes to the test-function (int[] to List<Integer>, length to size(), etc)
[C:\java_code\]java TimeIteratorVsIndexIntegerList 1000000
Test A: 3,429,929,976 nanoseconds
Test B: 5,262,782,488 nanoseconds
A faster by 1,832,852,512 nanoseconds (34.326681820485675% faster)

[C:\java_code\]java TimeIteratorVsIndexIntegerList 1000000
Test A: 2,907,391,427 nanoseconds
Test B: 3,957,718,459 nanoseconds
A faster by 1,050,327,032 nanoseconds (26.038700083921256% faster)

[C:\java_code\]java TimeIteratorVsIndexIntegerList 1000000
Test A: 2,566,004,688 nanoseconds
Test B: 4,221,746,521 nanoseconds
A faster by 1,655,741,833 nanoseconds (38.71935684115413% faster)

[C:\java_code\]java TimeIteratorVsIndexIntegerList 1000000
Test A: 2,770,945,276 nanoseconds
Test B: 3,829,077,158 nanoseconds
A faster by 1,058,131,882 nanoseconds (27.134122749113843% faster)

[C:\java_code\]java TimeIteratorVsIndexIntegerList 1000000
Test A: 3,467,474,055 nanoseconds
Test B: 5,183,149,104 nanoseconds
A faster by 1,715,675,049 nanoseconds (32.60101667104192% faster)

[C:\java_code\]java TimeIteratorVsIndexIntList 1000000
Test A: 3,439,983,933 nanoseconds
Test B: 3,509,530,312 nanoseconds
A faster by 69,546,379 nanoseconds (1.4816434912159906% faster)

[C:\java_code\]java TimeIteratorVsIndexIntList 1000000
Test A: 3,451,101,466 nanoseconds
Test B: 5,057,979,210 nanoseconds
A faster by 1,606,877,744 nanoseconds (31.269164666060377% faster)

In one test they're almost equivalent, but with collections, iterator wins.
This post is based on two answers I wrote on stackexchange:
https://stackoverflow.com/questions/22110482/uses-and-syntax-for-for-each-loop-in-java/22110517#22110517
Should I use an Iterator or a forloop to iterate?

Some more information: Which is more efficient, a for-each loop, or an iterator?
The full testing class
I created this compare-the-time-it-takes-to-do-any-two-things class after reading this question on stackoverflow
   import  java.text.NumberFormat;
   import  java.util.Locale;
/**
   &lt;P&gt;{@code java TimeIteratorVsIndexIntArray 1000000}&lt;/P&gt;

   @see  &lt;CODE&gt;&lt;A HREF=&quot;https://stackoverflow.com/questions/180158/how-do-i-time-a-methods-execution-in-java&quot;&gt;https://stackoverflow.com/questions/180158/how-do-i-time-a-methods-execution-in-java&lt;/A&gt;&lt;/CODE&gt;
 **/
public class TimeIteratorVsIndexIntArray  {
   public static final NumberFormat nf = NumberFormat.getNumberInstance(Locale.US);
   public static final void main(String[] tryCount_inParamIdx0)  {
      int testCount;
      //Get try-count from command-line parameter
         try  {
            testCount = Integer.parseInt(tryCount_inParamIdx0[0]);
         }  catch(ArrayIndexOutOfBoundsException | NumberFormatException x)  {
            throw  new IllegalArgumentException("Missing or invalid command line parameter: The number of testCount for each test. " + x);
         }

      //Test proper...START
         int[] intArray = new int[] {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100};

         long lStart = System.nanoTime();
            for(int i = 0; i < testCount; i++)  {
               testIterator(intArray);
            }
         long lADuration = outputGetNanoDuration("A", lStart);

         lStart = System.nanoTime();
            for(int i = 0; i < testCount; i++)  {
               testFor(intArray);
            }
         long lBDuration = outputGetNanoDuration("B", lStart);

         outputGetABTestNanoDifference(lADuration, lBDuration, "A", "B");
   }
      private static final void testIterator(int[] int_array)  {
         int total = 0;
         for(int i = 0; i < int_array.length; i++)  {
            total += int_array[i];
         }
      }
      private static final void testFor(int[] int_array)  {
         int total = 0;
         for(int i : int_array)  {
            total += i;
         }
      }
      //Test proper...END

//Timer testing utilities...START
   public static final long outputGetNanoDuration(String s_testName, long l_nanoStart)  {
      long lDuration = System.nanoTime() - l_nanoStart;
      System.out.println("Test " + s_testName + ": " + nf.format(lDuration) + " nanoseconds");
      return  lDuration;
   }

   public static final long outputGetABTestNanoDifference(long l_aDuration, long l_bDuration, String s_aTestName, String s_bTestName)  {
      long lDiff = -1;
      double dPct = -1.0;
      String sFaster = null;
      if(l_aDuration > l_bDuration)  {
         lDiff = l_aDuration - l_bDuration;
         dPct = 100.00 - (l_bDuration * 100.0 / l_aDuration + 0.5);
         sFaster = "B";
      }  else  {
         lDiff = l_bDuration - l_aDuration;
         dPct = 100.00 - (l_aDuration * 100.0 / l_bDuration + 0.5);
         sFaster = "A";
      }
      System.out.println(sFaster + " faster by " + nf.format(lDiff) + " nanoseconds (" + dPct + "% faster)");
      return  lDiff;
   }
//Timer testing utilities...END
}




it is not recommended, since variable-scope is not ideal, and the basic for loop is simply the standard and expected format for this use-case.


foreach vs. for: Performance


When accessing collections, a foreach is significantly faster than the basic for loop's array access. When accessing arrays, however--at least with primitive and wrapper-arrays--access via indexes is dramatically faster.


Timing the difference between iterator and index access for primitive int-arrays


Indexes are 23-40 percent faster than iterators when accessing int or Integer arrays. Here is the output from the testing class at the bottom of this post, which sums the numbers in a 100-element primitive-int array (A is iterator, B is index):


Indexes are 23-40 percent faster than iterators when accessing int or Integer arrays. Here is the output from the testing class at the bottom of this post, which sums the numbers in a 100-element primitive-int array (A is iterator, B is index):


I also ran this for an Integer array, and indexes are still the clear winner, but only between 18 and 25 percent faster.


I also ran this for an Integer array, and indexes are still the clear winner, but only between 18 and 25 percent faster.


For collections, iterators are faster than indexes


For a List of Integers, however, iterators are the clear winner. Just change the int-array in the test-class to


For a List of Integers, however, iterators are the clear winner. Just change the int-array in the test-class to


and make the necssary changes to the test-function (int[] to List<Integer>, length to size(), etc)


In one test they're almost equivalent, but with collections, iterator wins.


In one test they're almost equivalent, but with collections, iterator wins.


This post is based on two answers I wrote on stackexchange:
https://stackoverflow.com/questions/22110482/uses-and-syntax-for-for-each-loop-in-java/22110517#22110517
Should I use an Iterator or a forloop to iterate?



This post is based on two answers I wrote on stackexchange:
https://stackoverflow.com/questions/22110482/uses-and-syntax-for-for-each-loop-in-java/22110517#22110517
Should I use an Iterator or a forloop to iterate?



Some more information: Which is more efficient, a for-each loop, or an iterator?


Some more information: Which is more efficient, a for-each loop, or an iterator?


The full testing class


I created this compare-the-time-it-takes-to-do-any-two-things class after reading this question on stackoverflow


I created this compare-the-time-it-takes-to-do-any-two-things class after reading this question on stackoverflow


The for-each loop in java uses the underlying iterator mechanism. So it's identical to the following:


In Java 8 features you can use this:


It's implied by nsayer's answer, but it's worth noting that the OPs for(..) syntax will work when "someList" is anything that implements java.lang.Iterable -- it doesn't have to be a list, or some collection from java.util.  Even your own types, therefore, can be used with this syntax.


The Java "for-each" loop construct will allow iteration over two types of objects:


The Iterable<T> interface has only one method: Iterator<T> iterator().  This works on objects of type Collection<T> because the Collection<T> interface extends Iterable<T>.


A foreach loop syntax is:


EX:


Output:


WARNING: You can access array elements with the foreach loop, but can NOT initialize them. Use the original for loop for that.

WARNING: You must match the type of the array with the other object.


If you want to edit elements, use the original for loop like this:


Now if we dump s to the consle, we get


The concept of foreach loop as mentioned in wikipedia is highlighted below:


Unlike other for loop constructs, however, foreach loops usually
  maintain no explicit counter: they essentially say "do this to
  everything in this set", rather than "do this x times". This avoids
  potential off-by-one errors and makes code simpler to read.


So the concept of foreach loop describes that the loop does not use any explicit counter which means that there is no need of using indexes to traverse in the list thus it saves user from off-by-one error. To describe the general concept of this off-by-one error. Let us take an example of a loop to traverse in a list using indexes.


But suppose if the list starts with index 1 then this loop is going to throw an exception as it will found no element at index 0 and this error is called off-by-one error. So to avoid this off-by-one error the concept of foreach loop is used. There may be other advantages too but this is what I think is the main concept and advantage of using foreach loop.


As defined in JLS for-each loop can have two forms:


If the type of Expression is a subtype of Iterable then translation is as:


If the Expression necessarily has an array type T[] then:


Java 8 has introduced streams which perform generally better. We can use them as:


Here's an equivalent expression.


Also note that using the "foreach" method in the original question does have some limitations, such as not being able to remove items from the list during the iteration.


The new for-loop is easier to read and removes the need for a separate iterator, but is only really usable in read-only iteration passes.


It adds beauty to your code by removing all the basic looping clutter. It gives a clean look to your code, justified below.


Normal for loop:


Using for-each:


for-each is a construct over a collection that implements Iterator. Remember that, your collection should implement Iterator; otherwise you can't use it with for-each.


The following line is read as "for each TimerTask t in list."


There is less chance for errors in case of for-each. You don't have to worry about initializing the iterator or initializing the loop counter and terminating it (where there is scope for errors).


It would look something like this. Very crufty. 


There is a good writeup on for each in the Sun documentation.


Alternative forEach in order to avoid your "for each":


Varian 1 (plain):


Variant 2 (parallel execution (faster)):


As so many good answers said, an object must implement the Iterable interface if it wants to use a for-each loop.


I'll post a simple example and try to explain in a different way how a for-each loop works.


The for-each loop example:


Then, if we use javap to decompile this class, we will get this bytecode sample:


As we can see from the last line of the sample, the compiler will automatically convert the use of for-each keyword to the use of an Iterator at compile time. That may explain why object, which doesn't implement the Iterable interface, will throw an Exception when it tries to use the for-each loop.


The Java for-each idiom can only be applied to arrays or objects of type *Iterable. This idiom is implicit as it truly backed by an Iterator. The Iterator is programmed by the programmer and often uses an integer index or a node (depending on the data structure) to keep track of its position. On paper it is slower than a regular for-loop, a least for "linear" structures like arrays and Lists but it provides greater abstraction. 






Several times I've been criticized for having suggested the use of the following methods:


on Swing components. I don't see any alternative to their use when I want to define proportions between displayed components. I have been told this:


With layouts the answer is always the same: use a suitable
  LayoutManager


I have searched the web a little bit, but I haven't found any comprehensive analysis of the subject. So I have the following questions:


I hope to have been clear.


Should I completely avoid the use of those methods?


Yes for application code.


The methods have been defined for a reason. So when should I use them? In which context? For what purposes?


I don't know, personally I think of it as an API design accident. Slightly forced by compound components having special ideas about child sizes. "Slightly", because they should have implemented their needs with a custom LayoutManager.


What exactly are the negative consequences of using those methods? (I can only think adding portability between systems with different screen resolution.)


Some (incomplete, and unfortunately the links are broken due to migration of SwingLabs to java.net) technical reasons are for instance mentioned in the Rules (hehe) or in the link @bendicott found in his/her comment to my answer. Socially, posing tons of work onto your unfortunate fellow who has to maintain the code and has to track down a broken layout.


I don't think any LayoutManager can exactly satisfy all desired layout needs. Do I really need to implement a new LayoutManager for every little variation on my layout?


Yes, there are LayoutManagers powerful enough to satisfy a very good approximation to "all layout needs". The big three are JGoodies FormLayout, MigLayout, DesignGridLayout. So no, in practice, you rarely write LayoutManagers except for simple highly specialized environments.


If the answer to 4 is "yes", won't this lead to a proliferation of LayoutManager classes which will become difficult to maintain? 


(The answer to 4 is "no".)


In a situation where I need to define proportions between children of a Component (for example, child 1 should use 10% of space, child 2 40%, child 3 50%), is it possible to achieve that without implementing a custom LayoutManager?


Any of the Big-Three can, can't even GridBag (never bothered to really master, too much trouble for too little power).


A few heuristics:


Don't use set[Preferred|Maximum|Minimum]Size() when you really mean to override get[Preferred|Maximum|Minimum]Size(), as might be done in creating your own component, shown here.


Don't use set[Preferred|Maximum|Minimum]Size() when you could rely on a component's carefully overridden getPreferred|Maximum|Minimum]Size, as shown here and below.


Do use set[Preferred|Maximum|Minimum]Size() to derive post-validate() geometry, as shown below and here.


If a component has no preferred size, e.g. JDesktopPane, you may have to size the container, but any such choice is arbitrary. A comment may help clarify the intent.


Consider alternate or custom layouts when you find that you would have to loop through many components to obtain derived sizes, as mentioned in these comments.





Should I completely avoid the use of those methods?


No, there is no formal evidence to suggest calling or overriding these methods is not allowed. In fact Oracle says these methods are used for giving size hints: http://docs.oracle.com/javase/tutorial/uiswing/layout/using.html#sizealignment.


They may also be overriden (which is the best practice for Swing) when extending a Swing component (rather then calling the method on the custom component instance)


Most importatly no matter how you specify your component's size, be sure that your component's container uses a layout manager that respects the requested size of the component. 


The methods have been defined for a reason. So when should I use them?
  In which context? For what purposes?


When you need to provide customized size hints to the containers Layout manager, so that the component will be laid out well


What exactly are the negative consequences of using those methods? (I
  can only think adding portability between systems with different
  screen resolution).


Many layout managers do not pay attention to a component's requested maximum size. However, BoxLayout and SpringLayout do. Furthermore, GroupLayout provides the ability to set the minimum, preferred or maximum size explicitly, without touching the component.


Make sure that you really need to set the component's exact size. Each Swing component has a different preferred size, depending on the font it uses and the look and feel. Thus having a set size might produce varied looks of the UI on different Systems


sometimes problems can be encountered with GridBagLayout and text fields, wherein if the size of the container is smaller than the preferred size, the minimum size gets used, which can cause text fields to shrink quite substantially.


JFrame does not enforce overriden getMinimumSize() only calling setMinimumSize(..) on its works


I don't think any LayoutManager can exactly satisfy all desired layout
  needs. Do I really need to implement a new LayoutManager for every
  little variation on my layout ?


If by implementing you mean using then yes. Not one LayoutManger can handle everything, each LayoutManager has its pros and cons thus each can be used together to produce the final layout.


Reference:


There are a lot of good answers here but I want to add a little more about the reasons why you should normally avoid these (the question just came up again in a duplicate topic):


With few exceptions, if you are using these methods you are probably fine-tuning your GUI to look good on a specific look-and-feel (and with your system-specific settings, e.g. your preferred desktop font, etc.). The methods themselves aren't inherently evil, but the typical reasons for using them are. As soon as you start tuning pixel positions and sizes in a layout you run the risk of your GUI breaking (or at minimum, looking bad), on other platforms.


As an example of this, try changing your application's default look-and-feel. Even just with the options available on your platform, you may be surprised at how poorly the results can be rendered.


So, in the name of keeping your GUI functional and nice-looking on all platforms (remember, one of the major benefits of Java is its cross-platformness), you should rely on layout managers, etc., to automatically adjust the sizes of your components so that it renders correctly outside of your specific development environment.


All that said, you can certainly conceive of situations where these methods are justified. Again, they aren't inherently evil, but their usage is normally a big red flag indicating potential GUI issues. Just make sure you are aware of the high potential for complications if/when you use them, and always try and think if there is another look-and-feel-independent solution to your problems -- more often than not you will find that these methods are not necessary.


By the way, if you find yourself getting frustrated with standard layout managers, there are a lot of good free, open-source third-party ones, for example JGoodies' FormLayout, or MigLayout. Some GUI builders even have built-in support for third-party layout managers -- Eclipse's WindowBuilder GUI editor, for example, ships with support for FormLayout and MigLayout.


If you are having trouble with layouts in Java Swing, then I can highly recommend the JGoodies FormLayout provided freely as part of the Forms freeware library by Karsten Lentzsch here.


This very popular layout manager is extremely flexible, allowing for very polished Java UIs to be developed.


You'll find Karsten's documentation in this pdf, and some rather good documentation from google here.


In a situation where I need to define proportions between children of a Component (child 1 should use 10% of space, child2 40% ,child3 50%), is it possible to achieve that without implementing a custom layout manager?


Maybe GridBagLayout would satisfy your needs. Besides that, there's a ton of layout managers on the web, and I bet there's one that fits your requirements.


These methods are poorly understood by most people. You should absolutely not ignore these methods. It is up to the layout manager if they honor these methods. This page has a table that shows which layout managers honor which of those methods:


http://thebadprogrammer.com/swing-layout-manager-sizing/


I have been writing Swing code for 8+ years and the layout managers included in the JDK have always served my needs. I have never needed a 3rd party layout manager to achieve my layouts.


I will say that you shouldn't try to give the layout manager hints with these methods until you are sure you need them. Do your layout without giving any sizing hints (i.e. let the layout manager do its job) and then you can make minor corrections if you need to.


I am seeing it differenty than the accepted answer.


Never avoid! They're there to express the size constraints of your components to the layout manager. You can avoid using them if you're not using any layout manager and try to manage the visual layout on your own.


Unfortunately, Swing is not coming with reasonable default dimensions. However, instead of setting the dimensions of a component, it is better OOP to descend your own component with reasonable defaults. (In that case you call setXXX in your descendant class.) Alternatively, you can override the getXXX methods for the same effect.


Always. When you create a component, set its realistic min/preferred/max size according to the use of that component. For example, if you have a JTextField for entering country symbols such as UK, its preferred size shall be as wide to fit two chars (with the current font, etc.) but probably it is meaningless to let it grow any bigger. After all, country symbols are two chars. 
As opposite, if you have a JTextField for entering e.g. a customer name, it can have a preferred size for like the pixel size for 20 chars, but can grow to bigger if the layout is resized, so set the maximum size to more. At the same time, having a 0px wide JTextField is pointless, so set a realistic minimum size (I would say the pixel size of 2 chars).


(I can only think adding portability between systems with different screen resolution).


No negative consequences. These are hints for the layout manager.


Do I really need to implement a new LayoutManager for every little variation on my layout ?


No, definitely not. The usual approach is to cascade different basic layoutmanagers such as horizontal and vertical layout.


For example, the layout below:


is having two parts. The left and right parts are a horizontal layout. The right part is a JPanel added to the horizontal layout, and this JPanel is having a vertical layout which lays out the buttons vertically.


Of course, this can grow tricky with a real life layout. Therefore grid-based layout managers such as MigLayout are much better if you're about to develop anything serious.


No, you definitely shall not develop layout managers, unless you need something very special.


between children of a Component (eg, child1 should use 10% of space, child2 40% ,child3 50%), is it possible to achieve that without implementing a custom LayoutManager?


Basically, once the preferred sizes are set right, you may not want to do anything in percentage. Simply, because percentages are pointless (e.g. it is pointless to have a JTextField 10% of the window size - since one can shrink the window so that JTextField becomes 0px wide, or can expand the window so that the JTextField is across two displays on a multi-display setup).


But, may times you may use the percentages to control sizes of bigger building blocks of your gui (panels, for example).


You can use JSplitPane where you can pre-set the ratio of the two sides. Or, you can use MigLayout which allows you to set such constraints in percentage, pixels, and other units.






What issues / pitfalls must be considered when overriding equals and hashCode?


equals() (javadoc) must define an equivalence relation (it must be reflexive, symmetric, and transitive). In addition, it must be consistent (if the objects are not modified, then it must keep returning the same value). Furthermore, o.equals(null) must always return false.


hashCode() (javadoc) must also be consistent (if the object is not modified in terms of equals(), it must keep returning the same value).


The relation between the two methods is:


Whenever a.equals(b), then a.hashCode() must be same as b.hashCode().


If you override one, then you should override the other.


Use the same set of fields that you use to compute equals() to compute hashCode().


Use the excellent helper classes EqualsBuilder and HashCodeBuilder from the Apache Commons Lang library. An example:


When using a hash-based Collection or Map such as HashSet, LinkedHashSet, HashMap, Hashtable, or WeakHashMap, make sure that the hashCode() of the key objects that you put into the collection never changes while the object is in the collection. The bulletproof way to ensure this is to make your keys immutable, which has also other benefits.


There are some issues worth noticing if you're dealing with classes that are persisted using an Object-Relationship Mapper (ORM) like Hibernate, if you didn't think this was unreasonably complicated already!


Lazy loaded objects are subclasses


If your objects are persisted using an ORM, in many cases you will be dealing with dynamic proxies to avoid loading object too early from the data store. These proxies are implemented as subclasses of your own class. This means thatthis.getClass() == o.getClass() will return false. For example:


If you're dealing with an ORM, using o instanceof Person is the only thing that will behave correctly.


Lazy loaded objects have null-fields


ORMs usually use the getters to force loading of lazy loaded objects. This means that person.name will be null if person is lazy loaded, even if person.getName() forces loading and returns "John Doe". In my experience, this crops up more often in hashCode() and equals().


If you're dealing with an ORM, make sure to always use getters, and never field references in hashCode() and equals().


Saving an object will change its state


Persistent objects often use a id field to hold the key of the object. This field will be automatically updated when an object is first saved. Don't use an id field in hashCode(). But you can use it in equals().


A pattern I often use is


But: you cannot include getId() in hashCode(). If you do, when an object is persisted, its hashCode changes. If the object is in a HashSet, you'll "never" find it again.


In my Person example, I probably would use getName() for hashCode and getId() plus getName() (just for paranoia) for equals(). It's okay if there are some risk of "collisions" for hashCode(), but never okay for equals().


hashCode() should use the non-changing subset of properties from equals()


A clarification about the obj.getClass() != getClass().


This statement is the result of equals() being inheritance unfriendly. The JLS (Java language specification) specifies that if A.equals(B) == true then B.equals(A) must also return true. If you omit that statement inheriting classes that override equals() (and change its behavior) will break this specification.


Consider the following example of what happens when the statement is omitted:


Doing new A(1).equals(new A(1)) Also, new B(1,1).equals(new B(1,1)) result give out true, as it should.


This looks all very good, but look what happens if we try to use both classes:


Obviously, this is wrong.


If you want to ensure the symmetric condition. a=b if b=a and the Liskov substitution principle call super.equals(other) not only in the case of B instance, but check after for A instance:


Which will output:


Where, if a is not a reference of B, then it might be a be a reference of class A (because you extend it), in this case you call super.equals() too.


For an inheritance-friendly implementation, check out Tal Cohen's solution, How Do I Correctly Implement the equals() Method?


Summary:


In his book Effective Java Programming Language Guide (Addison-Wesley, 2001), Joshua Bloch claims that "There is simply no way to extend an instantiable class and add an aspect while preserving the equals contract."  Tal disagrees.


His solution is to implement equals() by calling another nonsymmetric blindlyEquals() both ways.  blindlyEquals() is overridden by subclasses, equals() is inherited, and never overridden.


Example:


Note that equals() must work across inheritance hierarchies if the Liskov Substitution Principle is to be satisfied.


Still amazed that none recommended the guava library for this. 


There are two methods in super class as java.lang.Object. We need to override them to custom object.


Equal objects must produce the same hash code as long as they are equal, however unequal objects need not produce distinct hash codes.


If you want get more, please check this link as http://www.javaranch.com/journal/2002/10/equalhash.html


This is another example,
http://java67.blogspot.com/2013/04/example-of-overriding-equals-hashcode-compareTo-java-method.html


Have Fun! @.@


There are a couple of ways to do your check for class equality before checking member equality, and I think both are useful in the right circumstances.


I use #1 in a final equals implementation, or when implementing an interface that prescribes an algorithm for equals (like the java.util collection interfaces—the right way to check with with (obj instanceof Set) or whatever interface you're implementing). It's generally a bad choice when equals can be overridden because that breaks the symmetry property.


Option #2 allows the class to be safely extended without overriding equals or breaking symmetry.


If your class is also Comparable, the equals and compareTo methods should be consistent too. Here's a template for the equals method in a Comparable class:


For equals, look into Secrets of Equals by Angelika Langer. I love it very much. She's also a great FAQ about Generics in Java. View her other articles here (scroll down to "Core Java"), where she also goes on with Part-2 and "mixed type comparison". Have fun reading them!


equals() method is used to determine the equality of two objects.


as int value of 10 is always equal to 10. But this equals() method is about equality of two objects. When we say object, it will have properties. To decide about equality those properties are considered. It is not necessary that all properties must be taken into account to determine the equality and with respect to the class definition and context it can be decided. Then the equals() method can be overridden.


we should always override hashCode() method whenever we override equals() method. If not, what will happen? If we use hashtables in our application, it will not behave as expected. As the hashCode is used in determining the equality of values stored, it will not return the right corresponding value for a key.


Default implementation given is hashCode() method in Object class uses the internal address of the object and converts it into integer and returns it.


Example Code Output:


One gotcha I have found is where two objects contain references to each other (one example being a parent/child relationship with a convenience method on the parent to get all children).
These sorts of things are fairly common when doing Hibernate mappings for example.


If you include both ends of the relationship in your hashCode or equals tests it's possible to get into a recursive loop which ends in a StackOverflowException.
The simplest solution is to not include the getChildren collection in the methods.


Logically we have:


a.getClass().equals(b.getClass()) && a.equals(b) ⇒ a.hashCode() == b.hashCode()


But not vice-versa!






What's the simplest way to create and write to a (text) file in Java?


Note that each of the code samples below throw IOExcepions. Try/catch/finally blocks have been omitted for brevity. See this tutorial for information about exception handling.


Creating a text file (note that this will overwrite the file if it already exists):


Creating a binary file (will also overwrite the file):


Java 7+ users can use the Files class to write to files:


Creating a text file:


Creating a binary file:


In Java 7 and up:


There are useful utilities for that though:


Note also that you can use a FileWriter, but it uses the default encoding, which is often a bad idea - it's best to specify the encoding explicitly.


Below is the original, prior-to-java-7 answer


See also: Reading, Writing, and Creating Files (includes NIO2).


If you already have the content you want to write to the file (and not generated on the fly), the java.nio.file.Files addition in Java 7 as part of native I/O provides the simplest and most efficient way to achieve your goals.


Basically creating and writing to a file is one line only, moreover one simple method call!


The following example creates and writes to 6 different files to showcase how it can be used:


Here's a little example program to create or overwrite a file. It's the long version so it can be understood more easily.


Use:


Using try() will close stream automatically. This version is short, fast (buffered) and enables choosing encoding.  


This feature was introduced in Java 7.  


A very simple way to create and write to a file in Java:


Reference: File create Example in java


Here we are entering a string into a text file:


We can easily create a new file and add content into it.


If you wish to have a relatively pain-free experience you can also have a look at the Apache Commons IO package, more specifically the FileUtils class.


Never forget to check third-party libraries. Joda-Time for date manipulation, Apache Commons Lang StringUtils for common string operations and such can make your code more readable. 


Java is a great language, but the standard library is sometimes a bit low-level. Powerful, but low-level nonetheless.


Since the author did not specify whether they require a solution for Java versions that have been EoL'd (by both Sun and IBM, and these are technically the most widespread JVMs), and due to the fact that most people seem to have answered the author's question before it was specified that it is a text (non-binary) file, I have decided to provide my answer.


First of all, Java 6 has generally reached end of life, and since the author did not specify he needs legacy compatibility, I guess it automatically means J7 or above (J7 is not yet EoL'd by IBM). So, we can look right at the file I/O tutorial: https://docs.oracle.com/javase/tutorial/essential/io/legacy.html


Prior to the Java SE 7 release, the java.io.File class was the
  mechanism used for file I/O, but it had several drawbacks.


Oh well, that rules out java.io.File. If a file cannot be written/appended, you may not be able to even know why.


We can continue looking at the tutorial: https://docs.oracle.com/javase/tutorial/essential/io/file.html#common


If you have all lines you will write (append) to the text file in advance, the recommended approach is
https://docs.oracle.com/javase/8/docs/api/java/nio/file/Files.html#write-java.nio.file.Path-java.lang.Iterable-java.nio.charset.Charset-java.nio.file.OpenOption...-


Here's an example (simplified):


Another example (append):


If you want to write file content as you go:
https://docs.oracle.com/javase/8/docs/api/java/nio/file/Files.html#newBufferedWriter-java.nio.file.Path-java.nio.charset.Charset-java.nio.file.OpenOption...-


Simplified example (J8 or up):


Another example (append):


These methods require minimal effort on the author's part and should be preferred to all others when writing to [text] files.


Use:


I think this is the shortest way:


If you for some reason want to separate the act of creating and writing, the Java equivalent of touch is


createNewFile() does an existence check and file create atomically.  This can be useful if you want to ensure you were the creator of the file before writing to it, for example.


To create file without overwriting existing file:


The simplest way I can find:


It will probably only work for 1.7+.


One line only !
path and line are Strings 


If we are using Java 7 and above and also know the content to be added (appended) to the file we can make use of newBufferedWriter method in NIO package.


There are few points to note:


Though OP has not asked but just in case we want to search for lines having some specific keyword e.g. confidential we can make use of stream APIs in Java:


File reading and writing using input and outputstream:


Just include this package:


And then you can use this code to write the file:


There are some simple ways, like:


It's worth a try for Java 7+:


It looks promising...


Using Google's Guava library, we can create and write to a file very 
easily.


The example creates a new fruits.txt file in the project root directory.


You can even create a temporary file using a system property, which will be independent of which OS you are using.


For multiple files you can use:


It's working great.


Reading collection with customers and saving to file, with JFilechooser.


Creating a sample file:






This is a canonical question for a problem frequently posted on StackOverflow.


I'm following a tutorial. I've created a new activity using a wizard. I get NullPointerException when attempting to call a method on Views obtained with findViewById() in my activity onCreate().


Activity onCreate():


Layout XML (fragment_main.xml):


The tutorial is probably outdated, attempting to create an activity-based UI instead of the fragment-based UI preferred by wizard-generated code.


The view is in the fragment layout (fragment_main.xml)  and not in the activity layout (activity_main.xml). onCreate() is too early in the lifecycle to find it in the activity view hierarchy, and a null is returned. Invoking a method on null causes the NPE.


The preferred solution is to move the code to the fragment onCreateView(), calling findViewById() on the inflated fragment layout rootView:


As a side note, the fragment layout will eventually be a part of the activity view hierarchy and discoverable with activity findViewById() but only after the fragment transaction has been run. Pending fragment transactions get executed in super.onStart() after onCreate().


Try OnStart() method and just use 


or Declare any View using getView().findViewById method in onStart() 


Declare click listener on view by anyView.setOnClickListener(this);


Agreed, this is a typical error because people often don't really understand how Fragments work when they begin working on Android development. To alleviate confusion, I created a simple example code that I originally posted on Application is stopped in android emulator , but I posted it here as well.


An example is the following:


activity_container.xml:


ExampleFragment:


fragment_example.xml:


And that should be a valid example, it shows how you can use an Activity to display a Fragment, and handle events in that Fragment. And also how to communicate with the containing Activity.


The view "something" is in fragment and not in activity, so instead of accessing it in activity you must access it in the fragment class like 


In PlaceholderFragment.class


You are trying to access UI elements in the onCreate() but , it is too early to access them , since in fragment views can be created in onCreateView() method. 
And onActivityCreated() method is reliable to handle any actions on them, since activity is fully loaded in this state.


Try to shift your accessing views to the onViewCreated method of fragment because sometimes when you try to access the views in onCreate method they are not rendered at the time resulting null pointer exception.


Since you have declared your View in the fragment_main.xml,move that piece of code where you get the NPE in the onCreateView() method of the fragment.
This should solve the issue.


Add the following in your activity_main.xml


in the posted code above in the question there is a problem :
you are using R.layout.activity_main in oncreate method, but the xml files name is "fragment_main.xml" , means you are trying to get the view of fragment_main.xml file which is not being shown so it gives null pointer exception. change the code like :


I've got the same NullPointerException initializing a listener after calling findViewById onCreate and onCreateView methods.


But when I've used the onActivityCreated(Bundle savedInstanceState) {...} it works. So, I could access the GroupView and set my listener.


I hope it be helpful.


You have to remember important thing is :
NullPointerException occurs when you have declared your variable and trying to retreive its value before assigning value to it.






In Java, arrays don't override toString(), so if you try to print one directly, you get weird output including the memory location:


But usually we'd actually want something more like [1, 2, 3, 4, 5]. What's the simplest way of doing that? Here are some example inputs and outputs:


Since Java 5 you can use Arrays.toString(arr) or Arrays.deepToString(arr) for arrays within arrays. Note that the Object[] version calls .toString() on each object in the array. The output is even decorated in the exact way you're asking.


Examples:


Output:


Output:


Output:


Output:


Always check the standard libraries first.  Try:


or if your array contains other arrays as elements:


This is nice to know, however, as for "always check the standard libraries first" I'd never have stumbled upon the trick of Arrays.toString( myarray )


--since I was concentrating on the type of myarray to see how to do this. I didn't want to have to iterate through the thing: I wanted an easy call to make it come out similar to what I see in the Eclipse debugger and myarray.toString() just wasn't doing it.


In JDK1.8 you can use aggregate operations and a lambda expression:


If you're using Java 1.4, you can instead do:


(This works in 1.5+ too, of course.)


Starting with Java 8, one could also take advantage of the join() method provided by the String class to print out array elements, without the brackets, and separated by a delimiter of choice (which is the space character for the example shown below):


The output will be "Hey there amigo!".


Arrays.deepToString(arr) only prints on one line. 


To actually get a table to print as a two dimensional table, I had to do this: 


It seems like the Arrays.deepToString(arr) method should take a separator string, but unfortunately it doesn't.


As a direct answer, the solution provided by several, including @Esko, using the Arrays.toString and Arrays.deepToString methods, is simply the best.


Below I try to list some of the other methods suggested, attempting to improve a little, with the most notable addition being the use of the Stream.collect operator, using a joining Collector, to mimic what the String.join is doing.


Prior to Java 8 we could have used Arrays.toString(array) to print one dimensional array and Arrays.deepToString(array) for multi-dimensional arrays. We have got the option of Stream and lambda in Java 8 which can also be used for the printing the array.


Printing One dimensional Array:


The output is:


[1, 2, 3, 4, 5]
  [John, Mary, Bob]
  1
  2
  3
  4
  5
  John
  Mary
  Bob


Printing Multi-dimensional Array
Just in case we want to print multi-dimensional array we can use Arrays.deepToString(array) as:


Now the point to observe is that the method Arrays.stream(T[]), which in case of int[] returns us Stream<int[]> and then method flatMapToInt() maps each element of stream with the contents of a mapped stream produced by applying the provided mapping function to each element.


The output is:


[[11, 12], [21, 22], [31, 32, 33]]
  [[John, Bravo], [Mary, Lee], [Bob, Johnson]]
  11
  12
  21
  22
  31
  32
  33
  John
  Bravo
  Mary
  Lee
  Bob
  Johnson


Different Ways to Print Arrays in Java:


Simple Way   


Output:
      [One, Two, Three, Four]


Using toString()


Output: [One, Two, Three, Four]


Printing Array of Arrays


Output: [[Ljava.lang.String;@1ad086a [[Ljava.lang.String;@10385c1,
  [Ljava.lang.String;@42719c] [[Fifth, Sixth], [Seventh, Eighth]]


Resource: Access An Array


Using regular for loop is the simplest way of printing array in my opinion.
Here you have a sample code based on your intArray


It gives output as yours
    1, 2, 3, 4, 5


There's one additional way if your array is of type char[]:


prints 


I came across this post in Vanilla #Java recently. It's not very convenient writing Arrays.toString(arr);, then importing java.util.Arrays; all the time.


Please note, this is not a permanent fix by any means. Just a hack that can make debugging simpler. 


Printing an array directly gives the internal representation and the hashCode. Now, all classes have Object as the parent-type. So, why not hack the Object.toString()? Without modification, the Object class looks like this:


What if this is changed to:


This modded class may simply be added to the class path by adding the following to the command line: -Xbootclasspath/p:target/classes.


Now, with the availability of deepToString(..) since Java 5, the toString(..) can easily be changed to deepToString(..) to add support for arrays that contain other arrays.


I found this to be a quite useful hack and it would be great if Java could simply add this. I understand potential issues with having very large arrays since the string representations could be problematic. Maybe pass something like a System.outor a PrintWriter for such eventualities. 


It should always work whichever JDK version you use:


It will work if the Array contains Objects. If the Array contains primitive types, you can use wrapper classes instead storing the primitive directly as..


Example: 


Replace it with:


Update :


Yes ! this is to be mention that converting an array to an object array OR to use the Object's array is costly and may slow the execution. it happens by the nature of java called autoboxing.   


So only for printing purpose, It should not be used. we can make a function which takes an array as parameter and prints the desired format as


A simplified shortcut I've tried is this:


It will print


No loops required in this approach and it is best for small arrays only


In java 8 it is easy. there are two keywords


method reference: ::println


If you want to print all elements in the array in the same line, then just use print instead of println i.e. 


Another way without method reference just use:


To add to all the answers, printing the object as a JSON string is also an option.


Using Jackson:


Using Gson:


You could loop through the array,  printing out each item, as you loop. For example:


Output:


Using org.apache.commons.lang3.StringUtils.join(*) methods can be an option
For example:


I used the following dependency 


for each loop can also be used to print elements of array:


There Are Following way to print Array 


The simplest way to print an array is to use a for-loop:






If I have a Java source file (*.java) or a class file (*.class), how can I convert it to a .exe file?


I also need an installer for my program.


Is there an open source program that can do that?


Some options: 


See also Distributing your Application as an executable JAR file and the Oracle docs on how to create a jar file that can be executed with a double-click on Windows.


(EDIT: Last release was in 2007)


JSmooth is a Java Executable Wrapper. It creates native Windows launchers (standard .exe) for your java applications. It makes java deployment much smoother and user-friendly, as it is able to find any installed Java VM by itself.


(EDIT: Shareware: Last updated in 08/29/2013 version-8.4)


JexePack is a command line tool (great for automated scripting) that allows you to package your Java application (class files), optionally along with its resources (like GIF/JPG/TXT/etc), into a single compressed 32-bit Windows EXE, which runs using Sun's Java Runtime Environment. Both console and windowed applications are supported.


(EDIT: Commercial with Free Trial, Last version is from 2012)


A LAX Executable is an executable file that is used to launch a Java application on any LaunchAnywhere-compatible platform. Currently, InstallAnywhere creates LaunchAnywheres on Windows 95/98/NT/2000/Me, Solaris, Linux, and Mac OS X. LaunchAnywhere enables end-users to double-click on an icon (Windows or Mac OS X) or type a single command (UNIX) to start a Java application.


See also for reference Convert Java to EXE: Why, When, When Not and How


Launch4j


Launch4j is a cross-platform tool for wrapping Java applications distributed as jars in lightweight Windows native executables. The executable can be configured to search for a certain JRE version or use a bundled one, and it's possible to set runtime options, like the initial/max heap size. The wrapper also provides better user experience through an application icon, a native pre-JRE splash screen, a custom process name, and a Java download page in case the appropriate JRE cannot be found. 


GCJ: The GNU Compiler for Java can compile Java source code into native machine code, including Windows executables.


Although not everything in Java is supported under GCJ, especially the GUI components (see 
What Java API's are supported? How complete is the support? question from the FAQ). I haven't used GCJ much, but from the limited testing I've done with console applications, it seems fine.


One downside of using GCJ to create an standalone executable is that the size of the resulting EXE can be quite large. One time I compiled a trivial console application in GCJ and the result was an executable about 1 MB. (There may be ways around this that I am not aware of. Another option would be executable compression programs.)


In terms of open-source installers, the Nullsoft Scriptable Install System is a scriptable installer. If you're curious, there are user contributed examples on how to detect the presence of a JRE and install it automatically if the required JRE is not installed. (Just to let you know, I haven't used NSIS before.)


For more information on using NSIS for installing Java applications, please take a look at my response for the question "What's the best way to distribute Java applications?"


You can try many of the java wrappers out there like JSmooth, JWrapper, and other utilities but you can also make a .bat with the following code:
start javaw -jar JarFile.jar
and convert the bat to an exe using any .bat to .exe converter.


The latest Java Web Start has been enhanced to allow good offline operation as well as allowing "local installation".  It is worth looking into.


We're using Install4J to build installers for windows or unix environments.


It's easily customizable up to the point where you want to write scripts for special actions that cannot be done with standard dialogues. But even though we're setting up windows services with it, we're only using standard components.


I think Launch4J is from the same company (just the launcher - no installer).


PS: sadly i'm not getting paid for this endorsement. I just like that tool.


IMHO JSmooth seems to do a pretty good job.


If you need to convert your entire application to native code, i.e. an EXE plus DLLs, there is ExcelsiorJET. I found it works well and provided an alternative to bundling a JRE.


Alternatively, you can use some java-to-c translator (e.g., JCGO) and compile the generated C files to a native binary (.exe) file for the target platform.


I would say launch4j is the best tool for converting a java source code(.java) to .exe file
You can even bundle a jre with it for distribution and the exe can even be iconified.
Although the size of application increases, it makes sure that the application will work perfectly even if the user does not have a jre installed. It also makes sure that you are able to provide the specific jre required for your app without the user having to install it separately.
But unfortunately, java loses its importance. Its multi platform support is totally ignored and the final app is only supported for windows. But that is not a big deal, if you are catering only to windows users.


You can use Janel. This last works as an application launcher or service launcher (available from 4.x).


I can be forgiven for being against converting a java program to a .exe Application and I have My reasons. the Major one being that a java program can be compiled to a jar file from A lot of IDE's. When the program is in .jar format, it can run in Multiple Platforms as opposed to .exe which would run Only in very limited Environment. I am for the Idea that Java Programs shoudl not be converted to Exe unless it is very neccesary. One can always write .bat files that runs the Java program while it is a jar file.


if it is really neccesary to convert it to exe, Jar2Exe converter silently does that and one can also attach Libraries that are compiled together with the Main Application.


You can convert jar to exe using jar2exe. However you need to purchase the software. If you need a open source software i would suggest JSmooth.






The Java Language Specification defines a raw type as follows:


A raw type is defined to be one of:


The reference type that is formed by taking the name of a generic type declaration without an accompanying type argument list.


An array type whose element type is a raw type.


A non-static member type of a raw type R that is not inherited from a superclass or superinterface of R.


Here's an example to illustrate:


Here, MyType<E> is a parameterized type (JLS 4.5). It is common to colloquially refer to this type as simply MyType for short, but technically the name is MyType<E>.


mt has a raw type (and generates a compilation warning) by the first bullet point in the above definition; inn also has a raw type by the second bullet point.


MyType.Nested is not a parameterized type, even though it's a member type of a parameterized type MyType<E>, because it's static.


mt1, and mt2 are both declared with actual type parameters, so they're not raw types.


Essentially, raw types behaves just like they were before generics were introduced. That is, the following is entirely legal at compile-time.


The above code runs just fine, but suppose you also have the following:


Now we run into trouble at run-time, because names contains something that isn't an instanceof String.


Presumably, if you want names to contain only String, you could perhaps still use a raw type and manually check every add yourself, and then manually cast to String every item from names. Even better, though is NOT to use a raw type and let the compiler do all the work for you, harnessing the power of Java generics.


Of course, if you DO want names to allow a Boolean, then you can declare it as List<Object> names, and the above code would compile.


The following is a quote from Effective Java 2nd Edition, Item 23: Don't use raw types in new code:


Just what is the difference between the raw type List and the parameterized type List<Object>? Loosely speaking, the former has opted out generic type checking, while the latter explicitly told the compiler that it is capable of holding objects of any type. While you can pass a List<String> to a parameter of type List, you can't pass it to a parameter of type List<Object>. There are subtyping rules for generics, and List<String> is a subtype of the raw type List, but not of the parameterized type List<Object>. As a consequence, you lose type safety if you use raw type like List, but not if you use a parameterized type like List<Object>.


To illustrate the point, consider the following method which takes a List<Object> and appends a new Object().


Generics in Java are invariant. A List<String> is not a List<Object>, so the following would generate a compiler warning:


If you had declared appendNewObject to take a raw type List as parameter, then this would compile, and you'd therefore lose the type safety that you get from generics.


List<Object>, List<String>, etc are all List<?>, so it may be tempting to just say that they're just List instead. However, there is a major difference: since a List<E> defines only add(E), you can't add just any arbitrary object to a List<?>. On the other hand, since the raw type List does not have type safety, you can add just about anything to a List.


Consider the following variation of the previous snippet:


The compiler did a wonderful job of protecting you from potentially violating the type invariance of the List<?>! If you had declared the parameter as the raw type List list, then the code would compile, and you'd violate the type invariant of List<String> names.


Back to JLS 4.8:


It is possible to use as a type the erasure of a parameterized type or the erasure of an array type whose element type is a parameterized type. Such a type is called a raw type.


[...]


The superclasses (respectively, superinterfaces) of a raw type are the erasures of the superclasses (superinterfaces) of any of the parameterizations of the generic type.


The type of a constructor, instance method, or non-static field of a raw type C that is not inherited from its superclasses or superinterfaces is the raw type that corresponds to the erasure of its type in the generic declaration corresponding to C.


In simpler terms, when a raw type is used, the constructors, instance methods and non-static fields are also erased.


Take the following example:


When we use the raw MyType, getNames becomes erased as well, so that it returns a raw List!


JLS 4.6 continues to explain the following:


Type erasure also maps the signature of a constructor or method to a signature that has no parameterized types or type variables. The erasure of a constructor or method signature s is a signature consisting of the same name as s and the erasures of all the formal parameter types given in s.


The return type of a method and the type parameters of a generic method or constructor also undergo erasure if the method or constructor's signature is erased.


The erasure of the signature of a generic method has no type parameters.


The following bug report contains some thoughts from Maurizio Cimadamore, a compiler dev, and Alex Buckley, one of the authors of the JLS, on why this sort of behavior ought to occur: https://bugs.openjdk.java.net/browse/JDK-6400189. (In short, it makes the specification simpler.)


Here's another quote from JLS 4.8:


The use of raw types is allowed only as a concession to compatibility of legacy code. The use of raw types in code written after the introduction of genericity into the Java programming language is strongly discouraged. It is possible that future versions of the Java programming language will disallow the use of raw types.


Effective Java 2nd Edition also has this to add:


Given that you shouldn't use raw types, why did the language designers allow them? To provide compatibility.


The Java platform was about to enter its second decade when generics were introduced, and there was an enormous amount of Java code in existence that did not use generics. It was deemed critical that all this code remains legal and interoperable with new code that does use generics. It had to be legal to pass instances of parameterized types to methods that were designed for use with ordinary types, and vice versa. This requirement, known as migration compatibility, drove the decision to support raw types.


In summary, raw types should NEVER be used in new code. You should always use parameterized types.


Unfortunately, because Java generics are non-reified, there are two exceptions where raw types must be used in new code:


What are raw types in Java, and why do I often hear that they shouldn't be used in new code?


Raw-types are ancient history of the Java language. In the beginning there were Collections and they held Objects nothing more and nothing less. Every operation on Collections required casts from Object to the desired type.


While this worked most of the time, errors did happen


The old typeless collections could not enforce type-safety so the programmer had to remember what he stored within a collection.
Generics where invented to get around this limitation, the developer would declare the stored type once and the compiler would do it instead.


For Comparison:


More complex the Compareable interface:


Note that it is impossible to implement the CompareAble interface with compareTo(MyCompareAble) with raw types.
Why you should not use them:


What the compiler does:
Generics are backward compatible, they use the same java classes as the raw types do. The magic happens mostly at compile time.


Will be compiled as:


This is the same code you would write if you used the raw types directly. Thought I'm not sure what happens with the CompareAble interface, I guess that it creates two compareTo functions, one taking a MyCompareAble and the other taking an Object and passing it to the first after casting it.


What are the alternatives to raw types: Use generics


A raw type is the name of a generic class or interface without any type arguments. For example, given the generic Box class:


To create a parameterized type of Box<T>, you supply an actual type argument for the formal type parameter T:


If the actual type argument is omitted, you create a raw type of Box<T>:


Therefore, Box is the raw type of the generic type Box<T>. However, a non-generic class or interface type is not a raw type.


Raw types show up in legacy code because lots of API classes (such as the Collections classes) were not generic prior to JDK 5.0. When using raw types, you essentially get pre-generics behavior — a Box gives you Objects. For backward compatibility, assigning a parameterized type to its raw type is allowed:


But if you assign a raw type to a parameterized type, you get a warning:


You also get a warning if you use a raw type to invoke generic methods defined in the corresponding generic type:


The warning shows that raw types bypass generic type checks, deferring the catch of unsafe code to runtime. Therefore, you should avoid using raw types.


The Type Erasure section has more information on how the Java compiler uses raw types.


As mentioned previously, when mixing legacy code with generic code, you may encounter warning messages similar to the following:


Note: Example.java uses unchecked or unsafe operations.


Note: Recompile with -Xlint:unchecked for details.


This can happen when using an older API that operates on raw types, as shown in the following example:


The term "unchecked" means that the compiler does not have enough type information to perform all type checks necessary to ensure type safety. The "unchecked" warning is disabled, by default, though the compiler gives a hint. To see all "unchecked" warnings, recompile with -Xlint:unchecked.


Recompiling the previous example with -Xlint:unchecked reveals the following additional information:


To completely disable unchecked warnings, use the -Xlint:-unchecked flag. The @SuppressWarnings("unchecked") annotation suppresses unchecked warnings. If you are unfamiliar with the @SuppressWarnings syntax, see Annotations.


Original source: Java Tutorials 


You should specify the type-parameter. 


The warning advises that types that are defined to support generics should be parameterized, rather than using their raw form.


List is defined to support generics: public class List<E>. This allows many type-safe operations, that are checked compile-time.


A "raw" type in Java is a class which is non-generic and deals with "raw" Objects, rather than type-safe generic type parameters.


For example, before Java generics was available, you would use a collection class like this:


When you add your object to the list, it doesn't care what type of object it is, and when you get it from the list, you have to explicitly cast it to the type you are expecting.


Using generics, you remove the "unknown" factor, because you must explicitly specify which type of objects can go in the list:


Notice that with generics you don't have to cast the object coming from the get call, the collection is pre-defined to only work with MyObject.  This very fact is the main driving factor for generics.  It changes a source of runtime errors into something that can be checked at compile time.


What is a raw type and why do I often hear that they shouldn't be used in new code?


A "raw type" is the use of a generic class without specifying a type argument(s) for its parameterized type(s), e.g. using List instead of List<String>. When generics were introduced into Java, several classes were updated to use generics.  Using these class as a "raw type" (without specifying a type argument) allowed legacy code to still compile.


"Raw types" are used for backwards compatibility. Their use in new code is not recommended because using the generic class with a type argument allows for stronger typing, which in turn may improve code understandability and lead to catching potential problems earlier.


What is the alternative if we can't use raw types, and how is it better?


The preferred alternative is to use generic classes as intended - with a suitable type argument (e.g. List<String>). This allows the programmer to specify types more specifically, conveys more meaning to future maintainers about the intended use of a variable or data structure, and it allows compiler to enforce better type-safety.  These advantages together may improve code quality and help prevent the introduction of some coding errors.


For example, for a method where the programmer wants to ensure a List variable called 'names' contains only Strings:


The compiler wants you to write this:


because otherwise, you could add any type you like into list, making the instantiation as new ArrayList<String>() pointless. Java generics are a compile-time feature only, so an object created with new ArrayList<String>() will happily accept Integer or JFrame elements if assigned to a reference of the "raw type" List - the object itself knows nothing about what types it's supposed to contain, only the compiler does.


A raw-type is the a lack of a type parameter when using a generic type.


Raw-type should not be used because it could cause runtime errors, like inserting a double into what was supposed to be a Set of ints.


When retrieving the stuff from the Set, you don't know what is coming out. Let's assume that you expect it to be all ints, you are casting it to Integer; exception at runtime when the double 3.45 comes along.


With a type parameter added to your Set, you will get a compile error at once. This preemptive error lets you fix the problem before something blows up during runtime (thus saving on time and effort).


Here I am Considering multiple cases  through which you can clearify  the concept


ArrayList<String> arr it is a ArrayList reference variable with type String which reference to a ArralyList Object of Type String. It means it can hold only String type Object.


It is a Strict to String not  a Raw Type so, It will never raise an warning .


In this case ArrayList<String> arr is a strict type but your Object new ArrayList(); is a raw type. 


here arr is a Strict type. So, It will raise compile time error when adding a integer.


Warning :- A Raw Type Object is referenced to a Strict type Referenced Variable of ArrayList.


In this case ArrayList arr is a raw type but your Object new ArrayList<String>(); is a Strict type. 


It will add any type of Object into it because arr is a Raw Type.


Warning :- A Strict Type Object is referenced to a raw type referenced Variable.


What is saying is that your list is a List of unespecified objects. That is that Java does not know what kind of objects are inside the list. Then when you want to iterate the list you have to cast every element, to be able to access the properties of that element (in this case, String).


In general is a better idea to parametrize the collections, so you don't have conversion problems, you will only be able to add elements of the parametrized type and your editor will offer you the appropiate methods to select.


tutorial page.  


A raw type is the name of a generic class or interface without any type arguments. For example, given the generic Box class:  


To create a parameterized type of Box, you supply an actual type argument for the formal type parameter T:  


If the actual type argument is omitted, you create a raw type of Box:  


I found this page after doing some sample exercises and having the exact same puzzlement.


============== I went from this code as provide by the sample ===============


====================== To This code ========================


===============================================================================


It may be safer but took 4  hours to demuddle the philosophy...






What is the main difference between an inner class and a static nested class in Java? Does design / implementation play a role in choosing one of these?


From the Java Tutorial:


Nested classes are divided into two categories: static and non-static. Nested classes that are declared static are simply called static nested classes. Non-static nested classes are called inner classes. 


Static nested classes are accessed using the enclosing class name:


For example, to create an object for the static nested class, use this syntax:


Objects that are instances of an inner class exist within an instance of the outer class. Consider the following classes:


An instance of InnerClass can exist only within an instance of OuterClass and has direct access to the methods and fields of its enclosing instance.


To instantiate an inner class, you must first instantiate the outer class. Then, create the inner object within the outer object with this syntax:


see: Java Tutorial - Nested Classes


For completeness note that there is also such a thing as an inner class without an enclosing instance:


Here, new A() { ... } is an inner class defined in a static context and does not have an enclosing instance.


The Java tutorial says:


Terminology: Nested classes are
  divided into two categories: static
  and non-static. Nested classes that
  are declared static are simply called
  static nested classes. Non-static
  nested classes are called inner
  classes.


In common parlance, the terms "nested" and "inner" are used interchangeably by most programmers, but I'll use the correct term "nested class" which covers both inner and static.


Classes can be nested ad infinitum, e.g. class A can contain class B which contains class C which contains class D, etc. However, more than one level of class nesting is rare, as it is generally bad design.


There are three reasons you might create a nested class:


There are four kinds of nested class in Java. In brief, they are:


Let me elaborate in more details.





Static classes are the easiest kind to understand because they have nothing to do with instances of the containing class.


A static class is a class declared as a static member of another class. Just like other static members, such a class is really just a hanger on that uses the containing class as its namespace, e.g. the class Goat declared as a static member of class Rhino in the package pizza is known by the name pizza.Rhino.Goat.


Frankly, static classes are a pretty worthless feature because classes are already divided into namespaces by packages. The only real conceivable reason to create a static class is that such a class has access to its containing class's private static members, but I find this to be a pretty lame justification for the static class feature to exist.





An inner class is a class declared as a non-static member of another class:


Like with a static class, the inner class is known as qualified by its containing class name, pizza.Rhino.Goat, but inside the containing class, it can be known by its simple name. However, every instance of an inner class is tied to a particular instance of its containing class: above, the Goat created in jerry, is implicitly tied to the Rhino instance this in jerry. Otherwise, we make the associated Rhino instance explicit when we instantiate Goat:


(Notice you refer to the inner type as just Goat in the weird new syntax: Java infers the containing type from the rhino part. And, yes new rhino.Goat() would have made more sense to me too.)


So what does this gain us? Well, the inner class instance has access to the instance members of the containing class instance. These enclosing instance members are referred to inside the inner class via just their simple names, not via this (this in the inner class refers to the inner class instance, not the associated containing class instance): 


In the inner class, you can refer to this of the containing class as Rhino.this, and you can use this to refer to its members, e.g. Rhino.this.barry.





A local inner class is a class declared in the body of a method. Such a class is only known within its containing method, so it can only be instantiated and have its members accessed within its containing method. The gain is that a local inner class instance is tied to and can access the final local variables of its containing method. When the instance uses a final local of its containing method, the variable retains the value it held at the time of the instance's creation, even if the variable has gone out of scope (this is effectively Java's crude, limited version of closures).


Because a local inner class is neither the member of a class or package, it is not declared with an access level. (Be clear, however, that its own members have access levels like in a normal class.)


If a local inner class is declared in an instance method, an instantiation of the inner class is tied to the instance held by the containing method's this at the time of the instance's creation, and so the containing class's instance members are accessible like in an instance inner class. A local inner class is instantiated simply via its name, e.g. local inner class Cat is instantiated as new Cat(), not new this.Cat() as you might expect.





An anonymous inner class is a syntactically convenient way of writing a local inner class. Most commonly, a local inner class is instantiated at most just once each time its containing method is run. It would be nice, then, if we could combine the local inner class definition and its single instantiation into one convenient syntax form, and it would also be nice if we didn't have to think up a name for the class (the fewer unhelpful names your code contains, the better). An anonymous inner class allows both these things:


This is an expression returning a new instance of an unnamed class which extends ParentClassName. You cannot supply your own constructor; rather, one is implicitly supplied which simply calls the super constructor, so the arguments supplied must fit the super constructor. (If the parent contains multiple constructors, the “simplest” one is called, “simplest” as determined by a rather complex set of rules not worth bothering to learn in detail--just pay attention to what NetBeans or Eclipse tell you.)


Alternatively, you can specify an interface to implement:


Such a declaration creates a new instance of an unnamed class which extends Object and implements InterfaceName. Again, you cannot supply your own constructor; in this case, Java implicitly supplies a no-arg, do-nothing constructor (so there will never be constructor arguments in this case).


Even though you can't give an anonymous inner class a constructor, you can still do any setup you want using an initializer block (a {} block placed outside any method).


Be clear that an anonymous inner class is simply a less flexible way of creating a local inner class with one instance. If you want a local inner class which implements multiple interfaces or which implements interfaces while extending some class other than Object or which specifies its own constructor, you're stuck creating a regular named local inner class.


I don't think the real difference became clear in the above answers. 


First to get the terms right: 


Martin's answer is right so far. However, the actual question is: What is the purpose of declaring a nested class static or not?


You use static nested classes if you just want to keep your classes together if they belong topically together or if the nested class is exclusively used in the enclosing class. There is no semantic difference between a static nested class and every other class.


Non-static nested classes are a different beast. Similar to anonymous inner classes, such nested classes are actually closures. That means they capture their surrounding scope and their enclosing instance and make that accessible. Perhaps an example will clarify that. See this stub of a Container:


In this case you want to have a reference from a child item to the parent container. Using a non-static nested class, this works without some work. You can access the enclosing instance of Container with the syntax Container.this.


More hardcore explanations following:


If you look at the Java bytecodes the compiler generates for an (non-static) nested class it might become even clearer:


As you can see the compiler creates a hidden field Container this$0. This is set in the constructor which has an additional parameter of type Container to specify the enclosing instance. You can't see this parameter in the source but the compiler implicitly generates it for a nested class. 


Martin's example


would so be compiled to a call of something like (in bytecodes)


For the sake of completeness:


An anonymous class is a perfect example of a non-static nested class which just has no name associated with it and can't be referenced later.


I think that none of the above answers explain to you the real difference between a nested class and a static nested class in term of application design : 


A nested class could be nonstatic or static and in each case is a class defined within another class. A nested class should exist only to serve is enclosing class, if a nested class is useful by other classes (not only the enclosing), should be declared as a top level class.


Nonstatic Nested class : is implicitly associated with the enclosing instance of the containing class, this means that it is possible to invoke methods and access variables of the enclosing instance. One common use of a nonstatic nested class is to define an Adapter class.


Static Nested Class : can't access enclosing class instance and invoke methods on it, so should be used when the nested class doesn't require access to an instance of the enclosing class . A common use of static nested class is to implement a components of the outer object.


So the main difference between the two from a design standpoint is : nonstatic nested class can access instance of the container class, while static can't.


In simple terms we need nested classes primarily because Java does not provide closures.


Nested Classes are classes defined inside the body of another enclosing class. They are of two types - static and non-static.


They are treated as members of the enclosing class, hence you can specify any of the four access specifiers - private, package, protected, public. We don't have this luxury with top-level classes, which can only be declared public or package-private.


Inner classes aka Non-stack classes have access to other members of the top class, even if they are declared private while Static nested classes do not have access to other members of the top class.


Inner1 is our static inner class and Inner2 is our inner class which is not static. The key difference between them, you can't create an Inner2 instance without an Outer where as you can create an Inner1 object independently.


When would you use Inner class?


Think of a situation where Class A and Class B are related, Class B needs to access Class A members, and Class B is related only to Class A. Inner classes comes into the picture.


For creating an instance of inner class, you need to create an instance of your outer class.


or


When would you use static Inner class?


You would define a static inner class when you know that it does not have any relationship with the instance of the enclosing class/top class. If your inner class doesn't use methods or fields of the outer class, it's just a waste of space, so make it static.


For example, to create an object for the static nested class, use this syntax:


The advantage of a static nested class is that it doesn't need an object of the containing class/top class to work. This can help you to reduce the number of objects your application creates at runtime.


I think, the convention that is generally followed is this:


However, few other points to remembers are:


Top level classes and static nested class are semantically same except that in case of static nested class it can make static reference to private static fields/methods of its Outer [parent] class and vice versa.


Inner classes have access to instance variables of the enclosing instance of the Outer [parent] class. However, not all inner classes have enclosing instances, for example inner classes in static contexts, like an anonymous class used in a static initializer block, do not.


Anonymous class by default extends the parent class or implements the parent interface and there is no further clause to extend any other class or implement any more interfaces. So,


I feel that the bigger question that remains open which one to use and when? Well that mostly depends on what scenario you are dealing with but reading the reply given by @jrudolph may help you making some decision.


Here is key differences and similarities between Java inner class and static nested class.


Hope it helps!


Associated with instance of enclosing class so to instantiate it first needs an instance of outer class (note new keyword place):


Cannot define any static members itself


Cannot access outer class instance methods or fields


Not associated with any instance of enclosing class So to instantiate it:


According to Oracle documentation there're several reasons (full documentation):


It is a way of logically grouping classes that are only used in one place: If a class is useful to only one other class, then it is logical to embed it in that class and keep the two together. Nesting such "helper classes" makes their package more streamlined.


It increases encapsulation: Consider two top-level classes, A and B, where B needs access to members of A that would otherwise be declared private. By hiding class B within class A, A's members can be declared private and B can access them. In addition, B itself can be hidden from the outside world.


It can lead to more readable and maintainable code: Nesting small classes within top-level classes places the code closer to where it is used.


Nested class: class inside class


Types:


Difference:


Non-static nested class [Inner class]


In non-static nested class object of inner class exist within object of outer class. So that data member of outer class is accessible to inner class. So to create object of inner class we must create object of outer class first.


Static nested class


In static nested class object of inner class don't need object of outer class, because the word "static" indicate no need to create object.


If you want to access x, then write the following inside method


The instance of the inner class is created when instance of the outer class is created. Therefore the members and methods of the inner class have access to the members and methods of the instance (object) of the outer class. When the instance of the outer class goes out of scope, also the inner class instances cease to exist.


The static nested class doesn't have a concrete instance. It's just loaded when it's used for the first time (just like the static methods). It's a completely independent entity, whose methods and variables doesn't have any access to the instances of the outer class.


The static nested classes are not coupled with the outer object, they are faster, and they don't take heap/stack memory, because its not necessary to create instance of such class. Therefore the rule of thumb is to try to define static nested class, with as limited scope as possible (private >= class >= protected >= public), and then convert it to inner class (by removing "static" identifier) and loosen the scope, if it's really necessary.


The terms are used interchangeably.  If you want to be really pedantic about it, then you could define "nested class" to refer to a static inner class, one which has no enclosing instance.  In code, you might have something like this:


That's not really a widely accepted definition though.


There is a subtlety about the use of nested static classes that might be useful in certain situations.


Whereas static attributes get instantiated before the class gets instantiated via its constructor,
static attributes inside of nested static classes don't seem to get instantiated until after the
class's constructor gets invoked, or at least not until after the attributes are first referenced,
even if they are marked as 'final'.


Consider this example:


Even though 'nested' and 'innerItem' are both declared as 'static final'. the setting
of nested.innerItem doesn't take place until after the class is instantiated (or at least
not until after the nested static item is first referenced), as you can see for yourself
by commenting and uncommenting the lines that I refer to, above. The same does not hold
true for 'outerItem'.


At least this is what I'm seeing in Java 6.0.


In the case of creating instance, the instance of non 
static inner class is created with the reference of
object of outer class in which it is defined. This
means it have inclosing instance.
But the instance of static inner class
is created with the reference of Outer class, not with
the reference of object of outer class. This means it
have not inclosing instance.


For example:


Nested class is a very general term: every class which is not top level is a nested class.
An inner class is a non-static nested class.
Joseph Darcy wrote a very nice explanation about Nested, Inner, Member, and Top-Level Classes.


Ummm... an inner class IS a nested class... do you mean anonymous class and inner class?


Edit:  If you actually meant inner vs anonymous... an inner class is just a class defined within a class such as:


Whereas an anonymous class is an extension of a class defined anonymously, so no actual "class is defined, as in:


Further Edit:


Wikipedia claims there is a difference in Java, but I've been working with Java for 8 years, and it's the first I heard such a distinction... not to mention there are no references there to back up the claim... bottom line, an inner class is a class defined within a class (static or not), and nested is just another term to mean the same thing.


There is a subtle difference between static and non-static nested class... basically non-static inner classes have implicit access to instance fields and methods of the enclosing class (thus they cannot be constructed in a static context, it will be a compiler error).  Static nested classes, on the other hand, don't have implicit access to instance fields and methods, and CAN be constructed in a static context.


Targeting learner, who are novice to Java and/or Nested Classes 


Nested classes can be either:
 1. Static Nested classes.
 2. Non Static Nested classes. (also known as Inner classes) =>Please remember this



1.Inner classes
Example:


Inner classes are subsets of nested classes:


Specialty of Inner class:



2.Static Nested Classes:
Example:


Case 1:Instantiating a static nested class from a non-enclosing class


Case 2:Instantiating a static nested class from an enclosing class


Specialty of Static classes:


Conclusion:
Question: What is the main difference between a inner class and a static nested class in Java?
Answer: just go through specifics of each class mentioned above.


I don't think there is much to add here, most of the answers perfectly explain the differences between static nested class and Inner classes. However, consider the following issue when using nested classes vs inner classes. 
As mention in a couple of answers inner classes can not be instantiated without and instance of their enclosing class which mean that they HOLD a pointer to the instance of their enclosing class which can lead to memory overflow or stack overflow exception due to the fact the GC will not be able to garbage collect the enclosing classes even if they are not used any more. To make this clear check the following code out: 


If you remove the comment on // inner = null; The program will out put 
"I am destroyed !", but keeping this commented it will not.
The reason is that white inner instance is still referenced GC cannot collect it and because it references (has a pointer to) the outer instance it is not collected too. Having enough of these objects in your project and can run out of memory.
Compared to static inner classes which does not hold a point to inner class instance because it is not instance related but class related. 
The above program can print "I am destroyed !" if you make Inner class static and instantiated with Outer.Inner i = new Outer.Inner(); 


Inner class and nested static class in Java both are classes declared inside another class, known as top level class in Java. In Java terminology, If you declare a nested class static, it will called nested static class in Java while non static nested class are simply referred as Inner Class. 


What is Inner Class in Java?


Any class which is not a top level or declared inside another class is known as nested class and out of those nested classes, class which are declared non static are known as Inner class in Java. there are three kinds of Inner class in Java:


1) Local inner class    - is declared inside a code block or method.
2) Anonymous inner class - is a class which doesn't have name to reference and initialized at same place where it gets created.
3) Member inner class - is declared as non static member of outer class.


What is nested static class in Java?


Nested static class is another class which is declared inside a class as member and made static. Nested static class is also declared as member of outer class and can be make private, public or protected like any other member. One of the main benefit of nested static class over inner class is that instance of nested static class is not attached to any enclosing instance of Outer class. You also don't need any instance of Outer class to create instance of nested static class in Java.


1) It can access static data members of outer class including private.
2) Static nested class cannot access non-static (instance) data member or method.


Ref: Inner class and nested Static Class in Java with Example


I think people here should notice to Poster that : Static Nest Class just only the first inner class.
For example:


So, summarize, static class doesn't depend which class its contains. So, they cannot in normal class. (because normal class need an instance).


When we declare static member class inside a class, it is known as top level nested class or a static nested class. It can be demonstrated as below : 


When we declare non-static member class inside a class it is known as inner class. Inner class can be demonstrated as below : 


The following is an example of static nested class and inner class:


OuterClass.java


OuterClassTest:


The difference is that a nested class declaration that is also static can be instantiated outside of the enclosing class.


When you have a nested class declaration that is not static, also known as an inner class, Java won't let you instantiate it except via the enclosing class. The object created out of the inner class is linked to the object created from the outer class, so the inner class can reference the fields of the outer.


But if it's static, then the link does not exist, the outer fields cannot be accessed (except via an ordinary reference like any other object) and you can therefore instantiate the nested class by itself.


First of all There is no such class called Static class.The Static modifier use with inner class (called as Nested Class) says that it is a static member of Outer Class which means we can access it as with other static members and without having any instance of Outer class. (Which is benefit of static originally.) 


Difference between using Nested class and regular Inner class is:


First We can to instantiate Outerclass then we Can access Inner.


But if Class is Nested then syntax is:


Which uses the static Syntax as normal implementation of static keyword.


I have illustrated various possible correct and error scenario which can occur in java code.






What does ArrayIndexOutOfBoundsException mean and how do I get rid of it? 


Here is a code sample that triggers the exception:


Your first port of call should be the documentation which explains it reasonably clearly:


Thrown to indicate that an array has been accessed with an illegal index. The index is either negative or greater than or equal to the size of the array.


So for example:


As for how to avoid it... um, don't do that. Be careful with your array indexes.


One problem people sometimes run into is thinking that arrays are 1-indexed, e.g.


That will miss out the first element (index 0) and throw an exception when index is 5. The valid indexes here are 0-4 inclusive. The correct, idiomatic for statement here would be:


(That's assuming you need the index, of course. If you can use the enhanced for loop instead, do so.)


Update: as per your code snippet, 


The index is inclusive the array's length. This is out of bounds. You need to replace <= by <.


To put it briefly:


In the last iteration of


i will equal name.length which is an illegal index, since array indices are zero-based.


Your code should read


It means that you are trying to access an index of an array which is not valid as it is not in between the bounds.


For example this would initialize a primitive integer array with the upper bound 4.


Programmers count from zero. So this for example would throw an ArrayIndexOutOfBoundsException as the upper bound is 4 and not 5.


To avoid an array index out-of-bounds exception, one should use the enhanced-for statement where and when they can.


The primary motivation (and use case) is when you are iterating and you do not require any complicated iteration steps.  You would not be able to use an enhanced-for to move backwards in an array or only iterate on every other element.


You're guaranteed not to run out of elements to iterate over when doing this, and your [corrected] example is easily converted over.


The code below:


...is equivalent to this:


What causes ArrayIndexOutOfBoundsException?


If you think of a variable as a "box" where you can place a value, then an array is a series of boxes placed next to eachother, where the number of boxes is a finite and explicit integer.


Creating an array like this:


creates a row of 5 boxes, each holding an int. Each of the boxes have an index, a position in the series of boxes. This index starts at 0, and ends at N-1, where N is the size of the array (the number of boxes).


To retrieve one of the values from this series of boxes, you can refer to it through its index, like this:


Which will give you the value of the 4th box in the series (since the first box has index 0).


An ArrayIndexOutOfBoundsException is caused by trying to retrive a "box" that does not exist, by passing an index that is higher than the index of last "box", or negative.


With my running example, these code snippets would produce such an exception:


How to avoid ArrayIndexOutOfBoundsException


In order to prevent ArrayIndexOutOfBoundsException, there are some key points to consider:


Looping


When looping through an array, always make sure that the index you are retrieving is strictly smaller than the length of the array (the number of boxes). For instance:


Notice the <, never mix a = in there..


You might want to be tempted to do something like this:


Just don't. Stick to the one above (if you need to use the index) and it will save you a lot of pain.


Where possible, use foreach:


This way you won't have to think about indexes at all.


When looping, whatever you do, NEVER change the value of the loop iterator (here: i). The only place this should change value is to keep the loop going. Changing it otherwise is just risking an exception, and is in most cases not neccessary.


Retrieval/update


When retrieving an arbitrary element of the array, always check that it is a valid index against the length of the array:


In your code you have accessed the elements from index 0 to the length of the string array. name.length gives the number of string objects in your array of string objects i.e 3, but you can access only upto index 2 name[2],
because the array can be accessed from index 0 to name.length - 1 where you get name.length number of objects.


Even while using a for loop you have started with index zero and you should end with name.length - 1. In an array a[n] you can access form a[0] to a[n-1].


For eg:


In your Case:


So much for this simple question, but I just wanted to highlight a new feature in Java which will avoid all confusions around indexing in arrays even for beginners. Java-8 has abstracted the task of iterating for you.


What's the benefit? Well, one thing is the readability like English. Second, you need not worry about the ArrayIndexOutOfBoundsException


The most common case I've seen for seemingly mysterious ArrayIndexOutOfBoundsExceptions, ie apparently not cause by your own array handling code, is the concurrent use of SimpleDateFormat.  Particularly in a servlet or controller


If two threads enter the SimplateDateFormat.parse() method together you will likely see an ArrayIndexOutOfBoundsException. Note the synchronization section of the class javadoc for SimpleDateFormat.


Make sure there is no place in your code are you accessing thread unsafe classes like SimpleDateFormat in a concurrent manner like a servlet or controller.  Check all instance variables of your servlets and controllers for likely suspects.


For any Array of Length n , elements of the array will have an index from 0 to n-1.


If your program is trying to access any element(or memory) having array index greater than n-1, then java will throw ArrayIndexOutOfBoundsException


So here are two solutions that we can use in program


1.Maintaining count:


or some other looping statement like 


2.Better way go with For Each loop, in this method programmer has no needs to bother about the number of elements in the array.


you are getting ArrayIndexOutOfBoundsException due to i<=name.length part. name.length return the length of the string name , which is 3. hence when you try to access name[3], its illegal and throw an exception. 


resolved code : 


It's defined in the Java language specification:


The public final field length, which contains the number of components
  of the array. length may be positive or zero.





That's how this type of exception looks when thrown in Eclipse;
The number in red signifies the index you tried to access. So the code would look like this:


The error is thrown when you try to access an index which doesn't exist in that array. If an array has a length of 3:


then the only valid indexes are:


if an array has a length of 1:


then the only valid index is:


Any integer equal to the length of the array, or bigger than it: is out of bounds.
Any integer less than 0: is out of bounds;


P.S. If you look to have a better understanding of arrays and do some practical exercises, there's a video here: tutorial on arrays in java


You could not iterate or store more data than length of your array. In this case you could do like this:


or this:






A GUI with no white space appears 'crowded'.  How can I provide white space without resorting to explicitly setting the position or size of components?­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­


Using various LayoutManagers one can provide spacing between various components. 


Getter and setter methods


For Horizontal Spacing : BorderLayout.getHgap() and BorderLayout.setHgap(int hgap)


For Vertical Spacing : BorderLayout.getVgap() and BorderLayout.setVgap()


Getter and setter methods


For Horizontal Spacing : FlowLayout.getHgap() and FlowLayout.setHgap(int hgap)


For Vertical Spacing : FlowLayout.getVgap() and FlowLayout.setVgap()


Getter and setter methods


For Horizontal Spacing : GridLayout.getHgap() and GridLayout.setHgap(int hgap)


For Vertical Spacing : GridLayout.getVgap() and GridLayout.setVgap()


GridBagConstraints.insets


CardLayout(int hGap, int vGap)





There are a number of ways in a Swing GUI to provide a separation between components, and white space around components:


But more generally, look to:


Here is an example of using the layout separator hGap & vGap values & borders (specifically an EmptyBorder) to provide 'white' (actually shown as 'red' to make it very obvious) space.  Adjust the spinners to see the result.








When you use BoxLayout, Box.createVerticalGlue() method can help you to make some white space.


Another method is BorderFactory.createEmptyBorder(int top, int left, int bottom, int right). It can help you to make some white space around component.


Thanks for Andrew Thompson's remind.I've revised BoxLayout in recent days and I     find that Box.createVerticalGlue() can add some white space depend on the panel's size and you can not set the explicit pixel value of the length of white space.But Box.createVerticalStrut() can do that.  Here is a MCTaRE and show the    effect of those two methods.





Box.createHorizontalGlue() and Box.createHorizontalStrut(int height) can be used too. Besides, Box.createRigidArea(Dimension d) has the ability too create white space too.


MigLayout has multiple ways of creating space. (A space is called a gap in this layout.)
Gaps can be created at the highest level with layout constraints, it is possible to
create gaps between rows and column and gaps can be also set between individual 
components with component constraints. There are also specific gaps around the borders
of a container called insets which have their own specific keyword to be set.


The following example creates all these kinds of gaps:


We have four panels in the layout. Each of this panels has a MigLayout manager.


This line creates container insets and vertical gaps between panels.


Here we apply gaps for the whole grid structure and also set container gaps.


This line creates gaps between columns.


Row gaps are defined with this code.


Finally, it is possible to create gaps between individual components.





JGoodies FormLayout. 


Author Karsten Lentzsch has a collection of presentations on UI design.   In particular this PDF speaks to the need for aesthetic whitespace.  Adding meaningful space while also paying attention to clutter separates the wheat from the chaff.






I'm a bit confused about how Java generics handle inheritance / polymorphism.


Assume the following hierarchy -


Animal (Parent)


Dog - Cat (Children)


So suppose I have a method doSomething(List<Animal> animals). By all the rules of inheritance and polymorphism, I would assume that a List<Dog> is a List<Animal> and a List<Cat> is a List<Animal> - and so either one could be passed to this method. Not so. If I want to achieve this behavior, I have to explicitly tell the method to accept a list of any subset of Animal by saying doSomething(List<? extends Animal> animals). 


I understand that this is Java's behavior. My question is why? Why is polymorphism generally implicit, but when it comes to generics it must be specified?


No, a List<Dog> is not a List<Animal>. Consider what you can do with a List<Animal> - you can add any animal to it... including a cat. Now, can you logically add a cat to a litter of puppies? Absolutely not.


Suddenly you have a very confused cat.


Now, you can't add a Cat to a List<? extends Animal> because you don't know it's a List<Cat>. You can retrieve a value and know that it will be an Animal, but you can't add arbitrary animals. The reverse is true for List<? super Animal> - in that case you can add an Animal to it safely, but you don't know anything about what might be retrieved from it, because it could be a List<Object>.


What you are looking for is called covariant type parameters.  The problem is that they are not type-safe in the general case, specifically for mutable lists.  Suppose you have a List<Dog>, and it is allowed to function as a List<Animal>.  What happens when you try to add a Cat to this List<Animal> which is really a List<Dog>?  Automatically allowing type parameters to be covariant therefore breaks the type system.


It would be useful to add syntax to allow type parameters to be specified as covariant, which avoids the ? extends Foo in method declarations, but that does add additional complexity.


The reason a List<Dog> is not a List<Animal>, is that, for example, you can insert a Cat into a List<Animal>, but not into a List<Dog>... you can use wildcards to make generics more extensible where possible; for example, reading from  a List<Dog> is the similar to reading from a List<Animal> -- but not writing.


The Generics in the Java Language and the Section on Generics from the Java Tutorials have a very good, in-depth explanation as to why some things are or are not polymorphic or permitted with generics.


I would say the whole point of Generics is that it doesn't allow that. Consider the situation with arrays, which do allow that type of covariance:


That code compiles fine, but throws a runtime error (java.lang.ArrayStoreException: java.lang.Boolean in the second line). It is not typesafe. The point of Generics is to add the compile time type safety, otherwise you could just stick with a plain class without generics.


Now there are times where you need to be more flexible and that is what the ? super Class and ? extends Class are for. The former is when you need to insert into a type Collection (for example), and the latter is for when you need to read from it, in a type safe manner. But the only way to do both at the same time is to have a specific type.


A point I think should be added to what other answers mention is that while


List<Dog> isn't-a List<Animal> in Java


it is also true that


A list of dogs is-a list of animals in English (well, under a reasonable interpretation)


The way the OP's intuition works - which is completely valid of course - is the latter sentence. However, if we apply this intuition we get a language that is not Java-esque in its type system: Suppose our language does allow adding a cat to our list of dogs. What would that mean? It would mean that the list ceases to be a list of dogs, and remains merely a list of animals. And a list of mammals, and a list of quadrapeds.


To put it another way: A List<Dog> in Java does not mean "a list of dogs" in English, it means "a list which can have dogs, and nothing else".


More generally, OP's intuition lends itself towards a language in which operations on objects can change their type, or rather, an object's type(s) is a (dynamic) function of its value. 


The basis logic for such behavior is that Generics follow a mechanism of type erasure. So at run time you have no way if identifying the type of collection unlike arrays where there is no such erasure process. So coming back to your question...


So suppose there is a method as given below:


Now if java allows caller to add List of type Animal to this method then you might add wrong thing into collection and at run time too it will run due to type erasure. While in case of arrays you will get a run time exception for such scenarios...


Thus in essence this behavior is implemented so that one cannot add wrong thing into collection. Now  I believe type erasure exists so as to give compatibility with legacy java without generics....


The answers given here didn't fully convince me. So instead, I make another example.


sounds fine, doesn't it? But you can only pass Consumers and Suppliers for Animals. If you have a Mammal consumer, but a Duck supplier, they should not fit although both are animals. In order to disallow this, additional restrictions have been added.


Instead of the above, we have to define relationships between the types we use.


E. g.,


makes sure that we can only use a supplier which provides us the right type of object for the consumer.


OTOH, we could as well do


where we go the other way: we define the type of the Supplier and restrict that it can be put into the Consumer.


We even can do


where, having the intuitive relations Life -> Animal -> Mammal -> Dog, Cat etc., we could even put a Mammal into a Life consumer, but not a String into a Life consumer.


Actually you can use an interface to achieve what you want.


}


you can then use the collections using


If you are sure that the list items are subclasses of that given super type you can cast the list using this approach:


This is usefull when you want to pass the list in a constructor or iterate over it


The answer https://stackoverflow.com/a/2745301/4350148 as well as other answers are correct. I am  going to add to those answers with a solution that I think will be helpful.  I think this comes up often in programming. One thing to note, is that for Collections(Lists,Sets, etc) the main issue is adding to the Collection. That is where things break down.  Even removing is OK.  In most cases we can use Collection<? extends T> rather then Collection<T> and that should be the first choice.  However, I am finding cases where it is not easy to do that.  It  is up for debate as to whether that is always the  best thing to do.  I am  presenting here a class DownCastCollection that can take convert a Collection<? extends T> to a Collection<T> (we can define similar classes for List, Set, NavigableSet,..) to be used when using the standard approach is very inconvenient.  Below is an example of how to use it (we could also use Collection<? extends Object> in this case, but I am keeping it simple to illustrate using DownCastCollection.


Now the class:


}


Lets take the example from JavaSE tutorial 


So why a list of dogs (circles) should not be considered implicitly a list of animals (shapes) is because of this situation:


So Java "architects" had 2 options which address this problem:


do not consider that a subtype is implicitly it's supertype, and give a compile error, like it happens now


consider the subtype to be it's supertype and restrict at compile the "add" method (so in the drawAll method, if a list of circles, subtype of shape, would be passed, the compiler should detected that and restrict you with compile error into doing that).


For obvious reasons, that chose the first way. 


I have same problem. But generic type support <? extends Y> to fix this problem:


Collection<A> aCollection= getAFromDB();
AUtil.findMetConidition(aCollection);


Class:


Method declaration:


To understand the problem it's useful to make comparison to arrays.


List<Dog> is not subclass of List<Animal>.
But Dog[] is subclass of Animal[].


Arrays are reifiable and covariant. Reifiable means their type information is fully available at runtime. Therefore arrays provide runtime type safety but not compile-time type safety.


It's vice versa for generics:
Generics are erased and invariant. Therefore generics can't provide runtime type safety, but they provide compile-time type safety. In the code below if generics were covariant it will be possible to make heap pollution at line 3.






Please explain the following about the "Cannot find symbol" error:


This question is designed to be a comprehensive question about "cannot find symbol" compilation errors in Java.


Firstly, it is a compilation error1.  It means that either there is a problem in your Java source code, or there is a problem in the way that you are compiling it.


Your Java source code consists of the following things:


A "Cannot find symbol" error is about the identifiers.  When your code is compiled, the compiler needs to work out what each and every identifier in your code means.  


A "Cannot find symbol" error means that the compiler cannot do this.  Your code appears to be referring to something that the compiler doesn't understand.


As a first order, there is only one cause.  The compiler looked in all of the places where the identifier should be defined, and it couldn't find the definition.  This could be caused by a number of things.  The common ones are as follows:


For identifiers that should be class names:


Perhaps you forgot a new as in:


For cases where type or instance doesn't appear to have the member you were expecting it to have:


The problem is often a combination of the above.  For example, maybe you "star" imported java.io.* and then tried to use the Files class ... which is in java.nio not java.io.  Or maybe you meant to write File ... which is a class in java.io.


Here is an example of how incorrect variable scoping can lead to a "Cannot find symbol" error:


This will give a "Cannot find symbol" error for i in the if statement.  Though we previously declared i, that declaration is only in scope for the for statement and its body.  The reference to i in the if statement cannot see that declaration of i.  It is out of scope.


(An appropriate correction here might be to move the if statement inside the loop, or to declare i before the start of the loop.)


Here is an example that causes puzzlement where a typo leads to a seemingly inexplicable "Cannot find symbol" error:


This will give you a compilation error in the println call saying that i cannot be found.  But (I hear you say) I did declare it!


The problem is the sneaky semicolon before the {.  The Java language defines that to be an empty statement.  So that code actually means this:


The { ... } block is NOT the body of the for loop, so the declaration of i is not in scope in the the block.


Here is another example of "Cannot find symbol" error that is caused by a typo.


Despite the previous declaration, the tmp in the tmp(...) expression is erroneous.  The compiler will look for a method called tmp, and won't find one.  The previously declared tmp is in the namespace for variables, not the namespace for methods.


In the example I came across, the programmer had actually left out an operator.  What he meant to write was this:


There is another reason why the compiler might not find a symbol if you are compiling from the command line.  You might simply have forgotten to compile or recompile some other class.  For example, if you have classes Foo and Bar where Foo uses Bar.  If you have never compiled Bar and you run javac Foo.java, you are liable to find that the compiler can't find the symbol Bar.  The simple answer is to Foo and Bar together; e.g. javac Foo.java Bar.java or javac *.java.  Or better still use a Java build tool; e.g. Ant, Maven, Gradle and so on.


There are some other more obscure causes too ... which I will deal with below.


Generally speaking, you start out by figuring out what caused the compilation error.


Then you think about what your code is supposed to be saying.  Then finally you work out what correction you need to make to your source code to do what you want.


Note that not every "correction" is correct. Consider this:


Suppose that the compiler says "Cannot find symbol" for j.  There are many ways I could "fix" that:


The point is that you need to understand what your code is trying to do in order to find the right fix.


Here are a couple of cases where the "Cannot find symbol" is seemingly inexplicable ... until you look closer.


You are looking at the wrong source code:  It often happens that a new Java programmers don't understand how the Java tool chain works, or haven't implemented a repeatable "build process"; e.g. using an IDE, Ant, Maven, Gradle and so on.  In such a situation, the programmer can end up chasing his tail looking for an illusory error that is actually caused by not recompiling the code properly, and the like ...


IDE issues: People have reported cases where their IDE gets confused and the compiler in the IDE cannot find a class that exists ... or the reverse situation.  


This can happen if the IDE's caches get out of sync with the file system.  There are IDE specific ways to fix that.


This could be an IDE bug.  For instance @Joel Costigliola describes a scenario where Eclipse does not handle a Maven "test" tree correctly: see this answer.


Redefining system classes: I've seen cases where the compiler complains that substring is an unknown symbol in something like the following


It turned out that the programmer had created their own version of String and that his version of the class didn't define a substring methods.


Lesson: Don't define your own classes with the same names as common library classes!


Homoglyphs:  If you use UTF-8 encoding for your source files, it is possible to have identifiers that look the same, but are in fact different because they contain homoglyphs.   See this page for more information.  


You can avoid this by restricting yourself to ASCII or Latin-1 as the source file encoding, and using Java \uxxxx escapes for other characters.


1 - If, perchance, you do see this in a runtime exception or error message, then either you have configured your IDE to run code with compilation errors, or your application is generating and compiling code .. at runtime.


You'll also get this error if you forget a new:


versus


One more example of 'Variable is out of scope'


As I've seen that kind of questions a few times already, maybe one more example to what's illegal even if it might feel okay.


Consider this code:


That's invalid code. Because neither of the variables named message is visible outside of their respective scope - which would be the surrounding brackets {} in this case. 


You might say: "But a variable named message is defined either way - so message is defined after the if". 


But you'd be wrong. 


Java has no free() or delete operators, so it has to rely on tracking variable scope to find out when variables are no longer used (together with references to these variables of cause). 


It's especially bad if you thought you did something good. I've seen this kind of error after "optimizing" code like this:


"Oh, there's duplicated code, let's pull that common line out" -> and there it it.


The  most common way to deal with this kind of scope-trouble would be to pre-assign the else-values to the variable names in the outside scope and then reassign in if:


One way to get this error in Eclipse : 


Result : Eclipse will compile the code, but maven will give "Cannot find symbol".


Underlying cause : Eclipse is using a combined build path for the main and test trees.  Unfortunately, it does not support using different build paths for different parts of an Eclipse project, which is what Maven requires.


Solution : 


If you're getting this error in the build somewhere else, while your IDE says everything is perfectly fine, then check that you are using the same Java versions in both places.


For example, Java 7 and Java 8 have different APIs, so calling a non-existent API in an older Java version would cause this error.


I too was getting this error. (for which I googled and I was directed to this page)


Problem: I was calling a static method defined in the class of a project A from a class defined in another project B. 
I was getting the following error:


Solution: I resolved this by first building the project where the method is defined then the project where the method was being called from.


For hints, look closer at the class name name that throws an error and the line number, example:
Compilation failure
[ERROR] \applications\xxxxx.java:[44,30] error: cannot find symbol


One other cause is unsupported method of for java version say jdk7 vs 8.
Check your %JAVA_HOME% 






How do we decide on the best implementation of hashCode() method for a collection (assuming that equals method has been overridden correctly) ?


The best implementation? That is a hard question because it depends on the usage pattern.


A for nearly all cases reasonable good implementation was proposed in Josh Bloch's  Effective Java in item 8. The best thing is to look it up there because the author explains there why the approach is good.


Create a int result and assign a non-zero value.


For every field f tested in the equals() method, calculate a hash code c by:


Combine the hash value c with result:


Return result


This should result in a proper distribution of hash values for most use situations.


If you're happy with the Effective Java implementation recommended by dmeister, you can use a library call instead of rolling your own:


This requires either guava (com.google.common.base.Objects.hashCode(...)) or JDK7 (java.util.Objects.hash(...)) but works the same way.


It is better to use the functionality provided by Eclipse which does a pretty good job and you can put your efforts and energy in developing the business logic.


Although this is linked to Android documentation (Wayback Machine) and My own code on Github, it will work for Java in general. My answer is an extension of dmeister's Answer with just code that is much easier to read and understand.


EDIT


Typically, when you override hashcode(...), you also want to override equals(...). So for those that will or has already implemented equals, here is a good reference from my Github...


First make sure that equals is implemented correctly. From an IBM DeveloperWorks article:


Then make sure that their relation with hashCode respects the contact (from the same article):


Finally a good hash function should strive to approach the ideal hash function.


about8.blogspot.com, you said 


if equals() returns true for two objects, then hashCode() should return the same value. If equals() returns false, then hashCode() should return different values


I cannot agree with you. If two objects have the same hashcode it doesn't have to mean that they are equal. 


If A equals B then A.hashcode must be equal to B.hascode


but


if A.hashcode equals B.hascode it does not mean that A must equals B


There's a good implementation of the Effective Java's hashcode() and equals() logic in Apache Commons Lang. Checkout HashCodeBuilder and EqualsBuilder.


If I understand your question correctly, you have a custom collection class (i.e. a new class that extends from the Collection interface) and you want to implement the hashCode() method.


If your collection class extends AbstractList, then you don't have to worry about it, there is already an implementation of equals() and hashCode() that works by iterating through all the objects and adding their hashCodes() together.


Now if what you want is the best way to calculate the hash code for a specific class, I normally use the ^ (bitwise exclusive or) operator to process all fields that I use in the equals method:


If you use eclipse, you can generate equals() and hashCode() using:


Source -> Generate hashCode() and equals(). 


Using this function you can decide which fields you want to use for equality and hash code calculation, and Eclipse generates the corresponding methods.


Just a quick note for completing other more detailed answer (in term of code):


If I consider the question how-do-i-create-a-hash-table-in-java and especially the jGuru FAQ entry, I believe some other criteria upon which a hash code could be judged are:


@about8 : there is a pretty serious bug there.  


same hashcode


you probably want something like


(can you get hashCode directly from int in Java these days? I think it does some autocasting.. if that's the case, skip the toString, it's ugly.)


As you specifically asked for collections, I'd like to add an aspect that the other answers haven't mentioned yet: A HashMap doesn't expect their keys to change their hashcode once they are added to the collection. Would defeat the whole purpose...


any hashing method that evenly distributes the hash value over the possible range is a good implementation. See effective java ( http://books.google.com.au/books?id=ZZOiqZQIbRMC&dq=effective+java&pg=PP1&ots=UZMZ2siN25&sig=kR0n73DHJOn-D77qGj0wOxAxiZw&hl=en&sa=X&oi=book_result&resnum=1&ct=result ) , there is a good tip in there for hashcode implementation (item 9 i think...). 


I prefer using utility methods fromm Google Collections lib from class Objects that helps me to keep my code clean. Very often equals and hashcode methods are made from IDE's template, so their are not clean to read. 


Use the reflection methods on Apache Commons EqualsBuilder and HashCodeBuilder.


I use a tiny wrapper around Arrays.deepHashCode(...) because it handles arrays supplied as parameters correctly


Here is another JDK 1.7+ approach demonstration with superclass logics accounted. I see it as pretty convinient with Object class hashCode() accounted, pure JDK dependency and no extra manual work. Please note Objects.hash() is null tolerant.


I have not include any equals() implementation but in reality you will of course need it.


For a simple class it is often easiest to implement hashCode() based on the class fields which are checked by the equals() implementation.


The most important thing is to keep hashCode() and equals() consistent: if equals() returns true for two objects, then hashCode() should return the same value. If equals() returns false, then hashCode() should return different values.


When combining hash values, I usually use the combining method that's used in the boost c++ library, namely:


This does a fairly good job of ensuring an even distribution.  For some discussion of how this formula works, see the StackOverflow post: Magic number in boost::hash_combine


There's a good discussion of different hash functions at: http://burtleburtle.net/bob/hash/doobs.html






I'm new to Java EE and I know that something like the following three lines


is an old school way of coding and in JSP version 2 there exists a method to avoid Java code in JSP files. Can someone please tell me the alternative JSP 2 lines, and what this technique is called?


The use of scriptlets (those <% %> things) in JSP is indeed highly discouraged since the birth of taglibs (like JSTL) and EL (Expression Language, those ${} things) over a decade ago.


The major disadvantages of scriptlets are:


Sun Oracle itself also recommends in the JSP coding conventions to avoid use of scriptlets whenever the same functionality is possible by (tag) classes. Here are several cites of relevance:


From JSP 1.2 Specification, it is highly recommended that the JSP Standard Tag Library  (JSTL) be used in your web application to help reduce the need for JSP scriptlets in your pages. Pages that use JSTL are, in general, easier to read and maintain. 


...


Where possible, avoid JSP scriptlets whenever tag libraries provide equivalent functionality. This makes pages easier to read and maintain, helps to separate business logic from presentation logic, and will make your pages easier to evolve into JSP 2.0-style pages (JSP 2.0 Specification supports but deemphasizes the use of scriptlets).


...


In the spirit of adopting the model-view-controller (MVC) design pattern to reduce coupling between the presentation tier from the business logic, JSP scriptlets should not be used for writing business logic. Rather, JSP scriptlets are used if necessary to transform data (also called "value objects") returned from processing the client's requests into a proper client-ready format. Even then, this would be better done with a front controller servlet or a custom tag.


How to replace scriptlets entirely depends on the sole purpose of the code/logic. More than often this code is to be placed in a fullworthy Java class:


If you want to invoke the same Java code on every request, less-or-more regardless of the requested page, e.g. checking if an user is logged in, then implement a filter and write code accordingly in doFilter() method. E.g.:


When mapped on an appropriate <url-pattern> covering the JSP pages of interest, then you don't need to copypaste the same piece of code over all JSP pages.


If you want to invoke some Java code to preprocess a request, e.g. preloading some list from a database to display in some table, if necessary based on some query parameters, then implement a servlet and write code accordingly in doGet() method. E.g.:


This way dealing with exceptions is easier. The DB is not accessed in the midst of JSP rendering, but far before the JSP is been displayed. You still have the possibility to change the response whenever the DB access throws an exception. In the above example, the default error 500 page will be displayed which you can anyway customize by an <error-page> in web.xml.


If you want to invoke some Java code to postprocess a request, e.g. processing a form submit, then implement a servlet and write code accordingly in doPost() method. E.g.:


This way dealing with different result page destinations is easier: redisplaying the form with validation errors in case of an error (in this particular example you can redisplay it using ${message} in EL), or just taking to the desired target page in case of success.


If you want to invoke some Java code to control the execution plan and/or the destination of the request and the response, then implement a servlet according the MVC's Front Controller Pattern. E.g.:


Or just adopt a MVC framework like JSF, Spring MVC, Wicket, etc so that you end up with just a JSP/Facelets page and a Javabean class without the need for a custom servlet.


If you want to invoke some Java code to control the flow inside a JSP page, then you need to grab an (existing) flow control taglib like JSTL core. E.g. displaying List<Product> in a table:


With XML-style tags which fits nicely among all that HTML, the code is better readable (and thus better maintainable) than a bunch of scriptlets with various opening and closing braces ("Where the heck does this closing brace belong to?"). An easy aid is to configure your web application to throw an exception whenever scriptlets are still been used by adding the following piece to web.xml:


In Facelets, the successor of JSP, which is part of the Java EE provided MVC framework JSF, it is already not possible to use scriptlets. This way you're automatically forced to do things "the right way".


If you want to invoke some Java code to access and display "backend" data inside a JSP page, then you need to use EL (Expression Language), those ${} things. E.g. redisplaying submitted input values:


The ${param.foo} displays the outcome of request.getParameter("foo").


If you want to invoke some utility Java code directly in the JSP page (typically public static methods), then you need to define them as EL functions. There's a standard functions taglib in JSTL, but you can also easily create functions yourself. Here's an example how JSTL fn:escapeXml is useful to prevent XSS attacks.


Note that the XSS sensitivity is in no way specifically related to Java/JSP/JSTL/EL/whatever, this problem needs to be taken into account in every webapplication you develop. The problem of scriptlets is that it provides no way of builtin preventions, at least not using the standard Java API. JSP's successor Facelets has already implicit HTML escaping, so you don't need to worry about XSS holes in Facelets.


As a Safeguard: Disable Scriptlets For Good


As another question is discussing, you can and always should disable scriptlets in your web.xml web application descriptor.


I would always do that in order to prevent any developer adding scriptlets, especially in bigger companies where you will lose overview sooner or later. The web.xml settings look like this:


JSTL offers tags for conditionals, loops, sets, gets, etc. For example:


JSTL works with request attributes - they are most often set in the request by a Servlet, which forwards to the JSP.


I'm not sure if i get this correct. 


You should read something about MVC. Spring MVC & Struts 2 are the two most common solutions. 


You can use JSTL tags together with EL expressions to avoid intermixing Java and HTML code:


There are also component-based frameworks such as Wicket that generate a lot of the HTML for you.  The tags that end up in the HTML are extremely basic and there is virtually no logic that gets mixed in.  The result is almost empty-like HTML pages with typical HTML elements.  The downside is that there are a lot of components in the Wicket API to learn and some things can be difficult to achieve under those constraints.


In the MVC Architectural pattern, JSPs represent the View layer. Embedding java code in JSPs is considered a bad practice.
You can use JSTL, freeMarker, velocity with JSP as "template engine".
The data provider to those tags depends on frameworks that you are dealing with. Struts 2 and webwork as an implementation for MVC Pattern uses OGNL "very interesting technique to expose Beans Properties to JSP ".


Experience has shown that JSP's have some shortcomings, one of them being hard to avoid mixing markup with actual code.


If you can, then consider using a specialized technology for what you need to do.  In Java EE 6 there is JSF 2.0, which provides a lot of nice features including gluing Java beans together with JSF pages through the #{bean.method(argument)} approach.


Wicket is also an alternative which completely separates java from html, so a designer and programmer can work together and on different sets of code with little understanding of each other.


Look at Wicket.


if you simply want to avoid the drawbacks of Java coding in JSP you can do so even with scriplets. Just follow some discipline to have minimal Java in JSP and almost no calculation and logic in the JSP page. 


Learn to customize and write your own tags using JSTL


Note that EL is EviL (runtime exceptions, refactoring)
Wicket may be evil too (performance, toilsome for small apps or simple view tier)
Example from java2s,


This must be added to the web application's web.xml


create File:java2s.tld in the /WEB-INF/


compile the following code into WEB-INF\classes\com\java2s


Start server and load the bodyContent.jsp in browser


You raised a good question and although you got good answers, I would suggest that you get rid of JSP. It is outdated technology which eventually will die. Use a modern approach, like template engines. You will have very clear separation of business and presentation layers, and certainly no Java code in templates, so you can generate templates directly from web presentation editing software, in most cases leveraging WYSIWYG.


And certainly stay away of filters and pre and post processing, otherwise you may deal with support/debugging difficulties since you always do not know where the variable gets the value.


No matter how much you try to avoid, when you work with other developers, some of them will still prefer scriptlet and then insert the evil code into the project. Therefore, setting up the project at the first sign is very important if you really want to reduce the scriptlet code. There are several techniques to get over this (including several frameworks that other mentioned). However, if you prefer the pure JSP way, then use the JSTL tag file. The nice thing about this is you can also set up master pages for your project, so the other pages can inherit the master pages


Create a master page called base.tag under your WEB-INF/tags with the following content


On this mater page, I created a fragment called "title", so that in the child page, I could insert more codes into this place of the master page. Also, the tag <jsp:doBody/> will be replaced by the content of the child page 


Create child page (child.jsp) in your WebContent folder:


<t:base> is used to specify the master page you want to use (which is base.tag at this moment). All the content inside the tag <jsp:body> here will replace the <jsp:doBody/> on your master page. Your child page can also include any tag lib and you can use it normally like the other mentioned. However, if you use any scriptlet code here (<%= request.getParameter("name") %> ...) and try to run this page, you will get a JasperException because  Scripting elements ( &lt;%!, &lt;jsp:declaration, &lt;%=, &lt;jsp:expression, &lt;%, &lt;jsp:scriptlet ) are disallowed here. Therefore, there is no way other people can include the evil code into the jsp file


Calling this page from your controller:


You can easily call the child.jsp file from your controller. This also works nice with the struts framework


in order to avoid java code in JSP files java now provides tag libraries like JSTL also java has come up with JSF into which u can write all programming structures in the form of tags


Use JSTL Tag libraries in JSP, that will work perfect.


Just use the JSTL tag and EL expression.


If somebody is really against programming in more languages than one, I suggest GWT, theoretically you can avoid all the JS and HTML elements, because Google Toolkit transforms all the client and shared code to JS, you won't have problem with them, so you have a webservice without coding in any other languages. Even you can use some default CSS from somewhere as it is given by extensions (smartGWT or Vaadin). You don't need to learn dozens of annotations. 


Of course if you want, you can hack yourself into the depths of the code and inject JS and enrich your HTML page, but really you can avoid it if you want, and the result will be good as it was written in any other frameworks. I say worths a try, and the basic GWT is well-documented.


And of course many fellow programmers hereby described or recommended several other solutions. GWT is for people who really don't want to deal with the web part or to minimalize it. 


A neat idea from the Python world are Template attribute languages; TAL was introduced by Zope (therefore a.k.a. "Zope Page Templates", ZPT) and is a standard, with implementations in PHP, XSLT and Java as well (I have used the Python/Zope and PHP incarnations). In this class of templating languages, one above example could look like this:


The code looks like ordinary HTML (or XHTML) plus some special attributes in an XML namespace; it can be viewed with a browser and safely be tweaked by a designer.
There is support for macros and for i18n as well:


If translations of the content are available, they are used.


I don't know very much about the Java implementation, though.


Using scriptlets in JSPs is not a good practice.


Instead, you can use:


Please refer to: 


Technically, JSP are all converted to Servlets during runtime. JSP was initially created for the purpose of the decoupling the business logic and the design logic, following the MVC pattern. So JSP are technically all java codes during runtime. But to answer the question, Tag Libraries are usually used for applying logic (removing Java codes) to JSP pages.


Sure, replace <%! counter++; %> by a event producer-consumer architecture, where the business layer is notified about the need to increment the counter, it reacts accordingly, and notifies the presenters so that they update the views. A number of database transactions are involved, since in future we will need to know the new and old value of the counter, who has incremented it and with what purpose in mind. Obviously serialization is involved, since the layers are entirely decoupled. You will be able to increment your counter over RMI, IIOP, SOAP. But only HTML is required, which you don't implement, since it is such a mundane case. Your new goal is to reach 250 increments a second on your new shiny E7, 64GB RAM server.


I have more than 20 years in programming, most of the projects fail before the sextet: Reusability Replaceability OO-ability Debuggability Testability Maintainability is even needed. Other projects, run by people who only cared about functionality, were extremely successful.  Also, stiff object structure, implemented too early in the project, makes the code unable to be adapted to the drastic changes in the specifications (aka agile).


So I consider as procrastination the activity of defining "layers" or redundant data structures either early in the project or when not specifically required.


If we use the following things in a java web application, java code can be eliminated from foreground of the JSP.


Use MVC architecture for web application


Use JSP Tags


a. Standard Tags


b. Custom Tags


Expression Language


How to avoid Java code in JSP files?


You can use tab library tags like JSTL in addition to Expression Language (EL). But EL does not work well with JSP. So it's is probably better to drop JSP completely and use Facelets.


Facelets is the first non JSP page declaration language designed for JSF (Java Server Faces) which provided a simpler and more powerful programming model to JSF developers as compare to JSP. It resolves different issues occurs in JSP for web applications development. 





JSP 2.0 has a feature called "Tag Files", you can write tags without external java code and tld. You need to create a .tag file and put it in WEB-INF\tags you can even create directory structure to package your tags.


For example:


Use it like


Also you can read the tag body easly


Use it 


The samples are very simple but you can do lots of complicated tasks here. Please consider you can use other tags (eg: JSTL which has controlling tags like if/forEcah/chosen text manipulation like format/contains/uppercase or even SQL tags select/update), pass all kind parameters, for example Hashmap, access session, request, ... in your tag file too.


Tag File  are so easy developed as you did not need to restart the server when changing them, like jsp files. This make them easy for development.


Even if you use a framework like struts 2, which have lots of good tags, you may find that having your own tags can reduce your code a lot. You can pass your tag parameters to struts and this way customize your framework tag.


You can use tag not only to avoid java but also minimize your HTML codes. I myself try to review HTML codes and build tags a lot as soon as see code duplicates start in my pages. 


(Even if you end up using the java in you jsp code, which I hope not, you can encapsulate that code in a tag)


As many answers says, use JSTL or create your own custom tags. Here is good explanation about creating custom tags


By using JSTL tags together with EL expression you can avoid this. Put the following things in your jsp page:






From what time I've spent with threads in Java, I've found these two ways to write threads:


With implements Runnable:


Or, with extends Thread:


Is there any significant difference in these two blocks of code ?


Yes: implements Runnable is the preferred way to do it, IMO. You're not really specialising the thread's behaviour.  You're just giving it something to run. That means composition is the philosophically "purer" way to go.


In practical terms, it means you can implement Runnable and extend from another class as well.


tl;dr: implements Runnable is better.  However, the caveat is important


In general, I would recommend using something like Runnable rather than Thread because it allows you to keep your work only loosely coupled with your choice of concurrency.  For example, if you use a Runnable and decide later on that this doesn't in fact require it's own Thread, you can just call threadA.run().


Caveat: Around here, I strongly discourage the use of raw Threads.  I much prefer the use of Callables and FutureTasks (From the javadoc: "A cancellable asynchronous computation").  The integration of timeouts, proper cancelling and the thread pooling of the modern concurrency support are all much more useful to me than piles of raw Threads.


Follow-up: there is a FutureTask constructor that allows you to use Runnables (if that's what you are most comfortable with) and still get the benefit of the modern concurrency tools.  To quote the javadoc:


If you don't need a particular result, consider using constructions of the form: 


So, if we replace their runnable with your threadA, we get the following:


Another option that allows you to stay closer to Runnables is a ThreadPoolExecutor.  You can use the execute method to pass in a Runnable to execute "the given task sometime in the future."


If you'd like to try using a thread pool, the code fragment above would become something like the following (using the Executors.newCachedThreadPool() factory method):


Moral of the story:


Inherit only if you want to override some behavior.


Or rather it should be read as:


Inherit less, interface more.


Well so many good Answers, i want to add more on this. This will help to understand Extending v/s Implementing Thread.Extends binds two class files very closely and can cause some pretty hard to deal with code.


Both approaches do the same job but there have been some differences.
The most common difference is 


However, one significant difference between implementing Runnable and extending Thread is that by extending Thread, each of your threads has a unique object associated with it, whereas implementing Runnable, many threads can share the same object instance.


The following example helps you to understand more clearly


Output of the above program.


In the Runnable interface approach, only one instance of a class is being created and it has been shared by different threads. So the value of counter is incremented for each and every thread access.


Whereas, Thread class approach, you must have to create separate instance for every thread access. Hence different memory is allocated for every class instances and each has separate counter, the value remains same, which means no increment will happen because none of the object reference is same.


When to use Runnable?
Use Runnable interface when you want to access the same resource from the group of threads. Avoid using Thread class here, because multiple objects creation consumes more memory and it becomes a big performance overhead.


A class that implements Runnable is not a thread and just a class. For a Runnable to become a Thread, You need to create an instance of Thread and passing itself in as the target.


In most cases, the Runnable interface should be used if you are only planning to override the run() method and no other Thread methods. This is important because classes should not be subclassed unless the programmer intends on modifying or enhancing the fundamental behavior of the class.


When there is a need to extend a superclass, implementing the Runnable interface is more appropriate than using the Thread class. Because we can extend another class while implementing Runnable interface to make a thread.


I hope this will help! 


One thing that I'm surprised hasn't been mentioned yet is that implementing Runnable makes your class more flexible.


If you extend thread then the action you're doing is always going to be in a thread.  However, if you implement Runnable it doesn't have to be.  You can run it in a thread, or pass it to some kind of executor service, or just pass it around as a task within a single threaded application (maybe to be run at a later time, but within the same thread).  The options are a lot more open if you just use Runnable than if you bind yourself to Thread.


If you want to implements or extends any other class then Runnable interface is most preferable other wise if you do not want any other class to extend or implement then Thread class is preferable 


The most common difference is





When you extends Thread class, after that you can’t extend any other class which you required. (As you know, Java does not allow inheriting more than one class).


When you implements Runnable, you can save a space for your class to extend any other class in future or now.


Java doesn't support multiple inheritance, which means you can only extend one class in Java so once you extended Thread class you lost your chance and can not extend or inherit another class in Java.


In Object oriented programming extending a class generally means adding new functionality, modifying or improving behaviors. If we are not making any modification on Thread then use Runnable interface instead.


Runnable interface represent a Task which can be executed by either plain Thread or Executors or any other means. so logical separation of Task as Runnable than Thread is good design decision.


Separating task as Runnable means we can reuse the task and also has liberty to execute it from different means. since you can not restart a Thread once it completes. again Runnable vs Thread for task, Runnable is winner.


Java designer recognizes this and that's why Executors accept Runnable as Task and they have worker thread which executes those task.


Inheriting all Thread methods are additional overhead just for representing a Task which can be done easily with Runnable.


Courtesy from javarevisited.blogspot.com


These were some of notable difference between Thread and Runnable in Java, if you know any other differences on Thread vs Runnable than please share it via comments. I personally use Runnable over Thread for this scenario and recommends to use Runnable or Callable interface based on your requirement.


However, the significant difference is.


When you extends Thread class, each of your thread creates unique object and associate with it.
When you implements Runnable, it shares the same object to multiple threads.


Actually, It is not wise to compare Runnable and Thread with each other.  


This two have a dependency and relationship in multi-threading just like Wheel and Engine relationship of motor vehicle.


I would say, there is only one way for multi-threading with two steps. Let me make my point.


Runnable:
When implementing interface Runnable it means you are creating something which is run able in a different thread. Now creating something which can run inside a thread (runnable inside a thread), doesn't mean to creating a Thread.
So the class MyRunnable is nothing but a ordinary class with a void run method.
And it's objects will be some ordinary objects with only a method run which will execute normally when called.  (unless we pass the object in a thread).


Thread:
class Thread, I would say A very special class with the capability of starting a new Thread which actually enables multi-threading through its start() method.


Why not wise to compare?
Because we need both of them for multi-threading.   


For Multi-threading we need two things:  


So technically and theoretically  both of them is necessary to start a thread, one will run and one will make it run (Like Wheel and Engine of motor vehicle).


That's why you can not start a thread with MyRunnable you need to pass it to a instance of Thread.


But it is possible to create and run a thread only using class Thread because Class Thread implements Runnable so we all know Thread also is a Runnable inside.


Finally Thread and Runnable are complement to each other for multithreading  not competitor or replacement.


You should implement Runnable, but if you are running on Java 5 or higher, you should not start it with new Thread but use an ExecutorService instead. For details see: How to implement simple threading in Java.


I'm not an expert, but I can think of one reason to implement Runnable instead of extend Thread: Java only supports single inheritance, so you can only extend one class.


Edit: This originally said "Implementing an interface requires less resources." as well, but you need to create a new Thread instance either way, so this was wrong.


I would say there is a third way:


Maybe this is influenced a bit by my recent heavy usage of Javascript and Actionscript 3, but this way your class doesn't need to implement a pretty vague interface like Runnable.


Instantiating an interface gives a cleaner separation between your code and the implementation of threads, so I'd prefer to implement Runnable in this case.


With the release of Java 8, there is now a third option.


Runnable is a functional interface, which means that instances of it can be created with lambda expressions or method references.


Your example can be replaced with:


or if you want to use an ExecutorService and a method reference:


These are not only much shorter than your examples, but also come with many of the advantages stated in other answers of using Runnable over Thread, such as single responsibility and using composition because you're not specializing the thread's behaviour. This way also avoids creating an extra class if all you need is a Runnable as you do in your examples.


Since this is a very popular topic and the good answers are spread all over and dealt with in great depth, I felt it is justifiable to compile the good answers from the others into a more concise form, so newcomers have an easy overview upfront:


You usually extend a class to add or modify functionality. So, if you don't want to overwrite any Thread behavior, then use Runnable.


In the same light, if you don't need to inherit thread methods, you can do without that overhead by using Runnable.


Single inheritance: If you extend Thread you cannot extend from any other class, so if that is what you need to do, you have to use Runnable.


It is good design to separate domain logic from technical means, in that sense it is better to have a Runnable task isolating your task from your runner.


You can execute the same Runnable object multiple times, a Thread object, however, can only be started once. (Maybe the reason, why Executors do accept Runnables, but not Threads.)


If you develop your task as Runnable, you have all flexibility how to use it now and in the future. You can have it run concurrently via Executors but also via Thread. And you still could also use/call it non-concurrently within the same thread just as any other ordinary type/object. 


This makes it also easier to separate task-logic and concurrency aspects in your unit tests.


If you are interested in this question, you might be also interested in the difference between Callable and Runnable.


Runnable because: 


Even if you don't need any of this now, you may in the future. Since there is no benefit to overriding Thread, Runnable is a better solution.


Everyone here seems to think that implementing Runnable is the way to go and I don't really disagree with them but there is also a case for extending Thread in my opinion, in fact you have sort of demonstrated it in your code.


If you implement Runnable then the class that implements Runnable has no control over the thread name, it is the calling code that can set the thread name, like so:


but if you extend Thread then you get to manage this within the class itself (just like in your example you name the thread 'ThreadB').  In this case you:


A) might give it a more useful name for debugging purposes 


B) are forcing that that name be used for all instances of that class (unless you ignore the fact that it is a thread and do the above with it as if it is a Runnable but we are talking about convention here in any case so can ignore that possibility I feel).


You might even for example take a stack trace of its creation and use that as the thread name.  This might seem odd but depending on how your code is structured it can be very useful for debugging purposes.


This might seem like a small thing but where you have a very complex application with a lot of threads and all of a sudden things 'have stopped' (either for reasons of deadlock or possibly because of a flaw in a network protocol which would be less obvious - or other endless reasons) then getting a stack dump from Java where all the threads are called 'Thread-1','Thread-2','Thread-3' is not always very useful (it depends on how your threads are structured and whether you can usefully tell which is which just by their stack trace - not always possible if you are using groups of multiple threads all running the same code).


Having said that you could of course also do the above in a generic way by creating an extension of the thread class which sets its name to a stack trace of its creation call and then use that with your Runnable implementations instead of the standard java Thread class (see below) but in addition to the stack trace there might be more context specific information that would be useful in the thread name for debugging (a reference to one of many queues or sockets it could processing for example in which case you might prefer to extend Thread specifically for that case so that you can have the compiler force you (or others using your libraries) to pass in certain info (e.g. the queue/socket in question) for use in the name).


Here's an example of the generic thread with the calling stack trace as its name:


and here's a sample of the output comparing the two names:


This is discussed in Oracle's Defining and Starting a Thread tutorial:


Which of these idioms should you use? The first idiom, which employs a
  Runnable object, is more general, because the Runnable object can
  subclass a class other than Thread. The second idiom is easier to use
  in simple applications, but is limited by the fact that your task
  class must be a descendant of Thread. This lesson focuses on the first
  approach, which separates the Runnable task from the Thread object
  that executes the task. Not only is this approach more flexible, but
  it is applicable to the high-level thread management APIs covered
  later.


In other words, implementing Runnable will work in scenarios where your class extends a class other than Thread. Java does not support multiple inheritance. Also, extending Thread will not be possible when using some of the high-level thread management APIs. The only scenario where extending Thread is preferable is in a small application that won't be subject to updates in future. It is almost always better to implement Runnable as it is more flexible as your project grows. A design change won't have a major impact as you can implement many interfaces in java, but only extend one class.


1) Java doesn't support multiple inheritance, which means you can only extend one class in Java so once you extended Thread class you lost your chance and can not extend or inherit another class in Java.


2) In Object oriented programming extending a class generally means adding new functionality, modifying or improving behaviors. If we are not making any modification on Thread than use Runnable interface instead.


3) Runnable interface represent a Task which can be executed by either plain Thread or Executors or any other means. so logical separation of Task as Runnable than Thread is good design decision.


4) Separating task as Runnable means we can reuse the task and also has liberty to execute it from different means. since you can not restart a Thread once it completes. again Runnable vs Thread for task, Runnable is winner.


5) Java designer recognizes this and that's why Executors accept Runnable as Task and they have worker thread which executes those task.


6) Inheriting all Thread methods are additional overhead just for representing a Task which can can be done easily with Runnable.


If I am not wrong, it's more or less similar to 


What is the difference between an interface and abstract class?


extends establishes "Is A" relation & interface provides "Has a" capability.


Prefer implements Runnable :


Prefer "extends Thread" :


Generally you don't need to override Thread behaviour. So implements Runnable is preferred for most of the times. 


On a different note, using advanced ExecutorService or ThreadPoolExecutorService API provides more flexibility and control.


Have a look at this SE Question:


ExecutorService vs Casual Thread Spawner


Separating the Thread class from the Runnable implementation also avoids potential synchronization problems between the thread and the run() method. A separate Runnable generally gives greater flexibility in the way that runnable code is referenced and executed.


One reason you'd want to implement an interface rather than extend a base class is that you are already extending some other class. You can only extend one class, but you can implement any number of interfaces.


If you extend Thread, you're basically preventing your logic to be executed by any other thread than 'this'. If you only want some thread to execute your logic, it's better to just implement Runnable.


if you use runnable you can save the space to extend to any of your other class.


Can we re-visit the basic reason we wanted our class to behave as a Thread?
There is no reason at all, we just wanted to execute a task, most likely in an asynchronous mode, which precisely means that the execution of the task must branch from our main thread and the main thread if finishes early, may or may not wait for the branched path(task).


If this is the whole purpose, then where do I see the need of a specialized Thread. This can be accomplished by picking up a RAW Thread from the System's Thread Pool and assigning it our task (may be an instance of our class) and that is it.


So let us obey the OOPs concept and write a class of the type we need. There are many ways to do things, doing it in the right way matters. 


We need a task, so write a task definition which can be run on a Thread. So use Runnable.


Always remember implements is specially used to impart a behaviour and extends is used to impart a feature/property.


We do not want the thread's property, instead we want our class to behave as a task which can be run.


Yes,
If you call ThreadA call , then  not need to call the start method and run method is call after call the ThreadA class only.
But If use the ThreadB call then need to necessary the start thread for call run method.
If you have any more help, reply me.


I find it is most useful to use Runnable for all the reasons mentioned, but sometimes I like to extend Thread so I can create my own thread stopping method and call it directly on the thread I have created.


That's the S of SOLID: Single responsibility. 


A thread embodies the running context (as in execution context: stack frame, thread id, etc.) of the asynchronous execution of a piece of code. That piece of code ideally should be the same implementation, whether synchronous or asynchronous.


If you bundle them together in one implementation, you give the resulting object two unrelated causes of change:


If the language you use supports partial classes or multiple inheritance, then you can segregate each cause in its own super class, but it boils down to the same as composing the two objects, since their feature sets don't overlap. That's for the theory. 


In practice, generally speaking, a programme does not need to carry more complexity than necessary. If you have one thread working on a specific task, without ever changing that task, there is probably no point in making the tasks separate classes, and your code remains simpler.  


In the context of Java, since the facility is already there, it is probably easier to start directly with stand alone Runnable classes, and pass their instances to Thread (or Executor) instances. Once used to that pattern, it is not harder to use (or even read) than the simple runnable thread case.


Difference between Thread and runnable
.If  we are creating Thread using Thread class then Number of thread equal to number of object we created  .
If we are creating thread  by implementing the runnable interface then we can use single object for creating multiple thread.So single object is shared by multiple Thread.So it will take less memory


So depending upon the requirement if our data is not senstive. So It can be shared between multiple Thread we can used Runnable interface.


Adding my two cents here -
Always whenever possible use implements Runnable . Below are two caveats on why you should not use 
extends Threads


Ideally you should never extend the Thread class; the Thread class should be made final.
At least its methods like thread.getId(). 
See this discussion for a bug related to extending Threads. 


Those who like to solve puzzles can see another side effect of extending Thread. The below code 
will print unreachable code when nobody is notifying them.


Please see  http://pastebin.com/BjKNNs2G. 


One difference between implementing Runnable and extending Thread is that by extending Thread, each of your threads has a unique object associated with it, whereas implementing Runnable, many threads can share the same object instance.


A class that implements Runnable is not a thread and just a class. For a Runnable to be executed by a Thread, you need to create an instance of Thread and pass the Runnable instance in as the target.


In most cases, the Runnable interface should be used if you are only planning to override the run() method and no other Thread methods. This is important because classes should not be subclassed unless the programmer intends on modifying or enhancing the fundamental behavior of the class.


When there is a need to extend a superclass, implementing the Runnable interface is more appropriate than using the Thread class. Because we can extend another class while implementing Runnable interface to make a thread. But if we just extend the Thread class we can't inherit from any other class.


The simplest explanation would be by implementing Runnable we can assign the same object to multiple threads and each Thread shares the same object states and behavior. 


For example, suppose there are two threads, thread1 puts an integer in an array and thread2 takes integers from the array when the array is filled up. Notice that in order for thread2 to work it needs to know the state of array, whether thread1 has filled it up or not. 


Implementing Runnable lets you to have this flexibility to share the object whereas extends Thread makes you to create new objects for each threads therefore any update that is done by thread1 is lost to thread2.    


The best way for most worker threads is to have the threading completely encapsuled in the worker class so that nothing can interfere from the outside and cause unwanted and invalid thread/class states.


I've just posted an example, so I'll also share this with you:






I want to develop with Servlets in Eclipse, but it says that the package javax.servlet cannot be resolved. How can I add javax.servlet package to my Eclipse project?


Ensure that you're using at least Eclipse IDE for Java EE developers (with the EE). It contains development tools to create dynamic web projects and easily integrate servletcontainers (those tools are part of Web Tools Platform, WTP). In case you already had Eclipse IDE for Java (without EE), and manually installed some EE related plugins, then chances are that it wasn't done properly. You'd best trash it and grab the real Eclipse IDE for Java EE one.


You also need to ensure that you already have a servletcontainer installed on your machine which implements at least the same Servlet API version as the servletcontainer in the production environment, for example Apache Tomcat, Oracle GlassFish, JBoss AS/WildFly, etc. Usually, just downloading the ZIP file and extracting it is sufficient. In case of Tomcat, do not download the EXE format, that's only for Windows based production environments. See also a.o. Several ports (8005, 8080, 8009) required by Tomcat Server at localhost are already in use.


A servletcontainer is a concrete implementation of the Servlet API. Note that the Java EE SDK download at Oracle.com basically contains GlassFish. So if you happen to already have downloaded Java EE SDK, then you basically already have GlassFish. Also note that for example GlassFish and JBoss AS/WildFly are more than just a servletcontainer, they also supports JSF, EJB, JPA and all other Java EE fanciness. See also a.o. What exactly is Java EE?


Once having installed both Eclipse for Java EE and a servletcontainer on your machine, do the following steps in Eclipse:


Integrate servletcontainer in Eclipse


a. Via Servers view


Pick the appropriate servletcontainer make and version and walk through the wizard.





b. Or, via Eclipse preferences


You can Add, Edit and Remove servers here.





Associate server with project


a. In new project


In the wizard, set the Target Runtime to the integrated server.





b. Or, in existing project


In Targeted Runtimes section, select the integrated server.





Either way, Eclipse will then automatically take the servletcontainer's libraries in the build path. This way you'll be able to import and use the Servlet API.


You should in any case not have the need to fiddle around in the Build Path property of the project. You should above all never manually copy/download/move/include the individual servletcontainer-specific libraries like servlet-api.jar, jsp-api.jar, el-api.jar, j2ee.jar, javaee.jar, etc. It would only lead to future portability, compatibility, classpath and maintainability troubles, because your webapp would not work when it's deployed to a servletcontainer of a different make/version than where those libraries are originally obtained from.


In case you're using Maven, you need to make absolutely sure that servletcontainer-specific libraries which are already provided by the target runtime are marked as <scope>provided</scope>.


Here are some typical exceptions which you can get when you litter the /WEB-INF/lib or even /JRE/lib, /JRE/lib/ext, etc with servletcontainer-specific libraries in a careless attempt to fix the compilation errors:





Go to properties of your project ( with Alt+Enter or righ-click )


check on Apache Tomcat v7.0 under Targeted Runtime and it works.


Little bit difference from Hari:


Right click on project ---> Properties ---> Java Build Path ---> Add Library...  --->  Server Runtime ---> Apache Tomcat ----> Finish.


Quick Fix- This worked in Eclipse - Right Click on project -> Properties -> Java Build Path (Tab) -> Add External JARs -> locate the servlet api jar implementation (if Tomcat - its named servlet-api.jar) -> click OK. That's it !!


Include servlet-api.jar from your server lib folder.


Do this step





I know this is an old post. However, I observed another instance where in the project already has Tomcat added but we still get this error. Did this to resolve that:

Alt + Enter
Project Facets
On the right, next to details, is another tab "Runtimes".
The installed tomcat server will be listed there. Select it.

Save the configuration and DONE!


Hope this helps someone.


you can simply copy the servlet-api.jar and copy that jar files into lib folder, which is in WEB-INF.
then just clean and built your project, your errors will be solved.


you can directly add jar files to library by using following steps.


Add javax.servlet dependency in pom.xml. Your problem will be resolved.


From wikipedia.


This, of course, works only if you have added the servlet-api.jar to Eclipse build path. Typically your application server (e.g Tomcat) will have the right jar file. 


I was getting a null pointer exception during project creation related to "Dynamic Web Module". 


To get the project to compile (that is, to javax.servlet to import successfully) I had to go to project's Properties, pick Project Facets in the sidebar, tick Dynamic Web Module and click Apply.


Surprisingly, this time "Dynamic Web Module" facet installed correctly, and import started to work.


You should above all never manually copy/download/move/include the individual servletcontainer-specific libraries like servlet-api.jar


@BalusC,


I would prefer to use the exact classes that my application is going to use rather than one provided by Eclipse (when I am feeling like a paranoid developer). 


Another solution would be to use Eclipse "Configure Build Path" > Libraries > Add External Jars, and add servlet api of whatever Container one chooses to use.


And follow @kaustav datta's solution when using ant to build - have a property like tomcat.home or weblogic.home. 
However it introduces another constraint that the developer must install Weblogic on his/her local machine if weblogic is being used ! 
Any other cleaner solution? 


In my case, when I went to the Targetted Runtimes, screen, Tomcat 7 was not listed (disabled) despite being installed.


To fix, I had to go to Preferences->Server->Runtime Environments then uninstall and reinstall Tomcat 7.


Many of us develop in Eclipse via a Maven project. If so,
you can include Tomcat dependencies in Maven via the tomcat-servlet-api and tomcat-jsp-api jars. One exists for each version of Tomcat. Usually adding these with scope provided to your POM is sufficient. This will keep your build more portable.


If you upgrade Tomcat in the future, you simply update the version of these jars as well.






A common problem that new Java developers experience is that their programs fail to run with the error message:  Could not find or load main class ...


What does this mean, what causes it, and how should you fix it?


First of all, you need to understand the correct way to launch a program using the java (or javaw) command.


The normal syntax1 is this:


where <option> is a command line option (starting with a "-" character), <class-name> is a fully qualified Java class name, and <argument> is an arbitrary command line argument that gets passed to your application.
1 - There is a second syntax for "executable" JAR files which I will describe at the bottom.


The fully qualified name (FQN) for the class is conventionally written as you would in Java source code; e.g.


However some versions of the java command allow you to use slashes instead of periods; e.g.


which (confusingly) looks like a file pathname, but isn't one.  Note that the term fully qualified name is standard Java terminology ... not something I just made up to confuse you :-)


Here is an example of what a java command should look like:


The above is going to cause the java command to do the following:


When you get the message "Could not find or load main class ...", that means that the first step has failed.  The java command was not able to find the class.  And indeed, the "..." in the message will be the fully qualified class name that java is looking for. 


So why might it be unable to find the class?  


The first likely cause is that you may have provided the wrong class name.  (Or ... the right class name, but in the wrong form.)   Considering the example above, here a variety of wrong ways to specify the class name:


Example #1 - a simple class name:


When the class is declared in a package such as com.acme.example, then you must use the full classname including the package name in the java command; e.g. 


Example #2 - a filename or pathname rather than a class name:


Example #3 - a class name with the casing incorrect:


Example #4 - a typo


Example #5 - a source filename


Example #6 - you forgot the class name entirely


The second likely cause is that the class name is correct, but that the java command cannot find the class.  To understand this, you need to understand the concept of the "classpath".  This is explained well by the Oracle documentation:


So ... if you have specified the class name correctly, the next thing to check is that you have specified the classpath correctly:


When you put a directory on the classpath, it notionally corresponds to the root of the qualified name space.  Classes are located in the directory structure beneath that root, by mapping the fully qualified name to a pathname.  So for example, if "/usr/local/acme/classes" is on the class path, then when the JVM looks for a class called com.acme.example.Foon, it will look for a ".class" file with this pathname:


If you had put "/usr/local/acme/classes/com/acme/example" on the classpath, then the JVM wouldn't be able to find the class.


If your classes FQN is com.acme.example.Foon, then the JVM is going to look for "Foon.class" in the directory "com/acme/example":


If your directory structure doesn't match the package naming as per the pattern above, the JVM won't find your class.


If you attempt rename a class by moving it, that will fail as well ... but the exception stacktrace will be different.  


The classpath needs to include all of the other (non-system) classes that your application depends on.  (The system classes are located automatically, and you rarely need to concern yourself with this.)  For the main class to load correctly, the JVM needs to find:


(Note: the JLS and JVM specifications allow some scope for a JVM to load classes "lazily", and this can affect when a classloader exception is thrown.)


It occasionally happens that someone puts a source code file into the
the wrong folder in their source code tree, or they leave out the package declaration.  If you do this in an IDE, the IDE's compiler will tell you about this immediately.  Similarly if you use a decent Java build tool, the tool will run javac in a way that will detect the problem.  However, if you build your Java code by hand, you can do it in such a way that the compiler doesn't notice the problem, and the resulting ".class" file is not in the place that you expect it to be.


The alternative syntax used for "executable" JAR files is as follows:


e.g.


In this case the name of the entry-point class (i.e. com.acme.example.ListUser) and the classpath are specified in the MANIFEST of the JAR file.


A typical Java IDE has support for running Java applications in the IDE JVM itself or in a child JVM.  These are generally immune from this particular exception, because the IDE uses its own mechanisms to construct the runtime classpath, identify the main class and create the java command line.


However it is still possible for this exception to occur, if you do things behind the back of the IDE.  For example, if you have previously set up an Application Launcher for your Java app in Eclipse, and you then moved the JAR file containing the "main" class to a different place in the file system without telling Eclipse, Eclipse would unwittingly launch the JVM with an incorrect classpath.


In short, if you get this problem in an IDE, check for things like stale IDE state, broken project references or broken launcher configurations.


It is also possible for an IDE to simply get confused.  IDE's are hugely complicated pieces of software comprising many interacting parts.  Many of these parts adopt various caching strategies in order to make the IDE as a whole responsive.  These can sometimes go wrong, and one possible symptom is problems when launching applications.  If you suspect this could be happening, it is worth restarting your IDE.


If your source code name is HelloWorld.java, your compiled code will be HelloWorld.class.


You will get that error if you call it using:


Instead, use this:


If your classes are in packages then you have to cd to the main directory and run using the full name of the class (packageName.MainClassName).


Example:


My classes are in here:


The full name of my main class is:


So I cd back to the main directory:


Then issue the java command:


If your main method is in the class under a package, you should run it over the hierarchical directory.


Assume there is a source code file (Main.java):


For running this code, you should place Main.Class in the package like directory ./com/test/Main.Java. And in the root directory use java com.test.Main.


When the same code works on one PC, but it shows the error in another, the best solution I have ever found is compiling like the following:


What helped me was specifying the classpath on the command line, for example:


Create a new folder, C:\temp


Create file Temp.java in C:\temp, with the following class in it:


Open a command line in folder C:\temp, and write the following command to compile the Temp class:


Run the compiled Java class, adding the -classpath option to let JRE know where to find the class:


According to the error message ("Could not find or load main class"), there are two categories of problems:


Main class could not be found when there is typo or wrong syntax in the fully qualified class name or it does not exist in the provided classpath.


Main class could not be loaded when the class cannot be initiated, typically the main class extends another class and that class does not exist in the provided classpath.


For example:


If camel-spring is not included, this error will be reported.


Sometimes what might be causing the issue has nothing to do with the main class, and I had to find this out the hard way. It was a referenced library that I moved, and it gave me the:


Could not find or load main class xxx Linux


I just deleted that reference, added it again, and it worked fine again.


I had such an error in this case:


It works with ; for Windows and : for Unix:


In this instance you have:


Could not find or load main class ?classpath


It's because you are using "-classpath", but the dash is not the same dash used by java on the command prompt. I had this issue copying and pasting from Notepad to cmd.


In my case, error appeared because I had supplied the source file name instead of the class name. 


We need to supply the class name containing the main method to the interpreter.


Try -Xdiag.


Steve C's answer covers the possible cases nicely, but sometimes to determine whether the class could not be found or loaded might not be that easy. Use java -Xdiag (since jdk 7). This prints out nice stacktrace which provides a hint to what the message Could not find or load main class message means.


For instance, it can point you to other classes used by the main class that could not be found and prevented the main class to be loaded.


First set the path using this command;


Then you need to load the program. Type "cd (folder name)" in the stored drive and compile it. For Example, if my program stored on the D drive, type "D:" press enter and type " cd (folder name)".


What fixed the problem in my case was:


Right click on the project/class you want to run, then Run As->Run Configurations. Then you should either fix your existing configuration or add new in the following way:


open the Classpath tab, click on the Advanced... button then add bin folder of your project.


Use this command


example if your classname is Hello.class created from Hello.java then use below command


If your file Hello.java is inside package com.demo then use below command


with jdk 8 many time it happens that class file is present in same folder but java command expects classpath and for this reason we add -cp . to take current folder as reference for classpath.


You really need to do this from the src folder. There you type the following command line:


Let's say your class is called CommandLine.class, and the code looks like this:


Then you should cd to the src folder and the command you need to run would look like this:


And the output on the command line would be:


Sometimes, in some online compilers that you might have tried you will get this error if you don't write public class [Classname] but just class [Classname]. 


I spent a decent amount of time trying to solve this problem. I thought that I was somehow setting my classpath incorrectly but the problem was that I typed:  


java -cp C:/java/MyClasses C:/java/MyClasses/utilities/myapp/Cool
  instead of:
  java -cp C:/java/MyClasses utilities/myapp/Cool
  I thought the meaning of fully qualified meant to include the full path name instead of the full package name.


This is a specific case, but since I came to this page looking for a solution and didn't find it, I'll add it here.


Windows (tested with 7) doesn't accept special characters (like á) in class and package names. Linux does, though.


I found this out when I built a .jar in NetBeans and tried to run it in command line. It ran in NetBeans but not in command line.


On Windows put .; at the CLASSPATH value in the beginning.


The . (dot) means "look in the current directory". This is a permanent solution.


Also you can set it "one time" with set CLASSPATH=%CLASSPATH%;.. This will last as long as your cmd window is open.





Class file location:         C:\test\com\company


File Name:                   Main.class


Fully qualified class name:  com.company.Main


Command line command: 


Note here that class path does NOT include \com\company


By default, Java uses ., the geek letter for "current working directory" (you now know one letter in the geek alphabet right?) as the default CLASSPATH. What this means is that when you type a command at the prompt e.g. java MyClass, the command is interpreted as if you had type java -cp . MyClass. Did you see that dot between -cp and MyClass? (cp is short for the longer classpath option)


This is sufficient for most cases and things seems to work just fine until at some time you try to add a directory to your CLASSPATH. In most cases when programmers need to do this, they just run a command like set CLASSPATH=path\to\some\dir. This command creates a new environment variable called CLASSPATH having the value path\to\some\dir or replaces its value with path\to\some\dir if CLASSPATH was already set before.


When this is done, you now have a CLASSPATH environment variable and Java no longer uses it's default classpath (.) but the one you've set. So the next day you open your editor, write some java program, cd to the directory where you saved it, compile it, and try to run it with the command java MyClass, and you are greeted with a nice output: Could not find or load main class ... (If your commands were working well before and you are now getting this output, then this might be the case for you).


What happens is that when you run the command java MyClass, Java searches for the class file named MyClass in the directory or directories that you have set in your CLASSPATH and not your current working directory so it doesn't find your class file there and hence complains.


What you need to do is add . to your class path again which can be done with the command set CLASSPATH=%CLASSPATH%;. (notice the dot after the semicolon). In plain english this command says "Pick what was initially the value of CLASSPATH (%CLASSPATH%), add . to it (;.) and assign the result back to CLASSPATH".


And viola, you are once again able to use your command java MyClass as usual.


Thanks.


When running the java with the -cp option as advertised in Windows PowerShell you may get an error that looks something like:


In order to for PowerShell to accept the command, the arguments of the -cp option must be contained in quotes as in:


Forming the command this way should allow Java process the classpath arguments correctly.


This might help you if your case is specifically like mine:  as a beginner I also ran into this problem when I tried to run a java program. 


I compiled it like this: 
javac HelloWorld.java


and tried to run also with the same extension


java Helloworld.java


When I removed the .java and rewrote the command like this java HelloWorld, 
The Program ran perfectly. :)


if you use maven to build the jar please making sure to specify the main class in the pom.xml


In Java, when you sometimes run the JVM from the command line using the java executable and are trying to start a program from a class file with public static void main (PSVM), you might run into the below error even though the classpath parameter to the JVM is accurate and the class file is present on the classpath:


This happens if the class file with PSVM could not be loaded. One possible reason for that is that the class may be implementing an interface or extending another class that is not on the classpath. Normally if a class is not on the classpath, the error thrown indicates as such. But, if the class in use is extended or implemented, java is unable to load the class itself.


Reference: https://www.computingnotes.net/java/error-main-class-not-found-or-loaded/


I got this error after doing mvn eclipse:eclipse
This messed up my .classpath file a little bit.


Had to change the lines in .classpath from


to 


I was unable to solve this problem with the solutions stated here (although the answer stated has, no doubt, cleared my concepts). I faced this problem two times and each time I have tried different solutions (in the Eclipse IDE).


Sometimes it's better to remove the added JAR files and add again with proper build helps. For me it has been a regular issue, and I followed the same approach:


All answers here are directed towards Windows users it seems. For Mac, the classpath separator is :, not ;. As an error setting the classpath using ; is not thrown then this can be a difficult to discover if coming from Windows to Mac.


Here is corresponding Mac command:


Where in this example the package is com.test and a lib folder is also to be included on classpath.






I've always been one to simply use:


I use the interface as the type name for portability, so that when I ask questions such as these I can rework my code.  


When should LinkedList be used over ArrayList and vice-versa?


TL;DR ArrayList with ArrayDeque are preferable in much more use-cases than LinkedList. Not sure — just start with ArrayList.


LinkedList and ArrayList are two different implementations of the List interface. LinkedList implements it with a doubly-linked list. ArrayList implements it with a dynamically re-sizing array.


As with standard linked list and array operations, the various methods will have different algorithmic runtimes.


For LinkedList<E>


Note: O(n/4) is average, O(1) best case (e.g. index = 0), O(n/2) worst case (middle of list)


For ArrayList<E>


Note: O(n/2) is average, O(1) best case (end of list), O(n) worst case (start of list)


LinkedList<E> allows for constant-time insertions or removals using iterators, but only sequential access of elements. In other words, you can walk the list forwards or backwards, but finding a position in the list takes time proportional to the size of the list. Javadoc says "operations that index into the list will traverse the list from the beginning or the end, whichever is closer", so those methods are O(n/4) on average, though O(1) for index = 0.


ArrayList<E>, on the other hand, allow fast random read access, so you can grab any element in constant time. But adding or removing from anywhere but the end requires shifting all the latter elements over, either to make an opening or fill the gap. Also, if you add more elements than the capacity of the underlying array, a new array (1.5 times the size) is allocated, and the old array is copied to the new one, so adding to an ArrayList is O(n) in the worst case but constant on average.


So depending on the operations you intend to do, you should choose the implementations accordingly. Iterating over either kind of List is practically equally cheap. (Iterating over an ArrayList is technically faster, but unless you're doing something really performance-sensitive, you shouldn't worry about this -- they're both constants.)


The main benefits of using a LinkedList arise when you re-use existing iterators to insert and remove elements. These operations can then be done in O(1) by changing the list locally only. In an array list, the remainder of the array needs to be moved (i.e. copied). On the other side, seeking in a LinkedList means following the links in O(n/2) for worst case, whereas in an ArrayList the desired position can be computed mathematically and accessed in O(1).


Another benefit of using a LinkedList arise when you add or remove from the head of the list, since those operations are O(1), while they are O(n) for ArrayList. Note that ArrayDeque may be a good alternative to LinkedList for adding and removing from the head, but it is not a List.


Also, if you have large lists, keep in mind that memory usage is also different. Each element of a LinkedList has more overhead since pointers to the next and previous elements are also stored. ArrayLists don't have this overhead. However, ArrayLists take up as much memory as is allocated for the capacity, regardless of whether elements have actually been added.


The default initial capacity of an ArrayList is pretty small (10 from Java 1.4 - 1.8). But since the underlying implementation is an array, the array must be resized if you add a lot of elements. To avoid the high cost of resizing when you know you're going to add a lot of elements, construct the ArrayList with a higher initial capacity.


Thus far, nobody seems to have addressed the memory footprint of each of these lists besides the general consensus that a LinkedList is "lots more" than an ArrayList so I did some number crunching to demonstrate exactly how much both lists take up for N null references.


Since references are either 32 or 64 bits (even when null) on their relative systems, I have included 4 sets of data for 32 and 64 bit LinkedLists and ArrayLists.


Note: The sizes shown for the ArrayList lines are for trimmed lists - In practice, the capacity of the backing array in an ArrayList is generally larger than its current element count.


Note 2: (thanks BeeOnRope) As CompressedOops is default now from mid JDK6 and up, the values below for 64-bit machines will basically match their 32-bit counterparts, unless of course you specifically turn it off.





The result clearly shows that LinkedList is a whole lot more than ArrayList, especially with a very high element count. If memory is a factor, steer clear of LinkedLists.


The formulas I used follow, let me know if I have done anything wrong and I will fix it up. 'b' is either 4 or 8 for 32 or 64 bit systems, and 'n' is the number of elements. Note the reason for the mods is because all objects in java will take up a multiple of 8 bytes space regardless of whether it is all used or not.


ArrayList:


LinkedList:


ArrayList is what you want. LinkedList is almost always a (performance) bug.


Why LinkedList sucks:


As someone who has been doing operational performance engineering on very large scale SOA web services for about a decade, I would prefer the behavior of LinkedList over ArrayList.  While the steady-state throughput of LinkedList is worse and therefore might lead to buying more hardware -- the behavior of ArrayList under pressure could lead to apps in a cluster expanding their arrays in near synchronicity and for large array sizes could lead to lack of responsiveness in the app and an outage, while under pressure, which is catastrophic behavior.


Similarly, you can get better throughput in an app from the default throughput tenured garbage collector, but once you get java apps with 10GB heaps you can wind up locking up the app for 25 seconds during a Full GCs which causes timeouts and failures in SOA apps and blows your SLAs if it occurs too often.  Even though the CMS collector takes more resources and does not achieve the same raw throughput, it is a much better choice because it has more predictable and smaller latency.


ArrayList is only a better choice for performance if all you mean by performance is throughput and you can ignore latency.  In my experience at my job I cannot ignore worst-case latency.


Algorithms: Big-Oh Notation


ArrayLists are good for write-once-read-many or appenders, but bad at add/remove from the front or middle.


Yeah, I know, this is an ancient question, but I'll throw in my two cents:


LinkedList is almost always the wrong choice, performance-wise.  There are some very specific algorithms where a LinkedList is called for, but those are very, very rare and the algorithm will usually specifically depend on LinkedList's ability to insert and delete elements in the middle of the list relatively quickly, once you've navigated there with a ListIterator.


There is one common use case in which LinkedList outperforms ArrayList: that of a queue.  However, if your goal is performance, instead of LinkedList you should also consider using an ArrayBlockingQueue (if you can determine an upper bound on your queue size ahead of time, and can afford to allocate all the memory up front), or this CircularArrayList implementation.  (Yes, it's from 2001, so you'll need to generify it, but I got comparable performance ratios to what's quoted in the article just now in a recent JVM)


It's an efficiency question.  LinkedList is fast for adding and deleting elements, but slow to access a specific element.  ArrayList is fast for accessing a specific element but can be slow to add to either end, and especially slow to delete in the middle.


Array vs ArrayList vs LinkedList vs Vector:   -- goes more in depth, as does 


Linked list


Correct or Incorrect: Please execute test locally and decide yourself!!


Edit/Remove is faster in LinkedList than ArrayList.


ArrayList, backed by Array, which needs to be double the size, is worse in large volume application.


Below is the unit test result for each operation.Timing is given in Nanoseconds.


ArrayList is essentially an array. LinkedList is implemented as a double linked list. 


The get is pretty clear. O(1) for ArrayList, because ArrayList allow random access by using index. O(n) for LinkedList, because it needs to find the index first. Note: there are different versions of add and remove. 


LinkedList is faster in add and remove, but slower in get. In brief, LinkedList should be preferred if: 


=== ArrayList ===


=== LinkedList ===


add(int index, E element)


Here is a figure from programcreek.com (add and remove are the first type, i.e., add an element at the end of the list and remove the element at the specified position in the list.):





ArrayList is randomly accessible, while LinkedList is really cheap to expand and remove elements from.  For most cases, ArrayList is fine.


Unless you're created large lists and have measured a bottleneck, you'll probably never need to worry about the difference.


1) Search: ArrayList search operation is pretty fast compared to the LinkedList search operation. get(int index) in ArrayList gives the performance of O(1) while LinkedList performance is O(n).


Reason: ArrayList maintains index based system for its elements as it uses array data structure implicitly which makes it faster for searching an element in the list. On the other side LinkedList implements doubly linked list which requires the traversal through all the elements for searching an element.


2) Deletion: LinkedList remove operation gives O(1) performance while ArrayList gives variable performance: O(n) in worst case (while removing first element) and O(1) in best case (While removing last element).


Conclusion: LinkedList element deletion is faster compared to ArrayList.


Reason: LinkedList’s each element maintains two pointers (addresses) which points to the both neighbor elements in the list. Hence removal only requires change in the pointer location in the two neighbor nodes (elements) of the node which is going to be removed. While In ArrayList all the elements need to be shifted to fill out the space created by removed element.


3) Inserts Performance: LinkedList add method gives O(1) performance while ArrayList gives O(n) in worst case. Reason is same as explained for remove.


4) Memory Overhead: ArrayList maintains indexes and element data while LinkedList maintains element data and two pointers for neighbor nodes hence the memory consumption is high in LinkedList comparatively.


There are few similarities between these classes which are as follows:


Both ArrayList and LinkedList are implementation of List interface.
They both maintain the elements insertion order which means while displaying ArrayList and LinkedList elements the result set would be having the same order in which the elements got inserted into the List.
Both these classes are non-synchronized and can be made synchronized explicitly by using Collections.synchronizedList method.
The iterator and listIterator returned by these classes are fail-fast (if list is structurally modified at any time after the iterator is created, in any way except through the iterator’s own remove or add methods, the iterator will throw a ConcurrentModificationException).


When to use LinkedList and when to use ArrayList?


1) As explained above the insert and remove operations give good performance (O(1)) in LinkedList compared to ArrayList(O(n)). Hence if there is a requirement of frequent addition and deletion in application then LinkedList is a best choice.


2) Search (get method) operations are fast in Arraylist (O(1)) but not in LinkedList (O(n)) so If there are less add and remove operations and more search operations requirement, ArrayList would be your best bet.


I know this is an old post, but I honestly can't believe nobody mentioned that LinkedList implements Deque.  Just look at the methods in Deque (and Queue); if you want a fair comparison, try running LinkedList against ArrayDeque and do a feature-for-feature comparison. 


If your code has add(0) and remove(0), use a LinkedList and it's prettier addFirst() and removeFirst() methods. Otherwise, use ArrayList.


And of course, Guava's ImmutableList is your best friend.


Here is the big O notation in both ArrayList and LinkedList and also CopyOnWrite-ArrayList

ArrayList

get --> O(1) 
add --> O(1) 
contains --> O(n) 
next --> O(1) 
remove --> O(n) 
iterator.remove --> O(n) 



LinkedList 
get --> O(n) 
add --> O(1) 
contains --> O(n) 
next --> O(1) 
remove --> O(1) 
iterator.remove --> O(1) 



CopyOnWrite-ArrayList

get --> O(1) 
add --> O(n) 
contains --> O(n) 
next --> O(1) 
remove --> O(n) 
iterator.remove --> O(n) 



Based on these you have to decide what to choose :)


Have a look at the below image....


http://javaconceptoftheday.com/wp-content/uploads/2014/12/ArrayListVsLinkedList.png


Image Source : ArrayList Vs LinkedList In Java.


Joshua Bloch, the author of LinkedList:


Does anyone actually use LinkedList?  I wrote it, and I never use it.


Link: https://twitter.com/joshbloch/status/583813919019573248


I'm sorry for the answer for being not that informative as the other answers, but I thought it would be the most interesting and self-explanatory.


Here is important different of both


In addition to the other good arguments above, you should notice ArrayList implements RandomAccess interface, while LinkedList implements Queue.
So somehow they address slightly different problems, with difference of efficiency and behavior (see their list of methods).


Let's compare LinkedList and ArrayList w.r.t. below parameters:


ArrayList is the resizable array implementation of list interface , while 


LinkedList is the Doubly-linked list implementation of the list interface.


ArrayList get(int index) operation runs in constant time i.e O(1)  while 


LinkedList get(int index) operation run time is O(n) .


The reason behind ArrayList being faster than LinkedList is that ArrayList uses index based system for its elements as it internally uses array data structure , on the other hand ,


LinkedList does not provide index based access for its elements as it iterates either from the beginning or end (whichever is closer) to retrieve the node at the specified element index.


Insertions in LinkedList are generally fast as compare to ArrayList. In LinkedList adding or insertion is O(1) operation . 


While in ArrayList, if array is full i.e worst case,  there is extra cost of  resizing array and copying elements to the new array , which makes runtime of add operation in ArrayList O(n) , otherwise it is O(1) .


Remove operation in LinkedList is generally same as ArrayList i.e. O(n).


In LinkedList , there are two overloaded remove methods. one is remove() without any parameter which removes the head of the list and runs in constant time O(1) . The other overloaded remove method in LinkedList is remove(int) or remove(Object) which removes the Object or int passed as parameter . This method traverses the LinkedList until it found the Object and unlink it from the original list . Hence this method run time is O(n). 


While in ArrayList remove(int) method involves copying elements from old array to new updated array , hence its run time is O(n).


LinkedList can be iterated in reverse direction using descendingIterator() while 


there is no descendingIterator() in ArrayList , so we need to write our own code to iterate over the ArrayList in reverse direction.


If the constructor  is not overloaded , then ArrayList creates an empty list of initial capacity 10 , while 


LinkedList  only constructs the empty list without any initial capacity.


Memory overhead in LinkedList is more as compared to ArrayList as node in LinkedList needs to maintain the addresses of next and previous node. While 


In ArrayList  each index only holds the actual object(data).


Source


See the Java Tutorials - List Implementations.


An array list is essentially an array with methods to add items etc. (and you should use a generic list instead). It is a collection of items which can be accessed through an indexer  (for example [0]). It implies a progression from one item to the next.


A linked list specifies a progression from one item to the next (Item a -> item b).  You can get the same effect with an array list, but a linked list absolutely says what item is supposed to follow the previous one. 


It depends upon what operations you will be doing more on the List.


ArrayList is faster to access an indexed value.  It is much worse when inserting or deleting objects.


To find out more, read any article that talks about the difference betwen arrays and linked lists.


I have read the responses, but there is one scenario where I always use a LinkedList over an ArrayList that I want to share to hear opinions:


Every time I had a method that returns a list of data obtained from a DB I always use a LinkedList.


My rationale was that because it is impossible to know exactly how many results am I getting, there will be not memory wasted (as in ArrayList with the difference between the capacity and actual number of elements), and there would be no time wasted trying to duplicate the capacity.


As far a ArrayList, I agree that at least you should always use the constructor with the initial capacity, to minimize the duplication of the arrays as much as possible.


An important feature of a linked list (which I didn't read in another answer) is the concatenation of two lists. With an array this is O(n) (+ overhead of some reallocations) with a linked list this is only O(1) or O(2) ;-)


Important: For Java its LinkedList this is not true! See Is there a fast concat method for linked list in Java?


Operation get(i) in ArrayList is faster than LinkedList, because:
ArrayList: Resizable-array implementation of the List interface
LinkedList: Doubly-linked list implementation of the List and Deque interfaces


Operations that index into the list will traverse the list from the beginning or the end, whichever is closer to the specified index. 


ArrayList and LinkedList have their own pros and cons.


ArrayList uses contiguous memory address compared to LinkedList which uses pointers toward the next node. So when you want to look up an element in an ArrayList is faster than doing n iterations with LinkedList.


On the other hand, insertion and deletion in a LinkedList are much easier because you just have to change the pointers whereas an ArrayList implies the use of shift operation for any insertion or deletion.


If you have frequent retrieval operations in your app use an ArrayList. If you have frequent insertion and deletion use a LinkedList. 


ArrayList and LinkedList both implements List interface  and their methods and results are almost identical. However there are few differences between them which make one better over another depending on the requirement.


1) Search: ArrayList search operation is pretty fast compared to the LinkedList search operation. get(int index) in ArrayList gives the performance of O(1) while LinkedList performance is O(n).


Reason: ArrayList maintains index based system for its elements as it uses array data structure implicitly which makes it faster for searching an element in the list. On the other side LinkedList implements doubly linked list which requires the traversal through all the elements for searching an element.


2) Deletion: LinkedList remove operation gives O(1) performance while ArrayList gives variable performance: O(n) in worst case (while removing first element) and O(1) in best case (While removing last element).


Conclusion: LinkedList element deletion is faster compared to
  ArrayList.


Reason: LinkedList’s each element maintains two pointers (addresses) which points to the both neighbor elements in the list. Hence removal only requires change in the pointer location in the two neighbor nodes (elements) of the node which is going to be removed. While In ArrayList all the elements need to be shifted to fill out the space created by removed element.


3) Inserts Performance: LinkedList add method gives O(1) performance while ArrayList gives O(n) in worst case. Reason is same as explained for remove.


4) Memory Overhead: ArrayList maintains indexes and element data while LinkedList maintains element data and two pointers for neighbor nodes 


hence the memory consumption is high in LinkedList comparatively.


Hence if there is a requirement of frequent addition and deletion in application then LinkedList is a best choice.


so If there are less add and remove operations and more search operations requirement, ArrayList would be your best bet.


Both remove() and insert() have a runtime efficiency of O(n) for both ArrayLists and LinkedLists. However the reason behind the linear processing time comes from two very different reasons:


In an ArrayList you get to the element in O(1), but actually removing or inserting something makes it O(n) because all the following elements need to be changed.


In a LinkedList it takes O(n) to actually get to the desired element, because we have to start at the very beginning until we reach the desired index. Actually removing or inserting is constant, because we only have to change 1 reference for remove() and 2 references for insert().


Which of the two is faster for inserting and removing depends on where it happens. If we are closer to the beginning the LinkedList will be faster, because we have to go through relatively few elements. If we are closer to the end an ArrayList will be faster, because we get there in constant time and only have to change the few remaining elements that follow it. When done precisely in the middle the LinkedList will be faster because going through n elements is quicker than moving n values.


Bonus: While there is no way of making these two methods O(1) for an ArrayList, there actually is a way to do this in LinkedLists. Lets say we want to go through the entire List removing and inserting elements on our way. Usually you would start from the very beginning for each elements using the LinkedList, we could also "save" the current element we're working on with an Iterator. With the help of the Iterator we get a O(1) efficiency for remove() and insert() when working in a LinkedList. Making it the only performance benefit I'm aware of where a LinkedList is always better than an ArrayList.


When you want to add an item or delete an item from a list, without bothering about item's location, use ArrayList. It will be faster than linked list. Suppose if you want to add to or delete from a peculiar location in a collection, use linked list


When should I use LinkedList? When working with stacks mostly, or when working with buffers.
When should I use ArrayList? Only when working with indexes,  otherwise you can use HashTable with linked list, then you get:


It seems like a good solution, and in most of the cases it is, how ever you should know:
HashTable takes a lot of disc space, so when you need to manage 1,000,000 elements list it can become a thing that matters. This can happen in server implementations, in clients it is rarely the case.


Also take a look at Red-Black-Tree






I'm trying to write a Java routine to evaluate simple math expressions from String values like:


I want to avoid a lot of if-then-else statements.
How can I do this?


With JDK1.6, you can use the built-in Javascript engine.


I've written this eval method for arithmetic expressions to answer this question. It does addition, subtraction, multiplication, division, exponentiation (using the ^ symbol), and a few basic functions like sqrt. It supports grouping using (...), and it gets the operator precedence and associativity rules correct.


Example:


Output: 7.5 (which is correct)


The parser is a recursive descent parser, so internally uses separate parse methods for each level of operator precedence in its grammar. I kept it short so it's easy to modify, but here are some ideas you might want to expand it with:


Variables:


The bit of the parser that reads the names for functions can easily be changed to handle custom variables too, by looking up names in a variable table passed to the eval method, such as a Map<String,Double> variables.


Separate compilation and evaluation:


What if, having added support for variables, you wanted to evaluate the same expression millions of times with changed variables, without parsing it every time? It's possible. First define an interface to use to evaluate the precompiled expression:


Now change all the methods that return doubles, so instead they return an instance of that interface. Java 8's lambda syntax works great for this. Example of one of the changed methods:


That builds a recursive tree of Expression objects representing the compiled expression (an abstract syntax tree). Then you can compile it once and evaluate it repeatedly with different values:


Different datatypes:


Instead of double, you could change the evaluator to use something more powerful like BigDecimal, or a class that implements complex numbers, or rational numbers (fractions). You could even use Object, allowing some mix of datatypes in expressions, just like a real programming language. :)


All code in this answer released to the public domain. Have fun!


The correct way to solve this is with a lexer and a parser. You can write simple versions of these yourself, or those pages also have links to Java lexers and parsers.


Creating a recursive descent parser is a really good learning exercise.


HERE is another open source library on GitHub named EvalEx.


Unlike the JavaScript engine this library is focused in evaluating mathematical expressions only. Moreover, the library is extensible and supports use of boolean operators as well as parentheses.


You can also try the BeanShell interpreter:


You can evaluate expressions easily if your Java application already accesses a database, without using any other JARs.


Some databases require you to use a dummy table (eg, Oracle's "dual" table) and others will allow you to evaluate expressions without "selecting" from any table.


For example, in Sql Server or Sqlite


and in Oracle


The advantage of using a DB is that you can evaluate many expressions at the same time. Also most DB's will allow you to use highly complex expressions and   will also have a number of extra functions that can be called as necessary.  


However performance may suffer if many single expressions need to be evaluated individually, particularly when the DB is located on a network server.


The following addresses the performance problem to some extent, by using a Sqlite in-memory database.    


Here's a full working example in Java


Of course you could extend the above code to handle multiple calculations at the same time.


This article points to 3 different approaches, one which is JEXL from Apache and allows for scripts that include references to java objects.


To my university project I was looking for a parser / evaluator supporting both basic formulas and more complicated equations (especially iterated operators). I found very nice open source library for JAVA and .NET called mXparser. I will give a few examples to make some feeling on the syntax, for further instructions please visit project website (especially tutorial section).


http://mathparser.org/


http://mathparser.org/mxparser-tutorial/


http://mathparser.org/api/


And few examples


1 - Simple furmula


2 - User defined arguments and constants


3 - User defined functions


4 - Iteration


Best regards


It seems like JEP should do the job


Another way is to use Spring Expression Language or SpEL which does a whole lot more along with evaluating mathematical expressions therefore maybe slightly overkill. You do not have to be using Spring framework to use this expression library as it is stand-alone. Copying examples from SpEL's documentation: 


Read more concise SpEL examples here and the complete docs here


This is another interesting alternative 
https://github.com/Shy-Ta/expression-evaluator-demo


The usage is very simple and gets the job done, for example:


I think what ever way you do this it's going to involve a lot of conditional statements. But for single operations like in your examples you could limit it to 4 if statements with something like 


It gets a whole lot more complicated when you want to deal with multiple operations like "4+5*6".


If you are trying to build a calculator then I'd surgest passing each section of the calculation separatly (each number or operator) rather than as a single string.


if we are going to implement it then we can can use the below algorithm :--


While there are still tokens to be read in,


1.1 Get the next token.
1.2 If the token is:


1.2.1 A number: push it onto the value stack.


1.2.2 A variable: get its value, and push onto the value stack.


1.2.3 A left parenthesis: push it onto the operator stack.


1.2.4 A right parenthesis:


1.2.5 An operator (call it thisOp):


While the operator stack is not empty,
1 Pop the operator from the operator stack.
2 Pop the value stack twice, getting two operands.
3 Apply the operator to the operands, in the correct order.
4 Push the result onto the value stack.


At this point the operator stack should be empty, and the value
stack should have only one value in it, which is the final result.


You might have a look at the Symja framework:


Take note that definitively more complex expressions can be evaluated:


This is actually complementing the answer given by @Boann. It has a slight bug which causes "-2 ^ 2" to give an erroneous result of -4.0. The problem for that is the point at which the exponentiation is evaluated in his. Just move the exponentiation to the block of parseTerm(), and you'll be all fine. Have a look at the below, which is @Boann's answer slightly modified. Modification is in the comments.


How about something like this:


and do the similar thing for every other mathematical operator accordingly .. 


It is possible to convert any expression string in infix notation to a postfix notation using Djikstra's shunting-yard algorithm. The result of the algorithm can then serve as input to the postfix algorithm with returns the result of the expression.


I wrote an article about it here, with an implementation in java


It's too late to answer but I came across same situation to evaluate expression in java, it might help someone


MVEL does runtime evaluation of expressions, we can write a java code in String to get it evaluated in this.


Yet another option: https://github.com/stefanhaustein/expressionparser


I have implemented this to have a simple but flexible option to permit both:


The TreeBuilder linked above is part of a CAS demo package that does symbolic derivation. There is also a BASIC interpreter example and I have started to build a TypeScript interpreter using it.


Try the following sample code using JDK1.6's Javascript engine with code injection handling.


package ExpressionCalculator.expressioncalculator;


import java.text.DecimalFormat;
import java.util.Scanner;


public class ExpressionCalculator {


}


A Java class that can evaluate mathematical expressions:


External library like RHINO or NASHORN can be used to run javascript. And javascript can evaluate simple formula without parcing the string. No performance impact as well if code is written well.
Below is an example with RHINO - 






I always thought Java was pass-by-reference; however I've seen a couple of blog posts (For example, this blog) that claim it's not. I don't think I understand the distinction they're making. 


What is the explanation?


Java is always pass-by-value. Unfortunately, they decided to call the location of an object a "reference".  When we pass the value of an object, we are passing the reference to it.  This is confusing to beginners.


It goes like this:


In this example aDog.getName() will still return "Max". The value aDog within main is not changed in the function foo with the Dog "Fifi" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return "Fifi" after the call to foo.


Likewise:


In the above example, FiFi is the dog's name after call to foo(aDog) because the object's name was set inside of foo(...). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog itself (except when d is changed to point to a different Dog instance like d = new Dog("Boxer")).


I just noticed you referenced my article.


The Java Spec says that everything in Java is pass-by-value. There is no such thing as "pass-by-reference" in Java.


The key to understanding this is that something like


is not a Dog; it's actually a pointer to a Dog.


What that means, is when you have


you're essentially passing the address of the created Dog object to the foo method.


(I say essentially because Java pointers aren't direct addresses, but it's easiest to think of them that way)


Suppose the Dog object resides at memory address 42. This means we pass 42 to the method.


if the Method were defined as


let's look at what's happening.


Now let's think about what happens outside the method:


Did myDog change?


There's the key.


Keeping in mind that myDog is a pointer, and not an actual Dog, the answer is NO. myDog still has the value 42; it's still pointing to the original Dog (but note that because of line "AAA", its name is now "Max" - still the same Dog; myDog's value has not changed.)


It's perfectly valid to follow an address and change what's at the end of it; that does not change the variable, however.


Java works exactly like C. You can assign a pointer, pass the pointer to a method, follow the pointer in the method and change the data that was pointed to. However, you cannot change where that pointer points.


In C++, Ada, Pascal and other languages that support pass-by-reference, you can actually change the variable that was passed.


If Java had pass-by-reference semantics, the foo method we defined above would have changed where myDog was pointing when it assigned someDog on line BBB.


Think of reference parameters as being aliases for the variable passed in. When that alias is assigned, so is the variable that was passed in.


Java always passes arguments by value NOT by reference.


Let me explain this through an example:



I will explain this in steps:


Declaring a reference named f of type Foo and assign it to a new object of type Foo with an attribute "f".





From the method side, a reference of type Foo with a name a is declared and it's initially assigned to null.





As you call the method changeReference, the reference a will be assigned to the object which is passed as an argument.





Declaring a reference named b of type Foo and assign it to a new object of type Foo with an attribute "b".





a = b is re-assigning the reference a NOT f to the object whose its attribute is "b".





As you call modifyReference(Foo c) method, a reference c is created and assigned to the object with attribute "f".





c.setAttribute("c"); will change the attribute of the object that reference c points to it, and it's same object that reference f points to it.





I hope you understand now how passing objects as arguments works in Java :)


This will give you some insights of how Java really works to the point that in your next discussion about Java passing by reference or passing by value you'll just smile :-)


Step one please erase from your mind that word that starts with 'p' "_ _ _ _ _ _ _", especially if you come from other programming languages. Java and 'p' cannot be written in the same book, forum, or even txt.


Step two remember that when you pass an Object into a method you're passing the Object reference and not the Object itself.


Now think of what an Object's reference/variable does/is:


In the following (please don't try to compile/execute this...):


What happens?


A picture is worth a thousand words:





Note that the anotherReferenceToTheSamePersonObject arrows is directed towards the Object and not towards the variable person!


If you didn't get it then just trust me and remember that it's better to say that Java is pass by value. Well, pass by reference value. Oh well, even better is pass-by-copy-of-the-variable-value! ;)


Now feel free to hate me but note that given this there is no difference between passing primitive data types and Objects when talking about method arguments.


You always pass a copy of the bits of the value of the reference!


Java is pass-by-value because inside a method you can modify the referenced Object as much as you want but no matter how hard you try you'll never be able to modify the passed variable that will keep referencing (not p _ _ _ _ _ _ _) the same Object no matter what!


The changeName function above will never be able to modify the actual content (the bit values) of the passed reference. In other word changeName cannot make Person person refer to another Object.


Of course you can cut it short and just say that  Java is pass-by-value!


Java is always pass by value, with no exceptions, ever.


So how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.


So, when calling a method


So if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.


Naturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference.


Java passes references by value.


So you can't change the reference that gets passed in.


Just to show the contrast, compare the following C++ and Java snippets:


In C++: Note: Bad code - memory leaks!  But it demonstrates the point.


In Java, 


Java only has the two types of passing: by value for built-in types, and by value of the pointer for object types.


I feel like arguing about "pass-by-reference vs pass-by-value" is not super-helpful.


If you say, "Java is pass by whatever (reference/value)", but in either case you're not provide a complete answer. Here's some additional information that will hopefully aid in understanding what's happening in memory.


Crash course on stack/heap before we get to the Java implementation:
Values go on and off the stack in a nice orderly fashion, like a stack of plates at a cafeteria.
Memory in the heap (also known as dynamic memory) is haphazard and disorganized. The JVM just finds space wherever it can, and frees it up as the variables that use it are no longer needed.


Okay. First off, local primitives go on the stack. So this code:


results in this:





When you declare and instantiate an object. The actual object goes on the heap. What goes on the stack? The address of the object on the heap. C++ programmers would call this a pointer, but some Java developers are racist against the word "pointer". Whatever. Just know that the address of the object goes in the stack.


Like so:





An array is an object, so it goes on the heap as well. And what about the objects in the array? They get their own heap space, and the address of each object goes inside the array.





So, what gets passed in when you call a method? If you pass in an object, what you're actually passing in is the address of the object. Some might say the "value" of the address, and some say it's just a reference to the object. This is the genesis of the holy war between "reference" and "value" proponents. What you call it isn't as important as that you understand that what's getting passed in is the address to the object.


One String gets created and space for it is allocated in the heap, and the address to the string is stored on the stack and given the identifier hisName, since the address of the second String is the same as the first, no new String is created and no new heap space is allocated, but a new identifier is created on the stack. Then we call shout(): a new stack frame is created and a new identifier, name is created and assigned the address of the already-existing String.





So, value, reference? You say "potato".


Java passes references to objects by value.


I can't believe that nobody mentioned Barbara Liskov yet. When she designed CLU in 1974, she ran into this same terminology problem, and she invented the term call by sharing (also known as call by object-sharing and call by object) for this specific case of "call by value where the value is a reference".


Basically, reassigning Object parameters doesn't affect the argument, e.g.,


will print out "Hah!" instead of NULL. The reason this works is because bar is a copy of the value of baz, which is just a reference to "Hah!". If it were the actual reference itself, then foo would have redefined baz to null.


The crux of the matter is that the word reference in the expression "pass by reference" means something completely different from the usual mening of the word reference in Java. 


Usually in Java reference means a a reference to an object. But the technical terms pass by reference/value from programming language theory is talking about a reference to the memory cell holding the variable, which is someting completely different.


In java everything is reference, so when you have something like:
    Point pnt1 = new Point(0,0); Java does following:





Java doesn't pass method arguments by reference; it passes them by value. I will use example from this site: 


Flow of the program:


Creating two different Point object with two different reference associated.



As expected output will be:


On this line 'pass-by-value' goes into the play... 


References pnt1 and pnt2 are passed by value to the tricky method, which means that now yours references pnt1 and pnt2 have their copies named arg1 and arg2.So pnt1 and arg1 points to the same object. (Same for the pnt2 and arg2)



In the tricky method:





Next in the tricky method


Here, you first create new temp Point reference which will point on same place like arg1 reference. Then you move reference arg1 to point to the same place like arg2 reference.
Finally arg2 will point to the same place like temp.





From here scope of tricky method is gone and you don't have access any more to the references: arg1, arg2, temp. But important note is that everything you do with these references when they are 'in life' will permanently affect object on which they are point to. 


So after executing method tricky, when you return to main, you have this situation:



So now, completely execution of program will be:


Getting an outside of the box view, let's look at Assembly or some low level memory management. At the CPU level a reference to anything immediately becomes a value if it gets written to memory or to one of the CPU registers. (That is why pointer is a good definition. It is a value, which has a purpose at the same time).


Data in memory has a Location and at that location there is a value (byte,word, whatever). In Assembly we have a convenient solution to give a Name to certain Location (aka variable), but when compiling the code, the assembler simply replaces Name with the designated location just like your browser replaces domain names with IP addresses.


Down to the core it is technically impossible to pass a reference to anything in any language without representing it (when it immediately becomes a value).


Lets say we have a variable Foo, its Location is at the 47th byte in memory and its Value is 5. We have another variable Ref2Foo which is at 223rd byte in memory, and its value will be 47. This Ref2Foo might be a technical variable, not explicitly created by the program. If you just look at 5 and 47 without any other information, you will see just two Values.
If you use them as references then to reach to 5 we have to travel:


This is how jump-tables work. 


If we want to call a method/function/procedure with Foo's value, there are a few possible way to pass the variable to the method, depending on the language and its several method invocation modes:


In every cases above a value - a copy of an existing value - has been created, it is now upto the receiving method to handle it. When you write "Foo" inside the method, it is either read out from EAX, or automatically  dereferenced, or double dereferenced, the process depends on how the language works and/or what the type of Foo dictates. This is hidden from the developer until she circumvents the dereferencing process. So a reference is a value when represented, because a reference is a value that has to be processed (at language level).


Now we have passed Foo to the method:


Nitpicking on insignificant details, even languages that do pass-by-reference will pass values to functions, but those functions know that they have to use it for dereferencing purposes. This pass-the-reference-as-value is just hidden from the programmer because it is practically useless and the terminology is only pass-by-reference.


Strict pass-by-value is also useless, it would mean that a 100 Mbyte array should have to be copied every time we call a method with the array as argument, therefore Java cannot be stricly pass-by-value. Every language would pass a reference to this huge array (as a value) and either employs copy-on-write mechanism if that array can be changed locally inside the method or allows the method (as Java does) to modify the array globally (from the caller's view) and a few languages allows to modify the Value of the reference itself.


So in short and in Java's own terminology, Java is pass-by-value where value can be: either a real value or a value that is a representation of a reference. 


No, it's not pass by reference.


Java is pass by value according to the Java Language Specification:


When the method or constructor is invoked (§15.12), the values of the actual argument expressions initialize newly created parameter variables, each of the declared type, before execution of the body of the method or constructor. The Identifier that appears in the DeclaratorId may be used as a simple name in the body of the method or constructor to refer to the formal parameter. 


As far as I know, Java only knows call by value. This means for primitive datatypes you will work with an copy and for objects you will work with an copy of the reference to the objects. However I think there are some pitfalls; for example, this will not work:


This will populate Hello World and not World Hello because in the swap function you use copys which have no impact on the references in the main. But if your objects are not immutable you can change it for example:


This will populate Hello World on the command line. If you change StringBuffer into String it will produce just Hello because String is immutable. For example:


However you could make a wrapper for String like this which would make it able to use it with Strings:


edit: i believe this is also the reason to use StringBuffer when it comes to "adding" two Strings because you can modifie the original object which u can't with immutable objects like String is.


Let me try to explain my understanding with the help of four examples. Java is pass-by-value, and not pass-by-reference


/**


Pass By Value


In Java, all parameters are passed by value, i.e. assigning a method argument is not visible to the caller.


*/


Example 1:


Result


Example 2:


/**
 * 
 * Pass By Value
 *
 */


Result


Example 3:


/**
  This 'Pass By Value has a feeling of 'Pass By Reference'


Some people say primitive types and 'String' are 'pass by value'
  and objects are 'pass by reference'.


But from this example, we can understand that it is infact pass by value only,
  keeping in mind that here we are passing the reference as the value.
  ie: reference is passed by value.
  That's why are able to change and still it holds true after the local scope.
  But we cannot change the actual reference outside the original scope.
  what that means is demonstrated by next example of PassByValueObjectCase2.


*/


Result


Example 4:


/**


In addition to what was mentioned in Example3 (PassByValueObjectCase1.java),  we cannot change the actual reference outside the original scope."


Note: I am not pasting the code for private class Student. The class definition for Student is same as Example3.


*/


Result


You can never pass by reference in Java, and one of the ways that is obvious is when you want to return more than one value from a method call. Consider the following bit of code in C++:


Sometimes you want to use the same pattern in Java, but you can't; at least not directly. Instead you could do something like this:


As was explained in previous answers, in Java you're passing a pointer to the array as a value into getValues. That is enough, because the method then modifies the array element, and by convention you're expecting element 0 to contain the return value. Obviously you can do this in other ways, such as structuring your code so this isn't necessary, or constructing a class that can contain the return value or allow it to be set. But the simple pattern available to you in C++ above is not available in Java.


I thought I'd contribute this answer to add more details from the Specifications.


First, What's the difference between passing by reference vs. passing by value?


Passing by reference means the called functions' parameter will be the
  same as the callers' passed argument (not the value, but the identity
  - the variable itself). 


Pass by value means the called functions' parameter will be a copy of
  the callers' passed argument.


Or from wikipedia, on the subject of pass-by-reference


In call-by-reference evaluation (also referred to as
  pass-by-reference), a function receives an implicit reference to a
  variable used as argument, rather than a copy of its value. This
  typically means that the function can modify (i.e. assign to) the
  variable used as argument—something that will be seen by its caller.


And on the subject of pass-by-value


In call-by-value, the argument expression is evaluated, and the
  resulting value is bound to the corresponding variable in the function [...]. 
  If the function or procedure is able to assign values to its
  parameters, only its local copy is assigned [...].


Second, we need to know what Java uses in its method invocations. The Java Language Specification states


When the method or constructor is invoked (§15.12), the values of the
  actual argument expressions initialize newly created parameter
  variables, each of the declared type, before execution of the body of
  the method or constructor.


So it assigns (or binds) the value of the argument to the corresponding parameter variable. 


What is the value of the argument?


Let's consider reference types, the Java Virtual Machine Specification states


There are three kinds of reference types: class types, array types,
  and interface types. Their values are references to dynamically
  created class instances, arrays, or class instances or arrays that
  implement interfaces, respectively.


The Java Language Specification also states


The reference values (often just references) are pointers to these objects, and a special null reference, which refers to no object.


The value of an argument (of some reference type) is a pointer to an object. Note that a variable, an invocation of a method with a reference type return type, and an instance creation expression (new ...) all resolve to a reference type value.


So


all bind the value of a reference to a String instance to the method's newly created parameter, param. This is exactly what the definition of pass-by-value describes. As such, Java is pass-by-value.


The fact that you can follow the reference to invoke a method or access a field of the referenced object is completely irrelevant to the conversation. The definition of pass-by-reference was


This typically means that the function can modify (i.e. assign to) the
  variable used as argument—something that will be seen by its caller.


In Java, modifying the variable means reassigning it. In Java, if you reassigned the variable within the method, it would go unnoticed to the caller. Modifying the object referenced by the variable is a different concept entirely. 


Primitive values are also defined in the Java Virtual Machine Specification, here. The value of the type is the corresponding integral or floating point value, encoded appropriately (8, 16, 32, 64, etc. bits).


The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value.


Java is always pass by values NOT pass by reference 


first of we understand what is pass by value and pass by reference


pass by value means you are making a copy in memory of the actual parameter's value that is passed in, a copy of the contents of the actual parameter


pass by reference (also called pass by address), a copy of the address of the actual parameter is stored


Some time it gives illusion pass by reference.lets see how it works by example


Output of this program is 


changevalue


lets understand step by step


test t=new test();


as we all know it will create object in heap and return return reference value back to t. suppose for example value of t is 0x100234(its JVM internal value as we don't about it i have just consider it for example) 





new Passbyvalue().changeValue(t);


when passing reference t to function it will not directly pass actual reference value of object test but it will create copy of t and then it pass to function ( as it pass by value it passes copy of variable not actual reference of it) . As we consider value of t will be0x100234 . so in this way both t and f will have same value and hence they will point to same object





so if you change any thing in function using reference f it will modify existing contain of object that why we were getting output "changevalue" which is updated in function


to understand this more clearly consider following example


will it give null pointer no because it passes only copy of reference .In case of by reference it could have given nullpointer exception 





Hopefully this will help 


As many people mentioned it before, Java is always pass-by-value


Here is another example that will help you understand the difference (the classic swap example):


Prints:  


Before: a = 2, b = 3
  After: a = 2, b = 3


This happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method.


Java is a call by value .


How it works  .


You always pass a copy of the bits of the value of the reference!


If it's a primitive data type these bits contain the value of the primitive data type itself , That's why if we change the value of header inside the method then it's not reflect the changes outside.


If it's a object data type like Foo foo=new Foo() then in this case copy of the address of the object passes like file shortcut  , suppose we have a text file abc.txt at C:\desktop and suppose we make shortcut of same file and put this inside C:\desktop\abc-shortcut so when you access the file from C:\desktop\abc.txt and write 'Stack Overflow' and close the file and again you open the file from shortcut then you write ' is the largest online community for programmers to learn' then total file change will be 'Stack Overflow is the largest online community for programmers to learn' which means it does't matters from where you open the file , each time we were accessing the same file , here we can assume Foo as a file and suppose foo stored at 123hd7h(original address like C:\desktop\abc.txt ) address and 234jdid(copied address like C:\desktop\abc-shortcut which actually contains the original address of the file inside) ..
So for better understanding make shortcut file and feel.


I always think of it as "pass by copy". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.


output of java PassByCopy:


name= Maxx
  name= Fido


Primitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects.


I have created a thread devoted to these kind of questions for any programming languages here.


Java is also mentioned. Here is the short summary:


To make a long story short, Java objects have some very peculiar properties.


In general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.


Does this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.


Take this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++.


A few corrections to some posts.


C does NOT support pass by reference. It is ALWAYS pass by value. C++ does support pass by reference, but is not the default and is quite dangerous.


It doesn't matter what the value is in Java: primitive or address(roughly) of object, it is ALWAYS passed by value.


If a Java object "behaves" like it is being passed by reference, that is a property of mutability and has absolutely nothing to do with passing mechanisms.


I am not sure why this is so confusing, perhaps because so many Java "programmers" are not formally trained, and thus do not understand what is really going on in memory?


In Java only references are passed and are passed by value:


Java arguments are all passed by value (the variable is copied when used by the method) :


In the case of primitive types, Java behaviour is simple: 
The value is copied in another instance of the primitive type.


In case of Objects, this is the same: 
Object variables are pointers (buckets) holding only Object’s address that was created using the "new" keyword, and are copied like primitive types.


The behaviour can appear different from primitive types: Because the copied object-variable contains the same address (to the same Object)
Object's content/members might still be modified within a method and later access outside, giving the illusion that the (containing) Object itself was passed by reference. 


"String" Objects appear to be a perfect counter-example to the urban legend saying that "Objects are passed by reference":


In effect, within a method you will never be able, to update the value of a String passed as argument:


A String Object, holds characters by an array declared final that can't be modified.
Only the address of the Object might be replaced by another using "new". 
Using "new" to update the variable, will not let the Object be accessed from outside, since the variable was initially passed by value and copied.


Java has only pass by value. A very simple example to validate this.


It's really quite, quite simple:


For a variable of primitive type (eg. int, boolean, char, etc...), when you use its name for a method argument, you are passing the value contained in it (5, true, or 'c'). This value gets "copied", and the variable retains its value even after the method invocation.


For a variable of reference type (eg. String, Object, etc...), when you use its name for a method argument, you are passing the value contained in it (the reference value that "points" to the object). This reference value gets "copied", and the variable retains its value even after the method invocation. The reference variable keeps "pointing" to the same object.


Either way, you're always passing stuff by value.


Compare this to say C++ where you can have a method to take an int&, or in C# where you could have take a ref int (although, in this case, you also have to use the ref modifier when passing the variable's name to the method.)






I have the following JSON text that I need to parse to get pageName, pagePic, post_id, etc.


What is the required code?


The org.json library is easy to use. Example code below:


You may find extra examples from: Parse JSON in Java


Downloadable jar:  http://mvnrepository.com/artifact/org.json/json


For the sake of the example lets assume you have a class Person with just a name.


My personal favourite as to the great JSON serialisation / de-serialisation of objects.


Update


If you want to get a single attribute out you can do it easily with the Google library as well:


If you don't need object de-serialisation but to simply get an attribute, you can try org.json (or look GSON example above!)


If one wants to create JAVA object from JSON and vice versa, use GSON or JACKSON third party jars etc.


But if one just want to parse a JSON string and get some values, (OR create a JSON string from scratch to send over wire) just use JaveEE jar which contains JsonReader, JsonArray, JsonObject etc. You may want to download the implementation of that spec like javax.json. With these two jars I am able to parse the json and use the values.  


These APIs actually follow the DOM/SAX parsing model of XML.       


quick-json parser is very straightforward, flexible, very fast and customizable. Try it


Features:


It can be used like this:


Almost all the answers given requires a full deserialization of the JSON into a Java object before accessing the value in the property of interest. Another alternative, which does not go this route is to use JsonPATH which is like XPath for JSON and allows traversing of JSON objects.


It is a specification and the good folks at JayWay have created a Java implementation for the specification which you can find here: https://github.com/jayway/JsonPath


So basically to use it, add it to your project, eg:


and to use:


etc...


Check the JsonPath specification page for more information on the other ways to transverse JSON.


You can use Jackson libraries, for binding JSON String into POJO (Plain Old Java Object) instances. POJO is simply a class with only private fields and public getter/setter methods. Jackson is going to traverse the methods (using reflection), and maps the JSON object into the POJO instance as the field names of the class fits to the field names of the JSON object.


In your JSON object, which is actually a composite object, the main object consists o two sub-objects. So, our POJO classes should have the same hierarchy. I'll call the whole JSON Object as Page object. Page object consist of a PageInfo object, and a Post object array.


So we have to create three different POJO classes;


The only package I've used is Jackson ObjectMapper, what we do is binding data;


The required dependencies, the jar files is listed below;


Here is the required code;


I've just copied your JSON sample into this file and put it under the project folder.


You could use Google Gson


Using this library you only need to create a model with the same json structure. Then the model is automatically filled in. You have to call your variables as your json keys, or use @SerializedName if you want to use different names.


For your example:


Json:


}


Model:


Now you can parse using Gson library:


You can generate model from json automatically using online tools like this


Use minimal-json which is very fast and easy to use.
you can parse from String obj and Stream.
Sample Data :


Parsing :


Creating Json :


Maven :


I believe the best practice should be to go through the official Java JSON API which are still work in progress.


This blew my mind with how easy it was. You can just pass a String holding your JSON to the constructor of a JSONObject in the default org.json package. 


Done. Drops microphone.
This works with JSONObjects as well. After that, you can just look through your hierarchy of Objects using the get() methods on your objects.


The below example shows how to read the text in the question, represented as the "jsonText" variable.  This solution uses the Java EE7 javax.json API (which is mentioned in some of the other answers).  The reason I've added it as a separate answer is that the following code shows how to actually access some of the values shown in the question.  An implementation of the javax.json API would be required to make this code run.  The full package for each of the classes required was included as I didn't want to declare "import" statements.


Now, before anyone goes and downvotes this answer because it doesn't use GSON, org.json, Jackson, or any of the other 3rd party frameworks available, it's an example of "required code" per the question to parse the provided text.  I am well aware that adherence to the current standard JSR 353 was not being considered for JDK 9 and as such the JSR 353 spec should be treated the same as any other 3rd party JSON handling implementation.


If you have some Java class(say Message) representing the JSON string(jsonString), you can use Jackson  JSON library with:


and from message object you can fetch any of its attribute.


In addition to other answers, I recomend this online opensource service jsonschema2pojo.org for quick generating Java classes from json or json schema for GSON, Jackson 1.x or Jackson 2.x. For example, if you have:


The jsonschema2pojo.org for GSON generated:


There are many JSON libraries available in Java.


The most notorious ones are: Jackson, GSON, Genson, FastJson and org.json.


There are typically three things one should look at for choosing any library:


Specifically for JSON libraries (and any serialization/deserialization libs), databinding is also usually of interest as it removes the need of writing boiler-plate code to pack/unpack the data.


For 1, see this benchmark: https://github.com/fabienrenaud/java-json-benchmark I did using JMH which compares (jackson, gson, genson, fastjson, org.json, jsonp) performance of serializers and deserializers using stream and databind APIs.
For 2, you can find numerous examples on the Internet. The benchmark above can also be used as a source of examples...


Quick takeaway of the benchmark: Jackson performs 5 to 6 times better than org.json and more than twice better than GSON.


For your particular example, the following code decodes your json with jackson:


Let me know if you have any questions.


Gson is easy to learn and implement, what we need to know are following two methods


toJson() – Convert Java object to JSON format


fromJson() – Convert JSON into Java object


`


`


Please do something like this:


Since nobody mentioned it yet, here is a beginning of a solution using Nashorn (Javascript Runtime part of Java 8). 


Solution


Performance comparison


I wrote a json containing 3 arrays of respectively 20, 20 and 100 elements. I only want to get the 100 elements from the third array. I use the following js function to parse and get my entries.


Running a million time the call using


Nashorn takes 7.5~7.8"


org.json takes 20~21"


Jackson takes 6.5~7"


In this case Jackson performs better than Nashorn, which performs much better than org.json.
Nashorn API is harder to use than org.json's or Jackson's. Depending on your requirements Jackson and Nashorn both can be viable solutions.


There are many open source libraries are present to parse json to object or just to read json values. Your requirement is just to read values and parsing it to custom object. So org.json library is enough in your case. 


Use org.json library to parse it and create JsonObject :- 


Now, use this object to get your values :- 


You can see complete example here :- 


How to parse Json in java 


Read following blog json in java


This post is a little bit old but still i want to answer you Question


Step 1: Create a pojo class of your data.


Step 2: now create a object using json.


For further reference you can refer following link


Thanks


you can use Jayway JsonPath. below is github link with source code,pom details and good documentation.


https://github.com/jayway/JsonPath


Please follow below steps.


Step 1: add jayway json path dependency in your class path using maven or download jar file and manually add it.


Step 2: please save your input json as file for this example. in my case i saved your json as sampleJson.txt. Note you missed a comma between pageInfo and posts


Step 3: read the json contents from above file using bufferedReader and save it as String.


Step 4: parse your json string using jayway json parser.


Step 5: read the details like below.


Output will be:


I have json Like.


Java class


Code for converting this json to Java class.


Maven


Top answers on this page use too simple examples like object with one property (e.g. {name: value}). I think that still simple but real life example can help someone. 


So this is the JSON returned by Google Translate API: 


I want to retrieve the value of "translatedText" attribute e.g. "Arbeit" using Google's Gson.


Two possible approaches: 


Retrieve just one needed attribute


Create Java object from JSON


...


First you need to select an implementation library to do that.


The Java API for JSON Processing (JSR 353) provides portable APIs to parse, generate, transform, and query JSON using object model and streaming APIs. 


The reference implementation is here: https://jsonp.java.net/ 


Here you can find a list of implementations of JSR 353:


What are the API that does implement JSR-353 (JSON)


And to help you decide... I found this article as well:


http://blog.takipi.com/the-ultimate-json-library-json-simple-vs-gson-vs-jackson-vs-json/


If you go for Jackson, here is a good article about conversion between JSON to/from Java using Jackson: https://www.mkyong.com/java/how-to-convert-java-object-to-from-json-jackson/


Hope it helps!


You can use the Gson Library to parse the JSON string.


You can also loop through the "posts" array as so:


You can use JsonNode for a structured tree representation of your Json string, it's part of the rock solid jackson library (https://github.com/FasterXML/jackson) which is omnipresent


We can use the JSONObject class to convert json string to JSON object,
and to iterate over the json object.Use the following code.


As @Gioele Costa asked before and it was marked as duplicate i will answer here:


Suppose to have this response from backend


Following a backend - frontend and json parser utility 


I used AsyncTask to implement the software client side 


JSONParser class (note Apache Http Client is not supported anymore )






Do Android devices have a unique ID, and if so, what is a simple way to access it using Java?


Settings.Secure#ANDROID_ID returns the Android ID as an unique for each user 64-bit hex string.


UPDATE: As of recent versions of Android, many of the issues with ANDROID_ID have been resolved, and I believe this approach is no longer necessary. Please take a look at Anthony's answer.


Full disclosure: my app that the below approach was originally used in no longer uses this approach, and we now use the approach outlined in the Android Developer Blog entry that emmby's answer links to (namely, generating and saving a UUID#randomUUID()).


There are many answers to this question, most of which will only work "some" of the time, and unfortunately that's not good enough.


Based on my tests of devices (all phones, at least one of which is not activated):


So if you want something unique to the device itself, TM.getDeviceId() should be sufficient.  Obviously some users are more paranoid than others, so it might be useful to hash 1 or more of these identifiers, so that the string is still virtually unique to the device, but does not explicitly identify the user's actual device.  For example, using String.hashCode(), combined with a UUID:


might result in something like: 00000000-54b3-e7c7-0000-000046bffd97


It works well enough for me.


As Richard mentions below, don't forget that you need permission to read the TelephonyManager properties, so add this to your manifest:


import libs


After reading every Stack Overflow post about creating a unique ID, the Google developer blog and Android documentation, I feel as if the 'Pseudo ID' is the best possible option.


Psuedo code:


Thanks to @stansult for posting all of our options (in this Stack Overflow question).


User Email - Software


User Phone Number - Software


IMEI - Hardware (only phones, needs android.permission.READ_PHONE_STATE)


Android ID - Hardware (can be null, can change upon factory reset, can be altered on a rooted device)


WLAN MAC Address - Hardware (needs android.permission.ACCESS_WIFI_STATE)


Bluetooth MAC Address - Hardware (devices with Bluetooth, needs android.permission.BLUETOOTH)


Pseudo-Unique ID - Software (for all Android devices)


I know there isn't any 'perfect' way of getting a unique ID without using permissions; however, sometimes we only really need to do is track the device installation. When it comes to creating a unique ID, we can create a 'pseudo unique id' based solely off of information that the Android API gives us without using extra permissions. This way, we can show the user respect and try to offer a good user experience as well.


With a pseudo-unique id, you really only run into the fact that there may be duplicates based on the fact that there are similar devices. You can tweak the combined method to make it more unique; however, some developers need to track device installs and this will do the trick or performance based on similar devices.


If their Android device is API 9 or over, this is guaranteed to be unique because of the 'Build.SERIAL' field.


REMEMBER, you are technically only missing out on around 0.5% of users who have API < 9. So you can focus on the rest: This is 99.5% of the users!


If the user's Android device is lower than API 9; hopefully, they have not done a factory reset and their 'Secure.ANDROID_ID' will be preserved or not 'null'. (see http://developer.android.com/about/dashboards/index.html)


If all else fails, if the user does have lower than API 9 (lower than Gingerbread), has reset their device or 'Secure.ANDROID_ID' returns 'null', then simply the ID returned will be solely based off their Android device information. This is where the collisions can happen.


Changes:


Please take a look at the method below:


From the Google Play Developer's console:


Beginning August 1st, 2014, the Google Play Developer Program Policy
  requires all new app uploads and updates to use the advertising ID in
  lieu of any other persistent identifiers for any advertising purposes.
  Learn more


Implementation:


Permission:


Code:


Source/Docs:


http://developer.android.com/google/play-services/id.html
http://developer.android.com/reference/com/google/android/gms/ads/identifier/AdvertisingIdClient.html


It is intended that the advertising ID completely replace existing
  usage of other identifiers for ads purposes (such as use of ANDROID_ID
  in Settings.Secure) when Google Play Services is available. Cases
  where Google Play Services is unavailable are indicated by a
  GooglePlayServicesNotAvailableException being thrown by
  getAdvertisingIdInfo().


http://en.kioskea.net/faq/34732-android-reset-your-advertising-id


I have tried to reference every link that I took information from. If you are missing and need to be included, please comment!


https://developers.google.com/instance-id/


As Dave Webb mentions, the Android Developer Blog has an article that covers this.  Their preferred solution is to track app installs rather than devices, and that will work well for most use cases.  The blog post will show you the necessary code to make that work, and I recommend you check it out.


However, the blog post goes on to discuss solutions if you need a device identifier rather than an app installation identifier.  I spoke with someone at Google to get some additional clarification on a few items in the event that you need to do so.  Here's what I discovered about device identifiers that's NOT mentioned in the aforementioned blog post:


Based on Google's recommendations, I implemented a class that will generate a unique UUID for each device, using ANDROID_ID as the seed where appropriate, falling back on TelephonyManager.getDeviceId() as necessary, and if that fails, resorting to a randomly generated unique UUID that is persisted across app restarts (but not app re-installations).


Note that for devices that have to fallback on the device ID, the unique ID WILL persist across factory resets.  This is something to be aware of.  If you need to ensure that a factory reset will reset your unique ID, you may want to consider falling back directly to the random UUID instead of the device ID.


Again, this code is for a device ID, not an app installation ID.  For most situations, an app installation ID is probably what you're looking for.  But if you do need a device ID, then the following code will probably work for you.


Here is the code that Reto Meier used in the Google I/O presentation this year to get a unique id for the user:


If you couple this with a backup strategy to send preferences to the cloud (also described in Reto's talk, you should have an id that ties to a user and sticks around after the device has been wiped, or even replaced. I plan to use this in analytics going forward (in other words, I have not done that bit yet :).


Also you might consider the Wi-Fi adapter's MAC address. Retrieved thusly:


Requires permission android.permission.ACCESS_WIFI_STATE in the manifest.


Reported to be available even when Wi-Fi is not connected. If Joe from the answer above gives this one a try on his many devices, that'd be nice.


On some devices, it's not available when Wi-Fi is turned off.


NOTE: From Android 6.x, it returns consistent fake mac address: 02:00:00:00:00:00


There’s rather useful info here.


It covers five different ID types:


The official Android Developers Blog now has a full article just about this very subject, Identifying App Installations.


At Google I/O Reto Meier released a robust answer to how to approach this which should meet most developers needs to track users across installations. Anthony Nolan shows the direction in his answer, but I thought I'd write out the full approach so that others can easily see how to do it (it took me a while to figure out the details).


This approach will give you an anonymous, secure user ID which will be persistent for the user across different devices (based on the primary Google account) and across installs. The basic approach is to generate a random user ID and to store this in the apps' shared preferences. You then use Google's backup agent to store the shared preferences linked to the Google account in the cloud.


Let's go through the full approach. First, we need to create a backup for our SharedPreferences using the Android Backup Service. Start by registering your app via http://developer.android.com/google/backup/signup.html.


Google will give you a backup service key which you need to add to the manifest. You also need to tell the application to use the BackupAgent as follows:


Then you need to create the backup agent and tell it to use the helper agent for sharedpreferences:


To complete the backup you need to create an instance of BackupManager in your main Activity:


Finally create a user ID, if it doesn't already exist, and store it in the SharedPreferences:


This User_ID will now be persistent across installations, even if the user moves device.


For more information on this approach see Reto's talk.


And for full details of how to implement the backup agent see Data Backup. I particularly recommend the section at the bottom on testing as the backup does not happen instantaneously and so to test you have to force the backup.


The following code returns the device serial number using a hidden Android API. But, this code don't works on Samsung Galaxy Tab because "ro.serialno" isn't set on this device.


I think this is sure fire way of building a skeleton for a unique ID...  check it out.


Pseudo-Unique ID, that works on all Android devices
Some devices don't have a phone (eg. Tablets) or for some reason you don't want to include the READ_PHONE_STATE permission. You can still read details like ROM Version, Manufacturer name, CPU type, and other hardware details, that will be well suited if you want to use the ID for a serial key check, or other general purposes. The ID computed in this way won't be unique: it is possible to find two devices with the same ID (based on the same hardware and rom image) but the chances in real world applications are negligible. For this purpose you can use the Build class:


Most of the Build members are strings, what we're doing here is to take their length and transform it via modulo in a digit. We have 13 such digits and we are adding two more in front (35) to have the same size ID like the IMEI (15 digits). There are other possibilities here are well, just have a look at these strings.
Returns something like: 355715565309247 . No special permission are required, making this approach very convenient.


(Extra info: The technique given above was copied from an article on Pocket Magic.)


Using the code below, you can get the unique device ID of an Android OS device as a string.


A Serial field was added to the Build class in API level 9 (Android 2.3 - Gingerbread). Documentation says it represents the hardware serial number. Thus it should be unique, if it exists on the device. 


I don't know whether it is actually supported (=not null) by all devices with API level >= 9 though.


One thing I'll add - I have one of those unique situations.


Using:


Turns out that even though my Viewsonic G Tablet reports a DeviceID that is not Null, every single G Tablet reports the same number.


Makes it interesting playing "Pocket Empires" which gives you instant access to someone's account based on the "unique" DeviceID.


My device does not have a cell radio.


For detailed instructions on how to get a unique identifier for each Android device your application is installed from, see the official Android Developers Blog posting Identifying App Installations.


It seems the best way is for you to generate one yourself upon installation and subsequently read it when the application is re-launched.


I personally find this acceptable but not ideal. No one identifier provided by Android works in all instances as most are dependent on the phone's radio states (Wi-Fi on/off, cellular on/off, Bluetooth on/off). The others, like Settings.Secure.ANDROID_ID must be implemented by the manufacturer and are not guaranteed to be unique.


The following is an example of writing data to an installation file that would be stored along with any other data the application saves locally.


Add Below code in class file:


Add in AndroidManifest.xml:


But I strongly recommend a method suggested by Google, see Identifying App Installations.


Adding to what others have said, there is a new Best practices for unique identifiers guide in the official Android documentation: http://developer.android.com/training/articles/user-data-ids.html


There are a lot of different approaches to work around those ANDROID_ID issues (may be null sometimes or devices of a specific model always return the same ID) with pros and cons:


I myself prefer using an existing OpenUDID implementation (see https://github.com/ylechelle/OpenUDID) for Android (see https://github.com/vieux/OpenUDID). It is easy to integrate and makes use of the ANDROID_ID with fallbacks for those issues mentioned above.


My two cents - NB this is for a device (err) unique ID - not the installation one as discussed in the Android developers's blog.


Of note that the solution provided by @emmby falls back in a per application ID as the SharedPreferences are not synchronized across processes (see here and here). So I avoided this altogether.


Instead, I encapsulated the various strategies for getting a (device) ID in an enum - changing the order of the enum constants affects the priority of the various ways of getting the ID. The first non-null ID is returned or an exception is thrown (as per good Java practices of not giving null a meaning). So for instance I have the TELEPHONY one first - but a good default choice would be the ANDROID_ID
beta:


How about the IMEI. That is unique for Android or other mobile devices.


Here is how I am generating the unique id:


Another way is to use /sys/class/android_usb/android0/iSerial in an app without any permissions whatsoever.


To do this in Java one would just use a FileInputStream to open the iSerial file and read out the characters. Just be sure you wrap it in an exception handler, because not all devices have this file. 


At least the following devices are known to have this file world-readable:


You can also see my blog post Leaking Android hardware serial number to unprivileged apps where I discuss what other files are available for information.


For hardware recognition of a specific Android device you could check the MAC Addresses.


you can do it that way:


in AndroidManifest.xml


<uses-permission android:name="android.permission.INTERNET" />


now in your code:


In every Android device their is at least a "wlan0" Interface witch is the WI-FI chip.
This code works even when WI-FI is not turned on.


P.S.
Their are a bunch of other Interfaces you will get from the list containing MACS But this can change between phones.


I found a library on Github that seems to bundle a few of the approaches discussed in this thread: https://github.com/thomashaertel/android-device-identification


Haven't tried it, but maybe it helps.


Google Instance ID


Released at I/O 2015; on Android requires play services 7.5.


https://developers.google.com/instance-id/
https://developers.google.com/instance-id/guides/android-implementation


It seems that Google intends for this ID to be used to identify installations across Android, Chrome, and iOS.


It identifies an installation rather then a device, but then again, ANDROID_ID (which is the accepted answer) now no longer identifies devices either.  With the ARC runtime a new ANDROID_ID is generated for every installation (details here), just like this new instance ID.  Also, I think that identifying installations (not devices) is what most of us are actually looking for.


The advantages of instance ID


It appears to me that Google intends for it to be used for this purpose (identifying your installations), it is cross-platform, and can be used for a number of other purposes (see the links above).


If you use GCM, then you will eventually need to use this instance ID because you need it in order to get the GCM token (which replaces the old GCM registration ID).


The disadvantages/issues


In the current implementation (GPS 7.5) the instance ID is retrieved from a server when your app requests it.  This means that the call above is a blocking call - in my unscientific testing it takes 1-3 seconds if the device is online, and 0.5 - 1.0 seconds if off-line (presumably this is how long it waits before giving up and generating a random ID).  This was tested in North America on Nexus 5 with Android 5.1.1 and GPS 7.5.


If you use the ID for the purposes they intend - eg. app authentication, app identification, GCM - I think this 1-3 seconds could be a nuisance (depending on your app, of course).


I use the following code to get the IMEI or use Secure.ANDROID_ID as an alternative, when the device doesn't have phone capabilities:


More specifically, Settings.Secure.ANDROID_ID. This is a 64-bit quantity that is generated and stored when the device first boots. It is reset when the device is wiped.


ANDROID_ID seems a good choice for a unique device identifier. There are downsides: First, it is not 100% reliable on releases of Android prior to 2.2 (“Froyo”). Also, there has been at least one widely-observed bug in a popular handset from a major manufacturer, where every instance has the same ANDROID_ID.


Android device mac id also a unique id, it won't change suppose if we format the device itself so using the following code to get mac id


Also do not forget to add the appropriate permissions into your 
AndroidManifest.xml


There are 30+ answers here and some are same and some are unique. This answer is based on few of those answers. One of them being @Lenn Dolling's answer.


It combines 3 IDs and creates a 32-digit hex string. It has worked very well for me.  


3 IDs are:
Pseudo-ID - It is generated based on physical device specifications
ANDROID_ID - Settings.Secure.ANDROID_ID
Bluetooth Address - Bluetooth adapter address


It will return something like this:  551F27C060712A72730B0A0F734064B1


Note: You can always add more IDs to the longId string. For example, Serial #. wifi adapter address. IMEI. This way you are making it more unique per device.






I am a starting Java developer, learning just from internet tutorials. I am learning full screen GUI applications. I was told yesterday that I shouldn't use AWT in my programs, because it is outdated. I already know about light and heavyweight components, the main problem is the mouse and keyboard listeners. 
Why is AWT outdated?
How to make a program without AWT (adding listeners to JComponents etc) (what kind of Swing things can replace the AWT)?


You're mis-interpreting the information given to you. You should avoid using Swing components with AWT components. It's OK to use Swing with the AWT listener structure, layout managers, etc. and in fact it's impossible not to.


There have been some good answers, but I would like to cover a slightly different aspect.  Things that Swing provides beyond AWT.


Swing supports styled documents in JEditorPane & JTextPane & to a limited extent using HTML in some other JComponents.  AWT does not support styled documents in any component.  


AWT provides no tree based structure like JTree, no tabular structure such as JTable, no version of JToolBar.


 


AWT has no equivalent (that I can find or recall) for JColorChooser & none for the simple utility class - JOptionPane.  





As mentioned in a comment, see the 20+ extra/alternate listeners in the javax.swing.event package.


Swing components can be set to a particular look & feel at run-time, including a native PLAF.  





See the screen shots on the Nested Layout Example for some more samples.


In addition to the plethora of AWT layouts, Swing provides:


There is probably a lot more I missed in that brief description, but the bottom line is that Swing is an altogether newer and more enabled GUI toolkit.  


Swing both builds on, and relies heavily on, classes in the AWT.


Java's Swing takes ActionListeners, which are part of the AWT package.  If you wish to use swing, you must use some form of an AWT ActionListener.  That is just the way things are.  I don't suggest using Java at all for complex guis, but nor would I say that AWT is outdated, as there is no direct replacement.  Thus, just go ahead and use AWT.


As an alternative, you could look into JOGL, but that's more if you are trying to create something game-oriented.


This is a small example which can demonstrate, the use of javax.swing.Action package
you should also refer to java doc for javax.swing.event package i think you are finding that . . . 






I'm very new to web apps and Servlets and I have the following question:


Whenever I print something inside the servlet and call it by the webbrowser, it returns a new page containing that text. Is there a way to print the text in the current page using Ajax?


Indeed, the keyword is "ajax": Asynchronous JavaScript and XML. However, last years it's more than often Asynchronous JavaScript and JSON. Basically, you let JS execute an asynchronous HTTP request and update the HTML DOM tree based on the response data.


Since it's pretty a tedious work to make it to work across all browsers (especially Internet Explorer versus others), there are plenty of JavaScript libraries out which simplifies this in single functions and covers as many as possible browser-specific bugs/quirks under the hoods, such as jQuery, Prototype, Mootools. Since jQuery is most popular these days, I'll use it in the below examples.


Create a /some.jsp like below (note: the code doesn't expect the JSP file being placed in a subfolder, if you do so, alter servlet URL accordingly):


Create a servlet with a doGet() method which look like this:


Map this servlet on an URL pattern of /someservlet or /someservlet/* as below (obviously, the URL pattern is free to your choice, but you'd need to alter the someservlet URL in JS code examples over all place accordingly):


Or, when you're not on a Servlet 3.0 compatible container yet (Tomcat 7, Glassfish 3, JBoss AS 6, etc or newer), then map it in web.xml the old fashioned way (see also our Servlets wiki page):


Now open the http://localhost:8080/context/test.jsp in the browser and press the button. You'll see that the content of the div get updated with the servlet response.


With JSON instead of plaintext as response format you can even get some steps further. It allows for more dynamics. First, you'd like to have a tool to convert between Java objects and JSON strings. There are plenty of them as well (see the bottom of this page for an overview). My personal favourite is Google Gson. Download and put its JAR file in /WEB-INF/lib folder of your webapplication. 


Here's an example which displays List<String> as <ul><li>. The servlet:


The JS code:


Do note that jQuery automatically parses the response as JSON and gives you directly a JSON object (responseJson) as function argument when you set the response content type to application/json. If you forget to set it or rely on a default of text/plain or text/html, then the responseJson argument wouldn't give you a JSON object, but a plain vanilla string and you'd need to manually fiddle around with JSON.parse() afterwards, which is thus totally unnecessary if you set the content type right in first place.


Here's another example which displays Map<String, String> as <option>:


And the JSP:


with 


Here's an example which displays List<Product> in a <table> where the Product class has the properties Long id, String name and BigDecimal price. The servlet:


The JS code:


Here's an example which does effectively the same as previous example, but then with XML instead of JSON. When using JSP as XML output generator you'll see that it's less tedious to code the table and all. JSTL is this way much more helpful as you can actually use it to iterate over the results and perform server side data formatting. The servlet:


The JSP code (note: if you put the <table> in a <jsp:include>, it may be reusable elsewhere in a non-ajax response):


The JS code:


You'll by now probably realize why XML is so much more powerful than JSON for the particular purpose of updating a HTML document using Ajax. JSON is funny, but after all generally only useful for so-called "public web services". MVC frameworks like JSF use XML under the covers for their ajax magic.


You can use jQuery $.serialize() to easily ajaxify existing POST forms without fiddling around with collecting and passing the individual form input parameters. Assuming an existing form which works perfectly fine without JavaScript/jQuery (and thus degrades gracefully when enduser has JavaScript disabled):


You can progressively enhance it with ajax as below:


You can in the servlet distinguish between normal requests and ajax requests as below:


The jQuery Form plugin does less or more the same as above jQuery example, but it has additional transparent support for multipart/form-data forms as required by file uploads.


If you don't have a form at all, but just wanted to interact with the servlet "in the background" whereby you'd like to POST some data, then you can use jQuery $.param() to easily convert a JSON object to an URL-encoded query string.


The same doPost() method as shown here above can be reused. Do note that above syntax also works with $.get() in jQuery and doGet() in servlet.


If you however intend to send the JSON object as a whole instead of as individual request parameters for some reason, then you'd need to serialize it to a string using JSON.stringify() (not part of jQuery) and instruct jQuery to set request content type to application/json instead of (default) application/x-www-form-urlencoded. This can't be done via $.post() convenience function, but needs to be done via $.ajax() as below.


Do note that a lot of starters mix contentType with dataType. The contentType represents the type of the request body. The dataType represents the (expected) type of the response body, which is usually unnecessary as jQuery already autodetects it based on response's Content-Type header.


Then, in order to process the JSON object in the servlet which isn't being sent as individual request parameters but as a whole JSON string the above way, you only need to manually parse the request body using a JSON tool instead of using getParameter() the usual way. Namely, servlets don't support application/json formatted requests, but only application/x-www-form-urlencoded or multipart/form-data formatted requests. Gson also supports parsing a JSON string into a JSON object.


Do note that this all is more clumsy than just using $.param(). Normally, you want to use JSON.stringify() only if the target service is e.g. a JAX-RS (RESTful) service which is for some reason only capable of consuming JSON strings and not regular request parameters.


Important to realize and understand is that any sendRedirect() and forward() call by the servlet on an ajax request would only forward or redirect the ajax request itself and not the main document/window where the ajax request originated. JavaScript/jQuery would in such case only retrieve the redirected/forwarded response as responseText variable in the callback function. If it represents a whole HTML page and not an ajax-specific XML or JSON response, then all you could do is to replace the current document with it.


Note that this doesn't change the URL as enduser sees in browser's address bar. So there are issues with bookmarkability. Therefore, it's much better to just return an "instruction" for JavaScript/jQuery to perform a redirect instead of returning the whole content of the redirected page. E.g. by returning a boolean, or an URL.





The right way to update the page currently displayed in the user's browser (without reloading it) is to have some code executing in the browser update the page's DOM.  


That code is typically javascript that is embedded in or linked from the HTML page, hence the AJAX suggestion.  (In fact, if we assume that the updated text comes from the server via an HTTP request, this is classic AJAX.)


It is also possible to implement this kind of thing using some browser plugin or add-on, though it may be tricky for a plugin to reach into the browser's data structures to update the DOM.  (Native code plugins normally write to some graphics frame that is embedded in the page.)


I will show you a whole example of servlet & how do ajax call.


Here, we are going to create the simple example to create the login form using servlet.


index.html


Here is ajax Sample


LoginServlet Servlet Code :-


Ajax (also AJAX) an acronym for Asynchronous JavaScript and XML) is a group of interrelated web development techniques used on the client-side to create asynchronous web applications. With Ajax, web applications can send data to, and retrieve data from, a server asynchronously 
Below is example code:


Jsp page java script function to submit data to servlet with two variable firstName and lastName:


Servlet to read data send back to jsp in xml format ( You could use text as well. Just you need to change response content to text and render data on javascript function.)


Normally you cant update a page from a servlet. Client (browser) has to request an update. Eiter client loads a whole new page or it requests an update to a part of an existing page. This technique is called Ajax. 


Using bootstrap multi select


Ajax


In Servlet






I need to read smallish (few MB at the most, UTF-8 encoded) XML files, rummage around looking at various elements and attributes, perhaps modify a few and write the XML back out again to disk (preferably with nice, indented formatting).


What would be the best XML parser for my needs?  There are lots to choose from.  Some I'm aware of are:


And of course the one in the JDK (I'm using Java 6).  I'm familiar with Xerces but find it clunky.


Recommendations?


If speed and memory is no problem, dom4j is a really good option. If you need speed, using a StAX parser like Woodstox is the right way, but you have to write more code to get things done and you have to get used to process XML in streams.


I think you should not consider any specific parser implementation. Java API for XML Processing lets you use any conforming parser implementation in a standard way. The code should be much more portable, and when you realise that a specific parser has grown too old, you can replace it with another without changing a line of your code (if you do it correctly).


Basically there are three ways of handling XML in a standard way:   


Forget about proprietary APIs such as JDOM or Apache ones (i.e. Apache Xerces XMLSerializer) because will tie you to a specific implementation that can evolve in time or lose backwards compatibility, which will make you change your code in the future when you want to upgrade to a new version of JDOM or whatever parser you use. If you stick to Java standard API (using factories and interfaces) your code will be much more modular and maintainable.


There is no need to say that all (I haven't checked all, but I'm almost sure) of the parsers proposed comply with a JAXP implementation so technically you can use all, no matter which.


Here is a nice comparision on DOM, SAX, StAX & TrAX 
(Source: http://download.oracle.com/docs/cd/E17802_01/webservices/webservices/docs/1.6/tutorial/doc/SJSXP2.html )


Feature                  StAX                      SAX                         DOM                     TrAX 


API Type                 Pull,streaming      Push,streaming      In memory tree     XSLT Rule


Ease of Use           High                     Medium                  High                     Medium  


XPath Capability    No                        No                         Yes                      Yes  


CPU & Memory     Good                  Good                    Varies                   Varies  


Forward Only         Yes                    Yes                         No                        No  


Read XML              Yes                    Yes                        Yes                     Yes  


Write XML               Yes                    No                          Yes                     Yes  


CRUD                       No                      No                         Yes                     No  


Simple XML http://simple.sourceforge.net/ is very easy for (de)serializing objects.


In addition to SAX and DOM there is STaX parsing available using XMLStreamReader which is an xml pull parser.


I have found dom4j to be the tool for working with XML. Especially compared to Xerces.


I wouldn't recommended this is you've got a lot of "thinking" in your app, but using XSLT could be better (and potentially faster with XSLT-to-bytecode compilation) than Java manipulation.


If you care less about performance, I'm a big fan of Apache Digester, since it essentially lets you map directly from XML to Java Beans.


Otherwise, you have to first parse, and then construct your objects. 






I need to read a large text file of around 5-6 GB line by line using Java.


How can I do this quickly? 


A common pattern is to use


You can read the data faster if you assume there is no character encoding. e.g. ASCII-7 but it won't make much difference.  It is highly likely that what you do with the data will take much longer.


EDIT: A less common pattern to use which avoids the scope of line leaking.


UPDATE: In Java 8 you can do


NOTE: You have to place the Stream in a try-with-resource block to ensure the file is closed. If you don't do this, the GC might clean up/close the file before you run out of file handles (or it might not)


Look at this blog:


The buffer size may be specified, or
  the default size may be used. The
  default is large enough for most
  purposes.


Once java-8 is out (March 2014) you'll be able to use streams:


Printing all the lines in the file:


Here is a sample with full error handling and supporting charset specification for pre-Java 7.  With Java 7 you can use try-with-resources syntax, which makes the code cleaner.


If you just want the default charset you can skip the InputStream and use FileReader.


Here is the Groovy version, with full error handling:


In Java 8, you could do:


Some notes: The stream returned by Files.lines (unlike most streams) needs to be closed. For the reasons mentioned here I avoid using forEach(). The strange code (Iterable<String>) lines::iterator casts a Stream to an Iterable.


What you can do is scan the entire text using Scanner and go through the text line by line.
Of course you should import the following:


Scanner basically scans all the text. The while loop is used to traverse through the entire text.


The .hasNextLine() function is a boolean that returns true if there are still more lines in the text. The .nextLine() function gives you an entire line as a String which you can then use the way you want. Try System.out.println(line) to print the text.


Side Note: .txt is the file type text.


FileReader won't let you specify the encoding, use InputStreamReaderinstead if you need to specify it:


If you imported this file from Windows, it might have ANSI encoding (Cp1252), so you have to specify the encoding. 


In Java 7:


You can use Scanner class


You need to use the readLine() method in class BufferedReader.
Create a new object from that class and operate this method on him and save it to a string.


BufferReader Javadoc


In Java 8, there is also an alternative to using Files.lines(). If your input source isn't a file but something more abstract like a Reader or an InputStream, you can stream the lines via the BufferedReaders lines() method.


For example:


will call processLine() for each input line read by the BufferedReader.


For Reading file with java 8


The clear way to achieve this,


For example:


If you have dataFile.txt on your current directory


The output like as below,



I usually do the reading routine straightforward: 


It works for me. Hope It will help you too.


You can also use apache commons io:


You can use this code:


You can use streams to do it more precisely:






I have a class defined as follows:


I tried to print an instance of my class:


but I got the following output: com.foo.Person@2f92e0f4.  A similar thing happened when I tried to print an array of Person objects:


I got the output: [Lcom.foo.Person;@28a418fc


What does this output mean? How do I change this output so it contains the name of my person? And how do I print collections of my objects?


Note: this is intended as a canonical Q&A about this subject.


All Java objects have a toString() method, which is invoked when you try and print the object. 


This method is defined in the Object class (the superclass of all Java objects). The Object.toString() method returns a fairly ugly looking string, composed of the name of the class, an @ symbol and the hashcode of the object in hexadecimal. The code for this looks like:


A result such as com.foo.MyType@2f92e0f4 can therefore be explained as:


The name of array classes look a little different, which is explained well in the Javadocs for Class.getName(). For instance, [Ljava.lang.String means:


To print something different when you call System.out.println(myObject), you must override the toString() method in your own class. Here's a simple example:


Now if we print a Person, we see their name rather than com.foo.Person@12345678.


Bear in mind that toString() is just one way for an object to be converted to a string. Typically this output should fully describe your object in a clear and concise manner. A better toString() for our Person class might be:


Which would print, e.g., Person[name=Henry]. That's a really useful piece of data for debugging/testing.


If you want to focus on just one aspect of your object or include a lot of jazzy formatting, you might be better to define a separate method instead, e.g. String toElegantReport() {...}.


Many IDEs offer support for auto-generating a toString() method, based on the fields in the class. See docs for Eclipse and IntelliJ, for example. 


Several popular Java libraries offer this feature as well. Some examples include:


ToStringBuilder from Apache Commons Lang


MoreObjects.ToStringHelper from Google Guava


@ToString annotation from Project Lombok


So you've created a nice toString() for your class. What happens if that class is placed into an array or a collection?


If you have an array of objects, you can call Arrays.toString() to produce a simple representation of the contents of the array. For instance, consider this array of Person objects:


Note:  this is a call to a static method called toString() in the Arrays class, which is different to what we've been discussing above.


If you have a multi-dimensional array, you can use Arrays.deepToString() to achieve the same sort of output.


Most collections will produce a pretty output based on calling .toString() on every element.


So you just need to ensure your list elements define a nice toString() as discussed above.


Every class in java has toString() method in it by default, which is called by System.out.println() if you pass some object of a class to it. When you try to print object of a class, the System.out.println() method will call toString() of the class which returns the className@hashcode of that object.


You can override the toString method of a class to get different output. See this example


I think apache provides a better util class which provides a function to get the string


In Eclipse,
Go to your class,
Right click->source->Generate toString();
It will override the toString() method and print the object of that class.


If you Directly print any object of Person It will the ClassName@HashCode to the Code.


in your case com.foo.Person@2f92e0f4 is getting printed . Where Person is a class to which object belongs and 2f92e0f4 is hashCode of the Object.


Now if you try to Use the object of Person then it will print the name


In intellij you can auto generate toString method by  pressing alt+inset and then selecting toString() here is an out put for a test class:


As you can see, it generates a String by concatenating, several attributes of the class, for primitives it will print their values and for reference types it will use their class type (in this case to string method of Test2).   


If you look at the Object class (Parent class of all classes in Java) the toString() method implementation is 


whenever you print any object in Java then toString() will be call. Now it's up to you if you override  toString() then your method will call other Object class method call.


Above function print array of object of different primitives.






Note: This is intended to be a canonical answer for a common problem.


I have a Spring @Service class (MileageFeeCalculator) that has an @Autowired field (rateService), but the field is null when I try to use it. The logs show that both the MileageFeeCalculator bean and the MileageRateService bean are being created, but I get a NullPointerException whenever I try to call the mileageCharge method on my service bean. Why isn't Spring autowiring the field?


Controller class:


Service class:


Service bean that should be autowired in MileageFeeCalculator but it isn't:


When I try to GET /mileage/3, I get this exception:


The field annotated @Autowired is null because Spring doesn't know about the copy of MileageFeeCalculator that you created with new and didn't know to autowire it.


The Spring Inversion of Control (IoC) container has three main logical components: a registry (called the ApplicationContext) of components (beans) that are available to be used by the application, a configurer system that injects objects' dependencies into them by matching up the dependencies with beans in the context, and a dependency solver that can look at a configuration of many different beans and determine how to instantiate and configure them in the necessary order.


The IoC container isn't magic, and it has no way of knowing about Java objects unless you somehow inform it of them. When you call new, the JVM instantiates a copy of the new object and hands it straight to you--it never goes through the configuration process. There are three ways that you can get your beans configured.


I have posted all of this code, using Spring Boot to launch, at this GitHub project; you can look at a full running project for each approach to see everything you need to make it work. Tag with the NullPointerException: nonworking


The most preferable option is to let Spring autowire all of your beans; this requires the least amount of code and is the most maintainable. To make the autowiring work like you wanted, also autowire the MileageFeeCalculator like this:


If you need to create a new instance of your service object for different requests, you can still use injection by using the Spring bean scopes.


Tag that works by injecting the @MileageFeeCalculator service object: working-inject-bean


If you really need objects created with new to be autowired, you can use the Spring @Configurable annotation along with AspectJ compile-time weaving to inject your objects. This approach inserts code into your object's constructor that alerts Spring that it's being created so that Spring can configure the new instance. This requires a bit of configuration in your build (such as compiling with ajc) and turning on Spring's runtime configuration handlers (@EnableSpringConfigured with the JavaConfig syntax). This approach is used by the Roo Active Record system to allow new instances of your entities to get the necessary persistence information injected.


Tag that works by using @Configurable on the service object: working-configurable


This approach is suitable only for interfacing with legacy code in special situations. It is nearly always preferable to create a singleton adapter class that Spring can autowire and the legacy code can call, but it is possible to directly ask the Spring application context for a bean.


To do this, you need a class to which Spring can give a reference to the ApplicationContext object:


Then your legacy code can call getContext() and retrieve the beans it needs:


Tag that works by manually looking up the service object in the Spring context: working-manual-lookup


If you are not coding a web application, make sure your class in which @Autowiring is done is a spring bean. Typically, spring container won't be aware of the class which we might think of as a spring bean. We have to tell the Spring container about our spring classes.


This can be achieved by configuring in appln-contxt or the better way is to annotate class as @Component and please do not create the annotated class using new operator.
Make sure you get it from Appln-context as below.


I once encountered the same issue when I was not quite used to the life in the IoC world. The @Autowired field of one of my beans is null at runtime.


The root cause is, instead of using the auto-created bean maintained by the Spring IoC container (whose @Autowired field is indeed properly injected), I am newing my own instance of that bean type and using it. Of course this one's @Autowired field is null because Spring has no chance to inject it.


Actually you should use either JVM managed Objects or Spring managed Object to invoke methods.
from your above code in your controller class you are creating new object to call your service class which have auto wired object.


so it won't work that way. 


solution is make this MileageFeeCalculator as autowired object in Controller itself.


Change your Controller class like below.


Your problem is new (object creation in java style)


With annotation @Service, @Component, @Configuration beans are created in the
    application context of Spring when server is started. But when we create objects 
    using new operator the object is not registered in  application context which  is already created. For Example Employee.java class i have used.


Check this out:


I'm new to Spring, but I discovered this working solution. Please tell me if it's a deprecable way.


I make Spring inject applicationContext in this bean:


You can put this code also in the main application class if you want.


Other classes can use it like this:


In this way any bean can be obtained by any object in the application (also intantiated with new) and in a static way.


I think you have missed to instruct spring to scan classes with annotation. 


You can use @ComponentScan("packageToScan") on the configuration class of your spring application to instruct spring to scan.


@Service, @Component etc annotations add meta description.
 


Spring only injects instances of those classes which are either created as bean or marked with annotation.


Classes marked with annotation need to be identified by spring before injecting, @ComponentScan instruct spring look for the classes marked with annotation. When Spring finds @Autowired it searches for the related bean, and injects the required instance.


Adding annotation only, does not fix or facilitate the dependency injection, Spring needs to know where to look for.


Another solution would be putting call:
SpringBeanAutowiringSupport.processInjectionBasedOnCurrentContext(this)
To MileageFeeCalculator constructor like this:


It seems to be rare case but here is what happened to me:


We used @inject instead of @autowired which is javaee standard supported by spring. Every places it worked fine and the beans injected correctly, instead of one place. The bean injection seems the same


At last we found that the error was that we (actually, the eclipse ide out complete feature) imported com.opensymphony.xwork2.Inject instead of javax.inject.Inject !


So to summarize, make sure that your annotations (@Autowired, @Inject, @Service ,... ) have correct packages!


UPDATE: Really smart people were quick to point on this answer, which explains the weirdness, described below


ORIGINAL ANSWER:


I don't know if it helps anyone, but I was stuck with the same problem even while doing things seemingly right. In my Main method, I have a code like this:


and in a token.xml file I've had a line


I noticed that the package.path does no longer exist, so I've just dropped the line for good. 


And after that, NPE started coming in. In a pep-config.xml I had just 2 beans: 


and SomeAbac class has a property declared as


for some unknown reason, settings is null in init(), when <context:component-scan/> element is not present at all, but when it's present and has some bs as a basePackage, everything works well. This line now looks like this: 


and it works. May be someone can provide an explanation, but for me it's enough right now )


You can also fix this issue using @Service annotation on service class and passing the required bean classA as a parameter to the other beans classB constructor and annotate the constructor of classB with @Autowired. Sample snippet here :






I would like to read a resource from within my jar like so:


and it works fine when running it in Eclipse, but if I export it to a jar the run it there is an IllegalArgumentException: 


and I really don't know why but with some testing I found if I change


to


then it works the opposite (it works in jar but not eclipse).


I'm using Eclipse and the folder with my file in is a class folder.


Rather than trying to address the resource as a File just ask the ClassLoader to return an InputStream for the resource instead via getResourceAsStream:


As long as the file.txt resource is available on the classpath then this approach will work the same way regardless of whether the file.txt resource is in a classes/ directory or inside a jar.


The URI is not hierarchical occurs because the URI for a resource within a jar file is going to look like something like this: file:/example.jar!/file.txt. You cannot read the entries within a jar (a zip file) like it was a plain old File.


This is explained well by the answers to:


If you wanna read as a file, I believe there still is a similar solution:


To access a file in a jar you have two options:


Place the file in directory structure matching your package name (after extracting .jar file, it should be in the same directory as .class file), then access it using getClass().getResourceAsStream("file.txt")


Place the file at the root (after extracting .jar file, it should be in the root), then access it using Thread.currentThread().getContextClassLoader().getResourceAsStream("file.txt")


The first option may not work when jar is used as a plugin.


You could also just use java.nio. Here is an example to slurp in text from a file at resourcePath in classpath:


Make sure that you  work with the correct separator. I replaced all / in a relative path with a File.separator. This worked fine in the IDE, however did not work in the build JAR.


If you are using spring, then you can use the the following method to read file from src/main/resources:


I had this problem before and I made fallback way for loading. Basically first way work within .jar file and second way works within eclipse or other IDE.






Is there a function built into Java that capitalizes the first character of each word in a String, and does not affect the others?


Examples:


*(Old McDonald would be find too, but I don't expect it to be THAT smart.)


A quick look at the Java String Documentation reveals only toUpperCase() and toLowerCase(), which of course do not provide the desired behavior. Naturally, Google results are dominated by those two functions. It seems like a wheel that must have been invented already, so it couldn't hurt to ask so I can use it in the future. 


WordUtils.capitalize(str) (from apache commons-lang)


(Note: if you need "fOO BAr" to become "Foo Bar", then use capitalizeFully(..) instead)


If you're only worried about the first letter of the first word being capitalized:


The following method converts all the letters into upper/lower case, depending on their position near a space or other special chars.


Try this very simple way


example givenString="ram is good boy"


Output will be: Ram Is Good Boy


I've written a small Class to capitalize all the words in a String. 


Optional multiple delimiters, each one with its behavior (capitalize before, after, or both, to handle cases like O'Brian);


Optional Locale; 


Don't breaks with Surrogate Pairs.


LIVE DEMO


Output: 


Note: first letter will always be capitalized (edit the source if you don't want that).


Please share your comments and help me to found bugs or to improve the code... 


Code:


Using org.apache.commons.lang.StringUtils make it very simple.


Use the Split method to split your string into words, then use the built in string functions to capitalize each word, then append together. 


Pseudo-code (ish)


In the end string looks something like
"The Sentence You Want To Apply Caps To"


This might be useful if you need to capitalize titles. It capitalizes each substring delimited by " ", except for specified strings such as "a" or "the". I haven't ran it yet because it's late, should be fine though. Uses Apache Commons StringUtils.join() at one point. You can substitute it with a simple loop if you wish.


With this simple code:


Result: Hello


im using this function i think is faster in performance.


Here is a simple function


There are many how to convert the first letter of the first word being capitalized. I have an idea. It's very simple:


If I'm not too late to the party here's my answer:


This is just another way of doing it:


Resuable Method for intiCap


}


I'm not sure how to use this SO answer box yet, but here is my solution.  I ran across this problem tonight and decided to search it. I found an answer by Neelam Singh that was almost there so I decided to fix the issue (broke on empty strings) and causes system crash.  


The method you are looking for is named capString(String s) below. 
It turns "It's only 5am here" into "It's Only 5am Here". 


The code is pretty well commented, so enjoy. Cheers!


package com.lincolnwdaniel.interactivestory.model;


public class StringS {


}


I made a solution in Java 8 that is imho more readable.


The Gist for this solution can be found here. https://gist.github.com/Hylke1982/166a792313c5e2df9d31


I decided to add one more solution for capitalizing words in a string:


Function:


Example call:


Result:


Did you mean Title case?


For those of you using Velocity in your MVC, you can use the capitalizeFirstLetter() method from the StringUtils class.


The Short and Precise way is as follows: 


without error if you try and change the name value to the three of values .Error free


this one work for Surname case..
with different type of separator, and keep the same sepator
jean-frederic  --> Jean-Frederic
jean frederic  --> Jean Frederic


the code work with GWT client side.


If you prefer Guava...


try this 






Due to the implementation of Java generics, you can't have code like this: 


How can I implement this while maintaining type safety?


I saw a solution on the Java forums that goes like this:


But I really don't get what's going on.


I have to ask a question in return: is your GenSet "checked" or "unchecked"?
What does that mean?


Checked: strong typing. GenSet knows explicitly what type of objects it contains (i.e. its constructor was explicitly called with a Class<E> argument, and methods will throw an exception when they are passed arguments that are not of type E. See Collections.checkedCollection.


-> in that case, you should write:


Unchecked: weak typing. No type checking is actually done on any of the objects passed as argument.


-> in that case, you should write


Note that the component type of the array should be the erasure of the type parameter:


All of this results from a known, and deliberate, weakness of generics in Java: it was implemented using erasure, so "generic" classes don't know what type argument they were created with at run time, and therefore can not provide type-safety unless some explicit mechanism (type-checking) is implemented.


You can always do this:


This is one of the suggested ways of implementing a generic collection in Effective Java; Item 26.  No type errors, no need to cast the array repeatedly.  However this triggers a warning because it is potentially dangerous, and should be used with caution.  As detailed in the comments, this Object[] is now masquerading as our E[] type, and can cause unexpected errors or ClassCastExceptions if used unsafely.


As a rule of thumb, this behavior is safe as long as the cast array is used internally (e.g. to back a data structure), and not returned or exposed to client code.  Should you need to return an array of a generic type to other code, the reflection Array class you mention is the right way to go.


Worth mentioning that wherever possible, you'll have a much happier time working with Lists rather than arrays if you're using generics.  Certainly sometimes you don't have a choice, but using the collections framework is far more robust.


Here's how to use generics to get an array of precisely the type you’re looking for while preserving type safety (as opposed to the other answers, which will either give you back an Object array or result in warnings at compile time):


That compiles without warnings, and as you can see in main, for whatever type you declare an instance of GenSet as, you can assign a to an array of that type, and you can assign an element from a to a variable of that type, meaning that the array and the values in the array are of the correct type.


It works by using class literals as runtime type tokens, as discussed in the Java Tutorials. Class literals are treated by the compiler as instances of java.lang.Class. To use one, simply follow the name of a class with .class. So, String.class acts as a Class object representing the class String. This also works for interfaces, enums, any-dimensional arrays (e.g. String[].class), primitives (e.g. int.class), and the keyword void (i.e. void.class). 


Class itself is generic (declared as Class<T>, where T stands for the type that the Class object is representing), meaning that the type of String.class is Class<String>.


So, whenever you call the constructor for GenSet, you pass in a class literal for the first argument representing an array of the GenSet instance's declared type (e.g. String[].class for GenSet<String>). Note that you won't be able to get an array of primitives, since primitives can't be used for type variables.


Inside the constructor, calling the method cast returns the passed Object argument cast to the class represented by the Class object on which the method was called. Calling the static method newInstance in java.lang.reflect.Array returns as an Object an array of the type represented by the Class object passed as the first argument and of the length specified by the int passed as the second argument. Calling the method getComponentType returns a Class object representing the component type of the array represented by the Class object on which the method was called (e.g. String.class for String[].class, null if the Class object doesn't represent an array).


That last sentence isn't entirely accurate. Calling String[].class.getComponentType() returns a Class object representing the class String, but its type is Class<?>, not Class<String>, which is why you can't do something like the following.


Same goes for every method in Class that returns a Class object.


Regarding Joachim Sauer's comment on this answer (I don't have enough reputation to comment on it myself), the example using the cast to T[] will result in a warning because the compiler can't guarantee type safety in that case.


Edit regarding Ingo's comments:


This is the only answer that is type safe


To extend to more dimensions, just add []'s and dimension parameters to newInstance() (T is a type parameter, cls is a Class<T>, d1 through d5 are integers):


See Array.newInstance() for details.


This is covered in Chapter 5 (Generics) of Effective Java, 2nd Edition, item 25...Prefer lists to arrays


Your code will work, although it will generate an unchecked warning (which you could suppress with the following annotation:


However, it would probably be better to use a List instead of an Array.


There's an interesting discussion of this bug/feature on the OpenJDK project site.


In Java 8, we can do a kind of generic array creation using a lambda or method reference. This is similar to the reflective approach (which passes a Class), but here we aren't using reflection.


For example, this is used by <A> A[] Stream.toArray(IntFunction<A[]>).


This could also be done pre-Java 8 using anonymous classes but it's more cumbersome.


Java generics work by checking types at compile time and inserting appropriate casts, but erasing the types in the compiled files. This makes generic libraries usable by code which doesn't understand generics (which was a deliberate design decision) but which means you can't normally find out what the type is at run time.


The public Stack(Class<T> clazz,int capacity) constructor requires you to pass a Class object at run time, which means class information is available at runtime to code that needs it. And the Class<T> form means that the compiler will check that the Class object you pass is precisely the Class object for type T. Not a subclass of T, not a superclass of T, but precisely T.


This then means that you can create an array object of the appropriate type in your constructor, which means that the type of the objects you store in your collection will have their types checked at the point they are added to the collection.


Hi although the thread is dead, I would like to draw your attention to this:


Generics is used for type checking during compile time:





Do don't worry about typecasting warnings when you are writing generic class. Worry when you are using it.


What about this solution?


It works and looks too simple to be true. Is there any drawback?


The example is using Java reflection to create an array. Doing this is generally not recommended, since it isn't typesafe. Instead, what you should do is just use an internal List, and avoid the array at all.


I made this code snippet to reflectively instantiate a class which is passed for a simple automated test utility.


Note this segment:


for array initiating where Array.newInstance(class of array, size of array). Class can be both primitive (int.class) and object (Integer.class).


BeanUtils is part of Spring.


Look also to this code:


It converts a list of any kind of object to an array of the same type.


I have found a quick and easy way that works for me. Note that i have only used this on Java JDK 8. I don't know if it will work with previous versions.


Although we cannot instantiate a generic array of a specific type parameter, we can pass an already created array to a generic class constructor.


Now in main we can create the array like so:


For more flexibility with your arrays you can use a linked list eg. the ArrayList and other methods found in the Java.util.ArrayList class.


You do not need to pass the Class argument to the constructor.
Try this.


and


result:


The forced cast suggested by other people did not work for me, throwing an exception of illegal casting.


However, this implicit cast worked fine:


where Item is a class I defined containing the member:


This way you get an array of type K (if the item only has the value) or any generic type you want defined in the class Item.


Actually an easier way to do so, is to create an array of objects and cast it to your desired type like the following example:


where SIZE is a constant and T is a type identifier


No one else has answered the question of what is going on in the example you posted.


As others have said generics are "erased" during compilation. So at runtime an instance of a generic doesn't know what its component type is. The reason for this is historical, Sun wanted to add generics without breaking the existing interface (both source and binary).


Arrays on the other hand do know their component type at runtime.


This example works around the problem by having the code that calls the constructor (which does know the type) pass a parameter telling the class the required type.


So the application would construct the class with something like


and the constructor now knows (at runtime) what the component type is and can use that information to construct the array through the reflection API.


Finally we have a type cast because the compiler has no way of knowing that the array returned by Array#newInstance() is the correct type (even though we know).


This style is a bit ugly but it can sometimes be the least bad solution to creating generic types that do need to know their component type at runtime for whatever reason (creating arrays, or creating instances of their component type, etc.).


I found a sort of a work around to this problem. 


The line below throws generic array creation error


However if I encapsulate List<Person> in a separate class, it works.


You can expose people in the class PersonList thru a getter. The line below will give you an array, that has a List<Person> in every element. In other words array of List<Person>.


I needed something like this in some code I was working on and this is what I did to get it to work. So far no problems.


Passing a list of values...


You could create an Object array and cast it to E everywhere. Yeah, it's not very clean way to do it but it should at least work.


try this.


An easy, albeit messy workaround to this would be to nest a second "holder" class inside of your main class, and use it to hold your data.


Maybe unrelated to this question but while I was getting the "generic array creation" error for using 


I find out the following works (and worked for me) with  @SuppressWarnings({"unchecked"}):


I'm wondering if this code would create an effective generic array?


Edit: Perhaps an alternate way of creating such an array, if the size you required was known and small, would be to simply feed the required number of "null"s into the zeroArray command?


Though obviously this isn't as versatile as using the createArray code.


You could use a cast:


I actually found a pretty unique solution to bypass the inability to initiate a generic array. What you have to do is create a class that takes in the generic variable T like so:


and then in your array class just have it start like so:


starting a new Generic Invoker[] will cause an issue with unchecked but there shouldn't actually be any issues.


To get from the array you should call the array[i].variable like so:


The rest, such as resizing the array can be done with Arrays.copyOf() like so:


And the add function can be added like so:






Output:


Output:


Note: Numbers between -128 and 127 are true.


When you compile a number literal in Java and assign it to a Integer (capital I) the compiler emits:


This line of code is also generated when you use autoboxing.


valueOf is implemented such that certain numbers are "pooled", and it returns the same instance for values smaller than 128.


From the java 1.6 source code, line 621:


The value of high can be configured to another value, with the system property.


-Djava.lang.Integer.IntegerCache.high=999


If you run your program with that system property, it will output true!


The obvious conclusion: never rely on two references being identical, always compare them with .equals() method.


So b2.equals(b3) will print true for all logically equal values of b2,b3.


Note that Integer cache is not there for performance reasons, but rather to comform to the JLS, section 5.1.7; object identity must be given for values -128 to 127 inclusive.


Integer#valueOf(int) also documents this behavior:


this method is likely to yield significantly better space and time performance by caching frequently requested values. This method will always cache values in the range -128 to 127, inclusive, and may cache other values outside of this range.


Autoboxing caches -128 to 127. This is specified in the JLS (5.1.7). 


If the value p being boxed is true, false, a byte, a char in the range \u0000 to \u007f, or an int or short number between -128 and
  127, then let r1 and r2 be the results of any two boxing conversions
  of p. It is always the case that r1 == r2.


A simple rule to remember when dealing with objects is - use .equals if you want to check if the two objects are "equal", use == when you want to see if they point to the same instance.


Using primitive data types, ints, would produce true in both cases, the expected output.


However, since you're using Integer objects the == operator has a different meaning.


In the context of objects, == checks to see if the variables refer to the same object reference.


To compare the value of the objects you should use the equals() method
E.g.


which will indicate whether b2 is less than b1, greater than, or equal to (check the API for details)


Have a look at the Integer.java, if the value is between -128 and 127, it will use the cached pool, so (Integer) 1 == (Integer) 1 while (Integer) 222 != (Integer) 222


It is memory optimization in Java related.


To save on memory, Java 'reuses' all the wrapper objects whose values
  fall in the following ranges:


All Boolean values (true and false)


All Byte values


All Character values from \u0000 to \u007f (i.e. 0 to 127 in decimal)


All Short and Integer values from -128 to 127.


Note:


if you create Boolean with new Boolean(value); you will always get new object


if you create String with new String(value); you will always get new object


if you create Integer with new Integer(value); you will always get new object


etc.


I wrote the following as this problem isn't just specific to Integer. My conclusion is that more often than not if you use the API incorrectly, you sill see incorrect behavior. Use it correctly and you should see the correct behavior:






I've developed an HTML page that sends information to a Servlet. In the Servlet, I am using the methods doGet() and doPost():


In the html page code that calls the Servlet is:


When I use method = "get" in the Servlet, I get the value of id and password, however when using method = "post", id and password are set to null. Why don't I get the values in this case?


Another thing I'd like to know is how to use the data generated or validated by the Servlet. For example, if the Servlet shown above authenticates the user, I'd like to print the user id in my HTML page. I should be able to send the string 'id' as a response and use this info in my HTML page. Is it possible?


You should use doGet() when you want to intercept on HTTP GET requests. You should use doPost() when you want to intercept on HTTP POST requests. That's all. Do not port the one to the other or vice versa (such as in Netbeans' unfortunate auto-generated processRequest() method). This makes no utter sense.


Usually, HTTP GET requests are idempotent. I.e. you get exactly the same result everytime you execute the request (leaving authorization/authentication and the time-sensitive nature of the page —search results, last news, etc— outside consideration). We can talk about a bookmarkable request. Clicking a link, clicking a bookmark, entering raw URL in browser address bar, etcetera will all fire a HTTP GET request. If a Servlet is listening on the URL in question, then its doGet() method will be called. It's usually used to preprocess a request. I.e. doing some business stuff before presenting the HTML output from a JSP, such as gathering data for display in a table.


Also view/edit detail links as shown in last column above are usually idempotent.


HTTP POST requests are not idempotent. If the enduser has submitted a POST form on an URL beforehand, which hasn't performed a redirect, then the URL is not necessarily bookmarkable. The submitted form data is not reflected in the URL. Copypasting the URL into a new browser window/tab may not necessarily yield exactly the same result as after the form submit. Such an URL is then not bookmarkable. If a Servlet is listening on the URL in question, then its doPost() will be called. It's usually used to postprocess a request. I.e. gathering data from a submitted HTML form and doing some business stuff with it (conversion, validation, saving in DB, etcetera). Finally usually the result is presented as HTML from the forwarded JSP page.


...which can be used in combination with this piece of Servlet:


You see, if the User is found in DB (i.e. username and password are valid), then the User will be put in session scope (i.e. "logged in") and the servlet will redirect to some main page (this example goes to http://example.com/contextname/home), else it will set an error message and forward the request back to the same JSP page so that the message get displayed by ${error}.


You can if necessary also "hide" the login.jsp in /WEB-INF/login.jsp so that the users can only access it by the servlet. This keeps the URL clean http://example.com/contextname/login. All you need to do is to add a doGet() to the servlet like this:


(and update the same line in doPost() accordingly)


That said, I am not sure if it is just playing around and shooting in the dark, but the code which you posted doesn't look good (such as using compareTo() instead of equals() and digging in the parameternames instead of just using getParameter() and the id and password seems to be declared as servlet instance variables — which is NOT threadsafe). So I would strongly recommend to learn a bit more about basic Java SE API using the Oracle tutorials (check the chapter "Trails Covering the Basics") and how to use JSP/Servlets the right way using those tutorials.


Update: as per the update of your question (which is pretty major, you should not remove parts of your original question, this would make the answers worthless .. rather add the information in a new block) , it turns out that you're unnecessarily setting form's encoding type to multipart/form-data. This will send the request parameters in a different composition than the (default) application/x-www-form-urlencoded which sends the request parameters as a query string (e.g. name1=value1&name2=value2&name3=value3). You only need multipart/form-data whenever you have a <input type="file"> element in the form to upload files which may be non-character data (binary data). This is not the case in your case, so just remove it and it will work as expected. If you ever need to upload files, then you'll have to set the encoding type so and parse the request body yourself. Usually you use the Apache Commons FileUpload there for, but if you're already on fresh new Servlet 3.0 API, then you can just use builtin facilities starting with HttpServletRequest#getPart(). See also this answer for a concrete example: How to upload files to server using JSP/Servlet?


Both GET and POST are used by the browser to request a single resource from the server.  Each resource requires a separate GET or POST request. 


The GET method is used in one of two ways:
When no method is specified, that is when you or the browser is requesting a simple resource such as an HTML page, an image, etc.
When a form is submitted, and you choose method=GET on the HTML  tag.  If the GET method is used with an HTML form, then the data collected through the form is sent to the server by appending a "?" to the end of the URL, and then adding all name=value pairs (name of the html form field and value entered in that field) separated by an "&"
Example: 
GET  /sultans/shop//form1.jsp?name=Sam%20Sultan&iceCream=vanilla  HTTP/1.0 optional headeroptional header<< empty line >>> 


The name=value form data will be stored in an environment variable called  QUERY_STRING. 
This variable will be sent to a processing program (such as JSP, Java servlet, PHP etc.) 


Example:
POST   /sultans/shop//form1.jsp  HTTP/1.0 optional headeroptional header<< empty line >>> name=Sam%20Sultan&iceCream=vanilla 


When using the post method, the QUERY_STRING environment variable will be empty. 
Advantages/Disadvantages of GET vs. POST


Advantages of the GET method:
Slightly faster 
Parameters can be entered via a form or by appending them after the URL
Page can be bookmarked with its parameters


Disadvantages of the GET method:
Can only send 4K worth of data.  (You should not use it when using a textarea field)
Parameters are visible at the end of the URL


Advantages of the POST method:
Parameters are not visible at the end of the URL.  (Use for sensitive data)
Can send more that 4K worth of data to server


Disadvantages of the POST method:
Can cannot be bookmarked with its data


The servlet container's implementation of HttpServlet.service() method will automatically forward to doGet() or doPost() as necessary, so you shouldn't need to override the service method.  


Could it be that you are  passing the data through get, not post?


If you do <form action="identification" > for your html form, data will be passed using 'Get' by default and hence you can catch this using doGet function in your java servlet code. This way data will be passed under the HTML header and hence will be visible in the URL when submitted.
On the other hand if you want to pass data in HTML body, then USE Post: <form action="identification" method="post"> and catch this data in doPost function. This was, data will be passed under the html body and not the html header, and you will not see the data in the URL after submitting the form.


Examples from my html:


Examples from my java servlet code:






I've written this test code:


But it gives the following error:


How do I get my methods to recognize my class variables?


You must understand the difference between a class and an instance of that class. If you see a car on the street, you know immediately that it's a car even if you can't see which model or type. This is because you compare what you see with the class "car". The class contains which is similar to all cars. Think of it as a template or an idea.


At the same time, the car you see is an instance of the class "car" since it has all the properties which you expect: There is someone driving it, it has an engine, wheels.


So the class says "all cars have a color" and the instance says "this specific car is red".


In the OO world, you define the class and inside the class, you define a field of type Color. When the class is instantiated (when you create a specific instance), memory is reserved for the color and you can give this specific instance a color. Since these attributes are specific, they are non-static.


Static fields and methods are shared with all instances. They are for values which are specific to the class and not a specific instance. For methods, this usually are global helper methods (like Integer.parseInt()). For fields, it's usually constants (like car types, i.e. something where you have a limited set which doesn't change often).


To solve your problem, you need to instantiate an instance (create an object) of your class so the runtime can reserve memory for the instance (otherwise, different instances would overwrite each other which you don't want).


In your case, try this code as a starting block:


The new main() method creates an instance of the class it contains (sounds strange but since main() is created with the class instead of with the instance, it can do this) and then calls an instance method (run()).


Static fields and methods are connected to the class itself and not its instances. If you have a class A, a 'normal' method b and a static method c and make an instance a of your class, the calls to A.c() and a.b() are valid. Method c() has so no idea, which instance is connected, so it cannot use non-static fields.


The solution for you is, that you make your fields static or make your methods non-static. You main could look like this then:


The static keyword modifies the lifecycle of a method or variable within a class. A static method or variable is created at the time a class is loaded. A method or variable that is not declared as static is created only when the class is instantiated as an object for example by using the new operator.


The lifecycle of a class, in broad terms, is: 


In order to have an initial entry point for an application, Java has adopted the convention that the Java program must have a class that contains a method with an agreed upon or special name. This special method is called main(). Since the method must exist whether the class containing the main method has been instantiated or not, the main() method must be declared with the static modifier so that as soon as the class is loaded, the main() method is available.


The result is that when you start your Java application by a command line such as java helloworld a series of actions happen. First of all a Java Virtual Machine is started up and initialized. Next the helloworld.class file containing the compiled Java code is loaded into the Java Virtual Machine. Then the Java Virtual Machine looks for a method in the helloworld class that is called main(String [] args). this method must be static so that it will exist even though the class has not actually been instantiated as an object. The Java Virtual Machine does not create an instance of the class by creating an object from the class. It just loads the class and starts execution at the main() method.


So you need to create an instance of your class as an object and then you can access the methods and variables of the class that have not been declared with the static modifier. Once your Java program has started with the main() function you can then use any variables or methods that have the modifier of static since they exist as part of the class being loaded. 


However, those variables and methods of the class which are outside of the main() method which do not have the static modifier can not be used until an instance of the class has been created as an object within the main() method. After creating the object you can then use the variables and methods of the object. An attempt to use the variables and methods of the class which do not have the static modifier without going through an object of the class is caught by the Java compiler at compile time and flagged as an error.


Let's analyze your program first..
In your program, your first method is main(), and keep it in mind it is the static method... Then you declare the local variable for that method (compareCount, low, high, etc..). The scope of this variable is only the declared method, regardless of it being a static or non static method. So you can't use those variables outside that method. This is the basic error u made.


Then we come to next point. You told static is killing you. (It may be killing you but it only gives life to your program!!) First you must understand the basic thing.
*Static method calls only the static method and use only the static variable.
*Static variable or static method are not dependent on any instance of that class. (i.e. If you change any state of the static variable it will reflect in all objects of the class)
*Because of this you call it as a class variable or a class method.
And a lot more is there about the "static" keyword.
I hope now you get the idea. First change the scope of the variable and declare it as a static (to be able to use it in static methods).


And the advice for you is: you misunderstood the idea of the scope of the variables and static functionalities. Get clear idea about that.


The very basic thing is static variables or static methods are at class level. Class level variables or methods gets loaded prior to instance level methods or variables.And obviously the thing which is not loaded can not be used. So java compiler not letting the things to be handled at run time resolves at compile time. That's why it is giving you error non-static things can not be referred from static context. You just need to read about Class Level Scope, Instance Level Scope and Local Scope.


To be able to access them from your static methods they need to be static member variables, like this:


Now you can add/use instances with in the method 


I will try to explain the static thing to you. First of all static variables do not belong to any particular instance of the class. They are recognized with the name of the class. Static methods again do not belong again to any particular instance. They can access only static variables. Imagine you call MyClass.myMethod() and myMethod is a static method. If you use non-static variables inside the method, how the hell on earth would it know which variables to use? That's why you can use from static methods only static variables. I repeat again they do NOT belong to any particular instance.


The first thing is to know the difference between an instance of a class, and the class itself. A class models certain properties, and the behaviour of the whole in the context of those properties. An instance will define specific values for those properties.


Anything bound to the static keyword is available in the context of the class rather than in the context of an instance of the class 


As a corollary to the above  


The lifetime of a static field/method is equivalent to the lifetime of your application 


E.g. 
Say, car has the property colour, and exhibits the behaviour 'motion'.
An instance of the car would be a Red Volkswagen Beetle in motion at 25kmph.


Now a static property of the car would be the number of wheels (4) on the road, and this would apply to all cars.


HTH


It is ClassLoader responsible to load the class files.Let's see what happens when we write our own classes.


Example 1:  


Now we can see that class "StaticTest" has 3 fields.But actually there is no existence of b,c member variable.But why ???. OK Lest's see. Here b,c are instance variable.Since instance variable gets the memory at the time of object creation. So here b,c are not getting any memory yet. That's why there is no existence of b,c. So There is only existence of a.
For ClassLoader it has only one information about a. ClassLoader yet not recognize b,c because it's object not instantiated yet.


Let's see another example:
Example 2:


Now if we try to compile this code compiler will give CE error.
CE: non-static method display() cannot be referenced from a static context.


Now For ClassLoader it looks like: 


In Example 2 CE error is because we call non static method from a static context. So it is not possible for ClassLoader to recognize method display() at compile time.So compile time error is occurred.    


This is bit diff to explain about static key word for all beginners.
You wil get to know it clearly when you work more with Classes and Objects.


|*| Static : Static items can be called with Class Name 
If you observe in codes, Some functions are directly called with Class names like


This is because NamFnc and println wil be declared using key word static before them.


|*| Non Static :Non Static items can be called with Class Variable
If its not static, you need a variable of the class,
put dot after the class variable and
then call function.



Below code explains you neatly


|*| Static and non Static function in class :



|*| Static and non Static Class inside a Class :






How can I prevent XSS attacks in a JSP/Servlet web application?


XSS can be prevented in JSP by using JSTL <c:out> tag or fn:escapeXml() EL function when (re)displaying user-controlled input. This includes request headers, cookies, URL, body, parameters, etc, the whole request. Also the user-controlled input which is stored in a database needs to be escaped during redisplaying.


For example:


This will escape characters which may malform the rendered HTML such as <, >, ", ' and & into HTML/XML entities such as &lt;, &gt;, &quot;, &apos; and &amp;.


Note that you don't need to escape them in the Java (Servlet) code, since they are harmless over there. Some may opt to escape them during request processing (as you do in Servlet) instead of response processing (as you do in JSP), but this way you may risk that the data unnecessarily get double-escaped or that the DB-stored data becomes unportable (e.g. when exporting data to CSV, XLS, PDF, etc which doesn't require HTML-escaping at all). 


If you'd like to redisplay user-controlled input as HTML wherein you would like to allow only a specific subset of HTML tags like <b>, <i>, <u>, etc, then you need to sanitize the input by a whitelist. You can use a Markdown parser like Pegdown or a HTML parser like Jsoup for this. See also I'm looking for a Java HTML encoder.


The only concern in the server side with regard to databases is SQL injection prevention. You need to make sure that you never string-concatenate user-controlled input straight in the SQL or JPQL query and that you're using parameterized queries all the way. In JDBC terms, this means that you should use PreparedStatement instead of Statement. In JPA terms, use Query.


An alternative would be to migrate from JSP/Servlet to Java EE's MVC framework JSF. It has builtin XSS prevention over all place. See also CSRF, XSS and SQL Injection attack prevention in JSF.


The how-to-prevent-xss has been asked several times. You will find a lot of information in StackOverflow. Also, OWASP website has an XSS prevention cheat sheet that you should go through.


On the libraries to use, OWASP's ESAPI library has a java flavour. You should try that out. Besides that, every framework that you use has some protection against XSS. Again, OWASP website has information on most popular frameworks, so I would recommend going through their site.


I had great luck with OWASP Anti-Samy and an AspectJ advisor on all my Spring Controllers that blocks XSS from getting in.


You can get the AspectJ advisor from the this stackoverflow post


I think this is a better approach then c:out particular if you do a lot of javascript.


Managing XSS requires multiple validations, data from the client side. 


I would suggest regularly testing for vulnerabilities using an automated tool, and fixing whatever it finds. It's a lot easier to suggest a library to help with a specific vulnerability then for all XSS attacks in general.


Skipfish is an open source tool from Google that I've been investigating: it finds quite a lot of stuff, and seems worth using.


There is no easy, out of the box solution against XSS. The OWASP ESAPI API has some support for the escaping that is very usefull, and they have tag libraries.


My approach was to basically to extend the stuts 2 tags in following ways.


If you didn't want to modify the classes in step 1, another approach would be to import the ESAPI tags into the freemarker templates and escape as needed. Then if you need to use a s:property tag in your JSP, wrap it with and ESAPI tag.


I have written a more detailed explanation here.


http://www.nutshellsoftware.org/software/securing-struts-2-using-esapi-part-1-securing-outputs/


I agree escaping inputs is not ideal. 


My personal opinion is that you should avoid using JSP/ASP/PHP/etc pages. Instead output to an API similar to SAX (only designed for calling rather than handling). That way there is a single layer that has to create well formed output.


If you want to automatically escape all JSP variables without having to explicitly wrap each variable, you can use an EL resolver as detailed here with full source and an example (JSP 2.0 or newer), and discussed in more detail here:


For example, by using the above mentioned EL resolver, your JSP code will remain like so, but each variable will be automatically escaped by the resolver


If you want to force escaping by default in Spring, you could consider this as well, but it doesn't escape EL expressions, just tag output, I think:


http://forum.springsource.org/showthread.php?61418-Spring-cross-site-scripting&p=205646#post205646


Note: Another approach to EL escaping that uses XSL transformations to preprocess JSP files can be found here:


http://therning.org/niklas/2007/09/preprocessing-jsp-files-to-automatically-escape-el-expressions/






I came across PECS (short for Producer extends and Consumer super) while reading up on generics. 


Can someone explain to me how to use PECS to resolve confusion between extends and super?


tl;dr: "PECS" is from the collection's point of view. If you are only pulling items from a generic collection, it is a producer and you should use extends; if you are only stuffing items in, it is a consumer and you should use super. If you do both with the same collection, you shouldn't use either extends or super.


Suppose you have a method that takes as its parameter a collection of things, but you want it to be more flexible than just accepting a Collection<Thing>.


Case 1: You want to go through the collection and do things with each item.
Then the list is a producer, so you should use a Collection<? extends Thing>.


The reasoning is that a Collection<? extends Thing> could hold any subtype of Thing, and thus each element will behave as a Thing when you perform your operation. (You actually cannot add anything to a Collection<? extends Thing>, because you cannot know at runtime which specific subtype of Thing the collection holds.)


Case 2: You want to add things to the collection.
Then the list is a consumer, so you should use a Collection<? super Thing>.


The reasoning here is that unlike Collection<? extends Thing>, Collection<? super Thing> can always hold a Thing no matter what the actual parameterized type is. Here you don't care what is already in the list as long as it will allow a Thing to be added; this is what ? super Thing guarantees.


The principles behind this in Computer Science is named after 


The picture below should explain the concept.


Picture courtesy : Andrey Tyukin





PECS (short for "Producer extends and Consumer super") can be explained by : Get and Put Principle


It states,


1. For Extends Wildcard(get values i.e Producer extends)


Here is a method, that takes a collection of numbers, converts each to a double, and sums them up


Let's call the method :


Since, sum() method uses extends, all of the following calls are legal.
The first two calls would not be legal if extends was not used.


EXCEPTION : You cannot put  anything  into  a  type  declared  with  an extends wildcard—except  for  the  value null, which belongs to every reference type:


2. For Super Wildcard(put values i.e Consumer super)


Here is a method, that takes a collection of numbers and an int n, and puts the first n integers, starting from zero, into the collection:


Let's call the method :


Since, count() method uses super, all of the following calls are legal:
The last two calls would not be legal if super was not used.


EXCEPTION : you cannot get anything out from a type declared with a super wildcard—except for a value of type Object, which is a supertype of every reference type:


3. When both Get and Put, don't Use wildcard


Whenever you both put values into and get values out of the same structure, you should not use a wildcard.


PECS(Producer extends and Consumer super) 


mnemonic --> Input and Output (i.e. return type principle)


In Java, arguments and type arguments does not support inheritance as follows.


for generics type arguments:


These kind of problem are solved by using Generics with wildcards:   


Note: wildcard ? means zero or one time.   


A wildcard describes a family of types.  There are 3 different flavours of wildcards:   





Angelika Langer is best to learn generics


Guidelines for Wildcard Use 


One of the more confusing aspects when learning to program with generics is determining when to use an upper bounded wildcard and when to use a lower bounded wildcard.    


For purposes of this discussion, it is helpful to think of variables as providing one of two functions:  


An "In" Variable
An "in" variable serves up data to the code. Imagine a copy method with two arguments: copy(src, dest). The src argument provides the data to be copied, so it is the "in" parameter.  


An "Out" Variable
An "out" variable holds data for use elsewhere. In the copy example, copy(src, dest), the dest argument accepts data, so it is the "out" parameter.  


Wildcard Guidelines: 


source 


Analogy: source 


In the following picture, the type A is a set of horses, the type B is a set of people, and the arrows describe a function of type Function1[A,B].  


The variance tells me that I can use this function with a more flexible type than plain Function1[A,B], I can use it with any type Function1[X,Y] where X is a subset of A and Y is a superset of B. "Using with this type" here means that I call this function in a context where I know (or, rather, the compiler can prove) that the argument passed to the function is always a member of the set X, and the code handling the result of the function can process any value that is a member of set Y. This is illustrated in the following picture:  


 


But the full type of Function1[-A,+B] contains these funny little signs that denote the variance, the minus meaning that it is contravariant in A, the plus meaning that it is covariant in B. 


The variance tells me that I can use this function with a more flexible type than plain Function1[A,B], I can use it with any type Function1[X,Y] where X is a subset of A and Y is a superset of B. "Using with this type" here means that I call this function in a context where I know (or, rather, the compiler can prove) that the argument passed to the function is always a member of the set X, and the code handling the result of the function can process any value that is a member of set Y. This is illustrated in the following picture:
 


It doesn't hurt at all if I restrict the function to just the brown horses, it will always return a well defined person for that horse. But it would fail if I called it with a cow.


As I explain in my answer to another question, PECS is a mnemonic device  created by Josh Bloch to help remember Producer extends, Consumer super.


This means that when a parameterized type being passed to a method will produce instances of T (they will be retrieved from it in some way), ? extends T should be used, since any instance of a subclass of T is also a T.


When a parameterized type being passed to a method will consume instances of T (they will be passed to it to do something), ? super T should be used because an instance of T can legally be passed to any method that accepts some supertype of T. A Comparator<Number> could be used on a Collection<Integer>, for example. ? extends T would not work, because a Comparator<Integer> could not operate on a Collection<Number>.


Note that generally you should only be using ? extends T and ? super T for the parameters of some method. Methods should just use T as the type parameter on a generic return type.


In nutshell easy to remember PECS 


(adding an answer because never enough examples with Generics wildcards)






How do I convert a java.io.File to a byte[]?


It depends on what best means for you. Productivity wise, don't reinvent the wheel and use Apache Commons. Which is here IOUtils.toByteArray(InputStream input).


From JDK 7 you can use Files.readAllBytes(Path).


Example:


Documentation for Java 8: http://docs.oracle.com/javase/8/docs/api/java/io/RandomAccessFile.html


Since JDK 7 - one liner:


No external dependencies needed.


Basically you have to read it in memory. Open the file, allocate the array, and read the contents from the file into the array. 


The simplest way is something similar to this: 


This has some unnecessary copying of the file content (actually the data is copied three times: from file to buffer, from buffer to ByteArrayOutputStream, from ByteArrayOutputStream to the actual resulting array).


You also need to make sure you read in memory only files up to a certain size (this is usually application dependent) :-). 


You also need to treat the IOException outside the function.


Another way is this: 


This has no unnecessary copying.


FileTooBigException is a custom application exception. 
The MAX_FILE_SIZE constant is an application parameters.


For big files you should probably think a stream processing algorithm or use memory mapping (see java.nio). 


As someone said, Apache Commons File Utils might have what you are looking for


Example use (Program.java):


You can use the NIO api as well to do it. I could do this with this code as long as the total file size (in bytes) would fit in an int.


I think its very fast since its using MappedByteBuffer.


Guava has Files.toByteArray() to offer you. It has several advantages:


Simplest Way for reading bytes from file


If you don't have Java 8, and agree with me that including a massive library to avoid writing a few lines of code is a bad idea:


Caller is responsible for closing the stream.


Using the same approach as the community wiki answer, but cleaner and compiling out of the box (preferred approach if you don't want to import Apache Commons libs, e.g. on Android):


Simple way to do it:


I belive this is the easiest way:


ReadFully Reads b.length bytes from this file into the byte array, starting at the current file pointer. This method reads repeatedly from the file until the requested number of bytes are read. This method blocks until the requested number of bytes are read, the end of the stream is detected, or an exception is thrown.


Let me add another solution without using third-party libraries. It re-uses an exception handling pattern that was proposed by Scott (link). And I moved the ugly part into a separate message (I would hide in some FileUtils class ;) )


If you want to read bytes into a pre-allocated byte buffer, this answer may help.


Your first guess would probably be to use InputStream read(byte[]). However, this method has a flaw that makes it unreasonably hard to use: there is no guarantee that the array will actually be completely filled, even if no EOF is encountered.


Instead, take a look at DataInputStream readFully(byte[]). This is a wrapper for input streams, and does not have the above mentioned issue. Additionally, this method throws when EOF is encountered. Much nicer.


Another Way for reading bytes from file






I have recently been thinking about the difference between the two ways of defining an array:


Is there a difference?


They are semantically identical. The int array[] syntax was only added to help C programmers get used to java.


int[] array is much preferable, and less confusing.


There is one slight difference, if you happen to declare more than one variable in the same declaration:


Note that this is bad coding style, although the compiler will almost certainly catch your error the moment you try to use d.


There is no difference.


I prefer the type[] name format at is is clear that the variable is an array (less looking around to find out what it is).


EDIT:


Oh wait there is a difference (I forgot because I never declare more than one variable at a time):


No, these are the same. However


is equivalent to:


Taken from Java Specification. That means that


are different. I would not recommend either of these multiple declarations. Easiest to read would (probably) be:


From section 10.2 of the Java Language Specification:


The [] may appear as part of the type at the beginning of the declaration, or as part of the declarator for a particular variable, or both, as in this example:


This declaration is equivalent to:


Personally almost all the Java code I've ever seen uses the first form, which makes more sense by keeping all the type information about the variable in one place. I wish the second form were disallowed, to be honest... but such is life...


Fortunately I don't think I've ever seen this (valid) code:


The two commands are the same thing.


You can use the syntax to declare multiple objects:


see: http://java.sun.com/docs/books/jls/second_edition/html/arrays.doc.html


No difference.


Quoting from Sun:


The [] may appear as part of the type at the beginning of the declaration, or as part of the declarator for a particular variable, or both, as in this example: byte[] rowvector, colvector, matrix[];


This declaration is equivalent to:
  byte rowvector[], colvector[], matrix[][];


There is no real difference; however, 


is preferred as it clearly indicates that the type is an array.


There isn't any difference between the two; both declare an array of ints.  However, the former is preferred since it keeps the type information all in one place.  The latter is only really supported for the benefit of C/C++ programmers moving to Java.


Both are equally valid. The int puzzle[] form is however discouraged, the int[] puzzle is preferred according to the coding conventions. See also the official Java arrays tutorial:


Similarly, you can declare arrays of other types:


You can also place the square brackets after the array's name:


However, convention discourages this form; the brackets identify the array type and should appear with the type designation. 


Note the last paragraph. 


I recommend reading the official Sun/Oracle tutorials rather than some 3rd party ones. You would otherwise risk end up in learning bad practices.


It is an alternative form, which was borrowed from C, upon which java is based.


As a curiosity, there are three ways to define a valid main method in java:


There is no difference, but Sun recommends putting it next to the type as explained here


The most preferred option is int[] a - because int[] is the type, and a is the name. 
(your 2nd option is the same as this, with misplaced space)


Functionally there is no difference between them.


In Java, these are simply different syntactic methods of saying the same thing.


The Java Language Specification says:


Thus they will result in exactly the same byte code.


There is no difference in functionality between both styles of declaration. Both declare array of int.


But int[] a  keeps type information together and is more verbose so I prefer it.


They are the same, but there is an important difference between these statements:


in 1. regular is just an int, as opposed to 2. where both regular and array are arrays of int's.


The second statement you have is therefore preferred, since it is more clear. The first form is also discouraged according to this tutorial on Oracle.


They're the same. One is more readable (to some) than the other.


They are completely equivalent.  int [] array is the preferred style.  int array[] is just provided as an equivalent, C-compatible style.


Both have the same meaning. However, the existence of these variants also allows this:


which is the same as:


However, this is horrible coding style and should never be done.


Yep, exactly the same. Personally, I prefer 


because it makes it immediately obvious to anyone reading your code that integers is an array of int's, as opposed to 


which doesn't make it all that obvious, particularly if you have multiple declarations in one line. But again, they are equivalent, so it comes down to personal preference.


Check out this page on arrays in Java for more in depth examples.


As already stated, there's no much difference (if you declare only one variable per line).


Note that SonarQube treats your second case as a minor code smell:


Array designators "[]" should be on the type, not the variable (squid:S1197)


Array designators should always be located on the type for better code
  readability. Otherwise, developers must look both at the type and the
  variable name to know whether or not a variable is an array.


Noncompliant Code Example


Compliant Solution


Both are ok. I suggest to pick one and stick with it. (I do the second one)


While the int integers[] solution roots in the C language (and can be thus considered the "normal" approach), many people find int[] integers more logical as it disallows to create variables of different types (i.e. an int and an array) in one declaration (as opposed to the C-style declaration).


when declaring a single array reference, there is not much difference between them. so the following two declarations are same.


when declaring multiple array references, we can find difference between them. the following two statements mean same. in fact, it is up to the programmer which one is follow. but the standard java notation is recommended.






I'm investigating the following java.lang.VerifyError


It occurs when the jboss server in which the servlet is deployed is started.
It is compiled with jdk-1.5.0_11 and I tried to recompile it with jdk-1.5.0_15 without succes. That is the compilation runs fine but when deployed, the java.lang.VerifyError occurs.


When I changed the method name and got the following error:


You can see that more of the method signature is shown.


The actual method signature is


I already tried looking at it with javap and that gives the method signature as it should be.


When my other colleagues check out the code, compile it and deploy it, they have the same problem. When the build server picks up the code and deploys it on development or testing environments (HPUX), the same error occurs. Also an automated testing machine running Ubuntu shows the same error during server startup.


The rest of the application runs okay, only that one servlet is out of order.
Any ideas where to look would be helpful.


java.lang.VerifyError can be the result when you have compiled against a different library than you are using at runtime.


For example, this happened to me when trying to run a program that was compiled against Xerces 1, but Xerces 2 was found on the classpath.  The required classes (in org.apache.* namespace) were found at runtime, so ClassNotFoundException was not the result.  There had been changes to the classes and methods, so that the method signatures found at runtime did not match what was there at compile-time.


Normally, the compiler will flag problems where method signatures do not match.  The JVM will verify the bytecode again when the class is loaded, and throws VerifyError when the bytecode is trying to do something that should not be allowed -- e.g. calling a method that returns String and then stores that return value in a field that holds a List.


java.lang.VerifyError are the worst.


You would get this error if the bytecode size of your method exceeds the 64kb limit; but you would probably have noticed that.


Are you 100% sure this class isn't present in the classpath elsewhere in your application, maybe in another jar?


Also, from your stacktrace, is the character encoding of the source file (utf-8?) Is that correct?


As Kevin Panko said, it's mostly because of library change.
So in some cases a "clean" of the project (directory) followed by a build does the trick.


I fixed this error on Android by making the project I was importing a library, as described here http://developer.android.com/tools/projects/projects-eclipse.html#SettingUpLibraryProject


Previously, I was just referencing the project (not making it a library) and I was getting this strange VerifyError.


Hope it helps someone.


VerifyError means that the class file contains bytecode that is syntactically correct but violates some semantic restriction e.g. a jump target that crosses method boundaries.


Basically, a VerifyError can only occur when there is a compiler bug, or when the class file gets corrupted in some other way (e.g. through faulty RAM or a failing HD).


Try compiling with a different JDK version and on a different machine.


One thing you might try is using -Xverify:all which will verify bytecode on load and sometimes gives helpful error messages if the bytecode is invalid.  


In my case my Android project depends on another Java project compiled for Java 7. java.lang.VerifyError disappeared after I changed Compiler Compliance Level of that Java project to 6.0


Later I found out that this is a Dalvik issue: https://groups.google.com/forum/?fromgroups#!topic/android-developers/sKsMTZ42pwE


I was getting this problem due to pack200 mangling a class file. A bit of searching turned this java bug up. Basically, setting --effort=4 caused the problem to go away.


Using java 1.5.0_17 (though it cropped up in every single variant of java 1.5 I tried it in).


I have fixed a similar java.lang.VerifyError issue by replacing


with


where MagickException was defined in a library project (on which my project has a dependency).


After that I have got a java.lang.NoClassDefFoundError about a class from the same library (fixed according to https://stackoverflow.com/a/9898820/755804 ).


This can happen on Android when you're trying to load a library that was compiled against Oracle's JDK.


Here is the problem for Ning Async HTTP client.


Minimal example that generates the error


One simple possibility is to use Jasmin, or to manually edit the bytecode with a binary file editor.


Lets create void method without a return instruction (generated by the return; statement in Java), which the JVMS says is illegal.


In Jasmin we could write:


We then do javac Main.j and javap -v Main says that we have compiled:


so really there is no return instruction.


Now if we try to run java Main we get:


This error can never happen in Java normally, since the Java compiler adds an implicit return to void methods for us. This is why we don't need to add a return to our main methods. You can check this with javap.


JVMS


VerifyError happens when you try to run certain types of illegal class file as specified by JVMS 7 chapter 4.5


The JVMS says that when Java loads a file, it must run a series of checks to see that the class file is OK before running it.


Such errors cannot be generated on a single compile and run cycle of Java code, because JVMS 7 4.10 says:


Even though a compiler for the Java programming language must only produce class files that satisfy all the static and structural constraints [...
  ]


So to see a minimal failure example, we will need to generate the source code without javac.


This page may give you some hints -
http://www.zanthan.com/itymbi/archives/000337.html


There may be a subtle bug in the body of that method that javac fails to spot. Difficult to diagnose unless you post the whole method here. 


You could start by declaring as many variables as possible as final... that would have caught the bug mentioned on the zanthan site, and is often a good practice anyways.


Well in my case, my project A had a dependency on another, say X(A was using some of the classes defined in X). So when I added X as a reference project in the build path of A , I got this error. However when I removed X as the referenced project and included X's jar as one of the libraries, the problem was solved.


In my case I had to remove this block:


It was showing error near Fragment.showDialog() method call.


Check for multiple versions of the same jar file on your classpath.  


For example, I had opennlp-tools-1.3.0.jar and opennlp-tools-1.5.3.jar on my classpath and got this error.  The solution was to delete opennlp-tools-1.3.0.jar.


CGLIB < 2.2 with JRE > 6 could trigger similar errors, see "Should I upgrade to CGLIB 3.0?" and some commentary at Spring SPR-9669.


This is especially true when everything works fine on JRE 6 and simply switching to JRE7 breaks things.


Another reason for this error can be the combination of AspectJ <= 1.6.11 with JRE > 6.


See Eclipse Bug 353467 and Kieker ticket 307 for details.


This is especially true when everything works fine on JRE 6 and moving to JRE7 breaks things. 


It could also happen when you have a lot of module imports with maven.
There will be two or more classes having exactly the same name ( same qualified name).
This error is resulting from difference of interpretation between compile time and runtime.


If you are migrating to java7 or using java7 then generally this error can be seen. I faced above errors and struggled a lot to find out the root cause, I would suggest to try adding "-XX:-UseSplitVerifier" JVM argument while running your application.


Though the reason mentioned by Kevin is correct, but I would definitely check below before moving to something else:


Chances are good that having multiple or conflicting version of any of the above could cause unexpected issues like the one in question.


java.lang.VerifyError means your compiled bytecode is referring to something that Android cannot find. This verifyError Issues me only with kitkat4.4 and lesser version not in above version of that even I ran the same build in both Devices. when I used jackson json parser of older version it shows java.lang.verifyerror


Then I have changed the Dependancy to the latest version 2.2 to 2.7 without the core library, then it works. which means the Methods and other contents of core is migrated to the latest version of Databind2.7. This fix my Issues.






What I would like is a method to convert a double to a string which rounds using the half-up method - i.e. if the decimal to be rounded is 5, it always rounds up to the previous number. This is the standard method of rounding most people expect in most situations.


I also would like only significant digits to be displayed - i.e. there should not be any trailing zeroes.


I know one method of doing this is to use the String.format method:


returns:


which is great, however it always displays numbers with 5 decimal places even if they are not significant: 


returns:


Another method is to use the DecimalFormatter:


returns:


However as you can see this uses half-even rounding. That is it will round down if the previous digit is even. What I'd like is this:


What is the best way to achieve this in Java?


Use setRoundingMode, set the RoundingMode explicitly to handle your issue with the half-even round, then use the format pattern for your required output.


Example:


gives the output:


Assuming value is a double, you can do:


That's for 5 digits precision. The number of zeros indicate the number of decimals.


will get you a BigDecimal.  To get the string out of it, just call that BigDecimal's toString method, or the toPlainString method for Java 5+ for a plain format string.  


Sample program:  


You can also use the 


to make sure you have the trailing 0's.


As some others have noted, the correct answer is to use either DecimalFormat or BigDecimal. Floating-point doesn't have decimal places so you cannot possibly round/truncate to a specific number of them in the first place. You have to work in a decimal radix, and that is what those two classes do.


I am posting the following code as a counter-example to all the answers in this thread and indeed all over StackOverflow (and elsewhere) that recommend multiplication followed by truncation followed by division. It is incumbent on advocates of this technique to explain why the following code produces the wrong output in over 92% of cases.


Output of this program:


EDIT: I note that this post has been here for nearly six months and no explanations have been forthcoming. Draw your own conclusions.


Suppose you have


you can use BigDecimal


or without BigDecimal 


with both solutions d == 9232.13


You can use the DecimalFormat class.


Real's Java How-to posts this solution, which is also compatible for versions before Java 1.6. 


@Milhous: the decimal format for rounding is excellent:


You can also use the 


to make sure you have the trailing 0's.


I would add that this method is very good at providing an actual
numeric, rounding mechanism - not only visually, but also when processing.


Hypothetical: you have to implement a rounding mechanism into a GUI
program. To alter the accuracy / precision of a result output simply 
change the caret format (i.e. within the brackets).  So that:


would return as output: 0.912385


would return as output: 0.91239


would return as output: 0.9124


[EDIT: also if the caret format is like so ("#0.############") and you
enter a decimal, e.g. 3.1415926, for argument's sake, DecimalFormat
does not produce any garbage (e.g. trailing zeroes) and will return:
3.1415926 .. if you're that way inclined. Granted, it's a little verbose
for the liking of some dev's - but hey, it's got a low memory footprint
during processing and is very easy to implement.]


So essentially, the beauty of DecimalFormat is that it simultaneously handles the string 
appearance - as well as the level of rounding precision set. Ergo: you 
get two benefits for the price of one code implementation. ;)


You could use the following utility method-


Here is a summary of what you can use if you want the result as String:


DecimalFormat#setRoundingMode():


BigDecimal#setScale()


Here is a suggestion of what libraries you can use if you want double as a result. I wouldn't recommend it for string conversion, though, as double may not be able to represent what you want exactly (see e.g. here):


Precision from Apache Commons Math 


Functions from Colt


Utils from Weka


You can use BigDecimal


Refer: http://www.javabeat.net/precise-rounding-of-decimals-using-rounding-mode-enumeration/


Try this: org.apache.commons.math3.util.Precision.round(double x, int scale)


See: http://commons.apache.org/proper/commons-math/apidocs/org/apache/commons/math3/util/Precision.html


Apache Commons Mathematics Library homepage is: http://commons.apache.org/proper/commons-math/index.html


The internal implemetation of this method is:


Since I found no complete answer on this theme I've put together a class that should handle this properly, with support for:


Usage is pretty simple:


(For the sake of this example I am using a custom locale)


Here is the class:


If you really want decimal numbers for calculation (and not only for output), do not use a binary-based floating point format like double. Use BigDecimal or any other decimal-based format. – Paŭlo Ebermann 


I do use BigDecimal for calculations, but bear in mind it is dependent on the size of
numbers you're dealing with.  In most my implementations, i find parsing from double or
integer to Long is sufficient enough for very large number calculations.  In fact, i've
recently used parsed-to-Long to get accurate representations (as opposed to hex results)
in a gui for numbers as big as ################################# characters (as an 
example).


If you're using DecimalFormat to convert double to String, it's very straightforward:


There are several RoundingMode enum values to select from, depending upon the behaviour you require.


Just in case someone still needs help with this. This solution works perfectly for me.


returns a  String  with the desired output.


The code snippet below shows how to display n digits.  The trick is to set variable pp to 1 followed by n zeros.  In the example below, variable pp value has 5 zeros, so 5 digits will be displayed.


I came here just wanting a simple answer on how to round a number. This is a supplemental answer to provide that.


The most common case is to use Math.round().


Numbers are rounded to the nearest whole number. A .5 value is rounded up. If you need different rounding behavior than that, you can use one of the other Math functions. See the comparison below.


As stated above, this rounds to the nearest whole number. .5 decimals round up.  This method returns an int.


Any decimal value is rounded up to the next integer. It goes to the ceiling. This method returns a double.


Any decimal value is rounded down to the next integer. This method returns a double.


This is similar to round in that decimal values round to the closest integer. However, unlike round, .5 values round to the even integer.  This method returns a double.


I agree with the chosen answer to use DecimalFormat --- or alternatively BigDecimal.


Please read Update below first!


However if you do want to round the double value and get a double value result, you can use org.apache.commons.math3.util.Precision.round(..) as mentioned above. The implementation uses BigDecimal, is slow and creates garbage.


A similar but fast and garbage-free method is provided by the DoubleRounder utility in the decimal4j library:


Here's a basic solution offered by jpdymond:


https://stackoverflow.com/a/22186845/212950


DecimalFormat is the best ways to output, but I don't prefer it. I always do this all the time, because it return the double value. So I can use it  more than just output.


OR


If you need large decimal places value, you can use BigDecimal instead. Anyways .0 is important. Without it the rounding of 0.33333d5 return 0.33333 and only 9 digits are allows. The second function without .0 has problems with 0.30000 return 0.30000000000000004.


Where dp = decimal place you want,
and value is a double.


Keep in mind that String.format() and DecimalFormat produce string using default Locale. So they may write formatted number with dot or comma as a separator between integer and decimal parts. To make sure that rounded String is in the format you want use java.text.NumberFormat as so:


Will print in English locale (no matter what your locale is):
  0.99
  123.57
  123.00


The example is taken from Farenda - how to convert double to String correctly.


If you Consider 5 or n number of decimal.
May be this answer solve your prob.


Output will be: 123.01
this can be solve with loop and recursive function.


Basically, the round() method returns the closest long or int, as indicated by the method's return type, to the argument:


And this gives the output:






This question already has an answer here:


Please explain the use of Xms and Xmx parameters in JVMs. What are the default values for them?


The flag Xmx specifies the maximum memory allocation pool for a Java Virtual Machine (JVM), while Xms specifies the initial memory allocation pool.


This means that your JVM will be started with Xms amount of memory and will be able to use a maximum of Xmx amount of memory. For example, starting a JVM like below will start it with 256MB of memory, and will allow the process to use up to 2048MB of memory:


The memory flag can also be specified in multiple sizes, such as kilobytes, megabytes, and so on.


The Xms flag has no default value, and Xmx typically has a default value of 256MB. A common use for these flags is when you encounter a java.lang.OutOfMemoryError.


When using these settings, keep in mind that these settings are for the JVM's heap, and that the JVM can/will use more memory than just the size allocated to the heap. From Oracle's Documentation:


Note that the JVM uses more memory than just the heap. For example Java methods, thread stacks and native handles are allocated in memory separate from the heap, as well as JVM internal data structures.


Just run the command java -X and you will get a list of all -X options:


The -X options are non-standard and subject to change without notice.


I hope this will help you understand Xms, Xmx as well as many more other things that matters the most. :)


You can specify in your IDE . eg for eclipse in Run Configuration> Vm Arguments
you enter -Xmx800m -Xms500m





The main part of the question has already been addressed above. 
Just adding part of the default values.


As per http://docs.oracle.com/cd/E13150_01/jrockit_jvm/jrockit/jrdocs/refman/optionX.html


The default value of Xmx will depend on platform and amount of memory available in the system.






This question already has an answer here:


Exactly what are the differences between variables, objects, and references?


For example: they all point to some type, and they must all hold values (unless of course you have the temporary null-able type), but precisely how are their functions and implementations different from each other?


Example:


They have the same concepts, but how are they different?


(Just to be clear, the explanation I'm giving here is specific to Java and C#. Don't assume it applies to other languages, although bits of it may.)


I like to use an analogy of telling someone where I live. I might write my address on a piece of paper:


Does that help?


The difference between a value type and a reference type is what gets written on the piece of paper. For example, here:


is like having a piece of paper with the number 12 written on it directly. Whereas:


doesn't write the Dog object contents itself on the piece of paper - it creates a new Dog, and then writes a reference to the dog on that paper.


In non-analogy terms:


I often use the following analogy when explaining these concepts.


Imagine that an object is a balloon. A variable is a person. Every person is either in the value type team or in the reference type team. And they all play a little game with the following rules:


Rules for value types: 


Rules for reference types:


You can think of it like a answering questions.


An object is a what...
It's like any physical thing in the world, a "thing" which is recognizable by itself and has significant properties that distinguishes from other "thing".
Like you know a dog is a dog because it barks, move its tail and go after a ball if you throw it.
A variable is a which...
Like if you watch your own hands. Each one is a hand itself. They have fingers, nails and bones within the skin but you know one is your left hand and the other the right one.
That is to say, you can have two "things" of the same type/kind but every one could be different in it's own way, can have different values.


A reference is a where...
If you look at two houses in a street, although they're have their own facade, you can get to each one by their one unique address, meaning, if you're far away like three blocks far or in another country, you could tell the address of the house cause they'll still be there where you left them, even if you cannot point them directly.


Now for programming's sake, examples in a C++ way


That is to say, Ana is a person, but she has unique properties that distinguishes her from another person.


Ana itself is the variable for storing the properties of the person named "Ana"


Jon's answer is great for approaching it from analogy.  If a more concrete wording is useful for you, I can pitch in.


Let's start with a variable.  A variable is a [named] thing which contains a value.  For instance, int x = 3 defines a variable named x, which contains the integer 3.  If I then follow it up with an assignment, x=4, x now contains the integer 4.  The key thing is that we didn't replace the variable.  We don't have a new "variable x whose value is now 4," we merely replaced the value of x with a new value.


Now let's move to objects.  Objects are useful because often you need one "thing" to be referenced from many places.  For example, if you have a document open in an editor and want to send it to the printer, it'd be nice to only have one document, referenced both by the editor and the printer.  That'd save you having to copy it more times than you might want.


However, because you don't want to copy it more than once, we can't just put an object in a variable.  Variables hold onto a value, so if two variables held onto an object, they'd have to make two copies, one for each variable.  References are the go-between that resolves this.  References are small, easily copied values which can be stored in variables.


So, in code, when you type Dog dog = new Dog(), the new operator creates a new Dog Object, and returns a Reference to that object, so that it can be assigned to a variable.  The assignment then gives dog the value of a Reference to your newly created Object.


new Dog() will instantiate an object Dog ie) it will create a memory for the object. You need to access the variable to manipulate some operations. For that you need an reference that is Dog myDog. If you try to print the object it will print an non readable value which is nothing but the address.






Unfortunately, it looks like this recently closed question was not well understood. Here is the typical output:


I'll try asking this question again: How can I kil*l on Runtime the first-opened top-Level Container, and help with closing for me one of Swing NightMares?


Invoking dispose() allows the host platform to reclaim memory consumed by the heavyweight peer, but it can't do so until after the WINDOW_CLOSING event is processed on the EventQueue. Even then, gc() is a suggestion.


Addendum: Another way to see the nightmare is via a profiler. Running the example below with jvisualvm, one can see that periodic collection never quite returns to baseline. I've exaggerated the vertical axis by starting with an artificially small heap. Additional examples are shown here. When memory is very limited, I've used two approaches:


Emergent: Loop from the command line, starting a new VM each time.


Urgent: Eliminate the heavyweight component entirely, running headless and composing in a BufferedImage using 2D graphics and lightweight components only.





I have completely reworked your example:


The resulting snippet follows:


The important conclusions are:


Hope this gives a clear and complete answer to your problem.


with the intent to blow away all doubts about EDT and confirm trashgod Updated suggestion, then output to the console is 


from code


I'm not sure if you question  is about "garbage collection" or about how to identify dialogs that are visible.


You can't control when garbage collection is done. Invoking the gc() method is only a suggestion.


If you want to ignore "disposed" dialogs then you can use the isDisplayable() method to check its status.


With the following program I got some interesting results. First change I made was to add some components to the dialog so that more resources would be used for each dialog which would increase the chance that the resources would be garbage collected.


On my machine I found that if I 


a) create 5 dialogs
b) close the dialogs
c) create 5 dialogs  


Then the first 5 appear to be garbage collected.


However if I create 5, then close then create 1, then close, it doesn't seem to work.


Bottom line is you can't depend on when garbage collection will be done, so I suggest you use the isDisplayable() method to determine how to do your processing. The "Display Dialogs" button uses this method as part of the displayed output.


There is a timeout defined in the AppContext before some resources will be released finally. This is set to something like 5 seconds. Thus if you wait for another five seconds also the context will dispose the (last) reference to your dialog.






I'm writing a Spring MVC application, deployed on Tomcat. See the following minimal, complete, and verifiable example:


Where SpringServletConfig is 


Finally, I have a @Controller in the package com.example.controllers


My application's context name is Example. When I send a request to


the application responds with an HTTP Status 404 and logs the following


I have a JSP resource at /WEB-INF/jsps/index.jsp I expected Spring MVC to use my controller to handle the request and forward to the JSP, so why is it responding with a 404?


This is meant to be a canonical post for questions about this warning message.


Your standard Spring MVC application will serve all requests through a DispatcherServlet that you've registered with your Servlet container.


The DispatcherServlet looks at its ApplicationContext and, if available, the ApplicationContext registered with a ContextLoaderListener for special beans it needs to setup its request serving logic. These beans are described in the documentation.


Arguably the most important, beans of type HandlerMapping map


incoming requests to handlers and a list of pre- and post-processors
  (handler interceptors) based on some criteria the details of which
  vary by HandlerMapping implementation. The most popular implementation
  supports annotated controllers but other implementations exists as
  well.


The javadoc of HandlerMapping further describes how implementations must behave.


The DispatcherServlet finds all beans of this type and registers them in some order (can be customized). While serving a request, the DispatcherServlet loops through these HandlerMapping objects and tests each of them with getHandler to find one that can handle the incoming request, represented as the standard HttpServletRequest. As of 4.3.x, if it doesn't find any, it logs the warning that you see 


No mapping found for HTTP request with URI [/some/path] in DispatcherServlet with name SomeName


and either throws a NoHandlerFoundException or immediately commits the response with a 404 Not Found status code.


The most common HandlerMapping implementation is RequestMappingHandlerMapping, which handles registering @Controller beans as handlers (really their @RequestMapping annotated methods). You can either declare a bean of this type yourself (with @Bean or <bean> or other mechanism) or you can use the built-in options. These are: 


As the link above describes, both of these will register a RequestMappingHandlerMapping bean (and a bunch of other stuff). However, a HandlerMapping isn't very useful without a handler. RequestMappingHandlerMapping expects some @Controller beans so you need to declare those too, through @Bean methods in a Java configuration or <bean> declarations in an XML configuration or through component scanning of @Controller annotated classes in either. Make sure these beans are present.


If you're getting the warning message and a 404 and you've configured all of the above correctly, then you're sending your request to the wrong URI, one that isn't handled by a detected @RequestMapping annotated handler method.


The spring-webmvc library offers other built-in HandlerMapping implementations. For example, BeanNameUrlHandlerMapping maps 


from URLs to beans with names that start with a slash ("/") 


and you can always write your own. Obviously, you'll have to make sure the request you're sending matches at least one of the registered HandlerMapping object's handlers.


If you don't explicitly register any HandlerMapping beans (or if detectAllHandlerMappings is true), the DispatcherServlet registers some defaults. These are defined in DispatcherServlet.properties in the same package as the DispatcherServlet class. They are BeanNameUrlHandlerMapping and DefaultAnnotationHandlerMapping (which is similar to RequestMappingHandlerMapping but deprecated).


Spring MVC will log handlers registered through RequestMappingHandlerMapping. For example, a @Controller like


will log the following at INFO level


This describes the mapping registered. When you see the warning that no handler was found, compare the URI in the message to the mapping listed here. All the restrictions specified in the @RequestMapping must match for Spring MVC to select the handler.


Other HandlerMapping implementations log their own statements that should hint to their mappings and their corresponding handlers.


Similarly, enable Spring logging at DEBUG level to see which beans Spring registers. It should report which annotated classes it finds, which packages it scans, and which beans it initializes. If the ones you expected aren't present, then review your ApplicationContext configuration.


A DispatcherServlet is just a typical Java EE Servlet. You register it with your typical <web.xml> <servlet-class> and <servlet-mapping> declaration, or directly through ServletContext#addServlet in a WebApplicationInitializer, or with whatever mechanism Spring boot uses. As such, you must rely on the url mapping logic specified in the Servlet specification, see Chapter 12. See also


With that in mind, a common mistake is to register the DispatcherServlet with a url mapping of /*, returning a view name from a @RequestMapping handler method, and expecting a JSP to be rendered. For example, consider a handler method like


with an InternalResourceViewResolver 


you might expect the request to be forwarded to a JSP resource at the path /WEB-INF/jsps/example-view-name.jsp. This won't happen. Instead, assuming a context name of Example, the DisaptcherServlet will report


No mapping found for HTTP request with URI [/Example/WEB-INF/jsps/example-view-name.jsp] in DispatcherServlet with name 'dispatcher'


Because the DispatcherServlet is mapped to /* and /* matches everything (except exact matches, which have higher priority), the DispatcherServlet would be chosen to handle the forward from the JstlView (returned by the InternalResourceViewResolver). In almost every case, the DispatcherServlet will not be configured to handle such a request.


Instead, in this simplistic case, you should register the DispatcherServlet to /, marking it as the default servlet. The default servlet is the last match for a request. This will allow your typical servlet container to chose an internal Servlet implementation, mapped to *.jsp, to handle the JSP resource (for example, Tomcat has JspServlet), before trying with the default servlet.


That's what you're seeing in your example.


I resolved my issue when in addition to described before:`


added tomcat-embed-jasper:


`
from: JSP file not rendering in Spring Boot web application


I came across another reason for the same error. This could also be due to the class files not generated for your controller.java file. As a result of which the  the dispatcher servlet mentioned in web.xml is unable to map it to the appropriate  method in the controller class.


In eclipse under Project->select clean ->Build Project.Do give a check if the class file has been generated for the controller file under builds in your workspace.






I am getting a NoClassDefFoundError when I run my Java application.  What is typically the cause of this?


This is caused when there is a class file that your code depends on and it is present at compile time but not found at runtime. Look for differences in your build time and runtime  classpaths. 


While it's possible that this is due to a classpath mismatch between compile-time and run-time, it's not necessarily true.


It is important to keep two or three different exceptions straight in our head in this case:


java.lang.ClassNotFoundException  This exception indicates that the class was not found on the classpath.  This indicates that we were trying to load the class definition, and the class did not exist on the classpath.


java.lang.NoClassDefFoundError  This exception indicates that the JVM looked in its internal class definition data structure for the definition of a class and did not find it.  This is different than saying that it could not be loaded from the classpath.  Usually this indicates that we previously attempted to load a class from the classpath, but it failed for some reason - now we're trying to use the class again (and thus need to load it, since it failed last time), but we're not even going to try to load it, because we failed loading it earlier (and reasonably suspect that we would fail again).  The earlier failure could be a ClassNotFoundException or an ExceptionInInitializerError (indicating a failure in the static initialization block) or any number of other problems.  The point is, a NoClassDefFoundError is not necessarily a classpath problem.


Here is the code to illustrate java.lang.NoClassDefFoundError.


NoClassDefFoundErrorDemo.java


SimpleCalculator.java


I have found that sometimes I get a NoClassDefFound error when code is compiled with an incompatible version of the class found at runtime.  The specific instance I recall is with the apache axis library.  There were actually 2 versions on my runtime classpath and it was picking up the out of date and incompatible version and not the correct one, causing a NoClassDefFound error.  This was in a command line app where I was using a command similar to this.  


I was able to get it to pick up the proper version by using:


NoClassDefFoundError In Java


Definition: 


Java Virtual Machine is not able to find a particular class at runtime which was available at compile time.


If a class was present during compile time but not available in java classpath during runtime.





Examples:


A simple example of NoClassDefFoundError is class belongs to a missing JAR file or JAR was not added into classpath or sometimes jar's name has been changed by someone like in my case one of my colleagues has changed tibco.jar into tibco_v3.jar and the program is failing with java.lang.NoClassDefFoundError and I were wondering what's wrong.


Just try to run with explicitly -classpath option with the classpath you think will work and if it's working then it's a sure short sign that someone is overriding java classpath.


Possible Solutions:


Resources:


3 ways to solve NoClassDefFoundError


java.lang.NoClassDefFoundError Problem patterns


I was using spring framework with maven and solved this error in my project.


There was a runtime error in the class.
I was reading a property as integer, but when it read the value from the property file, its value was double.
Spring did not give me a full stack trace of on which line the runtime failed.
It simply said NoClassDefFoundError. But when I executed it as a native Java Application (taking it out of MVC), it gave ExceptionInInitializerError which was the true cause and which is how I traced the error.


@xli's answer gave me insight into what may be wrong in my code.


I get NoClassFoundError when classes loaded by the runtime class loader cannot access classes already loaded by the java rootloader. Because the different class loaders are in different security domains (according to java) the jvm won't allow classes already loaded by the rootloader to be resolved in the runtime loader address space.


Run your program with 'java -javaagent:tracer.jar [YOUR java ARGS]'


It produces output showing the loaded class, and the loader env that loaded the class.  It's very helpful tracing why a class cannot be resolved.


This is the best solution I found so far.


Suppose we have a package called org.mypackage containing the classes:


and the files defining this package are stored physically under the directory D:\myprogram (on Windows) or /home/user/myprogram (on Linux).


The file structure will look like this:



When we invoke Java, we specify the name of the application to run: org.mypackage.HelloWorld. However we must also tell Java where to look for the files and directories defining our package. So to launch the program, we have to use the following command:



The technique below helped me many times:


where the TheNoDefFoundClass is the class that might be "lost" due to a preference for an older version of the same library used by your program. This most frequently happens with the cases, when the client software is being deployed into a dominant container, armed with its own classloaders and tons of ancient versions of most popular libs.


In case you have generated-code (EMF etc.) there can be too many static initialisers which consume all stack space. How to increase the Java stack size?.


I have a same problem I was stock long hr. I found the solution, In my case, there is the static method defined due to that The JVM can not create the another object of that class.
example,
private static HttpHost proxy = new HttpHost(proxyHost, Integer.valueOf(proxyPort), "http");


If someone comes here because of java.lang.NoClassDefFoundError: org/apache/log4j/Logger error, in my case it was produced because I used log4j 2 (but I didn't add all the files that come with it), and some dependency library used log4j 1. The solution was to add the Log4j 1.x bridge: the jar log4j-1.2-api-<version>.jar which comes with log4j 2. More info in the log4j 2 migration.


In my case, the problem was Eclipse's inability to differentiate between two different copies of the same project. I have one locked on trunk (SVN version control) and the other one working in one branch at a time. I tried out one change in the working copy as a JUnit test case, which included extracting a private inner class to be a public class on its own and while it was working, I open the other copy of the project to look around at some other part of the code that needed changes. At some point, the NoClassDefFoundError popped up complaining that the private inner class was not there; double-clicking in the stack trace brought me to the source file in the wrong project copy.


Closing the trunk copy of the project and running the test case again got rid of the problem.


make sure this matches in the module:app and module:lib 


I got this message after removing 2 files from the SRC library, and when I brought them back I kept seeing this Error message. 
My solution was:restart Eclipse. Since then I havn't seen this message again :-)






Suppose, I have a webserver which holds numerous servlets. For information passing among those servlets I am setting session and instance variables.


Now, if 2 or more users send request to this server then what happens to the session variables? Will they all be common for all the users or they will be different for each user. If they are different, then how was the server able to differentiate between different users?


One more similar question, if there are n users accessing a particular servlet, then this servlet gets instantiated only the first time the first user accessed it or does it get instantiated for all the users separately? In other words, what happens to the instance variables?


When the servlet container (like Apache Tomcat) starts up, it will deploy and load all its web applications. When a web application is loaded, the servlet container creates the ServletContext once and keeps it in the server's memory. The web app's web.xml file is parsed, and each <servlet>, <filter> and <listener> found (or each class annotated with @WebServlet, @WebFilter and @WebListener respectively) is instantiated once and kept in the server's memory as well. For each instantiated filter, its init() method is invoked immediately.


When the servlet container shuts down, it unloads all web applications, invokes the destroy() method of all its initialized servlets and filters, and all ServletContext, Servlet, Filter and Listener instances are trashed.


When a Servlet has a <servlet><load-on-startup> or @WebServlet(loadOnStartup) value greater than 0, its init() method is also immediately invoked during startup. Those servlets are initialized in the same order specified by that value (1 -> 1st, 2 -> 2nd, etc). If the same value is specified for more than one servlet, then each of those servlets is loaded in the order they appear in the web.xml, or @WebServlet classloading. In the event the "load-on-startup" value is absent, the init() method will be invoked whenever the HTTP request hits that servlet for the very first time. 


The servlet container is attached to a web server that listens for HTTP requests on a certain port number (port 8080 is usually used during development and port 80 in production). When a client (user with a web browser) sends an HTTP request, the servlet container creates new HttpServletRequest and HttpServletResponse objects and passes them through any defined Filter chain and, eventually, the Servlet instance. 


In the case of filters, the doFilter() method is invoked. When its code calls chain.doFilter(request, response), the request and response continue on to the next filter, or hit the servlet if there are no remaining filters.


In the case of servlets, the service() method is invoked. By default, this method determines which one of the doXxx() methods to invoke based off of  request.getMethod(). If the determined method is absent from the servlet, then an HTTP 405 error is returned in the response. 


The request object provides access to all of the information about the HTTP request, such as its headers and body. The response object provides the ability to control and send the HTTP response the way you want by, for instance, allowing you to set the headers and the body (usually with generated HTML content from a JSP file). When the HTTP response is committed and finished, both the request and response objects are recycled and made for reuse.


When a client visits the webapp for the first time and/or the HttpSession is obtained for the first time via request.getSession(), the servlet container creates a new HttpSession object, generates a long and unique ID (which you can get by session.getId()), and store it in the server's memory. The servlet container also sets a Cookie in the Set-Cookie header of the HTTP response with JSESSIONID as its name and the unique session ID as its value. 


As per the HTTP cookie specification (a contract a decent web browser and web server have to adhere to), the client (the web browser) is required to send this cookie back in subsequent requests in the Cookie header for as long as the cookie is valid (i.e. the unique ID must refer to an unexpired session and the domain and path are correct). Using your browser's built-in HTTP traffic monitor, you can verify that the cookie is valid (press F12 in Chrome / Firefox 23+ / IE9+, and check the Net/Network tab). The servlet container will check the Cookie header of every incoming HTTP request for the presence of the cookie with the name JSESSIONID and use its value (the session ID) to get the associated HttpSession from server's memory.


The HttpSession stays alive until it has not been used for more than the timeout value specified in <session-timeout>, a setting in web.xml. The timeout value defaults to 30 minutes. So, when the client doesn't visit the web app for longer than the time specified, the servlet container trashes the session. Every subsequent request, even with the cookie specified, will not have access to the same session anymore; the servlet container will create a new session.


On the client side, the session cookie stays alive for as long as the browser instance is running. So, if the client closes the browser instance (all tabs/windows), then the session is trashed on the client's side. In a new browser instance, the cookie associated with the session wouldn't exist, so it would no longer be sent. This causes an entirely new HTTPSession to be created, with an entirely new session cookie begin used.


That said, your major concern is possibly thread safety. You should now know that servlets and filters are shared among all requests. That's the nice thing of Java, it's multithreaded and different threads (read: HTTP requests) can make use of the same instance. It would otherwise be too expensive to recreate, init() and destroy() them for every single request.


You should also realize that you should never assign any request or session scoped data as an instance variable of a servlet or filter. It will be shared among all other requests in other sessions. That's not thread-safe! The below example illustrates this:






In short: the web server issues a unique identifier to each visitor on his first visit. The visitor must bring back that ID for him to be recognised next time around. This identifier also allows the server to properly segregate objects owned by one session against that of another.


If load-on-startup is false:






If load-on-startup is true:






Once he's on the service mode and on the groove, the same servlet will work on the requests from all other clients. 





Why isn't it a good idea to have one instance per client? Think about this: Will you hire one pizza guy for every order that came? Do that and you'd be out of business in no time.


It comes with a small risk though. Remember: this single guy holds all the order information in his pocket: so if you're not cautious about thread safety on servlets, he may end up giving the wrong order to a certain client.


Session in Java servlets is the same as session in other languages such as PHP.  It is unique to the user.  The server can keep track of it in different ways such as cookies, url rewriting etc.  This Java doc article explains it in the context of Java servlets and indicates that exactly how session is maintained is an implementation detail left to the designers of the server.  The specification only stipulates that it must be maintained as unique to a user across multiple connections to the server.  Check out this article from Oracle for more information about both of your questions.


Edit There is an excellent tutorial here on how to work with session inside of servlets. And here is a chapter from Sun about Java Servlets, what they are and how to use them.  Between those two articles, you should be able to answer all of your questions.  


When the servletcontainer (like Apache Tomcat) starts up, it will read from web.xml file (only one per application) if any thing goes wrong or shows up error at container side console, otherwise it will deploy and load all webapplications by using web.xml (so named it as deployment descriptor).


During instantiation phase of servlet, servletInstance is ready but it cannot serve the client request because it is missing with two pieces of information:
1:context information
2:initial configuration information


Servlet engine creates servletConfig interface object encapsulating the above missing information into it
servlet engine calls init() of servlet by suplying servletConfig object references as argument. Once init() is completedly executed servlet is ready to server the client request. 


A)only once (for every client request a new thread is created)
only one instance of the servlet serves any number of the client request ie, after serving one client request server does not die. It waits for other client requests 
ie what CGI (for every client request a new process is created) limitation is overcome with servlet (internally servlet engine creates thread).


A)whenever getSession() is called on HttpServletRequest object 


Step 1:request object is evalauated for incoming session ID.


Step 2:if ID not avaiable a brand new HttpSession object is created and its corresponding session ID is generated (ie of HashTable) session ID is stored into httpservlet response object and the reference of HttpSession object is returned to servlet (doGet/doPost). 


Step 3:if ID avaiable brand new session object is not created session ID is picked up from the request object search is made in the collection of sessions by using session ID as the key.  


Once the search is sucessful session ID is stored into HttpServletResponse and the exsisting session object references is returned to the doGet() or doPost() of UserDefineservlet.


1)when control leaves from servlet code to client dont forget that session object is being hold by servletcontainer ie, servletengine


2)multithreading is left to servlet devlopers people for implementing ie., handle the multiple request of client nothing to bother about multithread code 


A servlet is created when the application starts (it is deployed on the servlet container) or when it is first accessed (depending on the load-on-startup setting)
when the servlet is instantiated, the init() method of the servlet is called
then the servlet (its one and only instance) handles all requests (its service() method being called by multiple threads). That's why it is not advisable to have any synchronization in it, and you should avoid instance variables of the servlet
when the application is undeployed (the servlet container stops), the destroy() method is called.


Sessions - what Chris Thompson said.


Instantiation - a servlet is instantiated when the container receives the first request mapped to the servlet (unless the servlet is configured to load on startup with the <load-on-startup> element in web.xml). The same instance is used to serve subsequent requests.


The Servlet Specification JSR-315 clearly defines the web container behavior in the service (and doGet, doPost, doPut etc.) methods (2.3.3.1 Multithreading Issues, Page 9):


A servlet container may send concurrent requests through the service
  method of the servlet. To handle the requests, the Servlet Developer
  must make adequate provisions for concurrent processing with multiple
  threads in the service method.


Although it is not recommended, an alternative for the Developer is to
  implement the SingleThreadModel interface which requires the container
  to guarantee that there is only one request thread at a time in the
  service method. A servlet container may satisfy this requirement by
  serializing requests on a servlet, or by maintaining a pool of servlet
  instances. If the servlet is part of a Web application that has been
  marked as distributable, the container may maintain a pool of servlet
  instances in each JVM that the application is distributed across.


For servlets not implementing the SingleThreadModel interface, if the
  service method (or methods such as doGet or doPost which are
  dispatched to the service method of the HttpServlet abstract class)
  has been defined with the synchronized keyword, the servlet container
  cannot use the instance pool approach, but must serialize requests
  through it. It is strongly recommended that Developers not synchronize
  the service method (or methods dispatched to it) in these
  circumstances because of detrimental effects on performance






We all know you can't do this:


ConcurrentModificationException etc... this apparently works sometimes, but not always. Here's some specific code:


This, of course, results in:


... even though multiple threads aren't doing it... Anyway.


What's the best solution to this problem? How can I remove an item from the collection in a loop without throwing this exception?


I'm also using an arbitrary Collection here, not necessarily an ArrayList, so you can't rely on get.


Iterator.remove() is safe, you can use it like this:


Note that Iterator.remove is the only safe way to modify a collection during iteration; the behavior is unspecified if the underlying collection is modified in any other way while the iteration is in progress.


Source:


http://docs.oracle.com/javase/tutorial/collections/interfaces/collection.html


And similarly, if you have a ListIterator and want to add items, you can use ListIterator#add, for the same reason you can use Iterator#remove — it's designed to allow it.


Silly me:


I assumed that since a foreach loop is syntactic sugar for iterating, using an iterator wouldn't help... but it gives you this .remove() functionality.


With Java 8 you can use the new removeIf method. Applied to your example:


Since the question has been already answered i.e. the best way is to use the remove method of the iterator object, I would go into the specifics of the place where the error "java.util.ConcurrentModificationException" is thrown.


Every collection class has a private class which implements the Iterator interface and provides methods like next(), remove() and hasNext().


The code for next looks something like this...


Here the method checkForComodification is implemented as 


So, as you can see, if you explicitly try to remove an element from the collection. It results in modCount getting different from expectedModCount, resulting in the exception ConcurrentModificationException.


You can either use the iterator directly like you mentioned, or else keep a second collection and add each item you want to remove to the new collection, then removeAll at the end. This allows you to keep using the type-safety of the for-each loop at the cost of increased memory use and cpu time (shouldn't be a huge problem unless you have really, really big lists or a really old computer)


In such cases a common trick is (was?) to go backwards:


That said, I'm more than happy that you have better ways in Java 8, e.g. removeIf or filter on streams.


Same answer as Claudius with a for loop:


With Eclipse Collections (formerly GS Collections), the method removeIf defined on MutableCollection will work:


With Java 8 Lambda syntax this can be written as follows:


The call to Predicates.cast() is necessary here because a default removeIf method was added on the java.util.Collection interface in Java 8. 


Note: I am a committer for Eclipse Collections.


Make a copy of existing list and iterate over new copy.


With a traditional for loop


I have a suggestion for the problem above. No need of secondary list or any extra time. Please find an example which would do the same stuff but in a different way.



This would avoid the Concurrency Exception.


In case ArrayList:remove(int index)- if(index is last element's position) it avoids without System.arraycopy() and takes not time for this.


arraycopy time increases if(index decreases), by the way elements of list also decreases!


the best effective remove way is- removing its elements in descending order:
while(list.size()>0)list.remove(list.size()-1);//takes O(1)
while(list.size()>0)list.remove(0);//takes O(factorial(n))


ConcurrentHashMap or ConcurrentLinkedQueue or ConcurrentSkipListMap may be another option, because they will never throw any ConcurrentModificationException, even if you remove or add item.


A ListIterator allows you to add or remove items in the list.  Suppose you have a list of Car objects:


In addition to @assylias answer you can also use the new Stream api if you use Java 8:


If you invert the condition, the solution is even more concise since you do not need to negate() the predicate, thus allowing you to use just the method reference:


One of the beauties of this is that the stream is lazily evaluated, i.e. filter() operation is not actually evaluated until it is used by a terminal operation such as forEach(). More on this can be found in Oracle's Tutorial.


The catch is the after removing the element from the list if you skip the internal iterator.next() call. it still works! Though I dont propose to write code like this it helps to understand the concept behind it :-)


Cheers!


this might not be the best way, but for most of the small cases this should acceptable:


"create a second empty-array and add only the ones you want to keep"


I don't remeber where I read this from... for justiness I will make this wiki in hope someone finds it or just to don't earn rep I don't deserve.






I have a poorly designed class in a 3rd-party JAR and I need to access one of its private fields. For example,
why should I need to choose private field is it necessary?


How can I use reflection to get the value of stuffIWant?


In order to access private fields, you need to get them from the class's declared fields and then make them accessible:


EDIT: as has been commented by aperkins, both accessing the field, setting it as accessible and retrieving the value will all throw Exceptions, although the only checked exceptions you need to be mindful of are commented above.


The NoSuchFieldException would be thrown if you asked for a field by a name which did not correspond to a declared field. 


The IllegalAccessException would be thrown if the field was not accessible (for example, if it is private and has not been made accessible via missing out the f.setAccessible(true) line.


The RuntimeExceptions which may be thrown are either SecurityExceptions (if the JVM's SecurityManager will not allow you to change a field's accessibility), or IllegalArgumentExceptions, if you try and access the field on an object not of the field's class's type:


Try FieldUtils from apache commons-lang3:


Reflection isn't the only way to resolve your issue (which is to access the private functionality/behaviour of a class/component)


An alternative solution is to extract the class from the .jar, decompile it using (say) Jode or Jad, change the field (or add an accessor), and recompile it against the original .jar. Then put the new .class ahead of the .jar in the classpath, or reinsert it in the .jar. (the jar utility allows you to extract and reinsert to an existing .jar)


As noted below, this resolves the wider issue of accessing/changing private state rather than simply accessing/changing a field.


This requires the .jar not to be signed, of course.


One other option that hasn't been mentioned yet: use Groovy.  Groovy allows you to access private instance variables as a side effect of the design of the language.  Whether or not you have a getter for the field, you can just use 


As oxbow_lakes mentions, you can use reflection to get around the access restrictions (assuming your SecurityManager will let you).


That said, if this class is so badly designed that it makes you resort to such hackery, maybe you should look for an alternative. Sure this little hack might be saving you a few hours now, but how much will it cost you down the road?


Using the Reflection in Java you can access all the private/public fields and methods of one class to another .But as per the Oracle documentation  in the section drawbacks they recommended that : 


"Since reflection allows code to perform operations that would be illegal in non-reflective code, such as accessing private fields and methods, the use of reflection can result in unexpected side-effects, which may render code dysfunctional and may destroy portability. Reflective code breaks abstractions and therefore may change behavior with upgrades of the platform"


here is following code snapts to demonstrate basic concepts of Reflection 


Reflection1.java


Reflection2.java


Hope it will help.


Use the Soot Java Optimization framework to directly modify the bytecode.
http://www.sable.mcgill.ca/soot/


Soot is completely written in Java and works with new Java versions.


Just an additional note about reflection: I have observed in some special cases, when several classes with the same name exist in different packages, that reflection as used in the top answer may fail to pick the correct class from the object. So if you know what is the package.class of the object, then it's better to access its private field values as follows:


(This is the example class that was not working for me)


You need to do the following:


If using Spring, ReflectionTestUtils provides some handy tools that help out here with minimal effort. To address the posted example:






I have a try/catch block with returns inside it. Will the finally block be called?


For example:


I know I can just type this in an see what happens (which is what I'm about to do, actually) but when I googled for answers nothing came up, so I figured I'd throw this up as a question.


Yes, finally will be called.


The only times finally won't be called are:


Proof code:


Output:


Also, although it's bad practice, if there is a return statement within the finally block, it will trump any other return from the regular block. That is, the following block would return false:


Same thing with throwing exceptions from the finally block.


Here's the official words from the Java Language Specification.


14.20.2. Execution of try-finally and try-catch-finally


A try statement with a finally block is executed by first executing the try block. Then there is a choice:


The specification for return actually makes this explicit:


JLS 14.17 The return Statement


A return statement with no Expression attempts to transfer control to the invoker of the method or constructor that contains it. 


A return statement with an Expression attempts to transfer control to the invoker of the method that contains it; the value of the Expression becomes the value of the method invocation.


The preceding descriptions say "attempts to transfer control" rather than just "transfers control" because if there are any try statements within the method or constructor whose try blocks contain the return statement, then any finally clauses of those try statements will be executed, in order, innermost to outermost, before control is transferred to the invoker of the method or constructor. Abrupt completion of a finally clause can disrupt the transfer of control initiated by a return statement.


In addition to the other responses, it is important to point out that 'finally' has the right to override any exception/returned value by the try..catch block. For example, the following code returns 12:


Similarly, the following method does not throw an exception:


While the following method does throw it:


I tried the above example with slight modification-


The above code outputs:


finally trumps return.
  2


This is because when return i; is executed i has a value 2. After this the finally block is executed where 12 is assigned to i and then System.out out is executed.


After executing the finally block the try block returns 2, rather than returning 12, because this return statement is not executed again.


If you will debug this code in Eclipse then you'll get a feeling that after executing System.out of finally block the return statement of try block is executed again. But this is not the case. It simply returns the value 2.


Here's an elaboration of Kevin's answer. It's important to know that the expression to be returned is evaluated before finally, even if it is returned after.


Output:


That is the whole idea of a finally block. It lets you make sure you do cleanups that might otherwise be skipped because you return, among other things, of course.


Finally gets called regardless of what happens in the try block (unless you call System.exit(int) or the Java Virtual Machine kicks out for some other reason).


A logical way to think about this is:


Also a return in finally will throw away any exception.  http://jamesjava.blogspot.com/2006/03/dont-return-in-finally-clause.html


finally is always executed unless there is abnormal program termination (like calling System.exit(0)..). so, your sysout will get printed


No, not always one exception case is//
System.exit(0);
before the finally block prevents finally to be  executed.


}


Because a finally block will always be called unless you call System.exit() (or the thread crashes).


Finally is always run that's the whole point, just because it appears in the code after the return doesn't mean that that's how it's implemented. The Java runtime has the responsibility to run this code when exiting the try block.


For example if you have the following:


The runtime will generate something like this:


If an uncaught exception is thrown the finally block will run and the exception will continue propagating. 


The finally block is always executed unless there is abnormal program termination, either resulting from a JVM crash or from a call to System.exit(0).


On top of that, any value returned from within the finally block will override the value returned prior to execution of the finally block, so be careful of checking all exit points when using try finally.


Yes it will get called. That's the whole point of having a finally keyword. If jumping out of the try/catch block could just skip the finally block it was the same as putting the System.out.println outside the try/catch.


Concisely, in the official Java Documentation (Click here), it is written that - 


If the JVM exits while the try or catch code is being executed, then
  the finally block may not execute. Likewise, if the thread executing
  the try or catch code is interrupted or killed, the finally block may
  not execute even though the application as a whole continues.


That's actually true in any language...finally will always execute before a return statement, no matter where that return is in the method body. If that wasn't the case, the finally block wouldn't have much meaning.


Because the final is always be called in whatever cases you have. You don't have exception, it is still called, catch exception, it is still called


Consider this in a normal course of execution (i.e without any Exception being thrown): if method is not 'void' then it always explicitly returns something, yet, finally always gets executed


Yes, finally block is always execute. Most of developer use this block the closing the database connection, resultset object, statement object and also uses into the java hibernate to rollback the transaction.


This is because you assigned the value of i as 12, but did not return the value of i to the function. The correct code is as follows:


In addition to the point about return in finally replacing a return in the try block, the same is true of an exception.  A finally block that throws an exception will replace a return or exception thrown from within the try block.


If an exception is thrown, finally runs. If an exception is not thrown, finally runs. If the exception is caught, finally runs. If the exception is not caught, finally runs.


Only time it does not run is when JVM exits.


Try this code, you will understand the code in finally block is get executed after return statement.


Yes, it will. No matter what happens in your try or catch block unless otherwise System.exit() called or JVM crashed. if there is any return statement in the block(s),finally will be executed prior to that return statement.


finally block execute always, no matter exception object occur or not.


there are two possibility to stop finally block :
1. return statement.
2. System.exit(0);


Yes It will.
Only case it will not is JVM exits or crashes 


Finally block always execute whether exception  handle or not .if any exception occurred before try block then finally block will not execute.


A logical way to think about this is:


Code placed in a finally block must be executed whatever occurs within the try block.


So if code in the try block tries to return a value or throw an exception the item is placed ‘on the shelf’ till the finally block can execute
Because code in the finally block has (by definition) a high priority it can return or throw whatever it likes. In which case anything left ‘on the shelf’ is discarded.


The only exception to this is if the VM shuts down completely during the try block e.g. by ‘System.exit’


Never throw any exception from finally block


This is fine, as long as cleanUp() can never throw any exception. In the above example, if someMethod() throws an exception, and in the finally block also, cleanUp() throws an exception, that second exception will come out of method and the original first exception (correct reason) will be lost forever. If the code that you call in a finally block can possibly throw an exception, make sure that you either handle it, or log it. Never let it come out of the finally block.


Actually exiting the program (either by calling System.exit() or by causing a fatal error that causes the process to abort: sometimes referred to informally as a "hotspot" or "Dr Watson" in Windows) will prevent your finally block from being executed!


There's nothing to stop us nesting try/catch/finally blocks (for example, putting a try/finally block inside a try/catch block, or vice versa), and it's not such an uncommon thing to do.






I am trying to generate a random intvalue with Java, but in a specific range. 


For example:


My range is 5-10, meaning that 5 is the smallest possible value and 10 is the biggest. Any other number in between these numbers is possible to be a value, too. 


In Java, there is a method random() in the Math class, which returns a double value between 0.0 and 1.0. In the class Random there is the method nextInt(int n), which returns a random int value in the range of 0 (inclusive) and n (exclusive). I couldn't find a method, which returns a random integer value between two numbers.


I have tried the following things, but I still have problems:
(minimum and maximum are the smallest and biggest numbers).


Solution 1:


Problem:


randomNum can be bigger than maximum.


Solution 2:


Problem:


randomNum can be smaller than minimum.


How do I solve these problems?


I have tried also browsing through the archive and found:


But I couldn't solve the problem.


In Java 1.7 or later, the standard way to do this is as follows:


See the relevant JavaDoc.  This approach has the advantage of not needing to explicitly initialize a java.util.Random instance, which can be a source of confusion and error if used inappropriately.


However, conversely there is no way to explicitly set the seed so it can be difficult to reproduce results in situations where that is useful such as testing or saving game states or similar.  In those situations, the pre-Java 1.7 technique shown below can be used.


Before Java 1.7, the standard way to do this is as follows:


See the relevant JavaDoc.  In practice, the java.util.Random class is often preferable to java.lang.Math.random().


In particular, there is no need to reinvent the random integer generation wheel when there is a straightforward API within the standard library to accomplish the task.


Note that this approach is more biased and less efficient than a nextInt approach, https://stackoverflow.com/a/738651/360211


One standard pattern for accomplishing this is:


The Java Math library function Math.random() generates a double value in the range [0,1). Notice this range does not include the 1.


In order to get a specific range of values first, you need to multiply by the magnitude of the range of values you want covered. 


This returns a value in the range [0,Max-Min), where 'Max-Min' is not included.


For example, if you want [5,10], you need to cover five integer values so you use


This would return a value in the range [0,5), where 5 is not included.


Now you need to shift this range up to the range that you are targeting. You do this by adding the Min value.


You now will get a value in the range [Min,Max). Following our example, that means [5,10):


But, this still doesn't include Max and you are getting a double value. In order to get the Max value included, you need to add 1 to your range parameter (Max - Min) and then truncate the decimal part by casting to an int. This is accomplished via:


And there you have it. A random integer value in the range [Min,Max], or per the example [5,10]:


Use:


The integer x is now the random number that has a possible outcome of 5-10.


Use:


You can edit your second code example to:


With java-8 they introduced the method ints(int randomNumberOrigin, int randomNumberBound) in the Random class.


For example if you want to generate five random integers (or a single one) in the range [0, 10], just do:


The first parameter indicates just the size of the IntStream generated (which is the overloaded method of the one that produces an unlimited IntStream).


If you need to do multiple separate calls, you can create an infinite primitive iterator from the stream:


You can also do it for double and long values.


Hope it helps! :)


Just a small modification of your first solution would suffice.


See more here for implementation of Random class:
Random


ThreadLocalRandom equivalent of class java.util.Random for multithreaded environment. Generating a random number is carried out locally in each of the threads. So we have a better performance by reducing the conflicts. 


x,y - intervals e.g. (1,10)


The Math.Random class in Java is 0-based. So, if you write something like 


x will be between 0-9 inclusive.


So given the following array of 25 items, the code to generate a random number between 
0 (the base of the array) and array.length would be:


Since i.Length will return 25, the nextInt(i.Length) will return a number between the range of 0-24. The other option is going with Math.Random which works in the same way.


For a better understanding, check out forum post Random Intervals (archive.org).


Forgive me for being fastidious, but the solution suggested by the majority, i.e., min + rng.nextInt(max - min + 1)), seems perilous due to the fact that:


A foolproof solution would return correct results for any min <= max within [Integer.MIN_VALUE, Integer.MAX_VALUE]. Consider the following naïve implementation:


Although inefficient, note that the probability of success in the while-loop will always be 50% or higher.


I wonder if any of the random number generating methods provided by an Apache Commons Math library would fit the bill. 


For example: RandomDataGenerator.nextInt or RandomDataGenerator.nextLong


Let us take an example.


Suppose I wish to generate a number between 5-10.


Let us understand this...


Initialize max with highest value and min with the lowest value. 


Now, we need to determine how many possible values can be obtained. For this example, it would be 


5, 6, 7, 8, 9, 10


So, count of this would be max-min+1. 


i.e. 10-5+1=6


The random number will generate a number between 0-5. 


i.e.   0, 1, 2, 3, 4, 5


Adding the min value to the random number would produce


5, 6, 7, 8, 9, 10      


Hence we obtain the desired range. 


Generate a random number for the difference of min and max by using the nextint(n) method and then add min number to the result:


Here's a helpful class to generate random ints in a range with any combination of inclusive/exclusive bounds:


Try


This methods might be convenient to use:


This method will return a random number between the provided min and max value:


and this method will return a random number from the provided min and max value (so the generated number could also be the min or max number):


In case of rolling a dice it would be random number between 1 to 6 (not 0 to 6), so: 


Here is a simple sample that shows how to generate random number from closed [min, max] range, while min <= max is true


You can reuse it as field in hole class, also having all Random.class methods in one place


Results example:


Sources:


Or take a look to RandomUtils from Apache Commons.


Just use the Random class: 


When you need a lot of random numbers, I do not recommend the Random class in the API. It has just a too small period. Try the Mersenne twister instead. There is a Java implementation.


I found this example on http://www.javapractices.com/topic/TopicAction.do?Id=62: 


This example generates random integers in a specific range. 


An example run of this class :


If you want to try the answer with the most votes above, you can simply use this code:


It is just clean and simple.


It's better to use SecureRandom rather than just Random.


Another option is just using Apache Commons: 


OR


This is working fine. 


You can achieve that concisely in Java 8.






This question already has an answer here:


In Java, How to compose a HTTP request message and send it to a HTTP WebServer?


You can use java.net.HttpUrlConnection.


Example (from here), with improvements. Included in case of link rot:


From Oracle's java tutorial


I know others will recommend Apache's http-client, but it adds complexity (i.e., more things that can go wrong) that is rarely warranted. For a simple task, java.net.URL will do.


Apache HttpComponents. The examples for the two modules - HttpCore and HttpClient will get you started right away.


Not that HttpUrlConnection is a bad choice, HttpComponents will abstract a lot of the tedious coding away. I would recommend this, if you really want to support a lot of HTTP servers/clients with minimum code. By the way, HttpCore could be used for applications (clients or servers) with minimum functionality, whereas HttpClient is to be used for clients that require support for multiple authentication schemes, cookie support etc.


Here's a complete Java 7 program:


The new try-with-resources will auto-close the Scanner, which will auto-close the InputStream.


This will help you. Don't forget to add the JAR HttpClient.jar to the classpath.


Google java http client has nice API for http requests. You can easily add JSON support etc. Although for simple request it might be overkill.


You may use Socket for this like


There's a great link about sending a POST request here by Example Depot::


If you want to send a GET request you can modify the code slightly to suit your needs. Specifically you have to add the parameters inside the constructor of the URL. Then, also comment out this wr.write(data);


One thing that's not written and you should beware of, is the timeouts. Especially if you want to use it in WebServices you have to set timeouts, otherwise the above code will wait indefinitely or for a very long time at least and it's something presumably you don't want. 


Timeouts are set like this conn.setReadTimeout(2000); the input parameter is in milliseconds






How do I get a method's execution time?  Is there a Timer utility class for things like timing how long a task takes, etc?  


Most of the searches on Google return results for timers that schedule threads and tasks, which is not what I want.


There is always the old-fashioned way:


I go with the simple answer. Works for me.


It works quite well. The resolution is obviously only to the millisecond, you can do better with System.nanoTime(). There are some limitations to both (operating system schedule slices, etc.) but this works pretty well.


Average across a couple of runs (the more the better) and you'll get a decent idea.


Come on guys! Nobody mentioned the Guava way to do that (which is arguably awesome):


The nice thing is that Stopwatch.toString() does a good job of selecting time units for the measurement. I.e. if the value is small, it'll output 38 ns, if it's long, it'll show 5m 3s


Even nicer:


Note: Google Guava requires Java 1.6+


Using Instant and Duration from Java 8's new API,


outputs,


Use a profiler (JProfiler, Netbeans Profiler, Visual VM, Eclipse Profiler, etc). You'll get the most accurate results and is the least intrusive. They use the built-in JVM mechanism for profiling which can also give you extra information like stack traces, execution paths, and more comprehensive results if necessary.


When using a fully integrated profiler, it's faily trivial to profile a method. Right click, Profiler -> Add to Root Methods. Then run the profiler just like you were doing a test run or debugger.


This probably isn't what you wanted me to say, but this is a good use of AOP. Whip an proxy interceptor around your method, and do the timing in there.


The what, why and how of AOP is rather beyond the scope of this answer, sadly, but that's how I'd likely do it. 


Edit: Here's a link to Spring AOP to get you started, if you're keen. This is the most accessible implementation of AOP that Iive come across for java.


Also, given everyone else's very simple suggestions, I should add that AOP is for when you don't want stuff like timing to invade your code. But in many cases, that sort of simple and easy approach is fine.


System.currentTimeMillis(); IS NOT a good approach for measuring the performance of your algorithms. It measures the total time you experience as a user watching the computer screen. It includes also time consumed by everything else running on your computer in the background. This could make a huge difference in case you have a lot of programs running on your workstation.


Proper approach is  using java.lang.management package.


From http://nadeausoftware.com/articles/2008/03/java_tip_how_get_cpu_and_user_time_benchmarking website:


getCpuTime() method gives you sum of those:


Gathered all possible ways together into one place.


Date


System


Apache-StopWatch


Google-StopWatch


Human Readable Format


JODA-TIME


Java 8 using Instant and Duration


Also We can use StopWatch class of Apache commons for measuring the time.


Sample code


With Java 8 you can do also something like this with every normal methods:


with TimeIt like:


With this methode you can make easy time measurement anywhere in your code without breaking it. In this simple example i just print the time. May you add a Switch for TimeIt, e.g. to only print the time in DebugMode or something.


If you are working with Function you can do somthing like this:


We are using AspectJ and Java annotations for this purpose. If we need to know to execution time for a method, we simple annotate it. A more advanced version could use an own log level that can enabled and disabled at runtime.


Just a small twist, if you don't use tooling and want to time methods with low execution time: execute it many times, each time doubling the number of times it is executed until you reach a second, or so. Thus, the time of the Call to System.nanoTime and so forth, nor the accuracy of System.nanoTime does affect the result much.


Of course, the caveats about using the wall clock apply: influences of JIT-compilation, multiple threads / processes etc. Thus, you need to first execute the method a lot of times first, such that the JIT compiler does its work, and then repeat this test multiple times and take the lowest execution time.


Really good code.


http://www.rgagnon.com/javadetails/java-0585.html


You can use Perf4j. Very cool utility. Usage is simple


More information can be found in Developer Guide


Edit: Project seems dead


FYI, JEP 230: Microbenchmark Suite is an OpenJDK proposal to:


Add a basic suite of microbenchmarks to the JDK source code, and make it easy for developers to run existing microbenchmarks and create new ones.


This proposal did not make the cut for Java 9 but may be added later.


In the meantime you may want to look at the Java Microbenchmark Harness (JMH) project on which the proposal is based.


I basically do variations of this, but considering how hotspot compilation works, if you want to get accurate results you need to throw out the first few measurements and make sure you are using the method in a real world (read application specific) application.  


If the JIT decides to compile it your numbers will vary heavily.  so just be aware


There are a couple of ways to do that. I normally fall back to just using something like this: 


or the same thing with System.nanoTime();


For something more on the benchmarking side of things there seems also to be this one: http://jetm.void.fm/ Never tried it though.


Using AOP/AspectJ and @Loggable annotation from jcabi-aspects you can do it easy and compact:


Every call to this method will be sent to SLF4J logging facility with DEBUG logging level. And every log message will include execution time.


If you want wall-clock time


As "skaffman" said, use AOP OR you can use run time bytecode weaving, just like unit test method coverage tools use to transparently add timing info to methods invoked.


You can look at code used by open source tools tools like Emma (http://downloads.sourceforge.net/emma/emma-2.0.5312-src.zip?modtime=1118607545&big_mirror=0). The other opensource coverage tool is http://prdownloads.sourceforge.net/cobertura/cobertura-1.9-src.zip?download.


If you eventually manage to do what you set out for, pls. share it back with the community here with your ant task/jars.


I modified the code from correct answer to get result in seconds: 


Spring provides a utility class org.springframework.util.StopWatch, as per JavaDoc:


Simple stop watch, allowing for timing of a number of tasks, exposing
  total running time and running time for each named task.


Usage:


Output:


With Aspects:


You can try this way if just want know the time.    


Ok, this is a simple class to be used for simple simple timing of your functions. There is an example below it.


Sample of use:


Sample of console output:


System.nanoTime() is a pretty precise system utility to measure execution time. But be careful, if you're running on pre-emptive scheduler mode (default), this utility actually measures wall-clock time and not CPU time. Therefore, you may notice different execution time values from run to run, depending on system loads. If you look for CPU time, I think that running your program in real-time mode will do the trick. You have to use RT linux. link: Real-time programming with Linux 


Performance measurements on my machine


As mentioned, System.nanoTime() is thought to measure elapsed time. Just be aware of the cost if used insied a loop or the like.


It would be nice if java had a better functional support, so that the action, that needs to be measured, could be wrapped into a block: 


In java this could be done by anonymous functions, that look too verbose


In Java 8 a new class named Instant is introduced. As per doc:


Instant represents the start of a nanosecond on the time line. This
  class is useful for generating a time stamp to represent machine time.
  The range of an instant requires the storage of a number larger than a
  long. To achieve this, the class stores a long representing
  epoch-seconds and an int representing nanosecond-of-second, which will
  always be between 0 and 999,999,999. The epoch-seconds are measured
  from the standard Java epoch of 1970-01-01T00:00:00Z where instants
  after the epoch have positive values, and earlier instants have
  negative values. For both the epoch-second and nanosecond parts, a
  larger value is always later on the time-line than a smaller value.


This can be used as:


It prints PT7.001S.






In Java, are there clear rules on when to use each of access modifiers, namely the default (package private), public, protected and private, while making class and interface and dealing with inheritance?


The official tutorial may be of some use to you.


(Caveat:  I am not a Java programmer, I am a Perl programmer.  Perl has no formal protections which is perhaps why I understand the problem so well :) )


Like you'd think, only the class in which it is declared can see it.


Can only be seen and used by the package in which it was declared.  This is the default in Java (which some see as a mistake).


Package Private + can be seen by subclasses or package member.


Everyone can see it.


Visible outside the code I control.  (While not Java syntax, it is important for this discussion).


C++ defines an additional level called "friend" and the less you know about that the better.


When should you use what?  The whole idea is encapsulation to hide information.  As much as possible you want to hide the detail of how something is done from your users.  Why?  Because then you can change them later and not break anybody's code.  This lets you optimize, refactor, redesign and fix bugs without worry that someone was using that code you just overhauled.


So, rule of thumb is to make things only as visible as they have to be.  Start with private and only add more visibility as needed.  Only make public that which is absolutely necessary for the user to know, every detail you make public cramps your ability to redesign the system.


If you want users to be able to customize behaviors, rather than making internals public so they can override them, it's often a better idea to shove those guts into an object and make that interface public.  That way they can simply plug in a new object.  For example, if you were writing a CD player and wanted the "go find info about this CD" bit customizable, rather than make those methods public you'd put all that functionality into its own object and make just your object getter/setter public.  In this way being stingy about exposing your guts encourages good composition and separation of concerns


Personally, I stick with just "private" and "public".  Many OO languages just have that.  "Protected" can be handy, but it's really a cheat.  Once an interface is more than private it's outside of your control and you have to go looking in other people's code to find uses.


This is where the idea of "published" comes in.  Changing an interface (refactoring it) requires that you find all the code which is using it and change that, too.  If the interface is private, well no problem.  If it's protected you have to go find all your subclasses.  If it's public you have to go find all the code which uses your code.  Sometimes this is possible, for example if you're working on corporate code that's for internal use only it doesn't matter if an interface is public.  You can grab all the code out of the corporate repository.  But if an interface is "published", if there is code using it outside your control, then you're hosed.  You must support that interface or risk breaking code.  Even protected interfaces can be considered published (which is why I don't bother with protected).


Many languages find the hierarchical nature of public/protected/private to be too limiting and not in line with reality.  To that end there is the concept of a trait class, but that's another show.


Here's a better version of the table. (Future proof with a column for modules.)






A private member is only accessible within the same class as it is declared.


A member with no access modifier is only accessible within classes in the same package.


A protected member is accessible within all classes in the same package and within subclasses in other packages.


A public member is accessible to all classes (unless it resides in a module that does not export the package it is declared in).


Access modifiers is a tool to help you to prevent accidentally breaking encapsulation(*). Ask yourself if you intend the member to be something that's internal to the class, package, class hierarchy or not internal at all, and choose access level accordingly.


Examples:


(*) What is Encapsulation exactly?


Easy rule. Start with declaring everything private. And then progress towards public as the needs arises and design warrant it.


When exposing members ask yourself if you are exposing representation choices or abstraction choices. The first is something you want to avoid as it will introduce too much dependencies on the actual representation rather than on its observable behavior.


As a general rule I try to avoid overriding method implementations by subclassing; it's too easy to screw up the logic. Declare abstract protected methods if you intend for it to be overridden.


Also use the @Override annotation when overriding to keep things from breaking when you refactor.


It's actually a bit more complicated than a simple grid shows. The grid tells you whether an access is allowed, but what exactly constitutes an access? Also, access levels interact with nested classes and inheritance in complex ways.


The "default" access (specified by the absence of a keyword) is also called package-private. Exception: in an interface, no modifier means public access; modifiers other than public are forbidden. Enum constants are always public.


Is an access to a member with this access specifier allowed?


Local variables and formal parameters cannot take access specifiers. Since they are inherently inaccessible to the outside according to scoping rules, they are effectively private.


For classes in the top scope, only public and package-private are permitted. This design choice is presumably because protected and private would be redundant at the package level (there is no inheritance of packages).


All the access specifiers are possible on class members (constructors, methods and static member functions, nested classes).


Related: Java Class Accessibility


The access specifiers can be strictly ordered


public > protected > package-private > private


meaning that public provides the most access, private the least. Any reference possible on a private member is also valid for a package-private member; any reference to a package-private member is valid on a protected member, and so on. (Giving access to protected members to other classes in the same package was considered a mistake.)


You also have to consider nested scopes, such as inner classes. An example of the complexity is that inner classes have members, which themselves can take access modifiers. So you can have a private inner class with a public member; can the member be accessed? (See below.) The general rule is to look at scope and think recursively to see whether you can access each level.


However, this is quite complicated, and for full details, consult the Java Language Specification. (Yes, there have been compiler bugs in the past.)


For a taste of how these interact, consider this example. It is possible to "leak" private inner classes; this is usually a warning:


Compiler output:


Some related questions:


As a rule of thumb: 


As a result, if we divide access right into three rights: 


then we have this simple table:





In very short


The most misunderstood access modifier in Java is protected. We know that it's similar to the default modifier with one exception in which subclasses can see it. But how? Here is an example which hopefully clarifies the confusion:


Assume that we have 2 classes; Father and Son, each in its own package:


Let's add a protected method foo() to Father.


The method foo() can be called in 4 contexts:


Inside a class that is located in the same package where foo() is defined (fatherpackage):


Inside a subclass, on the current instance via this or super:


On an reference whose type is the same class:


On an reference whose type is the parent class and it is inside the package where foo() is defined (fatherpackage) [This can be included inside context no. 1]:


The following situations are not valid.


On an reference whose type is the parent class and it is outside the package where foo() is defined (fatherpackage):


A non-subclass inside a package of a subclass (A subclass inherits the protected members from its parent, and it makes them private to non-subclasses):


Methods, Variables and Constructors that are declared private can only be accessed within the declared class itself.


Private access modifier is the most restrictive access level. Class and interfaces cannot be private.


Note


Variables that are declared private can be accessed outside the class if public getter methods are present in the class.
Variables, methods and constructors which are declared protected in a superclass can be accessed only by the subclasses in other package or any class within the package of the protected members' class.



The protected access modifier cannot be applied to class and interfaces.


Methods, fields can be declared protected, however methods and fields in a interface cannot be declared protected.


Note


Protected access gives the subclass a chance to use the helper method or variable, while preventing a nonrelated class from trying to use it.





A class, method, constructor, interface etc declared public can be accessed from any other class. 


Therefore fields, methods, blocks declared inside a public class can be accessed from any class belonging to the Java Universe.


However if the public class we are trying to access is in a different package, then the public class still need to be imported.


Because of class inheritance, all public methods and variables of a class are inherited by its subclasses.





Default access modifier means we do not explicitly declare an access modifier for a class, field, method, etc.


A variable or method declared without any access control modifier is available to any other class in the same package. The fields in an interface are implicitly public static final and the methods in an interface are by default public.


Note


We cannot Override the Static fields.if you try to override it does not show any error 
but it doesnot work what we except.


http://docs.oracle.com/javase/tutorial/java/javaOO/accesscontrol.html
http://www.tutorialspoint.com/java/java_access_modifiers.htm 


The difference can be found in the links already provided but which one to use usually comes down to the "Principle of Least Knowledge". Only allow the least visibility that is needed.


Private : Limited Access to Class only


Default(No Modifier) : Limited Access to Class and Package


Protected: Limited Access to Class,Pacakge and Subclasses(Inside and Outside Package both)


Public: Accessible to Class,Package(All),Subclasses...In short everywhere


Access Modifiers are there to restrict access at several level.


Public : it is basically as simple as you can access from any class either that is in same package or     not. 


To access if you are in same package you can access directly but if you are in other package then you can create object of class.


Default : it is accessible in same package from any of the class of package.


to access you can create object of class. but you can not access this variable outside of the package.


Protected : you can access variables in same package as well as subclass in any other package.
so basically it is default + Inherited behavior.


To access protected field defined in base class you can create object of child class.


Private :  it can be access in same class.


In non-static methods you can access directly because of this reference (also in constructors)but to access in static methods you need to create object of the class.


Visible to the package. the default. No modifiers are needed.


Visible to the class only (private).


Visible to the world (public).


Visible to the package and all subclasses (protected).


Variables and methods can be declared without any modifiers that is called Default examples:


Private Access Modifier - private:
Methods, Variables and Constructors that are declared private can only be accessed within the declared class itself.Private access modifier is the most restrictive access level. Class and interfaces cannot be private.


Variables that are declared private can be accessed outside the class if public getter methods are present in the class.


Using the private modifier is the main way that an object encapsulates itself and hide data from the outside world.
examples:


Public Access Modifier - public:
A class, method, constructor, interface etc declared public can be accessed from any other class. Therefore fields, methods, blocks declared inside a public class can be accessed from any class belonging to the Java Universe.


However if the public class we are trying to access is in a different package, then the public class still need to be imported.


Because of class inheritance, all public methods and variables of a class are inherited by its subclasses.
example:


Protected Access Modifier - protected:
Variables, methods and constructors which are declared protected in a superclass can be accessed only by the subclasses in other package or any class within the package of the protected members' class.


The protected access modifier cannot be applied to class and interfaces. Methods, fields can be declared protected, however methods and fields in a interface cannot be declared protected.


Protected access gives the subclass a chance to use the helper method or variable, while preventing a nonrelated class from trying to use it.


Access Modifiers in Java.


Java access modifiers are used to provide access control in java.


1. Default:


Accessible to the classes in the same package only. 


e.g.


This access is more restricted than public and protected but less restricted than private.


2. Public


Can be accessed from anywhere. (Global Access)


e.g.


Output:Hello


3. Private


Accessible only inside the same class.


e.g.


If you try to access private members on one class in another will throw compile error. e.g.


4. Protected


Accessible only to the classes in the same package and to the subclasses


e.g.


Output:Hello





David's answer provides the meaning of each access modifier. As for when to use each, I'd suggest making public all classes and the methods of each class that are meant for external use (it's API), and everything else private. You'll develop over time a sense for when to make some classes package-private and when to declare certain methods protected for use in subclasses.


this page writes well about the protected & default access modifier


....
Protected: Protected access modifier is the a little tricky and you can say is a superset of the default access modifier. Protected members are same as the default members as far as the access in the same package is concerned. The difference is that, the protected members are also accessible to the subclasses of the class in which the member is declared which are outside the package in which the parent class is present. But these protected members are “accessible outside the package only through inheritance“. i.e you can access a protected member of a class in its subclass present in some other package directly as if the member is present in the subclass itself. But that protected member will not be accessible in the subclass outside the package by using parent class’s reference. 
....


I just want to address a detail that is extremely commonly got wrong, including by most of the answers on this page. "Default" access (when no access modifier is present) is not always the same as package-private. It depends on what the thing is.


Non-member types (that is, classes, enums, interfaces, and annotation types not declared inside another type) are package-private by default. (JLS §6.6.1)


Class members and constructors are package-private by default. (JLS §6.6.1)


Enum constructors are private by default. (Indeed, enum contructors must be private, and it is an error to try to make them public or protected). Enum constants are public, and do not allow any access specifier. Other members of enums are package-private by default. (JLS §8.9)


All members of interfaces and annotation types are public by default. (Indeed, members of interfaces and annotation types must be public, and it is an error to try to make them private or protected.) (JLS §9.3 to 9.5)


public - accessible from anywhere in the application.


default - accessible from package.


protected - accessible from package and sub-classes in other package.
as well


private - accessible from its class only.


Note: This is just a supplement for the accepted answer.


This is related to Java Access Modifiers.


From Java Access Modifiers:  


A Java access modifier specifies which classes can access a given
  class and its fields, constructors and methods. Access modifiers can
  be specified separately for a class, its constructors, fields and
  methods. Java access modifiers are also sometimes referred to in daily
  speech as Java access specifiers, but the correct name is Java access
  modifiers. Classes, fields, constructors and methods can have one of
  four different Java access modifiers:


From Controlling Access to Members of a Class tutorials:


Access level modifiers determine whether other classes can use a
  particular field or invoke a particular method. There are two levels
  of access control:


A class may be declared with the modifier public, in which case that
  class is visible to all classes everywhere. If a class has no modifier
  (the default, also known as package-private), it is visible only
  within its own package


The following table shows the access to members permitted by each
  modifier.


The first data column indicates whether the class itself has access to
  the member defined by the access level. As you can see, a class always
  has access to its own members. The second column indicates whether
  classes in the same package as the class (regardless of their
  parentage) have access to the member. The third column indicates
  whether subclasses of the class declared outside this package have
  access to the member. The fourth column indicates whether all classes
  have access to the member.


Access levels affect you in two ways. First, when you use classes that
  come from another source, such as the classes in the Java platform,
  access levels determine which members of those classes your own
  classes can use. Second, when you write a class, you need to decide
  what access level every member variable and every method in your class
  should have.


Public Protected Default and private are access modifiers.


They are meant for encapsulation, or hiding and showing contents of the class.


Private is not accessible outside the class
Default is accessible only in the package.
Protected in package as well as any class which extends it.
Public is open for all.


Normally, member variables are defined private, but member methods are public.


So let's talk about Access Control and Inheritance
The following rules for inherited methods are,


Often times I've realized that remembering the basic concepts of any language can made possible by creating real-world analogies. Here is my analogy for understanding access modifiers in Java:


Let's assume that you're a student at a university and you have a friend who's coming to visit you over the weekend. Suppose there exists a big statue of the university's founder in the middle of the campus.


When you bring him to the campus, the first thing that you and your friend sees is this statue. This means that anyone who walks in the campus can look at the statue without the university's permission. This makes the statue as PUBLIC.


Next, you want to take your friend to your dorm, but for that you need to register him as a visitor. This means that he gets an access pass (which is the same as yours) to get into various buildings on campus. This would make his access card as PROTECTED.


Your friend wants to login to the campus WiFi but doesn't have the any credentials to do so. The only way he can get online is if you share your login with him. (Remember, every student who goes to the university also possesses these login credentials). This would make your login credentials as NO MODIFIER.


Finally, your friend wants to read your progress report for the semester which is posted on the website. However, every student has their own personal login to access this section of the campus website. This would make these credentials as PRIVATE.


Hope this helps!


When you are thinking of access modifiers just think of it in this way (applies to both variables and methods):


public --> accessible from every where
private --> accessible only within the same class where it is declared


Now the confusion arises when it comes to default and protected


default --> No access modifier keyword is present. This means it is available strictly within the package of the class. Nowhere outside that package it can be accessed.


protected --> Slightly less stricter than default and apart from the same package classes it can be accessed by sub classes outside the package it is declared. 






I have been working with Java a couple of years, but up until recently I haven't run across this construct:


This is probably a very simple question, but can someone explain it?  How do I read it?  I am pretty sure I know how it works.


Correct?  What is this construct called?


Yes, it is a shorthand form of


It's called the conditional operator. Many people (erroneously) call it the ternary operator, because it's the only ternary (three-argument) operator in Java, C, C++, and probably many other languages. But theoretically there could be another ternary operator, whereas there can only be one conditional operator.


The official name is given in the Java Language Specification:


The conditional operator ? : uses the boolean value of one expression to decide which of two other expressions should be evaluated.


Note that both branches must lead to methods with return values:


It is a compile-time error for either the second or the third operand expression to be an invocation of a void method.


In fact, by the grammar of expression statements (§14.8), it is not permitted for a conditional expression to appear in any context where an invocation of a void method could appear.


So, if doSomething() and doSomethingElse() are void methods, you cannot compress this:


into this:


Simple words:


Others have answered this to reasonable extent, but often with the name "ternary operator".


Being the pedant that I am, I'd like to make it clear that the name of the operator is the conditional operator or "conditional operator ?:". It's a ternary operator (in that it has three operands) and it happens to be the only ternary operator in Java at the moment.


However, the spec is pretty clear that its name is the conditional  operator or "conditional operator ?:" to be absolutely unambiguous. I think it's clearer to call it by that name, as it indicates the behaviour of the operator to some extent (evaluating a condition) rather than just how many operands it has.


According to the Sun Java Specification, it's called the Conditional Operator. See section 15.25. You're right as to what it does.


The conditional operator ? : uses the boolean value of one expression to decide which of two other expressions should be evaluated.


The conditional operator is syntactically right-associative (it groups right-to-left), so that a?b:c?d:e?f:g means the same as a?b:(c?d:(e?f:g)).


The conditional operator has three operand expressions; ? appears between the first and second expressions, and : appears between the second and third expressions.


The first expression must be of type boolean or Boolean, or a compile-time error occurs.


means :


Not exactly correct, to be precise:


That "returned" is very important. It means the methods must return a value and that value must be assigned somewhere.


Also, it's not exactly syntactically equivalent to the if-else version. For example:


If coded with if-else will always result in more bytecode.


If the condition is true then return the first parameter. If the condition is false, return the second parameter.


It is called the Conditional Operator and it is a type of Ternary Operation.


Ternary, conditional; tomato, tomatoh.  What it's really valuable for is variable initialization.  If (like me) you're fond of initializing variables where they are defined, the conditional ternary operator (for it is both) permits you to do that in cases where there is conditionality about its value.  Particularly notable in final fields, but useful elsewhere, too.


e.g.:


Without that operator - by whatever name - you would have to make the field non-final or write a function simply to initialize it. Actually, that's not right - it can still be initialized using if/else, at least in Java.  But I find this cleaner.


This construct is called Ternary Operator in Computer Science and Programing techniques. And Wikipedia suggest the following explanation:


In computer science, a ternary operator (sometimes incorrectly called a tertiary operator) is an operator that takes three arguments. The arguments and result can be of different types. Many programming languages that use C-like syntax feature a ternary operator, ?: , which defines a conditional expression.


Not only in Java, this syntax is available within PHP, Objective-C too.


In the following link it gives the following explanation, which is quiet good to understand it:


A ternary operator is some operation operating on 3 inputs. It's a shortcut for an if-else statement, and is also known as a conditional operator.


In Perl/PHP it works as: boolean_condition ? true_value : false_value


In C/C++ it works as: logical expression ? action for true : action for false


This might be readable for some logical conditions which are not too complex otherwise it is better to use If-Else block with intended combination of conditional logic.


We can simplify the If-Else blocks with this Ternary operator for one code statement line.For Example:


Might be equal to the following:


So if we refer to your statement:


It is actually the 100% equivalent of the following If-Else block:


That's it! 
Hope this was helpful to somebody!
Cheers!


Correct. It's called the ternary operator. Some also call it the conditional operator.


You might be interested in a proposal for some new operators that are similar to the conditional operator. The null-safe operators will enable code like this:


It would be especially convenient where auto-unboxing takes place.


It has been selected for further consideration under JDK 7's "Project Coin."


Its Ternary Operator(?:)


It's the conditional operator, and it's more than just a concise way of writing if statements. 


Since it is an expression that returns a value it can be used as part of other expressions.


Yes, you are correct.  ?: is typically called the "ternary conditional operator", often referred to as simply "ternary operator".  It is a shorthand version of the standard if/else conditional.


Ternary Conditional Operator


I happen to really like this operator, but the reader should be taken into consideration.


You always have to balance code compactness with the time spent reading it, and in that it has some pretty severe flaws.


First of all, there is the Original Asker's case.  He just spent an hour posting about it and reading the responses.  How longer would it have taken the author to write every ?: as an if/then throughout the course of his entire life.  Not an hour to be sure.


Secondly, in C-like languages, you get in the habit of simply knowing that conditionals are the first thing in the line.  I noticed this when I was using Ruby and came across lines like:


If I was a long time Ruby user I probably wouldn't have had a problem with this line, but coming from C, when you see "callMethodWhatever" as the first thing in the line, you expect it to be executed.  The ?: is less cryptic, but still unusual enough as to throw a reader off.


The advantage, however, is a really cool feeling in your tummy when you can write a 3-line if statement in the space of 1 of the lines.  Can't deny that :)  But honestly, not necessarily more readable by 90% of the people out there simply because of its' rarity. 


When it is truly an assignment based on a Boolean and values I don't have a problem with it, but it can easily be abused.






This question already has an answer here:


I'm trying to connect to the local MySQL server but I keep getting an error.


Here is the code.


and the errors :


I've set the classpath, made sure my.cnf had the skip network option commented out. 


java version is 1.2.0_26 (64 bit)
mysql 5.5.14
mysql connector 5.1.17


I made sure that the user had access to my database.


I have had the same problem in two of my programs. My error was this:


I spent several days to solve this problem. I have tested many approaches that have been mentioned in different web sites, but non of them worked. Finally I changed my code and found out what was the problem. I'll try to tell you about different approaches and sum them up here.


While I was seeking the internet to find the solution for this error, I figured out that there are many solutions that worked for at least one person, but others say that it doesn't work for them! why there are many approaches to this error?
It seems this error can occur generally when there is a problem in connecting to the server. Maybe the problem is because of the wrong query string or too many connections to the database.


So I suggest you to try all the solutions one by one and don't give up!


Here are the solutions that I found on the internet and for each of them, there is at least on person who his problem has been solved with that solution.


Tip: For the solutions that you need to change the MySQL settings, you can refer to the following files:


Linux: /etc/mysql/my.cnf or /etc/my.cnf (depending on the Linux distribution and MySQL package used)


Windows: C:**ProgramData**\MySQL\MySQL Server 5.6\my.ini (Notice it's ProgramData, not Program Files)


Uncomment "bind-address" attribute or change it to one of the following IPs:


bind-address="127.0.0.1"


or


bind-address="0.0.0.0"


If there is a "skip-networking" line in your MySQL config file, make it comment by adding "#" sign at the beginning of that line.


Add these lines to the MySQL config file:


wait_timeout = number


interactive_timeout = number


connect_timeout = number


Since MySQL recognizes 127.0.0.1 (IPv4) but not :::1 (IPv6)


This could be avoided by using one of two approaches:


Option #1: In the connection string use 127.0.0.1 instead of localhost to avoid localhost being translated to :::1


Option #2: Run java with the option -Djava.net.preferIPv4Stack=true to force java to use IPv4 instead of IPv6. On Linux, this could also be achieved by running (or placing it inside /etc/profile:


Make sure the Firewall, or Anti-virus software isn't blocking MySQL service.


Stop iptables temporarily on linux. If iptables are misconfigured they may allow tcp packets to be sent to mysql port, but block tcp packets from coming back on the same connection.


Stop anti-virus software on Windows.


Check your query string. your connection string should be some thing like this:


Make sure you don't have spaces in your string. All the connection string should be continues without any space characters.


Try to replace "localhost" with the loopback address 127.0.0.1.
Also try to add port number to your connection string, like:


Usually default port for MySQL is 3306.


Don't forget to change username and password to the username and password of your MySQL server.


"max_allowed_packet" is a variable in MySQL config file that indicates the maximum packet size, not the maximum number of packets. So it will not help to solve this error.


change TOMCAT6_SECURITY=yes to TOMCAT6_SECURITY=no


use validationQuery="select now()" to make sure each query has responses


Add this code to your connection string:


Although non of these solutions worked for me, I suggest you to try them. Because there are some people who solved their problem with following these steps.


But what solved my problem?


My problem was that I had many SELECTs on database. Each time I was creating a connection and then closing it. Although I was closing the connection every time, but the system faced with many connections and gave me that error. What I did was that I defined my connection variable as a public (or private) variable for whole class and initialized it in the constructor. Then every time I just used that connection. It solved my problem and also increased my speed dramatically.


There is no simple and unique way to solve this problem. I suggest you to think about your own situation and choose above solutions. If you take this error at the beginning of the program and you are not able to connect to the database at all, you might have problem in your connection string. But If you take this error after several successful interaction to the database, the problem might be with number of connections and you may think about changing "wait_timeout" and other MySQL settings or rewrite your code how that reduce number of connections.


If you are using MAMP PRO, the easy fix, which I really wish I had realized before I started searching the internet for days trying to figure this out. Its really this simple...


You just have to click "Allow Network Access to MySQL" from the MAMP MySQL tab. 


Really, thats it.


Oh, and you MIGHT have to still change your bind address to either 0.0.0.0 or 127.0.0.1 like outlined in the posts above, but clicking that box alone will probably solve your problems if you are a MAMP user.


Setting the bind-address to the server's network IP instead of the localhost default, and setting privileges on my user worked for me.


my.cnf:


MySql Console:


As the detailed answer above says, this error can be caused by many things.


I had this problem too.  My setup was Mac OSX 10.8, using a Vagrant managed VirtualBox VM of Ubuntu 12.04, with MySQL 5.5.34.


I had correctly setup port forwarding in the Vagrant config file.  I could telnet to the MySQL instance both from my Mac and from within the VM.  So I knew the MySQL daemon was running and reachable.  But when I tried to connect over JDBC, I got the "Communications link failure" error. 


In my case, the problem was solved by editing the /etc/mysql/my.cnf file.  Specifically, I commented out the "#bind-address=127.0.0.1" line.  


In my case it was an idle timeout, that caused the connection to be dropped on the server. The connection was kept open, but not used for a long period of time. Then a client restart works, while I believe a reconnect will work as well.


A not bad solution is to have a daemon/service to ping the connection from time to time.


In my case,


Change the remote machine mysql configuration  at /etc/mysql/my.cnf: change 
bind-address = 127.0.0.1
to 
#bind-address = 127.0.0.1


On the remote machine, change mysql user permissions with
GRANT ALL PRIVILEGES ON *.* TO 'user'@'%' IDENTIFIED BY 'password';


IMPORTANT: restart mysql on the remote machine: sudo /etc/init.d/mysql restart


For me the solution was to change in the conf file of mysql server the parameter bind-address="127.0.0.1" or bind-address="x.x.x.x" to bind-address="0.0.0.0".
Thanks.


I've just faced the same problem.
It happened because the MySQL Daemon was binded to the IP of the machine, which is required to make connection with an user that has permission to connect @your_machine.
In this case, the user should have permission to connect USER_NAME@MACHINE_NAME_OR_IP


I wanted remote access to my machine so I changed in my.cnf from


To


Which will allow an user from localhost AND even outside (in my case) to connect to the instance.
Both below permissions will work if you bind the MySQL to 0.0.0.0:


In case you are having problem with a set of Docker containers, then make sure that you do not only EXPOSE the port 3306, but as well map the port from outside the container -p 3306:3306. For docker-compose.yml:


It happens (in my case) when there is not enough memory for MySQL. A restart fixes it, but if that's the case consider a nachine with more memory, or limit the memory taken by jvms


Go to Windows services in the control panel and start the MySQL service. For me it worked. When I was doing a Java EE project I got this error" Communication link failure". I restarted my system and then it worked. 


After that I again got the same error even after restarting my system. Then I tried to open the MySQL command line console and login with root, even then it gave me an error. 


Finally when I started the MySQL service from Windows services, it worked.


Had the same.
Removing port helped in my case, so I left it as jdbc:mysql://localhost/


If you are using hibernate, this error can be caused for keeping open a Session object more time than wait_timeout


I've documented a case in here for those who are interested.


I found the solution


since MySQL need the Localhost in-order to work.


go to /etc/network/interfaces file and make sure you have the localhost configuration set there:


NOW RESTART the Networking subsystem and the MySQL Services:


sudo /etc/init.d/networking restart


sudo /etc/init.d/mysql restart


Try it now


It is majorly because of weak connection between mysql client and remote mysql server.


In my case it is because of flaky VPN connection.


In phpstorm + vagrant autoReconnect driver option helped.


The resolution provided by Soheil was successful in my case.


To clarify, the only change I needed to make was with MySQL's server configuration;


I am using an external MySQL server for my application. It is a basic Debian 7.5 installation with MySQL Server 5.5 - default configuration.


IMPORTANT:


Always backup the original of any configuration files you may modify. Always take care when elevated as super user.


File


Line


Restart your MySQL Server service:


As you can see, I simply provided the network IP of the server and commented out the default entry. Please note that simply copy and paste my solution will not work for you, unless by some miracle our hosts share the same IP.


Thanks @ Soheil


I was experiencing similar problem and the solution for my case was 


the thing i felt is we should never give up, i tried every options from this post and from other forums as well...happy it works @saurab


I faced this problem also.


As Soheil suggested, 
I went to php.ini file at the  path C:\windows\php.ini , then I revised port number in this  file. 


it is on the line mysqli.default_port =..........


So I  changed it in my java app as it's in the php.ini file,now it works fine with me.


I know this is an old thread but I have tried numerous things and fixed my issue using the following means.. 


I'm developing a cross platform app on Windows but to be used on Linux and Windows servers. 


A MySQL database called "jtm" installed on both systems. For some reason, in my code I had the database name as "JTM". On Windows it worked fine, in fact on several Windows systems it flew along. 


On Ubuntu I got the error above time and time again. I tested it out with the correct case in the code "jtm" and it works a treat. 


Linux is obviously a lot less forgiving about case sensitivity (rightly so), whereas Windows makes allowances. 


I feel a bit daft now but check everything. The error message is not the best but it does seem fixable if you persevere and get things right. 


I just restarted MySQL (following a tip from here: https://stackoverflow.com/a/14238800) and it solved the issue.


I had the same issue on MacOS (10.10.2) and MySql (5.6.21) installed via homebrew.


The confusing thing was that one of my apps connected to the database fine and the other did not.


After trying many things on the app that threw the exception com.mysql.jdbc.CommunicationsException as suggested by the  the accepted answer of this question to no avail, I was surprised that restarting MySQL worked.


The cause of my issue might have been the following as suggested in the answer in the aforementioned link:


Are you using connection pool ? If yes, then try to restart the
  server. Probably few of the connections in your connection pool are in closed state.


For Windows :-
Goto start menu write , "MySqlserver Instance Configuration Wizard" and reconfigure your mysql server instance.
Hope it will solve your problem.


After years having the same issue and no permanent solution this is whats solved it for the past 3 weeks (which is a record in terms of error free operation)


set global wait_timeout=3600;
set global interactive_timeout=230400;


Don't forget to make this permanent if it works for you.


In my case (I am a noob), I was testing Servlet that make database connection with MySQL and one of the Exception is the one mentioned above.


It made my head swing for some seconds but I came to realize that it was because I have not started my MySQL server in localhost.
After starting the server, the problem was fixed.


So, check whether MySQL server is running properly.


If you are using local emulator, you have to use IP address 10.0.2.2 instead of localhost to access to your local MySQL server.






I read about sorting ArrayLists using a Comparator but in all of the examples people used compareTo which according to some research is a method for Strings.


I wanted to sort an ArrayList of custom objects by one of their properties: a Date object
(getStartDay()). Normally I compare them by item1.getStartDate().before(item2.getStartDate()) so I was wondering whether I could write something like:


Since Date implements Comparable, it has a compareTo method just like String does.


So your custom Comparator could look like this:


The compare() method must return an int, so you couldn't directly return a boolean like you were planning to anyway.


Your sorting code would be just about like you wrote:


A slightly shorter way to write all this, if you don't need to reuse your comparator, is to write it as an inline anonymous class:


You can now write the last example in a shorter form by using a lambda expression for the Comparator:


And List has a sort(Comparator) method, so you can shorten this even further:


This is such a common idiom that there's a built-in method to generate a Comparator for a class with a Comparable key:


All of these are equivalent forms.


Classes that has a natural sort order (a class Number, as an example) should implement the Comparable interface, whilst classes that has no natural sort order (a class Chair, as an example) should be provided with a Comparator (or an anonymous Comparator class).


Two examples:


Usage:


For sorting an ArrayList you could use the following code snippet:


Yes, you can.  There are two options with comparing items, the Comparable interface, and the Comparator interface.


Both of these interfaces allow for different behavior.  Comparable allows you to make the object act like you just described Strings (in fact, String implements Comparable).  The second, Comparator, allows you to do what you are asking to do.  You would do it like this:


That will cause the Collections.sort method to use your comparator for it's sorting mechanism.  If the objects in the ArrayList implement comparable, you can instead do something like this:


The Collections class contains a number of these useful, common tools.


With Java 8 you can use a method reference for your comparator:


Since technologies appear everyday, the answer will change in the time. I took a look at LambdaJ and seems very interesting.


You can try solving these tasks with LambdaJ. You can find it here: http://code.google.com/p/lambdaj/


Here you have an example:


Sort Iterative


Sort with lambda


Of course, having this kind of beauty impacts in the performance (an average of 2 times), but can you find a more readable code?


You can use the Bean Comparator to sort on any property in your custom class.


From Java 8 and onward we don't have to use Collections.sort() directly. List interface has a default sort() method:


See http://visvv.blogspot.in/2016/01/sorting-objects-in-java-8.html.


Best easy way with JAVA 8 is for English Alphabetic sort


Class Implementation


Sort


If you want to sort for alphabet that contains non English characters you can use Locale... Below code use Turkish character sort...


Class Implementation


Sort


You can try Guava Ordering:


Yes, that's possible for instance  in this answer I sort by the property v of the class IndexValue 


If you notice here I'm creating a anonymous inner class ( which is the Java for closures ) and passing it directly to the sort method of the class Arrays 


Your object may also implement Comparable ( that's what String and most of the core libraries in Java does ) but that would define the "natural sort order" of the class it self, and doesn't let you plug new ones.


This code snippets might be useful. If you want to sort an Object
in my case I want to sort by VolumeName:


This works. I use it in my jsp.


Java 8 Lambda shortens the sort.


I found most if not all of these answers rely on the underlying class (Object) to implement comparable or to have a helper comparable interface.


Not with my solution! The following code lets you compare object's field by knowing their string name. You could easily modify it not to use the name, but then you need to expose it or construct one of the Objects you want to compare against.


With this library here you can sort the list of custom objects on multiple columns. The library uses version 8.0 features. Sample is also available there. Here is a sample to do


You can Sort using  java 8


You can have a look into this presentation hold at the Java Forum in Stuttgart Germany in 2016.


Only a few slides use German language, 99% of the content is "English based" Java source code; like


where OurCustomComparator is using default methods (and other interesting ideas). As shown, leading to very concise code to pick some getter method for sorting; and super simple chaining (or reversing) of sort criteria. 


If you are into java8, you find a lot of material there to get you started.


your customComparator class must implement java.util.Comparator in order to be used.
it must also overide compare() AND equals()


compare() must answer the question:  Is object 1 less than, equal to or greater than object 2?


full docs: http://java.sun.com/j2se/1.5.0/docs/api/java/util/Comparator.html


I prefer this process:


If you list of objects has a property called startDate, you call use this over and over.  You can even chain them startDate.time.


This requires your object to be Comparable which means you need a compareTo, equals, and hashCode implementation.


Yes, it could be faster... But now you don't have to make a new Comparator for each type of sort.  If you can save on dev time and give up on runtime, you might go with this one.


For Java 8:


or


It seems to work with String date type also like "2015-12-14T21:55:51Z"


Another way is


New since 1.8 is a List.sort() method instead of using the Collection.sort()
so you directly call  mylistcontainer.sort()


Here is a code snippet which demonstrates the List.sort() feature:


The Fruit class is:


} // end of Fruit class   






I need a solution to properly stop the thread in Java.


I have IndexProcessorclass which implements the Runnable interface:


And I have ServletContextListener class which starts and stops the thread:


But when I shutdown tomcat, I get the exception in my IndexProcessor class:


I am using JDK 1.6. So the question is:


How can I stop the thread and not throw any exceptions? 


P.S. I do not want to use .stop(); method because it is deprecated.


In the IndexProcessor class you need a way of setting a flag which informs the thread that it will need to terminate, similar to the variable run that you have used just in the class scope.


When you wish to stop the thread, you set this flag and call join() on the thread and wait for it to finish.


Make sure that the flag is thread safe by using a volatile variable or by using getter and setter methods which are synchronised with the variable being used as the flag.


Then in SearchEngineContextListener:


Using Thread.interrupt() is a perfectly acceptable way of doing this. In fact, it's probably preferrable to a flag as suggested above.  The reason being that if you're in an interruptable blocking call (like Thread.sleep or using java.nio Channel operations), you'll actually be able to break out of those right away.


If you use a flag, you have to wait for the blocking operation to finish and then you can check your flag.  In some cases you have to do this anyway, such as using standard InputStream/OutputStream which are not interruptable.


In that case, when a thread is interrupted, it will not interrupt the IO, however, you can easily do this routinely in your code (and you should do this at strategic points where you can safely stop and cleanup)


Like I said, the main advantage to Thread.interrupt() is that you can immediately break out of interruptable calls, which you can't do with the flag approach.


Simple answer:
You can stop a thread INTERNALLY in one of two common ways:


You can also stop threads EXTERNALLY:


*: The expectation is that this is supposed to stop a thread.  However, what the thread actually does when this happens is entirely up to what the developer wrote when they created the thread implementation.


A common pattern you see with run method implementations is a while(boolean){}, where the boolean is typically something named isRunning, it's a member variable of its thread class, it's volatile, and typically accessible by other threads by a setter method of sorts, e.g. kill() { isRunnable=false; }. These subroutines are nice because they allow the thread to release any resources it holds before terminating.


You should always end threads by checking a flag in the run() loop (if any).


Your thread should look like this:


Then you can end the thread by calling thread.stopExecuting(). That way the thread is ended clean, but this takes up to 15 seconds (due to your sleep).
You can still call thread.interrupt() if it's really urgent - but the prefered way should always be checking the flag.


To avoid waiting for 15 seconds, you can split up the sleep like this:


For synchronizing threads I prefer using CountDownLatch which helps threads to wait until the process being performed complete. In this case, the worker class is set up with a CountDownLatch instance with a given count. A call to await method will block until the current count reaches zero due to invocations of the countDown method or the timeout set is reached. This approach allows interrupting a thread instantly without having to wait for the specified waiting time to elapse:


When you want to finish execution of the other thread, execute countDown on the CountDownLatch and join the thread to the main thread:


Some supplementary info.
Both flag and interrupt are suggested in the Java doc. 


https://docs.oracle.com/javase/8/docs/technotes/guides/concurrency/threadPrimitiveDeprecation.html


For a thread that waits for long periods (e.g., for input), use Thread.interrupt 


I didn't get the interrupt to work in Android, so I used this method, works perfectly:


If we are using JDK 1.0 , we can call Thread's deprecated method stop() to terminate it. Using stop() is incredibly dangerous, as it will kill your thread even if it is in the middle of something important. There is no way to protect yourself, so if you spot code that uses stop(), you should frown.


How do we shutdown a thread cleanly?


In Java, starting a threads is easy, but shutting them down require a lot of attention and efforts.


Here is how it is designed in Java. There is a flag called Interrupt status flag in every java thread that we can set from the outside i.e. parent or main thread. And the thread may check it occasionally and stops its execution. Voluntarily..!! Here is how:


source: How to stop thread in java | MultiThreading  






Can somebody recommend the best way to convert a string in the format 'January 2, 2010' to a date in java?  Ultimately, I want to break out the month, the day, and the year as integers so that I can use:


to convert the date into time.


Don't do it, that's the hard way.  Moreover, those setter methods of java.util.Date are deprecated since Java 1.1 (1997). Simply format date using SimpleDateFormat using a format pattern matching the input string.


In your specific case of "January 2, 2010" as input string, "January" is the full text month, so use MMMM pattern for it, "2" is the short day-of-month, so use d pattern for it, "2010" is the 4-digit year, so use yyyy pattern for it.


Note the importance of explicit Locale argument. If you omit it, then it will use the default locale which is not necessarily English as used in the month name of the input string. If the locale doesn't match with the input string, then you would confusingly get a java.text.ParseException even though when the format pattern seems valid.


Here's an extract of relevance from the javadoc, listing all available format patterns:


Note that the patterns are case sensitive and that text based patterns of 4 characters or more represents the full form, otherwise a short or abbreviated form is used if available. So e.g. MMMMM or more is unnecessary.


Here are some examples of valid SimpleDateFormat patterns to parse a given string to date:


Important note is that SimpleDateFormat is not thread safe. In other words, you should never declare and assign it as a static or instance variable and then reuse from different methods/threads. You should always create it brand new within the method local scope.


If you happen to be on Java 8 already, then use DateTimeFormatter (also here, click the link to see all predefined formatters and available format patterns; the tutorial is available here). This new API is inspired by JodaTime.


Note: if your format pattern happens to contain the time part as well, then use LocalDateTime#parse(text, formatter) instead of LocalDate#parse(text, formatter). And, if your format pattern happens to contain the time zone as well, then use ZonedDateTime#parse(text, formatter) instead.


Here's an extract of relevance from the javadoc, listing all available format patterns:


Do note that it has several predefined formatters for the more popular patterns. So instead of e.g. DateTimeFormatter.ofPattern("EEE, d MMM yyyy HH:mm:ss Z", Locale.ENGLISH);, you could use DateTimeFormatter.RFC_1123_DATE_TIME. This is possible because they are, on the contrary to SimpleDateFormat, thread safe. You could thus also define your own, if necessary.


For particular input string format, you don't need to use an explicit DateTimeFormatter: a standard ISO 8601 date, like 2016-09-26T17:44:57Z,  can be parsed directly with LocalDateTime#parse(text) as it already uses the ISO_LOCAL_DATE_TIME formatter. Similarly, LocalDate#parse(text) parses a ISO date without the time component (see ISO_LOCAL_DATE), and ZonedDateTime#parse(text) parses an ISO date with an offset and time zone added (see ISO_ZONED_DATE_TIME).


Ah yes the Java Date discussion, again.  To deal with date manipulation we use Date, Calendar, GregorianCalendar, and SimpleDateFormat.  For example using your January date as input:


Then you can manipulate that with something like:


With Java 8 we get a new Date / Time API (JSR 310).


The following way can be used to parse the date in Java 8 without relying on Joda-Time:


LocalDate is the standard Java 8 class for representing a date (without time). If you want to parse values that contain date and time information you should use LocalDateTime. For values with timezones use ZonedDateTime. Both provide a parse() method similar to LocalDate:


The list formatting characters from DateTimeFormatter Javadoc:


While some of the answers are technically correct, they are not advisable. 


A few notes about Joda-Time follow.


In Joda-Time, a DateTime object truly knows its own assigned time zone. This contrasts the java.util.Date class which seems to have a time zone but does not.


Note in the example code below how we pass a time zone object to the formatter which parses the string. That time zone is used to interpret that date-time as having occurred in that time zone. So you need to think about and determine the time zone represented by that string input.


Since you have no time portion in your input string, Joda-Time assigns the first moment of the day of the specified time zone as the time-of-day. Usually this means 00:00:00 but not always, because of Daylight Saving Time (DST) or other anomalies. By the way, you can do the same to any DateTime instance by calling withTimeAtStartOfDay.


The characters used in a formatter's pattern are similar in Joda-Time to those in java.util.Date/Calendar but not exactly the same. Carefully read the doc.


We usually use the immutable classes in Joda-Time. Rather than modify an existing Date-Time object, we call methods that create a new fresh instance based on the other object with most aspects copied except where alterations were desired. An example is the call to withZone in last line below. Immutability helps to make Joda-Time very thread-safe, and can also make some work more clear.


You will need java.util.Date objects for use with other classes/framework that do not know about Joda-Time objects. Fortunately, it is very easy to move back and forth.


Going from a java.util.Date object (here named date) to Joda-Time DateTime…


Going the other direction from Joda-Time to a java.util.Date object…


When run…


While on dealing with SimpleDateFormat Class, its important to remember that Date is not Thread-safe and you can not share a single Date object with multiple thread.Also there is big difference between "m" and "M" where small case is used for minutes and capital case is used for Month. Same with "d" and "D". This can cause subtle bugs which often get overlooked. See Javadoc or Guide to Convert String to Date in Java for more details


Thanks for posters. Updated answer and test more. It works fine for me.
Have Fun! @.@


Also SimpleDateFormat is not available with some of the client side technologies like gwt.
Its a good idea to go for Calendar.getInstance() and your requirement is to compare two dates go for long date.


My humble test program. I use it to play around with the formatter and look-up long dates that I find in log-files (but who has put them there...).


My test program:


Test results:


Simple two formtter we are used
1) which format date we want?
2) Which format date actully present?
We parse full date to time format.


date="2016-05-06 16:40:32";


I had a task where I had to write a code that would take any string and attempt to convert it to date when the string's format is not known in advance. I wrote an interesting utility. Here is the article that describes the idea: Java 8 java.time package: parsing any string to date. This was implemented in Java 8 but the idea could be implemented in earlier versions as well


Try this


You can use SimpleDateformat for  change string to date 




SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd");
String strDate = "2000-01-01";
Date date= new Date(sdf.parse(strDate ).getTime());









I want to access my current working directory using 


OutPut:  


My output is not correct because C drive is not my current directory.
Need help in this regard.


This will print a complete absolute path from where your application was initialized.


See: http://docs.oracle.com/javase/tutorial/essential/io/pathOps.html


Using java.nio.file.Path and java.nio.file.Paths, you can do the following to show what Java thinks is your current path. This for 7 and on, and uses NIO.


This outputs Current relative path is: /Users/george/NetBeansProjects/Tutorials that in my case is where I ran the class from. Constructing paths in a relative way, by not using a leading separator to indicate you are constructing an absolute path, will use this relative path as the starting point.


The following works on Java 7 and up (see here for documentation).


What makes you think that c:\windows\system32 is not your current directory? The user.dir property is explicitly to be "User's current working directory".


To put it another way, unless you start Java from the command line, c:\windows\system32 probably is your CWD. That is, if you are double-clicking to start your program, the CWD is unlikely to be the directory that you are double clicking from.


Edit: It appears that this is only true for old windows and/or Java versions. 


This is the solution for me


Use CodeSource#getLocation(). 


This works fine in JAR files as well. You can obtain CodeSource by ProtectionDomain#getCodeSource() and the ProtectionDomain in turn can be obtained by Class#getProtectionDomain().


generally, as a File object:


you may want to have full qualified string like "D:/a/b/c" doing:


I'm on Linux and get same result for both of these approaches:


Paths.get("") docs


System.getProperty("user.dir") docs


I hope you want to access the current directory including the package i.e. If your Java program is in c:\myApp\com\foo\src\service\MyTest.java and you want to print until c:\myApp\com\foo\src\service then you can try the following code:


Note:


Using Windows user.dir returns the directory as expected, but NOT when you start your application with elevated rights (run as admin), in that case you get C:\WINDOWS\system32


Current working directory is defined differently in different Java implementations. For certain version prior to Java 7 there was no consistent way to get the working directory. You could work around this by launching Java file with -D and defining a variable to hold the info


Something like


That's not quite right, but you get the idea. Then System.getProperty("com.mycompany.workingDir")...


On Linux when you run a jar file from terminal, these both will return the same String: "/home/CurrentUser", no matter, where youre jar file is. It depends just on what current directory are you using with your terminal, when you start the jar file.


If your Class with main would be called MainClass, then try:


This will return a String with absolute path of the jar file.


Mention that it is checked only in Windows but i think it works perfect on other Operating Systems [Linux,MacOs,Solaris] :).


I had 2 .jar files in the same directory . I wanted from the one .jar file to start the other .jar file which is in the same directory.


The problem is that when you start it from the cmd the current directory is system32.


Warnings!


🍂..


🍂getBasePathForClass(Class<?> classs):


None of the answers posted here worked for me.  Here is what did work:


Edit:  The final version in my code:


assume that you're trying to run your project inside eclipse, or netbean or stand alone from command line. I have write a method to fix it


To use, everywhere you want to get base path to read file, you can pass your anchor class to above method, result may be the thing you need :D


Best,


This will give you the path of your working directory:


And this will give you the path to a file called "Foo.txt" in the working directory:


this is current directory name    


this is current directory path


System.getProperty("java.class.path")






How do you connect to a MySQL database in Java?


DriverManager is a fairly old way of doing things. The better way is to get a DataSource, either by looking one up that your app server container already configured for you:


or instantiating and configuring one from your database driver directly:


and then obtain connections from it, same as above:


Here's a step by step explanation how to install MySQL and JDBC and how to use it:


Download and install the MySQL server. Just do it the usual way. Remember the port number whenever you've changed it. It's by default 3306.


Download the JDBC driver and put in classpath, extract the ZIP file and put the containing JAR file in the classpath. The vendor-specific JDBC driver is a concrete implementation of the JDBC API (tutorial here). 


If you're using an IDE like Eclipse or Netbeans, then you can add it to the classpath by adding the JAR file as Library to the Build Path in project's properties. 


If you're doing it "plain vanilla" in the command console, then you need to specify the path to the JAR file in the -cp or -classpath argument when executing your Java application.


The . is just there to add the current directory to the classpath as well so that it can locate com.example.YourClass and the ; is the classpath separator as it is in Windows. In Unix and clones : should be used.


Create a database in MySQL. Let's create a database javabase. You of course want World Domination, so let's use UTF-8 as well.


Create an user for Java and grant it access. Simply because using root is a bad practice.


Yes, java is the username and password is the password here.


Determine the JDBC URL. To connect the MySQL database using Java you need an JDBC URL in the following syntax:


hostname: The hostname where MySQL server is installed. If it's installed at the same machine where you run the Java code, then you can just use localhost. It can also be an IP address like 127.0.0.1. If you encounter connectivity problems and using 127.0.0.1 instead of localhost solved it, then you've a problem in your network/DNS/hosts config.


port: The TCP/IP port where MySQL server listens on. This is by default 3306.


databasename: The name of the database you'd like to connect to. That's javabase.


So the final URL should look like:


Test the connection to MySQL using Java. Create a simple Java class with a main() method to test the connection. 


If you get a SQLException: No suitable driver, then it means that either the JDBC driver wasn't autoloaded at all or that the JDBC URL is wrong (i.e. it wasn't recognized by any of the loaded drivers). Normally, a JDBC 4.0 driver should be autoloaded when you just drop it in runtime classpath. To exclude one and other, you can always manually load it as below:


Note that the newInstance() call is not needed here. It's just to fix the old and buggy org.gjt.mm.mysql.Driver. Explanation here. If this line throws ClassNotFoundException, then the JAR file containing the JDBC driver class is simply not been placed in the classpath.


Note that you don't need to load the driver everytime before connecting. Just only once during application startup is enough.


If you get a SQLException: Connection refused or Connection timed out or a MySQL specific CommunicationsException: 
Communications link failure, then it means that the DB isn't reachable at all. This can have one or more of the following causes:


To solve the one or the other, follow the following advices:


Note that closing the Connection is extremely important. If you don't close connections and keep getting a lot of them in a short time, then the database may run out of connections and your application may break. Always acquire the Connection in a try-with-resources statement. Or if you're not on Java 7 yet, explicitly close it in finally of a try-finally block. Closing in finally is just to ensure that it get closed as well in case of an exception. This also applies to Statement, PreparedStatement and ResultSet.


That was it as far the connectivity concerns. You can find here a more advanced tutorial how to load and store fullworthy Java model objects in a database with help of a basic DAO class.


Using a Singleton Pattern for the DB connection is a bad approach. See among other questions: http://stackoverflow.com/q/9428573/. This is a #1 starters mistake.


Initialize database constants


Create constant properties database username, password, URL and drivers, polling limit etc.


Initialize Connection and Properties


Once the connection is established, it is better to store for reuse purpose.


Create Properties


The properties object hold the connection information, check if it is already set.


Connect the Database


Now connect to database using the constants and properties initialized.


Disconnect the database


Once you are done with database operations, just close the connection.


Everything together


Use this class MysqlConnect directly after changing database_name, username and password etc.


How to Use?


Initialize the database class.


Somewhere else in your code ...


This is all :) If anything to improve edit it! Hope this is helpful.


Here's the very minimum you need to get data out of a MySQL database:


Add exception handling, configuration etc. to taste.


Short and Sweet code.


For SQL server 2012


You can see all steps to connect MySQL database from Java application here. For other database, you just need to change the driver in first step only. Please make sure that you provide right path to database and correct username and password.


Visit http://apekshit.com/t/51/Steps-to-connect-Database-using-JAVA


you need to have mysql connector jar in your classpath. 


in Java JDBC API makes everything with databases. using JDBC  we can write Java applications to
1. Send queries or  update SQL to DB(any relational Database) 
2. Retrieve and process the results from DB


with below three steps we can able to retrieve data from any  Database


Connection I was using some time ago, it was looking like the easiest way, but also there were recommendation to make there if statement- exactly 


Or something like in that way :)


Probably there's some case, while getConnection can return null  :)


MySQL JDBC Connection with useSSL. 


MySql JDBC Connection:


Short Code






I am trying to reverse an int array in Java.


This method does not reverse the array.  


What is wrong with it?


To reverse an int array, you swap items up until you reach the midpoint, like this:


The way you are doing it, you swap each element twice, so the result is the same as the initial list.


With Commons.Lang, you could simply use 


Most of the time, it's quicker and more bug-safe to stick with easily available libraries already unit-tested and user-tested when they take care of your problem.


I think it's a little bit easier to follow the logic of the algorithm if you declare explicit variables to keep track of the indices that you're swapping at each iteration of  the loop.


I also think it's more readable to do this in a while loop.


java.util.Collections.reverse() can reverse java.util.Lists and java.util.Arrays.asList() returns a list that wraps the the specific array you pass to it, therefore yourArray is reversed after the invocation of Collections.reverse().


The cost is just the creation of one List-object and no additional libraries are required.


A similar solution has been presented in the answer of Tarik and their commentors, but I think this answer would be more concise and more easily parsable.


This will help you


Simple for loop!


If working with data that is more primitive (i.e. char, byte, int, etc) then you can do some fun XOR operations.


This is how I would personally solve it. The reason behind creating the parametrized method is to allow any array to be sorted... not just your integers.


I hope you glean something from it.


With Guava:


There are already a lot of answers here, mostly focused on modifying the array in-place. But for the sake of completeness, here is another approach using Java streams to preserve the original array and create a new reversed array:


It is most efficient to simply iterate the array backwards.


I'm not sure if Aaron's solution does this vi this call Collections.reverse(list); Does anyone know?


Your program will work for only length = 0, 1.
You can try :


Here's a simple an quick solution. Hope it helps!.


Wouldn't doing it this way be much more unlikely for mistakes?


below is the complete program to run in your machine.


For programs on matrix using arrays this will be the good source.Go through the link.


Using the XOR solution to avoid the temp variable your code should look like


See this link for a better explanation:


http://betterexplained.com/articles/swap-two-variables-using-xor/


Try this code: 


Here is a simple implementation, to reverse array of any type, plus full/partial support.


Here is the corresponding Unit Test 


Another way to reverse array 


This works if you want to reverse until you get to the middle of the array?


As I intended to keep my original Array as it was, I solved this problem in the following manner:


So basically loop through the initial array and add all the values in reversed order to the new (reversed) array. The type of the list can be anything.
I work my way through this code multiple times, this causes some of the other solutions not to work.


Here is what I've come up with:


In case of Java 8 we can also use streams to reverse the integer array as:


Solution with o(n) time complexity and o(1) space complexity.






What are some common, real world examples of using the Builder Pattern?  What does it buy you?  Why not just use a Factory Pattern?


The key difference between a builder and factory IMHO, is that a builder is useful when you need to do lots of things to build an object. For example imagine a DOM. You have to create plenty of nodes and attributes to get your final object. A factory is used when the factory can easily create the entire object within one method call.


One example of using a builder is a building an XML document, I've used this model when building HTML fragments for example I might have a Builder for building a specific type of table and it might have the following methods (parameters are not shown):


This builder would then spit out the HTML for me. This is much easier to read then walking through a large procedural method.


Check out Builder Pattern on Wikipedia.


Below are some reasons arguing for the use of the pattern and example code in Java, but it is an implementation of the Builder Pattern covered by the Gang of Four in Design Patterns. The reasons you would use it in Java are also applicable to other programming languages as well.


As Joshua Bloch states in Effective Java, 2nd Edition: 


The builder pattern is a good choice when designing classes whose constructors or static factories would have more than a handful of parameters.


We've all at some point encountered a class with a list of constructors where each addition adds a new option parameter:


This is called the Telescoping Constructor Pattern. The problem with this pattern is that once constructors are 4 or 5 parameters long it becomes difficult to remember the required order of the parameters as well as what particular constructor you might want in a given situation.


One alternative you have to the Telescoping Constructor Pattern is the JavaBean Pattern where you call a constructor with the mandatory parameters and then call any optional setters after: 


The problem here is that because the object is created over several calls it may be in an inconsistent state partway through its construction. This also requires a lot of extra effort to ensure thread safety.


The better alternative is to use the Builder Pattern.


Note that Pizza is immutable and that parameter values are all in a single location. Because the Builder's setter methods return the Builder object they are able to be chained.


This results in code that is easy to write and very easy to read and understand. In this example, the build method could be modified to check parameters after they have been copied from the builder to the Pizza object and throw an IllegalStateException if an invalid parameter value has been supplied. This pattern is flexible and it is easy to add more parameters to it in the future. It is really only useful if you are going to have more than 4 or 5 parameters for a constructor. That said, it might be worthwhile in the first place if you suspect you may be adding more parameters in the future.


I have borrowed heavily on this topic from the book Effective Java, 2nd Edition by Joshua Bloch. To learn more about this pattern and other effective Java practices I highly recommend it. 


Consider a restaurant. The creation of "today's meal" is a factory pattern, because you tell the kitchen "get me today's meal" and the kitchen (factory) decides what object to generate, based on hidden criteria.


The builder appears if you order a custom pizza. In this case, the waiter tells the chef (builder) "I need a pizza; add cheese, onions and bacon to it!" Thus, the builder exposes the attributes the generated object should have, but hides how to set them.


.NET StringBuilder class is a great example of builder pattern. It is mostly used to create a string in a series of steps. The final result you get on doing ToString() is always a string but the creation of that string varies according to what functions in the StringBuilder class were used. To sum up, the basic idea is to build complex objects and hide the implementation details of how it is being built.


For a multi-threaded problem, we needed a complex object to be built up for each thread. The object represented the data being processed, and could change depending on the user input.


Could we use a factory instead? Yes


Why didn't we? Builder makes more sense I guess. 


Factories are used for creating different types of objects that are the same basic type (implement the same interface or base class). 


Builders build the same type of object over and over, but the construction is dynamic so it can be changed at runtime.


You use it when you have lots of options to deal with.  Think about things like jmock:


It feels a lot more natural and is...possible.


There's also xml building, string building and many other things.  Imagine if java.util.Map had put as a builder.  You could do stuff like this:


While going through Microsoft MVC framework, I got a thought about builder pattern. I came across the pattern in the ControllerBuilder class. This class is to return the controller factory class, which is then used to build concrete controller.


Advantage I see in using builder pattern is that, you can create a factory of your own and plug it into the framework. 


@Tetha, there can be a restaurant (Framework) run by Italian guy, that serves Pizza. In order to prepare pizza Italian guy (Object Builder) uses Owen (Factory) with a pizza base (base class).


Now Indian guy takes over the restaurant from Italian guy. Indian restaurant (Framework) servers dosa instead of pizza. In order to prepare dosa Indian guy (object builder) uses Frying Pan (Factory) with a Maida (base class)


If you look at scenario, food is different,way food is prepared is different, but in the same restaurant (under same framework). Restaurant should be build in such a way that it can support Chinese, Mexican or any cuisine. Object builder inside framework facilitates to plugin kind of cuisine you want. for example


Another advantage of the builder is that if you have a Factory, there is still some coupling in you code, because for the Factory to work, it has to know all the objects it can possibly create. If you add another object that could be created, you will have to modify the factory class to include him. This happens in the Abstract Factory as well.


With the builder, on the other hand, you just have to create a new concrete builder for this new class. The director class will stay the same, because it receives the builder in the constructor.


Also, there are many flavors of builder. Kamikaze Mercenary`s gives another one.


Building on the previous answers (pun intended), an excellent real-world example is Groovy's built in support for Builders.


See Builders in the Groovy Documentation


I used builder in home-grown messaging library. The library core was receiving data from the wire, collecting it with Builder instance, then, once Builder decided it've got everything it needed to create a Message instance, Builder.GetMessage() was constructing a message instance using the data collected from the wire.


When I wanted to use the standard XMLGregorianCalendar for my XML to object marshalling of DateTime in Java, I heard a lot of comments on how heavy weight and cumbersome it was to use it. I was trying to comtrol the XML fields in the xs:datetime structs to manage timezone, milliseconds, etc.


So I designed a utility to build an XMLGregorian calendar from a GregorianCalendar or java.util.Date.


Because of where I work I'm not allowed to share it online without legal, but here's an example of how a client uses it. It abstracts the details and filters some of the implementation of XMLGregorianCalendar that are less used for xs:datetime.


Granted this pattern is more of a filter as it sets fields in the xmlCalendar as undefined so they are excluded, it still "builds" it. I've easily added other options to the builder to create an xs:date, and xs:time struct and also to manipulate timezone offsets when needed.


If you've ever seen code that creates and uses XMLGregorianCalendar, you would see how this made it much easier to manipulate.


Check out InnerBuilder, an IntelliJ IDEA plugin that adds a 'Builder' action to the Generate menu (Alt+Insert) which generates an inner builder class as described in Effective Java


https://github.com/analytically/innerbuilder


I always disliked the Builder pattern as something unwieldy, obtrusive and very often abused by less experienced programmers. Its a pattern which only makes sense if you need to assemble the object from some data which requires a post-initialisation step (i.e. once all the data is collected - do something with it). Instead, in 99% of the time builders are simply used to initialise the class members.


In such cases it is far better to simply declare withXyz(...) type setters inside the class and make them return a reference to itself. 


Consider this:


Now we have a neat single class that manages its own initialization and does pretty much the same job as the builder, except that its far more elegant. 


A great real world example is to use when unit testing your classes. You use sut (System Under Test) builders.


Example:


Class:


Test:


sut Builder:






How can i have this image like below into the slavePanel and on top of that JPanel adjust the JButtons which looks like the image but having buttons correctly wrapped around? (Right now they are shaped in 1 row, 4 column)





Follow up: Excellent one from Andrew Thompson  + at-least my broken method








Starting from this example, I got a start by changing MoveButton like this:


You could give ControlPanel a Custom Layout Manager. I'd also add a background image and some kind of visual feedback based on the ButtonModel state, as suggested here.


1) you have to prepare the Icons before and for every 5 JButtons (event here came from ButtonModel)


basic Icon without Focus 


Icon for isRollover()


Icon for isPressed()


2) how to set Icons and to remove all "balast" from JButton


3) put these 5 JButtons to the JPanel with painted circles (RemoteSet)






I'm trying to get random numbers between 0 and 100. But I want them to be unique, not repeated in a sequence. For example if I got 5 numbers, they should be 82,12,53,64,32 and not 82,12,53,12,32
I used this, but it generates same numbers in a sequence.


Here is a simple implementation.  This will print 3 unique random numbers from the range 1-10.


The first part of the fix with the original approach, as Mark Byers pointed out in an answer now deleted, is to use only a single Random instance.  


That is what is causing the numbers to be identical.  A Random instance is seeded by the current time in milliseconds.  For a particular seed value, the 'random' instance will return the exact same sequence of pseudo random numbers.


With Java 8+ you can use the ints method of Random to get an IntStream of random values then distinct and limit to reduce the stream to a number of unique random values.


Random also has methods which create LongStreams and DoubleStreams if you need those instead.


If you want all (or a large amount) of the numbers in a range in a random order it might be more efficient to add all of the numbers to a list, shuffle it, and take the first n because the above example is currently implemented by generating random numbers in the range requested and passing them through a set (similarly to Rob Kielty's answer), which may require generating many more than the amount passed to limit because the probability of a generating a new unique number decreases with each one found. Here's an example of the other way:


Use Collections.shuffle() on all 100 numbers and select the first five, as shown here.


I re-factored Anand's answer to make use not only of the unique properties of a Set but also use the boolean false returned by the set.add() when an add to the set fails.


I feel like this method is worth mentioning.


I have come here from another question, which has been duplicate of this question (Generating unique random number in java)


Store  1 to 100 numbers in an Array.


Generate random number between 1 to 100 as position and return array[position-1] to get the value  


Once you use a number in array, mark the value as -1 ( No need to maintain another array to check if this number is already used)


If value in array is -1, get the random number again to fetch new location in array.


This will work to generate unique random numbers................


One clever way to do this is to use exponents of a primitive element in modulus.


For example, 2 is a primitive root mod 101, meaning that the powers of 2 mod 101 give you a non-repeating sequence that sees every number from 1 to 100 inclusive:


In Java code, you would write:


Finding a primitive root for a specific modulus can be tricky, but Maple's "primroot" function will do this for you.


try this out


Check this 


Choose n unique random numbers from 0 to m-1.


Imagine a list containing numbers from 0 to m-1. To choose the first number, we simply use rand.nextInt(m). Then remove the number from the list. Now there remains m-1 numbers, so we call rand.nextInt(m-1). The number we get represents the position in the list. If it is less than the first number, then it is the second number, since the part of list prior to the first number wasn't changed by the removal of the first number. If the position is greater than or equal to the first number, the second number is position+1. Do some further derivation, you can get this algorithm.






What is null? 


Is null an instance of anything? 


What set does null belong to?


How is it represented in the memory?


Is null an instance of anything? 


No, there is no type which null is an instanceof.


At run time, the result of the instanceof operator is true if the value of the RelationalExpression is not null and the reference could be cast to the ReferenceType without raising a ClassCastException. Otherwise the result is false.


This means that for any type E and R, for any E o, where o == null, o instanceof R is always false.


What set does 'null' belong to?


There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null is merely a special literal that can be of any reference type.


What is null?


As the JLS quote above says, in practice you can simply pretend that it's "merely a special literal that can be of any reference type".


In Java, null == null (this isn't always the case in other languages). Note also that by contract, it also has this special property (from java.lang.Object):


public boolean equals(Object obj)


For any non-null reference value x, x.equals(null) should return false. 


It is also the default value (for variables that have them) for all reference types:


How this is used varies. You can use it to enable what is called lazy initialization of fields, where a field would have its initial value of null until it's actually used, where it's replaced by the "real" value (which may be expensive to compute).


There are also other uses. Let's take a real example from java.lang.System:


public static Console console()


Returns: The system console, if any, otherwise null.


This is a very common use pattern: null is used to denote non-existence of an object.


Here's another usage example, this time from java.io.BufferedReader:


public String readLine() throws IOException


Returns: A String containing the contents of the line, not including any line-termination characters, or null if the end of the stream has been reached.


So here, readLine() would return instanceof String for each line, until it finally returns a null to signify the end. This allows you to process each line as follows:


One can design the API so that the termination condition doesn't depend on readLine() returning null, but one can see that this design has the benefit of making things concise. Note that there is no problem with empty lines, because an empty line "" != null.


Let's take another example, this time from java.util.Map<K,V>:


V get(Object key)


Returns the value to which the specified key is mapped, or null if this map contains no mapping for the key.


If this map permits null values, then a return value of null does not necessarily indicate that the map contains no mapping for the key; it's also possible that the map explicitly maps the key to null. The containsKey operation may be used to distinguish these two cases. 


Here we start to see how using null can complicate things. The first statement says that if the key isn't mapped, null is returned. The second statement says that even if the key is mapped, null can also be returned.


In contrast, java.util.Hashtable keeps things simpler by not permitting null keys and values; its V get(Object key), if returns null, unambiguously means that the key isn't mapped.


You can read through the rest of the APIs and find where and how null is used. Do keep in mind that they aren't always the best practice examples.


Generally speaking, null are used as a special value to signify:


How is it represented in the memory?


In Java? None of your concern. And it's best kept that way.


This is now borderline subjective. Some people say that null causes many programmer errors that could've been avoided. Some say that in a language that catches NullPointerException like Java, it's good to use it because you will fail-fast on programmer errors. Some people avoid null by using Null object pattern, etc.


This is a huge topic on its own, so it's best discussed as answer to another question.


I will end this with a quote from the inventor of null himself, C.A.R Hoare (of quicksort fame):


I call it my billion-dollar mistake. It was the invention of the null reference in 1965. At that time, I was designing the first comprehensive type system for references in an object oriented language (ALGOL W). My goal was to ensure that all use of references should be absolutely safe, with checking performed automatically by the compiler. But I couldn't resist the temptation to put in a null reference, simply because it was so easy to implement. This has led to innumerable errors, vulnerabilities, and system crashes, which have probably caused a billion dollars of pain and damage in the last forty years.


The video of this presentation goes deeper; it's a recommended watch.


Is null an instance of anything? 


No.  That is why null instanceof X will return false for all classes X.  (Don't be fooled by the fact that you can assign null to a variable whose type is an object type.  Strictly speaking, the assignment involves an implicit type conversion; see below.)


What set does 'null' belong to?


It is the one and only member of the null type, where the null type is defined as follows:


"There is also a special null type, the type of the expression null, which has no name. Because the null type has no name, it is impossible to declare a variable of the null type or to cast to the null type. The null reference is the only possible value of an expression of null type. The null reference can always be cast to any reference type. In practice, the programmer can ignore the null type and just pretend that null  is merely a special literal that can be of any reference type." JLS 4.1


What is null?


See above.  In some contexts, null is used to denote "no object" or "unknown" or "unavailable", but these meanings are application specific.


How is it represented in the memory?


That is implementation specific, and you won't be able to see the representation of null in a pure Java program.  (But null is represented as a zero machine address / pointer in most if not all Java implementations.)


What is null?


It is nothing.


Is null an instance of anything?


No as it is nothing It can't be instance of any thing.


What set does null belong to?


No any set


How is it represented in the memory?


If some reference points to it like:


In heap memory some space assigned to new created object. And o will point to that assigned space in memory.


Now o=null;


This means now o will not point to that memory space of object.


No it's not the instance of anything, instanceof will always be false.


The null keyword is a literal that represents a null reference, one that does not refer to any object. null is the default value of reference-type variables.


Also maybe have a look at 


null : Java Glossary


Null in Java(tm)


In C and C++, "NULL" is a constant defined in a header file, with a value like:


or:


or:


depending on the compiler and memory model options. NULL is not, strictly speaking, part of C/C++ itself.


In Java(tm), "null" is not a keyword, but a special literal of the null type. It can be cast to any reference type, but not to any primitive type such as int or boolean. The null literal doesn't necessarily have value zero. And it is impossible to cast to the null type or declare a variable of this type.


Null is not an instance of any class.


However, you can assign null to variables of any (object or array) type:


null is special value, it is not instance of anything. For obviously reason it cannot be instanceof anything.


null is a special value that is not an instance of any class. This is illustrated by the following program:


Bytecode representation


null has direct JVM support: three instructions are used to implement it:


Chapter 6 "The Java Virtual Machine Instruction Set " then mentions the effects of null on other instructions: it throws a NullPointerException for many of them.


2.4. "Reference Types and Values" also mentions null in generic terms:


A reference value may also be the special null reference, a reference to no object, which will be denoted here by null. The null reference initially has no run-time type, but may be cast to any type. The default value of a reference type is null.


An interesting way to see null in java in my opinion is to see it as something that DOES NOT denote an absence of information but simply as a literal value that can be assigned to a reference of any type. If you think about it if it denoted absence of information then for a1==a2 to be true doesn't make sense (in case they were both assigned a value of null) as they could really could be pointing to ANY object (we simply don't know what objects they should be pointing to)... By the way null == null returns true in java. If java e.g. would be like SQL:1999 then null==null would return unknown (a boolean value in SQL:1999 can take three values : true,false and unknown but in practise unknown is implemented as null in real systems)... http://en.wikipedia.org/wiki/SQL


There are two major categories of types in Java: primitive and reference. Variables declared of a primitive type store values; variables declared of a reference type store references. 


In this case, the initialization statement declares a variables “x”. “x” stores String reference. It is null here. First of all, null is not a valid object instance, so there is no memory allocated for it. It is simply a value that indicates that the object reference is not currently referring to an object.


Short and precise answer which answers all your questions formally from JLS:


3.10.7. The Null Literal


The null type has one value, the null reference, represented by the
  null literal null, which is formed from ASCII characters. 


A null literal is always of the null type.


Only a reference of type which is assigned to null is allocated. You don't assign any value (object) to the reference. 
Such allocation is specific to JVM how much reference will take and in which memory area it will be allocated.


null in Java is like/similar to nullptr in C++.


Program in C++:


Same program in Java:


Now do you understand from the codes above what is null in Java? If no then I recommend you to learn pointers in C/C++ and then you will understand.


Note that in C, unlike C++, nullptr is undefined, but NULL is used instead, which can also be used in C++ too, but in C++ nullptr is more preferable than just NULL, because the NULL in C is always related to pointers and that's it, so in C++ the suffix "ptr" was appended to end of the word, and also all letters are now lowercase, but this is less important.


In Java every variable of type class non-primitive is always reference to object of that type or inherited and null is null class object reference, but not null pointer, because in Java there is no such a thing "pointer", but references to class objects are used instead, and null in Java is related to class object references, so you can also called it as "nullref" or "nullrefobj", but this is long, so just call it "null".


In C++ you can use pointers and the nullptr value for optional members/variables, i.e. member/variable that has no value and if it has no value then it equals to nullptr, so how null in Java can be used for example.






I have an array that is initialized like:


I would like to convert this array into an object of the ArrayList class.


Given:


The simplest answer is to do:


This will work fine.  But some caveats:


(old thread, but just 2 cents as none mention Guava or other libs and some other details)


It's worth pointing out the Guava way, which greatly simplifies these shenanigans:


Use the ImmutableList class and its of() and copyOf() factory methods (elements can't be null):


Use the Lists class and its newArrayList() factory methods:


Please also note the similar methods for other data structures in other classes, for instance in Sets.


The main attraction could be to reduce the clutter due to generics for type-safety, as the use of the Guava factory methods allow the types to be inferred most of the time. However, this argument holds less water since Java 7 arrived with the new diamond operator.


But it's not the only reason (and Java 7 isn't everywhere yet): the shorthand syntax is also very handy, and the methods initializers, as seen above, allow to write more expressive code. You do in one Guava call what takes 2 with the current Java Collections.


Use the JDK's Arrays class and its asList() factory method, wrapped with a Collections.unmodifiableList():


Note that the returned type for asList() is a List using a concrete ArrayList implementation, but it is NOT java.util.ArrayList. It's an inner type, which emulates an ArrayList but actually directly references the passed array and makes it "write through" (modifications are reflected in the array).


It forbids modifications through some of the List API's methods by way of simply extending an AbstractList (so, adding or removing elements is unsupported), however it allows calls to set() to override elements. Thus this list isn't truly immutable and a call to asList() should be wrapped with Collections.unmodifiableList().


See the next step if you need a mutable list.


Same as above, but wrapped with an actual java.util.ArrayList:


Since this question is pretty old, it surprises me that nobody suggested the simplest form yet:


As of Java 5, Arrays.asList() takes a varargs parameter and you don't have to construct the array explicitly.


Make sure that myArray is the same type as T. You'll get a compiler error if you try to create a List<Integer> from an array of int, for example.


Another way (although essentially equivalent to the new ArrayList(Arrays.asList(array)) solution performance-wise:


You probably just need a List, not an ArrayList.  In that case you can just do:


Another update, almost ending year 2014, you can do it with Java 8 too:


A few characters would be saved, if this could be just a List 


To convert an array to an ArrayList, developers often do this:


Arrays.asList() will return an ArrayList which is a private static class inside Arrays, it is not the java.util.ArrayList class. The java.util.Arrays.ArrayList class has set(), get(), contains() methods, but does not have any methods for adding elements, so its size is fixed. 
To create a real ArrayList, you must do:


The constructor of ArrayList can accept a Collection type, which is also a super type for java.util.Arrays.ArrayList


In Java 9, you can use List.of static factory method in order to create a List literal. Something like the following:


This would return an immutable list containing three elements. If you want a mutable list, pass that list to the ArrayList constructor:


JEP 269 provides some convenience factory methods for Collections API. This factory methods are not in current Java version, which is 8, but are planned for Java 9 release. You can try out this feature using JDK 9 Early Access.


If you use :


you may create and fill two lists ! Filling twice a big list is exactly what you don't want to do because it will create another Object[] array each time the capacity needs to be extended.


Fortunately the JDK implementation is fast and Arrays.asList(a[]) is very well done. It create a kind of ArrayList named Arrays.ArrayList where the Object[] data points directly to the array.


The dangerous side is that if you change the initial array, you change the List ! Are you sure you want that ? Maybe yes, maybe not.


If not, the most understandable way is to do this :


Or as said @glglgl, you can create another independant ArrayList with :


I love to use Collections, Arrays, or Guava. But if it don't fit, or you don't feel it, just write another inelegant line instead.


According with the question the answer using java 1.7 is:


However it's better always use the interface:


You can convert using different methods


List<Element> list = Arrays.asList(array);


List<Element> list = new ArrayList();
Collections.addAll(list, array);


Arraylist list = new Arraylist();
list.addAll(Arrays.asList(array));


For more detail you can refer to http://javarevisited.blogspot.in/2011/06/converting-array-to-arraylist-in-java.html


You also can do it with stream in Java 8.


In Java 9 you can use:


If we see the definition of Arrays.asList() method you will get something like this: 


So, you might initialize arraylist like this: 


Note : each new Element(int args) will be treated as Individual Object and can be passed as a var-args.


There might be another answer for this question too.
If you see declaration for java.util.Collections.addAll() method you will get something like this:


So, this code is also useful to do so


Since Java 8 there is easier way to transform:


Another simple way is to add all elements from the array to a new ArrayList using a for-each loop.


and the common newest way to create array is observableArrays


thus the answer is 


that is according to Oracle Docs


observableArrayList()
  Creates a new empty observable list that is backed by an arraylist.
  observableArrayList(E... items)
  Creates a new observable array list with items added to it.


Given:


Use:


Even though there are many perfectly written answers to this question, I will add my inputs. 


Say you have Element[] array = { new Element(1), new Element(2), new Element(3) };


New ArrayList can be created in the following ways


And they very well support all operations of ArrayList


But the following operations returns just a List view of an ArrayList and not actual ArrayList.


Therefore, they will give error when trying to make some ArrayList operations


More on List representation of array link.


Simplest way to do so is by adding following code. Tried and Tested.


Another Java8 solution (I may have missed the answer among the large set. If so, my apologies). This creates an ArrayList (as opposed to a List) i.e. one can delete elements


Output is... 
Hello 
world


We can easily convert an array to ArrayList.
We use Collection interface's addAll() method for the purpose of copying content from one list to another. 


Already everyone has provided enough good answer for your problem. 
Now from the all suggestions, you need to decided which will fit your requirement. There are two types of collection which you need to know. One is unmodified collection and other one collection which will allow you to modify the object later.


So, Here I will give short example for two use cases.


Immutable collection creation :: When you don't want to modify the collection object after creation


List<Element> elementList = Arrays.asList(array)


Mutable collection creation :: When you may want to modify the created collection object after creation.


List<Element> elementList = new ArrayList<Element>(Arrays.asList(array));


You can do it in java 8 as follows


You can create an ArrayList using Cactoos (I'm one of the developers):


There is no guarantee that the object will actually be of class ArrayList. If you need that guarantee, do this:


If the array is of a primitive type, the given answers won't work. But since Java 8 you can use:






What is an efficient way to implement a singleton pattern in Java?


Use an enum:


Joshua Bloch explained this approach in his Effective Java Reloaded talk at Google I/O 2008: link to video. Also see slides 30-32 of his presentation (effective_java_reloaded.pdf):


Edit: An online portion of "Effective Java" says: 


"This approach is functionally equivalent to the public field approach, except that it is more concise, provides the serialization machinery for free, and provides an ironclad guarantee against multiple instantiation, even in the face of sophisticated serialization or reflection attacks. While this approach has yet to be widely adopted, a single-element enum type is the best way to implement a singleton."


Depending on the usage, there are several "correct" answers.


Since java5 the best way to do it is to use an enum:


Pre java5, the most simple case is:


Let's go over the code. First, you want the class to be final. In this case, I've used the final keyword to let the users know it is final. Then you need to make the constructor private to prevent users to create their own Foo. Throwing an exception from the constructor prevents users to use reflection to create a second Foo. Then you create a private static final Foo field to hold the only instance, and a public static Foo getInstance() method to return it. The Java specification makes sure that the constructor is only called when the class is first used.


When you have a very large object or heavy construction code AND also have other accessible static methods or fields that might be used before an instance is needed, then and only then you need to use lazy initialization.


You can use a private static class to load the instance. The code would then look like:


Since the line private static final Foo INSTANCE = new Foo(); is only executed when the class FooLoader is actually used, this takes care of the lazy instantiation, and is it guaranteed to be thread safe.


When you also want to be able to serialize your object you need to make sure that deserialization won't create a copy.


The method readResolve() will make sure the only instance will be returned, even when the object was serialized in a previous run of your program.


The solution posted by Stu Thompson is valid in Java5.0 and later. But I would prefer not to use it because I think it is error prone.


It's easy to forget the volatile statement and difficult to understand why it is necessary. Without the volatile this code would not be thread safe anymore due to the double-checked locking antipattern. See more about this in paragraph 16.2.4 of Java Concurrency in Practice. In short: This pattern (prior to Java5.0 or without the volatile statement) could return a reference to the Bar object that is (still) in an incorrect state.


This pattern was invented for performance optimization. But this is really not a real concern anymore. The following lazy initialization code is fast and -more importantly- easier to read.


Disclaimer: I have just summarized all of the awesome answers and wrote it in my words.


While implementing Singleton we have 2 options
1. Lazy loading
2. Early loading


Lazy loading adds bit overhead(lots of to be honest) so use it only when you have a very large object or heavy construction code AND also have other accessible static methods or fields that might be used before an instance is needed, then and only then you need to use lazy initialization.Otherwise choosing early loading is a good choice.


Most simple way of implementing Singleton is 


Everything is good except its early loaded singleton. Lets try lazy loaded singleton


So far so good but our hero will not survive while fighting alone with multiple evil threads who want many many instance of our hero.
So lets protect it from evil multi threading


but it is not enough to protect out hero, Really!!! This is the best we can/should do to help our hero  


This is called "Double-Checked Locking idiom". It's easy to forget the volatile statement and difficult to understand why it is necessary.
For details :  http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html


Now we are sure about evil thread but what about the cruel serialization? We have to make sure even while de-serialiaztion no new object is created


The method readResolve() will make sure the only instance will be returned, even when the object was serialized in a previous run of our program.


Finally we have added enough protection  against threads and serialization but our code is looking bulky and ugly. Lets give our hero a make over


Yes this is our very same hero :)
Since the line private static final Foo INSTANCE = new Foo(); is only executed when the class FooLoader is actually used, this takes care of the lazy instantiation, 


and is it guaranteed to be thread safe.


And we have came so far, here is the best way to achieve everything we did is best possible way 


Which internally will be treated like  


That's it no more fear of serialization, threads and ugly code. Also ENUMS singleton are lazily initialized. 


This approach is functionally equivalent to the public field approach,
  except that it is more concise, provides the serialization machinery
  for free, and provides an  ironclad guarantee against multiple
  instantiation, even in the face of sophisticated serialization or
  reflection attacks. While this approach has yet to be widely  adopted,
  a single-element enum type is the best way to implement a singleton.


-Joshua Bloch in "Effective Java"      


Now you might have realized why ENUMS are considered as best way to implement Singleton and thanks for your patience :)
Updated it on my blog. 


Thread safe in Java 5+:


EDIT: Pay attention to the volatile modifier here.  :)  It is important because without it, other threads are not guaranteed by the JMM (Java Memory Model) to see changes to its value.  The synchronization does not take care of that--it only serializes access to that block of code.


EDIT 2: 
@Bno 's answer details the approach recommended by Bill Pugh (FindBugs) and is arguable better.  Go read and vote up his answer too.


Forget lazy initialization, it's too problematic. This is the simplest solution:


Make sure that you really need it. Do a google for "singleton anti-pattern" to see some arguments against it. There's nothing inherently wrong with it I suppose but it's just a mechanism for exposing some global resource/data so make sure that this is the best way. In particular I've found dependency injection more useful particularly if you are also using unit tests because DI allows you to use mocked resources for testing purposes.


Don't forget the Singleton is only a Singleton for the Classloader that loaded it. If you are using multiple loaders (Containers) each COULD have its own version of the Singleton.


I'm mystified by some of the answers that suggest DI as an alternative to using singletons; these are unrelated concepts. You can use DI to inject either singleton or non-singleton (e.g. per-thread) instances. At least this is true if you use Spring 2.x, I can't speak for other DI frameworks.


So my answer to the OP would be (in all but the most trivial sample code) to:


This approach gives you a nice decoupled (and therefore flexible and testable) architecture where whether to use a singleton is an easily reversible implementation detail (provided any singletons you use are threadsafe, of course).


Really consider why you need a singleton before writing it. There is a quasi-religious debate about using them which you can quite easily stumble over if you google singletons in Java.


Personally I try to avoid singletons as often as possible for many reasons, again most of which can be found by googling singletons. I feel that quite often singletons are abused because they're easy to understand by everybody, they're used as a mechanism for getting "global" data into an OO design and they are used because it is easy to circumvent object lifecycle management (or really thinking about how you can do A from inside B). Look at things like Inversion of Control (IoC) or Dependency Injection (DI) for a nice middleground.


If you really need one then wikipedia has a good example of a proper implementation of a singleton.


Following are 3 different approaches


1) Enum


2) Double checked Locking /Lazy loading


3) Static factory method


I use the Spring Framework to manage my singletons.  It doesn't enforce the "singleton-ness" of the class (which you can't really do anyway if there are multiple class loaders involved) but provides a really easy way to build and configure different factories for creating different types of objects.


Version 1:


Lazy loading, thread safe with blocking, low performance because of synchronized.


Version 2:


Lazy loading, thread safe with non-blocking, high performance.


Wikipedia has some examples of singletons, also in Java. The Java 5 implementation looks pretty complete, and is thread-safe (double-checked locking applied).


If you do not need lazy loading then simply try


If you want lazy loading and you want your Singleton to be thread-safe, try the double-checking pattern 


As the double checking pattern is not guaranteed to work (due to some issue with compilers, I don't know anything more about that.), you could also try to synchronize the whole getInstance-method or create a registry for all your Singletons. 


I would say Enum singleton 


Singleton using enum in Java is generally way to declare enum singleton. Enum singleton may contain instance variable and instance method. For simplicity's sake, also note that if you are using any instance method than you need to ensure thread safety of that method if at all it affect the state of object.


The use of an enum is very easy to implement and has no drawbacks regarding serializable objects, which have to be circumvented in the other ways.


You can access it by Singleton.INSTANCE, much easier than calling getInstance() method on Singleton.


1.12    Serialization of Enum Constants


Enum constants are serialized differently than ordinary serializable or externalizable objects. The serialized form of an enum constant consists solely of its name; field values of the constant are not present in the form. To serialize an enum constant, ObjectOutputStream writes the value returned by the enum constant's name method. To deserialize an enum constant, ObjectInputStream reads the constant name from the stream; the deserialized constant is then obtained by calling the java.lang.Enum.valueOf method, passing the constant's enum type along with the received constant name as arguments. Like other serializable or externalizable objects, enum constants can function as the targets of back references appearing subsequently in the serialization stream.


The process by which enum constants are serialized cannot be customized: any class-specific writeObject, readObject, readObjectNoData, writeReplace, and readResolve methods defined by enum types are ignored during serialization and deserialization. Similarly, any serialPersistentFields or serialVersionUID field declarations are also ignored--all enum types have a fixed serialVersionUID of 0L. Documenting serializable fields and data for enum types is unnecessary, since there is no variation in the type of data sent.


Quoted from Oracle docs


Another problem with conventional Singletons are that once you implement Serializable interface, they no longer remain Singleton because readObject() method always return a new instance  like constructor in Java. This can be avoided by using readResolve() and discarding newly created instance by replacing with singleton like below 


This can become even more complex if your Singleton Class maintain state, as you need to make them transient, but with in Enum Singleton, Serialization is guaranteed by JVM.


Good Read


You need double-checking idiom if you need to load the instance variable of a class lazily. 
If you need to load a static variable or a singleton lazily, you need initilization on demand holder idiom. 


In addition, if the singleton needs to be seriliazble, all other fields needs to be transient and readResolve() method needs to be implemented in order to maintain the singleton object invariant. Otherwise, each time the object is deserialized, a new instance of the object will be created. What readResolve() does is replace the new object read by readObject(), which forced that new object to be garbage collected as there is no variable referring to it.


Various ways to make singleton object:


As per Joshua Bloch - Enum would be the best.


you can use double check locking also.


Even inner static class can be used.


Enum singleton


The simplest way to implement a Singleton that is thread-safe is using an Enum


This code works since the introduction of Enum in Java 1.5


Double checked locking


If you want to code a “classic” singleton that works in a multithreaded environment (starting from Java 1.5) you should use this one.


This is not thread-safe before 1.5 because the implementation of the volatile keyword was different.


Early loading Singleton (works even before Java 1.5)


This implementation instantiates the singleton when the class is loaded and provides thread safety.


This is how to implement a simple singleton:


This is how to properly lazy create your singleton:


For JSE 5.0 and above take the Enum approach, otherwise use static singleton holder approach ( (a lazy loading approach described by Bill Pugh). Latter solution is also thread-safe without requiring special language constructs (i.e. volatile or synchronized).


Another argument often used against Singletons are their testability problems. Singletons are not easily mockable for testing purposes. If this turns out to be a problem, I like to make the following slight modification:


The added setInstance method allows setting a mockup implementation of the singleton class during testing:


This also works with early initialization approaches:


This has the drawback of exposing this functionality to the normal application too. Other developers working on that code could be tempted to use the ´setInstance´ method to alter alter a specific function and thus changing the whole application behaviour, therefore this method should contain at least a good warning in it's javadoc.


Still, for the possibility of mockup-testing (when needed), this code exposure may be an acceptable price to pay.


simplest singleton class


I still think after java 1.5, enum is the best available singleton implementation available as it also ensures that even in the multi threaded environments - only one instance is created.


public enum Singleton{
  INSTANCE;
}


and you are done !!!


Have a look at this post.


Examples of GoF Design Patterns in Java's core libraries


From the best answer's "Singleton" section,


You can also learn the example of Singleton from Java native classes themselves.


To achieve this ( TRUE Singleton) ,


Useful links: All answers in this post +


Singleton_pattern : Initialization-on-demand holder idiom from wikipedia


journaldev article


Demonstration of various methods of achieving Singleton


output:


Might be a little late to the game on this, but there is a lot of nuance around implementing a singleton. The holder pattern can not be used in many situations. And IMO when using a volatile - you should also use a local variable. Let's start at the beginning and iterate on the problem. You'll see what I mean.


The first attempt might look something like this:


Here we have the MySingleton class which has a private static member called INSTANCE, and a public static method called getInstance(). The first time getInstance() is called, the INSTANCE member is null. The flow will then fall into the creation condition and create a new instance of the MySingleton class. Subsequent calls to getInstance() will find that the INSTANCE variable is already set, and therefore not create another MySingleton instance. This ensures there is only one instance of MySingleton which is shared among all callers of getInstance().


But this implementation has a problem. Multi-threaded applications will have a race condition on the creation of the single instance. If multiple threads of execution hit the getInstance() method at (or around) the same time, they will each see the INSTANCE member as null. This will result in each thread creating a new MySingleton instance and subsequently setting the INSTANCE member.


Here we’ve used the synchronized keyword in the method signature to synchronize the getInstance() method. This will certainly fix our race condition. Threads will now block and enter the method one at a time. But it also creates a performance problem. Not only does this implementation synchronize the creation of the single instance, it synchronizes all calls to getInstance(), including reads. Reads do not need to be synchronized as they simply return the value of INSTANCE. Since reads will make up the bulk of our calls (remember, instantiation only happens on the first call), we will incur an unnecessary performance hit by synchronizing the entire method.


Here we’ve moved synchronization from the method signature, to a synchronized block that wraps the creation of the MySingleton instance. But does this solve our problem? Well, we are no longer blocking on reads, but we’ve also taken a step backward. Multiple threads will hit the getInstance() method at or around the same time and they will all see the INSTANCE member as null. They will then hit the synchronized block where one will obtain the lock and create the instance. When that thread exits the block, the other threads will contend for the lock, and one by one each thread will fall through the block and create a new instance of our class. So we are right back where we started.


Here we issue another check from INSIDE the block. If the INSTANCE member has already been set, we’ll skip initialization. This is called double-checked locking.


This solves our problem of multiple instantiation. But once again, our solution has presented another challenge. Other threads might not “see” that the INSTANCE member has been updated. This is because of how Java optimizes memory operations. Threads copy the original values of variables from main memory into the CPU’s cache. Changes to values are then written to, and read from, that cache. This is a feature of Java designed to optimize performance. But this creates a problem for our singleton implementation. A second thread — being processed by a different CPU or core, using a different cache — will not see the changes made by the first. This will cause the second thread to see the INSTANCE member as null forcing a new instance of our singleton to be created.


We solve this by using the volatile keyword on the declaration of the INSTANCE member. This will tell the compiler to always read from, and write to, main memory, and not the CPU cache.


But this simple change comes at a cost. Because we are bypassing the CPU cache, we will take a performance hit each time we operate on the volatile INSTANCE member — which we do 4 times. We double-check existence (1 and 2), set the value (3), and then return the value (4). One could argue that this path is the fringe case as we only create the instance during the first call of the method. Perhaps a performance hit on creation is tolerable. But even our main use-case, reads, will operate on the volatile member twice. Once to check existence, and again to return its value.


Since the performance hit is due to operating directly on the volatile member, let’s set a local variable to the value of the volatile and operate on the local variable instead. This will decrease the number of times we operate on the volatile, thereby reclaiming some of our lost performance. Note that we have to set our local variable again when we enter the synchronized block. This ensures it is up to date with any changes that occured while we were waiting for the lock.


I wrote an article about this recently. Deconstructing The Singleton. You can find more info on these examples and an example of the "holder" pattern there. There is also a real-world example showcasing the double-checked volatile approach. Hope this helps.


Sometimes a simple "static Foo foo = new Foo();" is not enough. Just think of some basic data insertion you want to do.


On the other hand you would have to synchronize any method that instantiates the singleton variable as such. Synchronisation is not bad as such, but it can lead to performance issues or locking (in very very rare situations using this example. The solution is


Now what happens? The class is loaded via the class loader. Directly after the class was interpreted from a byte Array, the VM executes the static { } - block. that's the whole secret: The static-block is only called once, the time the given class (name) of the given package is loaded by this one class loader.


As we have added the Synchronized keyword before getInstance, we have avoided the race condition in the case when two threads call the getInstance at the same time.






I want to package my project in a single executable JAR for distribution.


How can I make Maven package all dependency JARs into my JAR?


and you run it with


Compile goal should be added before assembly:single or otherwise the code on your own project is not included.


See more details in comments.


Commonly this goal is tied to a build phase to execute automatically. This ensures the JAR is built when executing mvn install or performing a deployment/release.


You can use the dependency-plugin to generate all dependencies in a separate directory before the package phase and then include that in the classpath of the manifest:


Alternatively use ${project.build.directory}/classes/lib as OutputDirectory to integrate all jar-files into the main jar, but then you will need to add custom classloading code to load the jars.


Taking Unanswered's answer and reformatting it, we have:


Next, I would recommend making this a natural part of your build, rather than something to call explicitly.  To make this a integral part of your build, add this plugin to your pom.xml and bind it to the package lifecycle event.  However, a gotcha is that you need to call the assembly:single goal if putting this in your pom.xml, while you would call 'assembly:assembly' if executing it manually from the command line.


I blogged about some different ways to do this.


See Executable Jar with Apache Maven (WordPress)


or executable-jar-with-maven-example (GitHub)


Those pros and cons are provided by Stephan.


At this point the jar is actually executable with external classpath elements.


The jar file is only executable with the sibling ...lib/ directory. We need to make archives to deploy with the directory and its content.



Now you have target/${project.build.finalName}.(zip|tar|tar.bz2|tar.gz) which each contains the jar and lib/*.


You have target/${project.bulid.finalName}-jar-with-dependencies.jar.


You have target/${project.build.finalName}-shaded.jar.


You have target/${project.bulid.finalName}-spring-boot.jar.


Use the maven-shade-plugin to package all dependencies into one uber-jar. It can also be used to build an executable jar by specifying the main class. After trying to use maven-assembly and maven-jar , I found that this plugin best suited my needs. 


I found this plugin particularly useful as it merges content of specific files instead of overwriting them. This is needed when there are resource files that are have the same name across the jars and the plugin tries to package all the resource files


See example below 


You can use maven-dependency-plugin, but the question was how to create an executable JAR. To do that requires the following alteration to Matthew Franglen's response (btw, using the dependency plugin takes longer to build when starting from a clean target):


Long used the maven assembly plugin, but I could not find a solution to the problem with "already added, skipping". Now, I'm using another plugin - onejar-maven-plugin. Example below (mvn package build jar):


You need to add repository for that plugin:


Another option if you really want to repackage the other JARs contents inside your single resultant JAR is the Maven Assembly plugin.  It unpacks and then repacks everything into a directory via <unpack>true</unpack>. Then you'd have a second pass that built it into one massive JAR.


Another option is the OneJar plugin.  This performs the above repackaging actions all in one step.


You can add the following to your pom.xml:


Afterwards you have to switch via the console to the directory, where the pom.xml is located. Then you have to execute mvn assembly:single and then your executable JAR file with dependencies will be hopefully build. You can check it when switching to the output (target) directory with cd ./target and starting your jar with a command similiar to java -jar mavenproject1-1.0-SNAPSHOT-jar-with-dependencies.jar. 


I tested this with Apache Maven 3.0.3.


You could combine the maven-shade-plugin and maven-jar-plugin.


Example POM configuration for maven-jar-plugin:


Finally create the executable jar by invoking:


Here's an executable jar plugin for Maven that we use at Credit Karma. It creates a jar of jars with a classloader capable of loading classes from nested jars.  This allows you to have the same classpath in dev and prod and still keep all classes in a single signed jar file.


https://github.com/creditkarma/maven-exec-jar-plugin


And here's a blog post with details about the plugin and why we made it: 
https://engineering.creditkarma.com/general-engineering/new-executable-jar-plugin-available-apache-maven/


Ken Liu has it right in my opinion. The maven dependency plugin allows you to expand all the dependencies, which you can then treat as resources. This allows you to include them in the main artifact. The use of the assembly plugin creates a secondary artifact which can be difficult to modify - in my case I wanted to add custom manifest entries. My pom ended up as:


I went through every one of these responses looking to make a fat executable jar containing all dependencies and none of them worked right.  The answer is the shade plugin, its very easy and straightforward.


Be aware that your dependencies need to have a scope of compile or runtime for this to work properly.


This example came from mkyong.com


it should be like that


unpacking have to be in generate-resources phase because, if in package phase, will not be included as resources.
Try clean package and you'll see


Use onejar plugin to build it as one executable jar file which packages all the dependancy jars in it. That solved my problem which was similar to this. When assembly plugin was used, it unpacked all the dependancy jars into source folder and repackage them as a jar, it had over written all the similar implementations I had inside my code which were having the same class names. onejar is an easy solution in here.


Problem with locating shared assembly file with maven-assembly-plugin-2.2.1?


Try using descriptorId configuration parameter instead of descriptors/descriptor or descriptorRefs/descriptorRef parameters.


Neither of them do what you need: look for the file on classpath.
Of course you need adding the package where the shared assembly resides on maven-assembly-plugin's classpath (see below).
If you're using Maven 2.x (not Maven 3.x), you may need adding this dependency in top-most parent pom.xml in pluginManagement section.


See this for more details.


Class: org.apache.maven.plugin.assembly.io.DefaultAssemblyReader


Example:


I won't answer directly the question as other have already done that before, but I really wonder if it's a good idea to embed all the dependencies in the project's jar itself.


I see the point (ease of deployment / usage) but it depends of the use case of your poject (and there may be alternatives (see below)).


If you use it fully standalone, why not.


But if you use your project in other contexts (like in a webapp, or dropped in a folder where other jars are sitting), you may have jar duplicates in your classpath (the ones in the folder, the one in the jars). Maybe not a bid deal but i usually avoid this.


A good alternative :


Like this, with in the end just a manifest and a "special dynamic classloader main", you can start your project with :


If you want if from command Line itself . Just run the below command from the project path 


mvn assembly:assembly


You can also use this plug-in, it is pretty good and I use it for packaging my jars http://sonatype.github.io/jarjar-maven-plugin/


Something that have worked for me was:


I had extraordinary case because my dependency was system one:


I have changed the code provided by @user189057 with changes:
1) maven-dependency-plugin is executed in "prepare-package" phase
2) I am extracting unpacked classess directly to "target/classes"


This is the best way i found:


With this configuration, all dependencies will be located in /dependency-jars. My application has no Main class, just context ones, but one of my dependencies do have a Main class (com.myDomain.etc.MainClassName) that starts the JMX server, and receives a start or a stop parameter. So with this i was able to start my application like this:


I wait it be useful for you all.


The maven-assembly-plugin worked great for me.
I spent hours with the maven-dependency-plugin and couldn't make it work. The main reason was that I had to define in the configuration section explicitly the artifact items which should be included as it is described in the documentation. 
There is an example there for the cases when you want to use it like: mvn dependency:copy, where there are not included any artifactItems but it doesn't work.


I tried the most up-voted answer here, and was able to get the jar runnable. But the program didn't run correctly. I do not know what the reason was. When I try to run from Eclipse, I get a different result but when I run the jar from command-line I get a different result (it crashes with a program-specific runtime error).


I had a similar requirement as the OP just that I had too many (Maven) dependencies for my project. Fortunately, the only solution that worked for me was that using Eclipse. Very simple and very straightforward. This is not a solution to the OP but is a solution for someone who has a similar requirement but with many Maven dependencies,


1) Just right-click on your project folder (in Eclipse) and select Export


2) Then select Java -> Runnable Jar


3) You will be asked to choose the location of the jar file


4) Finally, select the class that has the Main method that you want to run and choose Package dependencies with the Jar file and click Finish


This could also be an option,You will be able to build your jar file


I compared the tree plugins mentioned in this post. I generated 2 jars and a directory with all the jars. I compared the results and definitely the maven-shade-plugin is the best. My challenge was that I have multiple spring resources that needed to be merged, as well as jax-rs, and JDBC services. They were all merged properly by the shade plugin in comparison with the maven-assembly-plugin. In which case the spring will fail unless you copy them to your own resources folder and merge them manually one time. Both plugins output the correct dependency tree. I had multiple scopes like test,provide, compile, etc the test and provided were skipped by both plugins. They both produced the same manifest but I was able to consolidate licenses with the shade plugin using their transformer.
With the maven-dependency-plugin of course you don't have those problems because the jars are not extracted. But like some other have pointed you need to carry one extra file(s) to work properly.
Here is a snip of the pom.xml


To resolve this issue we will use Maven Assembly Plugin that will create the JAR together with its dependency JARs into a single executable JAR file. Just add below plugin configuration in your pom.xml file.


After doing this don’t forget to run MAVEN tool with this command mvn clean compile assembly:single


http://jkoder.com/maven-creating-a-jar-together-with-its-dependency-jars-into-a-single-executable-jar-file/


Add to pom.xml:


and


Thats it. Next mvn package will also create one fat jar additionally, including all dependency jars.


You can use maven-shade plugin to build a uber jar like below


This blog post shows another approach with combining the maven-jar and maven-assembly plugins. With the assembly configuration xml from the blog post it can also be controlled if dependencies will be expanded or just be collected in a folder and referenced by a classpath entry in the manifest:


The ideal solution is to include the jars in a lib folder and the manifest.mf file of the main jar include all the jars in classpath.


And exactly that one is described here: https://caffebig.wordpress.com/2013/04/05/executable-jar-file-with-dependent-jars-using-maven/


Okay, so this is my solution. I know it's not using the pom.xml file. But I had the problem my programmme compiling and running on Netbeans but it failing when I tried Java -jar MyJarFile.jar. Now, I don't fully understand Maven and I think this why was having trouble getting Netbeans 8.0.2 to include my jar file in a library to put them into a jar file. I was thinking about how I used to use jar files with no Maven in Eclipse. 


It's Maven that can compile all the dependanices and plugins. Not Netbeans. (If you can get Netbeans and be able to use java .jar to do this please tell me how (^.^)v )


[Solved - for Linux] by opening a terminal. 


Then


Next


Next


This will create jar file in the target directory.


Now


(You may need to run: chmod +x MyJarFile-1.0-jar-with-dependencies.jar)


And finally


Please see 


https://cwiki.apache.org/confluence/display/MAVEN/LifecyclePhaseNotFoundException


I'll post this solution in on a couple of other pages with a similar problem. Hopefully I can save somebody from a week of frustration.






My question is about one particular usage of static keyword. It is possible to use static keyword to cover a code block within a class which does not belong to any function. For example following code compiles:


If you remove the static keyword it complains because the variable a is final. However it is possible to remove both final and static keywords and make it compile. 


It is confusing for me in both ways. How am I supposed to have a code section that does not belong to any method? How is it possible to invoke it? In general, what is the purpose of this usage? Or better, where can I find documentation about this?


The code block with the static modifier signifies a class initializer; without the static modifier the code block is an instance initializer.  


Class initializers are executed in the order they are defined (top down, just like simple variable initializers) when the class is loaded (actually, when it's resolved, but that's a technicality).


Instance initializers are executed in the order defined when the class is instantiated, immediately before the constructor code is executed, immediately after the invocation of the super constructor.


If you remove static from int a, it becomes an instance variable, which you are not able to access from the static initializer block. This will fail to compile with the error "non-static variable a cannot be referenced from a static context".


If you also remove static from the initializer block, it then becomes an instance initializer and so int a is initialized at construction.


Uff! what is static initializer?


The static initializer is a static {} block of code inside java class, and run only one time before the constructor or main method is called.


OK! Tell me more...


Hmm where can I use it?


Can be used anywhere you feel ok :) that simple. But I see most of the time it is used when doing database connection, API init, Logging and etc.


Don't just bark! where is example?


Output???


Inside Static Initializer.


Apple


Orange


Pear


End Static Initializer.


Inside Main Method.


Hope this helps!


The static block is a "static initializer".


It's automatically invoked when the class is loaded, and there's no other way to invoke it (except maybe via Reflection?).


I've personally only ever used it when writing JNI code:


This is directly from http://www.programcreek.com/2011/10/java-class-instance-initializers/


Look at the following class, do you know which one gets executed first?


Output:


static initializer called


instance initializer called


constructor called


instance initializer called


constructor called


The instance initializer above contains a println statement. To understand how it works, we can treat it as a variable assignment statement, e.g., b = 0. This can make it more obvious to understand.


Instead of


int b = 0, you could write


Therefore, instance initializers and instance variable initializers are pretty much the same.


The use of instance initializers are rare, but still it can be a useful alternative to instance variable initializers if:


(1) initializer code must handle exceptions
(2) perform calculations that can’t be expressed with an instance variable initializer.


Of course, such code could be written in constructors. But if a class had multiple constructors, you would have to repeat the code in each constructor.


With an instance initializer, you can just write the code once, and it will be executed no matter what constructor is used to create the object. (I guess this is just a concept, and it is not used often.)


Another case in which instance initializers are useful is anonymous inner classes, which can’t declare any constructors at all. (Will this be a good place to place a logging function?)


Thanks to Derhein.


Also note that Anonymous classes that implement interfaces [1] have no constructors. Therefore instance initializers are neede to execute any kinds of expressions at construction time.


"final" guarantees that a variable must be initialized before end of object initializer code. Likewise "static final" guarantees that a variable will be initialized by the end of class initialization code. Omitting the "static" from your initialization code turns it into object initialization code; thus your variable no longer satisfies its guarantees.


You will not write code into a static block that needs to be invoked anywhere in your program. If the purpose of the code is to be invoked then you must place it in a method.


You can write static initializer blocks to initialize static variables when the class is loaded but this code can be more complex..


A static initializer block looks like a method with no name, no arguments, and no return type.  Since you never call it it doesn't need a name.  The only time its called is when the virtual machine loads the class.


The static code block can be used to instantiate or initialize class variables (as opposed to object variables).  So declaring "a" static means that is only one shared by all Test objects, and the static code block initializes "a" only once, when the Test class is first loaded, no matter how many Test objects are created.


when a developer use an initializer block, the Java Compiler copies the initializer into each constructor of the current class.


Example:


the following code:


is equivalent to:


I hope my example is understood by developers.


A definition of static block from: Static keyword in java


A static block is a block of statements inside a java class which is executed when a class is first loaded into the JVM e.g. it is initialized the first time the class is referenced in the code.


Normally, static blocks are used for initializing static class variables, and they are different from constructors in that static blocks execute only once at the time of class loading and initialization by JVM while constructor is called every time a new instance of the class is created.


P.S: you can’t use instance variables or invoke instance methods inside the static block.


A typical example of using a static block is when you support retrieving an Enum instance by its value, to do that you define a hashmap as a static variable which maps each value to its corresponding Enum instance, the map is initialized and filled inside a static block before the Enum is ever used in the application.






This question already has an answer here:


This code separates a string into tokens and stores them in an array of strings, and then compares a variable with the first home ... why isn't it working?


Use the string.equals(Object other) function to compare strings, not the == operator.


The function checks the actual contents of the string, the == operator checks whether the references to the objects are equal.  Note that string constants are usually "interned" such that two constants with the same value can actually be compared with ==, but it's better not to rely on that.


NB: the compare is done on 'usuario' because that's guaranteed non-null in your code, although you should still check that you've actually got some tokens in the datos array otherwise you'll get an array-out-of-bounds exception.


Jorman is a successful businessman and has 2 houses. 





But others don't know that.


When you ask neighbours from either Madison or Burke streets, this is the only thing they can say:





Using the residence alone, it's tough to confirm that it's the same Jorman. Since they're 2 different addresses, it's just natural to assume that those are 2 different persons.


That's how the operator == behaves. So it will say that datos[0]==usuario is false, because it only compares the addresses.


What if we sent an investigator? We know that it's the same Jorman, but we need to prove it. Our detective will look closely at all physical aspects. With thorough inquiry, the agent will be able to conclude whether it's the same person or not. Let's see it happen in Java terms.


Here's the source code of String's equals() method:





It compares the Strings character by character, in order to come to a conclusion that they are indeed equal.


That's how the String equals method behaves. So datos[0].equals(usuario) will return true, because it performs a logical comparison.


It's good to notice that in some cases use of "==" operator can lead to the expected result, because the way how java handles strings - string literals are interned  (see String.intern()) during compilation - so when you write for example "hello world" in two classes and compare those strings with "==" you could get result: true, which is expected according to specification; when you compare same strings (if they have same value) when the first one is string literal (ie. defined through "i am string literal") and second is constructed during runtime ie. with "new" keyword like new String("i am string literal"), the == (equality) operator returns false, because both of them are different instances of the String class. 


Only right way is using .equals() -> datos[0].equals(usuario). == says only if two objects are the same instance of object (ie. have same memory address)


Update: 01.04.2013 I updated this post due comments below which are somehow right. Originally I declared that interning (String.intern) is side effect of JVM optimization. Although it certainly save memory resources (which was what i meant by "optimization") it is mainly feature of language


equals() function is a method of Object class which should be overridden by programmer. String class overrides it to check if two strings are equal i.e. in content and not reference. 


== operator checks if the references of both the objects are the same. 


Consider the programs


Here the abc and xyz, both refer to same String "Awesome". Hence the expression (abc == xyz) is true.


Here abc and xyz are two different strings with the same content "Hello World". Hence here the expression (abc == xyz) is false where as (abc.equals(xyz)) is true.


Hope you understood the difference between == and <Object>.equals() 


Thanks.


Instead of


use 


== compares the reference of the variable where .equals() compares the values which is what you want.


== tests for reference equality.


.equals() tests for value equality.


Consequently, if you actually want to test whether two strings have the same value you should use .equals() (except in a few situations where you can guarantee that two strings with the same value will be represented by the same object eg: String interning).


== is for testing whether two strings are the same Object.


It is important to note that == is much cheaper than equals() (a single pointer comparision instead of a loop), thus, in situations where it is applicable (i.e. you can guarantee that you are only dealing with interned strings) it can present an important performance improvement. However, these situations are rare.


Note that .equals() method belongs to Class Object(Super class of all classes). You need to override it as per you class requirement but for String it is already implemented and it checks whether two string have same value or not.


It will also work if you call intern() on the string before inserting it into the array.
Interned strings are reference-equal (==) if and only if they are value-equal (equals().)


Let's analyze the following Java, to understand the identity and equality of Strings:


When the first line of code String str1 = "Hello world." executes, a string \Hello world."
is created, and the variable str1 refers to it. Another string "Hello world." will not be created again when the next line of code executes because of optimization. The variable str2 also refers to the existing ""Hello world.".


The operator == checks identity of two objects (whether two variables refer to same object). Since str1 and str2 refer to same string in memory, they are identical to each other. The method equals checks equality of two objects (whether two objects have same content). Of course, the content of str1 and str2 are same.


When code String str3 = new String("Hello world.") executes, a new instance of string with content "Hello world." is created, and it is referred to by the variable str3. And then another instance of string with content "Hello world." is created again, and referred to by
str4. Since str3 and str4 refer to two different instances, they are not identical, but their
content are same.


Therefore, the output contains four lines:


You should use string equals to compare two strings for equality, not operator == which just compares the references.


== operator compares the reference of an object in java. You can use string's equals method .


The == operator is a simple comparison of values.
For object references the (values) are the (references). So x == y returns true if x and y reference the same object.


I know this is an old question but here's how I look at it (I find very useful):


Technical explanations


In Java, all variables are either primitive types or references.


(If you need to know what a reference is: "Object variables" are just pointers to objects. So with Object something = ..., something is really an address in memory (a number).)


== compares the exact values. So it compares if the primitive values are the same, or if the references (addresses) are the same. That's why == often doesn't work on Strings; Strings are objects, and doing == on two string variables just compares if the address is same in memory, as others have pointed out. .equals() calls the comparison method of objects, which will compare the actual objects pointed by the references. In the case of Strings, it compares each character to see if they're equal.


The interesting part:


So why does == sometimes return true for Strings? Note that Strings are immutable. In your code, if you do


Since strings are immutable (when you call .trim() or something, it produces a new string, not modifying the original object pointed to in memory), you don't really need two different String("hi") objects. If the compiler is smart, the bytecode will read to only generate one String("hi") object. So if you do 


right after, they're pointing to the same object, and will return true. But you rarely intend this. Instead, you're asking for user input, which is creating new strings at different parts of memory, etc. etc.


Note: If you do something like baz = new String(bar) the compiler may still figure out they're the same thing. But the main point is when the compiler sees literal strings, it can easily optimize same strings.


I don't know how it works in runtime, but I assume the JVM doesn't keep a list of "live strings" and check if a same string exists. (eg if you read a line of input twice, and the user enters the same input twice, it won't check if the second input string is the same as the first, and point them to the same memory). It'd save a bit of heap memory, but it's so negligible the overhead isn't worth it. Again, the point is it's easy for the compiler to optimize literal strings.


There you have it... a gritty explanation for == vs. .equals() and why it seems random.


@Melkhiah66 You can use equals method instead of '==' method to check the equality.
If you use intern() then it checks whether the object is in pool if present then returns
equal else unequal. equals method internally uses hashcode and gets you the required result.






If You are going to compare any assigned value of the string ie)primitive string, Both "==" and .equals will work, but for the new string object you should use only .equals, here "==" will not work


Example:


if(a == b)  and (a.equals(b)) will return true.


but


in this case if(a == b) will return false


so its better to use .equals operator....


The .equals() will check if the two strings have the same value and return the boolean value where as the == operator checks to see if the two strings are the same object.


Generally .equals is used for Object comparison, where you want to verify if two Objects have an identical value.


== for reference comparison (are the two Objects the same Object on the heap) & to check if the Object is null. It is also used to compare the values of primitive types.


Use Split rather than tokenizer,it will surely provide u exact output
for E.g:


After this I am sure you will get better results.....


Someone said on a post higher up that  == is used for int and for checking nulls.
It may also be used to check for Boolean operations and char types.


Be very careful though and double check that you are using a char and not a String.
for example 


for strings you would then check
This would be correct


but 


would be incorrect, you would need to do the following


a==b


Compares references, not values. The use of == with object references is generally limited to the following:


Comparing to see if a reference is null.


Comparing two enum values. This works because there is only one object for each enum constant.


You want to know if two references are to the same object


"a".equals("b")


Compares values for equality. Because this method is defined in the Object class, from which all other classes are derived, it's automatically defined for every class. However, it doesn't perform an intelligent comparison for most classes unless the class overrides it. It has been defined in a meaningful way for most Java core classes. If it's not defined for a (user) class, it behaves the same as ==.






I am relatively new to Java, and often find that I need to sort a Map<Key, Value> on the values. Since the values are not unique, I find myself converting the keySet into an array, and sorting that array through array sort with a custom comparator that sorts on the value associated with the key. Is there an easier way?


Here's a generic-friendly version you're free to use:


And an associated JUnit4 test so you don't have to take my word for it:


Java 7 Version


Java 8 Version. This will sort according to the value in ascending order; for descending order, it is just possible to uncomment the call to Collections.reverseOrder().


There is one more technique to sort HashMap by Values. Here, no Comparator is used. We do sort based on Keys, swap keys and values, sort based on values and again swap to get the finalMap, which is sorted HashMap based on Values.


This code can break in multiple ways. If you intend to use the code provided, be sure to read the comments as well to be aware of the implications. For example, values can no longer be retrieved by their key. (get always returns null.)


It seems much easier than all of the foregoing. Use a TreeMap as follows:


Output:


Three 1-line answers...


I would use Google Collections Guava to do this - if your values are Comparable then you can use


Which will create a function (object) for the map [that takes any of the keys as input, returning the respective value], and then apply natural (comparable) ordering to them [the values].


If they're not comparable, then you'll need to do something along the lines of


These may be applied to a TreeMap (as Ordering extends Comparator), or a LinkedHashMap after some sorting


NB: If you are going to use a TreeMap, remember that if a comparison == 0, then the item is already in the list (which will happen if you have multiple values that compare the same).  To alleviate this, you could add your key to the comparator like so (presuming that your keys and values are Comparable):


= Apply natural ordering to the value mapped by the key, and compound that with the natural ordering of the key


Note that this will still not work if your keys compare to 0, but this should be sufficient for most comparable items (as hashCode, equals and compareTo are often in sync...)


See Ordering.onResultOf() and Functions.forMap().


So now that we've got a comparator that does what we want, we need to get a result from it. 


Now this will most likely work work, but:


Point 1 is a bit of a deal-breaker for me; google collections is incredibly lazy (which is good: you can do pretty much every operation in an instant; the real work is done when you start using the result), and this requires copying a whole map!


Don't worry though; if you were obsessed enough with having a "live" map sorted in this manner, you could solve not one but both(!) of the above issues with something crazy like the following:


Note: This has changed significantly in June 2012 - the previous code could never work: an internal HashMap is required to lookup the values without creating an infinite loop between the TreeMap.get() -> compare() and compare() -> get()


When we put, we ensure that the hash map has the value for the comparator, and then put to the TreeSet for sorting. But before that we check the hash map to see that the key is not actually a duplicate. Also, the comparator that we create will also include the key so that duplicate values don't delete the non-duplicate keys (due to == comparison).
These 2 items are vital for ensuring the map contract is kept; if you think you don't want that, then you're almost at the point of reversing the map entirely (to Map<V,K>).


The constructor would need to be called as 


From http://www.programmersheaven.com/download/49349/download.aspx


Java 8 offers a new answer: convert the entries into a stream, and use the comparator combinators from Map.Entry:


This will let you consume the entries sorted in ascending order of value.  If you want descending value, simply reverse the comparator:


If the values are not comparable, you can pass an explicit comparator:


You can then proceed to use other stream operations to consume the data. For example, if you want the top 10 in a new map:


Or print to System.out:


Sorting the keys requires the Comparator to look up each value for each comparison. A more scalable solution would use the entrySet directly, since then the value would be immediately available for each comparison (although I haven't backed this up by numbers).


Here's a generic version of such a thing:


There are ways to lessen memory rotation for the above solution. The first ArrayList created could for instance be re-used as a return value; this would require suppression of some generics warnings, but it might be worth it for re-usable library code. Also,  the Comparator does not have to be re-allocated at every invocation.


Here's a more efficient albeit less appealing version:


Finally, if you need to continously access the sorted information (rather than just sorting it once in a while), you can use an additional multi map. Let me know if you need more details...


The commons-collections library contains a solution called TreeBidiMap. Or, you could have a look at the Google Collections API. It has TreeMultimap which you could use.


And if you don't want to use these framework... they come with source code.


With Java 8, you can use the streams api to do it in a significantly less verbose way:


I've looked at the given answers, but a lot of them are more complicated than needed or remove map elements when several keys have same value.


Here is a solution that I think fits better:


Note that the map is sorted from the highest value to the lowest.


To accomplish this with the new features in Java 8:


The entries are ordered by their values using the given comparator. Alternatively, if your values are mutually comparable, no explicit comparator is needed:


The returned list is a snapshot of the given map at the time this method is called, so neither will reflect subsequent changes to the other. For a live iterable view of the map:


The returned iterable creates a fresh snapshot of the given map each time it's iterated, so barring concurrent modification, it will always reflect the current state of the map.


Create customized comparator and use it while creating new TreeMap object.


Use the below code in your main func


Output:


While I agree that the constant need to sort a map is probably a smell, I think the following code is the easiest way to do it without using a different data structure.


}


And here is an embarrassingly incomplete unit test:


}


The result is a sorted list of Map.Entry objects, from which you can obtain the keys and values.


Use a generic comparator such as :


The answer voted for the most does not work when you have 2 items that equals.
the TreeMap leaves equal values out.


the exmaple:
unsorted map


results


So leaves out E!!


For me it worked fine to adjust the comparator, if it equals do not return 0 but -1.


in the example:


class ValueComparator implements Comparator {


Map base;
      public ValueComparator(Map base) {
          this.base = base;
      }


public int compare(Object a, Object b) {


}
    }


now it returns:


unsorted map:


results:


as a response to Aliens (2011 nov. 22):
I Am using this solution for a map of Integer Id's and names, but the idea is the same, so might be the code above is not correct (I will write it in a test and give you the correct code), this is the code for a Map sorting, based on the solution above:


and this is the test class (I just tested it, and this works for the Integer, String Map:


here is the code for the Comparator of a Map:


and this is the testcase for this:


of cource you can make this a lot more generic, but I just needed it for 1 case (the Map)


Instead of using Collections.sort as some do I'd suggest using Arrays.sort. Actually what Collections.sort does is something like this:


It just calls toArray on the list and then uses Arrays.sort. This way all the map entries will be copied three times: once from the map to the temporary list (be it a LinkedList or ArrayList), then to the temporary array and finally to the new map.


My solution ommits this one step as it does not create unnecessary LinkedList. Here is the code, generic-friendly and performance-optimal:


This is a variation of Anthony's answer, which doesn't work if there are duplicate values:


Note that it's rather up in the air how to handle nulls. 


One important advantage of this approach is that it actually returns a Map, unlike some of the other solutions offered here.


Major problem. If you use the first answer (Google takes you here), change the comparator to add an equal clause, otherwise you cannot get values from the sorted_map by keys:


There are a lot of answers for this question already, but none provided me what I was looking for, a map implementation that returns keys and entries sorted by the associated value, and maintains this property as keys and values are modified in the map. Two other questions ask for this specifically. 


I cooked up a generic friendly example that solves this use case. This implementation does not honor all of the contracts of the Map interface, such as reflecting value changes and removals in the sets return from keySet() and entrySet() in the original object. I felt such a solution would be too large to include in a Stack Overflow answer. If I manage to create a more complete implementation, perhaps I will post it to Github and then to it link in an updated version of this answer.


This is just too complicated. Maps were not supposed to do such job as sorting them by Value. The easiest way is to create your own Class so it fits your requirement.


In example lower you are supposed to add TreeMap a comparator at place where * is. But by java API it gives comparator only keys, not values. All of examples stated here is based on 2 Maps. One Hash and one new Tree. Which is odd.


The example:


So change the map into a set this way:


You will create class Results,


and the Comparator class:


This way you can easily add more dependencies.


And as the last point I'll add simple iterator:


Best Approach


Output


Based on @devinmoore code, a map sorting methods using generics and supporting both ascending and descending ordering.


Here is an OO solution (i.e., doesn't use static methods):


Hereby donated to the public domain.


Afaik the most cleaner way is utilizing collections to sort map on value:


Since TreeMap<> does not work for values that can be equal, I used this:


You might want to put list in a LinkedHashMap, but if you're only going to iterate over it right away, that's superfluous...


Some simple changes in order to have a sorted map with pairs that have duplicate values. In the compare method (class ValueComparator) when values are equal do not return 0 but return the result of comparing the 2 keys. Keys are distinct in a map so you succeed to keep duplicate values (which are sorted by keys by the way). So the above example could be modified like this:


For sure the solution of Stephen is really great, but for those who can't use Guava:


Here's my solution for sorting by value a map.
This solution handle the case where there are twice the same value etc...


The exec:
http://www.ideone.com/dq3Lu


The output:


Hope it will help some folks


I've merged the solutions of user157196 and Carter Page:


If you have duplicate keys and only a small set of data (<1000) and your code is not performance critical you can just do the following:


inputUnsortedMap is the input to the code.


The variable sortedOutputMap will contain the data in decending order when iterated over. To change order just change > to a < in the if statement.


Is not the fastest sort but does the job without any additional dependencies.


You can try Guava's multimaps:


As a result you get a map from original values to collections of keys that correspond to them. This approach can be used even if there are multiple keys for the same value.


Depending on the context, using java.util.LinkedHashMap<T> which rememebers the order in which items are placed into the map.  Otherwise, if you need to sort values based on their natural ordering, I would recommend maintaining a separate List which can be sorted via Collections.sort().






How do I read an entire InputStream into a byte array?


You can use Apache Commons IO to handle this and similar tasks.


The IOUtils type has a static method to read an InputStream and return a byte[].


Internally this creates a ByteArrayOutputStream and copies the bytes to the output, then calls toByteArray(). It handles large files by copying the bytes in blocks of 4KiB.


You need to read each byte from your InputStream and write it to a ByteArrayOutputStream.  You can then retrieve the underlying byte array by calling toByteArray(); e.g.


Finally, after twenty years, there’s a simple solution without the need for a 3rd party library, thanks to Java 9:


Note also the convenience methods readNBytes(byte[] b, int off, int len) and transferTo(OutputStream) addressing recurring needs.


If you happen to use google guava, it'll be as simple as :


Use vanilla Java's DataInputStream and its readFully Method (exists since at least Java 1.4):


There are some other flavors of this method, but I use this all the time for this use case.


Do you really need the image as a byte[]? What exactly do you expect in the byte[] - the complete content of an image file, encoded in whatever format the image file is in, or RGB pixel values?


Other answers here show you how to read a file into a byte[]. Your byte[] will contain the exact contents of the file, and you'd need to decode that to do anything with the image data.


Java's standard API for reading (and writing) images is the ImageIO API, which you can find in the package javax.imageio. You can read in an image from a file with just a single line of code:


This will give you a BufferedImage, not a byte[]. To get at the image data, you can call getRaster() on the BufferedImage. This will give you a Raster object, which has methods to access the pixel data (it has several getPixel() / getPixels() methods).


Lookup the API documentation for javax.imageio.ImageIO, java.awt.image.BufferedImage, java.awt.image.Raster etc.


ImageIO supports a number of image formats by default: JPEG, PNG, BMP, WBMP and GIF. It's possible to add support for more formats (you'd need a plug-in that implements the ImageIO service provider interface).


See also the following tutorial: Working with Images


If you don't want to use the Apache commons-io library, this snippet is taken from the sun.misc.IOUtils class. It's nearly twice as fast as the common implementation using ByteBuffers:


As always, also Spring framework (spring-core since 3.2.2) has something for you: StreamUtils.copyToByteArray()


@Adamski: You can avoid buffer entirely.


Code copied from http://www.exampledepot.com/egs/java.io/File2ByteArray.html (Yes, it is very verbose, but needs half the size of memory as the other solution.)


In-case someone is still looking for a solution without a dependency && If you have a file.


1) DataInputStream


2) ByteArrayOutputStream


3) RandomAccessFile


I know it's too late but here I think is cleaner solution that's more readable...


Java 9 will give you finally a nice method:


I tried to edit @numan's answer with a fix for writing garbage data but edit was rejected. While this short piece of code is nothing brilliant I can't see any other better answer. Here's what makes most sense to me:


btw ByteArrayOutputStream need not be closed. try/finally constructs omitted for readability


See the InputStream.available() documentation:


It is particularly important to realize that you must not use this
  method to size a container and assume that you can read the entirety
  of the stream without needing to resize the container. Such callers
  should probably write everything they read to a ByteArrayOutputStream
  and convert that to a byte array. Alternatively, if you're reading
  from a file, File.length returns the current length of the file
  (though assuming the file's length can't change may be incorrect,
  reading a file is inherently racy).


I use this.


This is my copy-paste version:


Java 7 and later:


Java 8 way (thanks to BufferedReader and Adam Bien)


Note that this solution wipes carriage return ('\r') and can be inappropriate.


Here is an optimized version, that tries to avoid copying data bytes as much as possible:


You're doing an extra copy if you use ByteArrayOutputStream. If you know the length of the stream before you start reading it (e.g. the InputStream is actually a FileInputStream, and you can call file.length() on the file, or the InputStream is a zipfile entry InputStream, and you can call zipEntry.length()), then it's far better to write directly into the byte[] array -- it uses half the memory, and saves time.


N.B. the last line above deals with files getting truncated while the stream is being read, if you need to handle that possibility, but if the file gets longer while the stream is being read, the contents in the byte[] array will not be lengthened to include the new file content, the array will simply be truncated to the old length inputStreamLength.


You can try Cactoos:


Below Codes


OR


The other case to get correct byte array via stream, after send request to server and waiting for the response.


This works for me,


readSourceContent()


encodeString()


Wrap it in a DataInputStream if that is off the table for some reason, just use read to hammer on it until it gives you a -1 or the entire block you asked for.






What's the advantage of using getters and setters - that only get and set - instead of simply using public fields for those variables?


If getters and setters are ever doing more than just the simple get/set, I can figure this one out very quickly, but I'm not 100% clear on how:


is any worse than:


Whereas the former takes a lot less boilerplate code.



Compiling the list up here at the top of what seemed winners to me, from the viewpoint of a Java web dev:


There are actually many good reasons to consider using accessors rather than directly exposing fields of a class - beyond just the argument of encapsulation and making future changes easier. 


Here are the some of the reasons I am aware of:


Because 2 weeks (months, years) from now when you realize that your setter needs to do more than just set the value, you'll also realize that the property has been used directly in 238 other classes :-)


A public field is not worse than a getter/setter pair that does nothing except returning the field and assigning to it. First, it's clear that (in most languages) there is no functional difference. Any difference must be in other factors, like maintainability or readability.


An oft-mentioned advantage of getter/setter pairs, isn't. There's this claim that you can change the implementation and your clients don't have to be recompiled. Supposedly, setters let you add functionality like validation later on and your clients don't even need to know about it. However, adding validation to a setter is a change to its preconditions, a violation of the previous contract, which was, quite simply, "you can put anything in here, and you can get that same thing later from the getter".


So, now that you broke the contract, changing every file in the codebase is something you should want to do, not avoid. If you avoid it you're making the assumption that all the code assumed the contract for those methods was different.


If that should not have been the contract, then the interface was allowing clients to put the object in invalid states. That's the exact opposite of encapsulation If that field could not really be set to anything from the start, why wasn't the validation there from the start?


This same argument applies to other supposed advantages of these pass-through getter/setter pairs: if you later decide to change the value being set, you're breaking the contract. If you override the default functionality in a derived class, in a way beyond a few harmless modifications (like logging or other non-observable behaviour), you're breaking the contract of the base class. That is a violation of the Liskov Substitutability Principle, which is seen as one of the tenets of OO.


If a class has these dumb getters and setters for every field, then it is a class that has no invariants whatsoever, no contract. Is that really object-oriented design? If all the class has is those getters and setters, it's just a dumb data holder, and dumb data holders should look like dumb data holders:


Adding pass-through getter/setter pairs to such a class adds no value. Other classes should provide meaningful operations, not just operations that fields already provide. That's how you can define and maintain useful invariants.


Client: "What can I do with an object of this class?"
Designer: "You can read and write several variables."
Client: "Oh... cool, I guess?"


There are reasons to use getters and setters, but if those reasons don't exist, making getter/setter pairs in the name of false encapsulation gods is not a good thing. Valid reasons to make getters or setters include the things often mentioned as the potential changes you can make later, like validation or different internal representations. Or maybe the value should be readable by clients but not writable (for example, reading the size of a dictionary), so a simple getter is a nice choice. But those reasons should be there when you make the choice, and not just as a potential thing you may want later. This is an instance of YAGNI (You Ain't Gonna Need It).


Lots of people talk about the advantages of getters and setters but I want to play devil's advocate. Right now I'm debugging a very large program where the programmers decided to make everything getters and setters. That might seem nice, but its a reverse-engineering nightmare.


Say you're looking through hundreds of lines of code and you come across this:


It's a beautifully simply piece of code until you realize its a setter. Now, you follow that setter and find that it also sets person.firstName, person.lastName, person.isHuman, person.hasReallyCommonFirstName, and calls person.update(), which sends a query out to the database, etc. Oh, that's where your memory leak was occurring.


Understanding a local piece of code at first glance is an important property of good readability that getters and setters tend to break. That is why I try to avoid them when I can, and minimize what they do when I use them.


There are many reasons. My favorite one is when you need to change the behavior or regulate what you can set on a variable. For instance, lets say you had a setSpeed(int speed) method. But you want that you can only set a maximum speed of 100. You would do something like:


Now what if EVERYWHERE in your code you were using the public field and then you realized you need the above requirement? Have fun hunting down every usage of the public field instead of just modifying your setter.


My 2 cents :)


One advantage of accessors and mutators is that you can perform validation.


For example, if foo was public, I could easily set it to null and then someone else could try to call a method on the object. But it's not there anymore! With a setFoo method, I could ensure that foo was never set to null.


Accessors and mutators also allow for encapsulation - if you aren't supposed to see the value once its set (perhaps it's set in the constructor and then used by methods, but never supposed to be changed), it will never been seen by anyone. But if you can allow other classes to see or change it, you can provide the proper accessor and/or mutator.


In a pure object-oriented world getters and setters is a terrible anti-pattern. Read this article: Getters/Setters. Evil. Period. In a nutshell, they encourage programmers to think about objects as of data structures, and this type of thinking is pure procedural (like in COBOL or C). In an object-oriented language there are no data structures, but only objects that expose behavior (not attributes/properties!)


You may find more about them in Section 3.5 of Elegant Objects (my book about object-oriented programming).


Depends on your language.  You've tagged this "object-oriented" rather than "Java", so I'd like to point out that ChssPly76's answer is language-dependent.  In Python, for instance, there is no reason to use getters and setters.  If you need to change the behavior, you can use a property, which wraps a getter and setter around basic attribute access.  Something like this:


Well i just want to add that even if sometimes they are necessary for the encapsulation and security of your variables/objects, if we want to code a real Object Oriented Program, then we need to STOP OVERUSING THE ACCESSORS, cause sometimes we depend a lot on them when is not really necessary and that makes almost the same as if we put the variables public.


Thanks, that really clarified my thinking. Now here is (almost) 10 (almost) good reasons NOT to use getters and setters:


The last three I'm just leaving (N/A or D/C)...


It can be useful for lazy-loading.  Say the object in question is stored in a database, and you don't want to go get it unless you need it.  If the object is retrieved by a getter, then the internal object can be null until somebody asks for it, then you can go get it on the first call to the getter.


I had a base page class in a project that was handed to me that was loading some data from a couple different web service calls, but the data in those web service calls wasn't always used in all child pages.  Web services, for all of the benefits, pioneer new definitions of "slow", so you don't want to make a web service call if you don't have to.


I moved from public fields to getters, and now the getters check the cache, and if it's not there call the web service.  So with a little wrapping, a lot of web service calls were prevented.


So the getter saves me from trying to figure out, on each child page, what I will need.  If I need it, I call the getter, and it goes to find it for me if I don't already have it.


I know it's a bit late, but I think there are some people who are interested in performace :)


I've done a little performance test. I wrote a class "NumberHolder" which, well, holds an Integer. You can either read that Integer by using the getter method
anInstance.getNumber() or by directly accessing the number by using anInstance.number. My programm reads the number 1,000,000,000 times, via both ways. That process is repeated five times and the time is printed. I've got the following result:


(Time 1 is the direct way, Time 2 is the getter)


You see, the getter is (almost) always a bit faster. Then I tried with different numbers of cycles. Instead of 1 million, I used 10 million and 0.1 million.
The results:


10 million cycles: 


With 10 million cycles, the times are almost the same.
Here are 100 thousand (0.1 million) cycles:


Also with different amounts of cycles, the getter is a little bit faster than the regular way. I hope this helped you! :)


By the way, I am a german seventh grade, using my own knowledge and Google Translator. So don't be so strict with my english ;)


I spent quite a while thinking this over for the Java case, and I believe the real reasons are:


In other words, the only way you can specify a field in an interface is by providing a method for writing a new value and a method for reading the current value.  


Those methods are the infamous getter and setter....


Don't use getters setters unless needed for your current delivery I.e. Don't think too much about what would happen in the future, if any thing to be changed its a change request in most of the production applications, systems.


Think simple, easy, add complexity when needed.


I would not take advantage of ignorance of business owners of deep technical know how just because I think it's correct or I like the approach.


I have massive system written without getters setters only with access modifiers and some methods to validate n perform biz logic. If you absolutely needed the. Use anything.


Getter and setter methods are public interfaces to access private class members.


The encapsulation mantra is to make fields private and methods public.


Getter Methods: We can get access to private variables.


Setter Methods: We can modify private fields.


Even though the getter and setter methods do not add new functionality, we can change our mind come back later to make that method


Anywhere a value can be used, a method that returns that value can be added. Instead of:


use





Suppose we need to store the details of this Person. This Person has the fields name, age and sex. Doing this involves creating methods for name, age and sex. Now if we need create another person, it becomes necessary to create the methods for name, age, sex all over again.


Instead of doing this, we can create a bean class(Person) with getter and setter methods.  So tomorrow we can just create objects of this Bean class(Person class) whenever we need to add a new person (see the figure). Thus we are reusing the fields and methods of bean class, which is much better.


One aspect I missed in the answers so far, the access specification:


EDIT: I answered this question because there are a bunch of people learning programming asking this, and most of the answers are very technically competent, but they're not as easy to understand if you're a newbie. We were all newbies, so I thought I'd try my hand at a more newbie friendly answer.


The two main ones are polymorphism, and validation. Even if it's just a stupid data structure.


Let's say we have this simple class:


A very simple class that holds how much liquid is in it, and what its capacity is (in milliliters).


What happens when I do:


Well, you wouldn't expect that to work, right?
You want there to be some kind of sanity check. And worse, what if I never specified the maximum capacity? Oh dear, we have a problem.


But there's another problem too. What if bottles were just one type of container? What if we had several containers, all with capacities and amounts of liquid filled? If we could just make an interface, we could let the rest of our program accept that interface, and bottles, jerrycans and all sorts of stuff would just work interchangably. Wouldn't that be better? Since interfaces demand methods, this is also a good thing.


We'd end up with something like:


Great! And now we just change Bottle to this:


I'll leave the definition ofthe BottleOverflowException as an exercise to the reader.


Now notice how much more robust this is. We can deal with any type of container in our code now by accepting LiquidContainer instead of Bottle. And how these bottles deal with this sort of stuff can all differ. You can have bottles that writer their state to disk when it changes, or bottles that save on SQL databases or GNU knows what else.


And all these can have different ways to handle various whoopsies. The Bottle just checks and if it's overflowing it throws a RuntimeException. But that might be the wrong thing to do. 
(There is a useful discussion to be had about error handling, but I'm keeping it very simple here on purpose. People in comments will likely point out the flaws of this simplistic approach. ;) )


And yes, it seems like we go from a very simple idea to getting much better answers quickly.


There's also the third thing that not everyone has addressed: Getters and setters use method calls. That means that they look like normal methods everywhere else does. Instead of having weird specific syntax for DTOs and stuff, you have the same thing everywhere.


One of the basic principals of OO design: Encapsulation!


It gives you many benefits, one of which being that you can change the implementation of the getter/setter behind the scenes but any consumer of that value will continue to work as long as the data type remains the same.


In languages which don't support "properties" (C++, Java) or require recompilation of clients when changing fields to properties (C#), using get/set methods is easier to modify. For example, adding validation logic to a setFoo method will not require changing the public interface of a class.


In languages which support "real" properties (Python, Ruby, maybe Smalltalk?) there is no point to get/set methods.


From a object orientation design standpoint both alternatives can be damaging to the maintenance of the code by weakening the encapsulation of the classes. For a discussion you can look into this excellent article: http://typicalprogrammer.com/?p=23 


Getter and setter methods are accessor methods, meaning that they are generally a public interface to change private class members. You use getter and setter methods to define a property. You access getter and setter methods as properties outside the class, even though you define them within the class as methods. Those properties outside the class can have a different name from the property name in the class.


There are some advantages to using getter and setter methods, such as the ability to let you create members with sophisticated functionality that you can access like properties. They also let you create read-only and write-only properties.


Even though getter and setter methods are useful, you should be careful not to overuse them because, among other issues, they can make code maintenance more difficult in certain situations. Also, they provide access to your class implementation, like public members. OOP practice discourages direct access to properties within a class.


When you write classes, you are always encouraged to make as many as possible of your instance variables private and add getter and setter methods accordingly. This is because there are several times when you may not want to let users change certain variables within your classes. For example, if you have a private static method that tracks the number of instances created for a specific class, you don't want a user to modify that counter using code. Only the constructor statement should increment that variable whenever it's called. In this situation, you might create a private instance variable and allow a getter method only for the counter variable, which means users are able to retrieve the current value only by using the getter method, and they won't be able to set new values using the setter method. Creating a getter without a setter is a simple way of making certain variables in your class read-only.


Code evolves.  private is great for when you need data member protection.  Eventually all classes should be sort of "miniprograms" that have a well-defined interface that you can't just screw with the internals of.


That said, software development isn't about setting down that final version of the class as if you're pressing some cast iron statue on the first try.  While you're working with it, code is more like clay.  It evolves as you develop it and learn more about the problem domain you are solving.  During development classes may interact with each other than they should (dependency you plan to factor out), merge together, or split apart.  So I think the debate boils down to people not wanting to religiously write


So you have:


Instead of


Not only is getVar() visually noisy, it gives this illusion that gettingVar() is somehow a more complex process than it really is.  How you (as the class writer) regard the sanctity of var is particularly confusing to a user of your class if it has a passthru setter -- then it looks like you're putting up these gates to "protect" something you insist is valuable, (the sanctity of var) but yet even you concede var's protection isn't worth much by the ability for anyone to just come in and set var to whatever value they want, without you even peeking at what they are doing.


So I program as follows (assuming an "agile" type approach -- ie when I write code not knowing exactly what it will be doing/don't have time or experience to plan an elaborate waterfall style interface set):


1) Start with all public members for basic objects with data and behavior.  This is why in all my C++ "example" code you'll notice me using struct instead of class everywhere.


2) When an object's internal behavior for a data member becomes complex enough, (for example, it likes to keep an internal std::list in some kind of order), accessor type functions are written.  Because I'm programming by myself, I don't always set the member private right away, but somewhere down the evolution of the class the member will be "promoted" to either protected or private.


3) Classes that are fully fleshed out and have strict rules about their internals (ie they know exactly what they are doing, and you are not to "fuck" (technical term) with its internals) are given the class designation, default private members, and only a select few members are allowed to be public.


I find this approach allows me to avoid sitting there and religiously writing getter/setters when a lot of data members get migrated out, shifted around, etc. during the early stages of a class's evolution.


There is a good reason to consider using accessors is there is no property inheritance. See next example:


Output:


You should use getters and setters when:


So this is very rarely a general OO question; it's a language-specific question, with different answers for different languages (and different use cases).


From an OO theory point of view, getters and setters are useless. The interface of your class is what it does, not what its state is. (If not, you've written the wrong class.) In very simple cases, where what a class does is just, e.g., represent a point in rectangular coordinates,* the attributes are part of the interface; getters and setters just cloud that. But in anything but very simple cases, neither the attributes nor getters and setters are part of the interface.


Put another way: If you believe that consumers of your class shouldn't even know that you have a spam attribute, much less be able to change it willy-nilly, then giving them a set_spam method is the last thing you want to do.


* Even for that simple class, you may not necessarily want to allow setting the x and y values. If this is really a class, shouldn't it have methods like translate, rotate, etc.? If it's only a class because your language doesn't have records/structs/named tuples, then this isn't really a question of OO…


But nobody is ever doing general OO design. They're doing design, and implementation, in a specific language. And in some languages, getters and setters are far from useless.


If your language doesn't have properties, then the only way to represent something that's conceptually an attribute, but is actually computed, or validated, etc., is through getters and setters.


Even if your language does have properties, there may be cases where they're insufficient or inappropriate. For example, if you want to allow subclasses to control the semantics of an attribute, in languages without dynamic access, a subclass can't substitute a computed property for an attribute.


As for the "what if I want to change my implementation later?" question (which is repeated multiple times in different wording in both the OP's question and the accepted answer): If it really is a pure implementation change, and you started with an attribute, you can change it to a property without affecting the interface. Unless, of course, your language doesn't support that. So this is really just the same case again.


Also, it's important to follow the idioms of the language (or framework) you're using. If you write beautiful Ruby-style code in C#, any experienced C# developer other than you is going to have trouble reading it, and that's bad. Some languages have stronger cultures around their conventions than others.—and it may not be a coincidence that Java and Python, which are on opposite ends of the spectrum for how idiomatic getters are, happen to have two of the strongest cultures.


Beyond human readers, there will be libraries and tools that expect you to follow the conventions, and make your life harder if you don't. Hooking Interface Builder widgets to anything but ObjC properties, or using certain Java mocking libraries without getters, is just making your life more difficult. If the tools are important to you, don't fight them.


One other use (in languages that support properties) is that setters and getters can imply that an operation is non-trivial.  Typically, you want to avoid doing anything that's computationally expensive in a property.


Getters and setters are used to implement two of the fundamental aspects of Object Oriented Programming which are: 


Suppose we have an Employee class:


Here the implementation details of Full Name is hidden from the user and is not accessible directly to the user, unlike a public attribute.   


Additionally, this is to "future-proof" your class. In particular, changing from a field to a property is an ABI break, so if you do later decide that you need more logic than just "set/get the field", then you need to break ABI, which of course creates problems for anything else already compiled against your class.


In an object oriented language the methods, and their access modifiers, declare the interface for that object. Between the constructor and the accessor and mutator methods it is possible for the developer to control access to the internal state of an object. If the variables are simply declared public then there is no way to regulate that access.


I would just like to throw the idea of annotation : @getter and @setter. With @getter, you should be able to obj = class.field but not class.field = obj. With @setter, vice versa. With @getter and @setter you should be able to do both. This would preserve encapsulation and reduce the time by not calling trivial methods at runtime.


I can think of one reason why you wouldn't just want everything public.


For instance, variable you never intended to use outside of the class could be accessed, even irdirectly via chain variable access (i.e.  object.item.origin.x ).  


By having mostly everything private, and only the stuff you want to extend and possibly refer to in subclasses as protected, and generally only having static final objects as public, then you can control what other programmers and programs can use in the API and what it can access and what it can't by using setters and getters to access the stuff you want the program, or indeed possibly other programmers who just happen to use your code, can modify in your program.  






Here is a piece of C++ code that seems very peculiar. For some strange reason, sorting the data miraculously makes the code almost six times faster.


Initially, I thought this might be just a language or compiler anomaly. So I tried it in Java.


With a somewhat similar but less extreme result.


My first thought was that sorting brings the data into the cache, but then I thought how silly that is because the array was just generated.


You are a victim of branch prediction fail.


Consider a railroad junction:



Image by Mecanismo, via Wikimedia Commons. Used under the CC-By-SA 3.0 license.


Now for the sake of argument, suppose this is back in the 1800s - before long distance or radio communication.


You are the operator of a junction and you hear a train coming. You have no idea which way it is supposed to go. You stop the train to ask the driver which direction they want to go. And then you set the switch appropriately.


Trains are heavy and have a lot of inertia. So they take forever to start up and slow down.


Is there a better way? You guess which direction the train will go!


If you guess right every time, the train will never have to stop.
If you guess wrong too often, the train will spend a lot of time stopping, backing up, and restarting.


Consider an if-statement: At the processor level, it is a branch instruction:





You are a processor and you see a branch. You have no idea which way it will go. What do you do? You halt execution and wait until the previous instructions are complete. Then you continue down the correct path.


Modern processors are complicated and have long pipelines. So they take forever to "warm up" and "slow down".


Is there a better way? You guess which direction the branch will go!


If you guess right every time, the execution will never have to stop.
If you guess wrong too often, you spend a lot of time stalling, rolling back, and restarting.


This is branch prediction. I admit it's not the best analogy since the train could just signal the direction with a flag. But in computers, the processor doesn't know which direction a branch will go until the last moment.


So how would you strategically guess to minimize the number of times that the train must back up and go down the other path? You look at the past history! If the train goes left 99% of the time, then you guess left. If it alternates, then you alternate your guesses. If it goes one way every 3 times, you guess the same...


In other words, you try to identify a pattern and follow it. This is more or less how branch predictors work.


Most applications have well-behaved branches. So modern branch predictors will typically achieve >90% hit rates. But when faced with unpredictable branches with no recognizable patterns, branch predictors are virtually useless.


Further reading: "Branch predictor" article on Wikipedia.


Notice that the data is evenly distributed between 0 and 255. 
When the data is sorted, roughly the first half of the iterations will not enter the if-statement. After that, they will all enter the if-statement.


This is very friendly to the branch predictor since the branch consecutively goes the same direction many times.
Even a simple saturating counter will correctly predict the branch except for the few iterations after it switches direction.


Quick visualization:


However, when the data is completely random, the branch predictor is rendered useless because it can't predict random data.
Thus there will probably be around 50% misprediction. (no better than random guessing)


So what can be done?


If the compiler isn't able to optimize the branch into a conditional move, you can try some hacks if you are willing to sacrifice readability for performance.


Replace:


with:


This eliminates the branch and replaces it with some bitwise operations.


(Note that this hack is not strictly equivalent to the original if-statement. But in this case, it's valid for all the input values of data[].)


Benchmarks: Core i7 920 @ 3.5 GHz


C++ - Visual Studio 2010 - x64 Release


Java - Netbeans 7.1.1 JDK 7 - x64


Observations:


A general rule of thumb is to avoid data-dependent branching in critical loops. (such as in this example)


Update:


GCC 4.6.1 with -O3 or -ftree-vectorize on x64 is able to generate a conditional move. So there is no difference between the sorted and unsorted data - both are fast.


VC++ 2010 is unable to generate conditional moves for this branch even under /Ox.


Intel Compiler 11 does something miraculous. It interchanges the two loops, thereby hoisting the unpredictable branch to the outer loop. So not only is it immune the mispredictions, it is also twice as fast as whatever VC++ and GCC can generate! In other words, ICC took advantage of the test-loop to defeat the benchmark...


If you give the Intel Compiler the branchless code, it just out-right vectorizes it... and is just as fast as with the branch (with the loop interchange).


This goes to show that even mature modern compilers can vary wildly in their ability to optimize code...


Branch prediction.


With a sorted array, the condition data[c] >= 128 is first false for a streak of values, then becomes true for all later values. That's easy to predict. With an unsorted array, you pay for the branching cost.


The reason why performance improves drastically when the data is sorted is that the branch prediction penalty is removed, as explained beautifully in Mysticial's answer.


Now, if we look at the code


we can find that the meaning of this particular if... else... branch is to add something when a condition is satisfied. This type of branch can be easily transformed into a conditional move statement, which would be compiled into a conditional move instruction: cmovl, in an x86 system. The branch and thus the potential branch prediction penalty is removed.


In C, thus C++, the statement, which would compile directly (without any optimization) into the conditional move instruction in x86, is the ternary operator ... ? ... : .... So we rewrite the above statement into an equivalent one:


While maintaining readability, we can check the speedup factor.


On an Intel Core i7-2600K @ 3.4 GHz and Visual Studio 2010 Release Mode, the benchmark is (format copied from Mysticial):


x86


x64


The result is robust in multiple tests. We get a great speedup when the branch result is unpredictable, but we suffer a little bit when it is predictable. In fact, when using a conditional move, the performance is the same regardless of the data pattern.


Now let's look more closely by investigating the x86 assembly they generate. For simplicity, we use two functions max1 and max2.


max1 uses the conditional branch if... else ...:


max2 uses the ternary operator ... ? ... : ...:


On a x86-64 machine, GCC -S generates the assembly below.


max2 uses much less code due to the usage of instruction cmovge. But the real gain is that max2 does not involve branch jumps, jmp, which would have a significant performance penalty if the predicted result is not right.


So why does a conditional move perform better?


In a typical x86 processor, the execution of an instruction is divided into several stages. Roughly, we have different hardware to deal with different stages. So we do not have to wait for one instruction to finish to start a new one. This is called pipelining.


In a branch case, the following instruction is determined by the preceding one, so we cannot do pipelining. We have to either wait or predict.


In a conditional move case, the execution conditional move instruction is divided into several stages, but the earlier stages like Fetch and Decode does not depend on the result of the previous instruction; only latter stages need the result. Thus, we wait a fraction of one instruction's execution time. This is why the conditional move version is slower than the branch when prediction is easy.


The book Computer Systems: A Programmer's Perspective, second edition explains this in detail. You can check Section 3.6.6 for Conditional Move Instructions, entire Chapter 4 for Processor Architecture, and Section 5.11.2 for a special treatment for Branch Prediction and Misprediction Penalties.


Sometimes, some modern compilers can optimize our code to assembly with better performance, sometimes some compilers can't (the code in question is using Visual Studio's native compiler). Knowing the performance difference between branch and conditional move when unpredictable can help us write code with better performance when the scenario gets so complex that the compiler can not optimize them automatically.


If you are curious about even more optimizations that can be done to this code, consider this:


Starting with the original loop:


With loop interchange, we can safely change this loop to:


Then, you can see that the if conditional is constant throughout the execution of the i loop, so you can hoist the if out:


Then, you see that the inner loop can be collapsed into one single expression, assuming the floating point model allows it (/fp:fast is thrown, for example)


That one is 100,000x faster than before 


No doubt some of us would be interested in ways of identifying code that is problematic for the CPU's branch-predictor. The Valgrind tool cachegrind has a branch-predictor simulator, enabled by using the --branch-sim=yes flag. Running it over the examples in this question, with the number of outer loops reduced to 10000 and compiled with g++, gives these results:


Sorted:


Unsorted:


Drilling down into the line-by-line output produced by cg_annotate we see for the loop in question:


Sorted:


Unsorted:


This lets you easily identify the problematic line - in the unsorted version the if (data[c] >= 128) line is causing 164,050,007 mispredicted conditional branches (Bcm) under cachegrind's branch-predictor model, whereas it's only causing 10,006 in the sorted version.


Alternatively, on Linux you can use the performance counters subsystem to accomplish the same task, but with native performance using CPU counters.


Sorted:


Unsorted:


It can also do source code annotation with dissassembly.


See the performance tutorial for more details.


Just read up on the thread and I feel an answer is missing. A common way to eliminate branch prediction that I've found to work particularly good in managed languages is a table lookup instead of using a branch. (although I haven't tested it in this case)


This approach works in general if:


Background and why


Pfew, so what the hell is that supposed to mean?


From a processor perspective, your memory is slow. To compensate for the difference in speed, they build in a couple of caches in your processor (L1/L2 cache) that compensate for that. So imagine that you're doing your nice calculations and figure out that you need a piece of memory. The processor will get his 'load' operation and loads the piece of memory into cache - and then uses the cache to do the rest of the calculations. Because memory is relatively slow, this 'load' will slow down your program. 


Like branch prediction, this was optimized in the Pentium processors: the processor predicts that it needs to load a piece of data and attempts to load that into the cache before the operation actually hits the cache. As we've already seen, branch prediction sometimes goes horribly wrong -- in the worst case scenario you need to go back and actually wait for a memory load, which will take forever (in other words: failing branch prediction is bad, a memory load after a branch prediction fail is just horrible!).


Fortunately for us, if the memory access pattern is predictable, the processor will load it in its fast cache and all is well.


First thing we need to know is what is small? While smaller is generally better, a rule of thumb is to stick to lookup tables that are <=4096 bytes in size. As an upper limit: if your lookup table is larger than 64K it's probably worth reconsidering.


Constructing a table


So we've figured out that we can create a small table. Next thing to do is get a lookup function in place. Lookup functions are usually small functions that use a couple of basic integer operations (and, or, xor, shift, add, remove and perhaps a multiply). What you want is to have your input translated by the lookup function to some kind of 'unique key' in your table, which then simply gives you the answer of all the work you wanted it to do.


In this case: >=128 means we can keep the value, <128 means we get rid of it. The easiest way to do that is by using an 'AND': if we keep it, we AND it with 7FFFFFFF ; if we want to get rid of it, we AND it with 0. Notice also that 128 is a power of 2 -- so we can go ahead and make a table of 32768/128 integers and fill it with one zero and a lot of 7FFFFFFFF's.


Managed languages


You might wonder why this works well in managed languages. After all, managed languages check the boundaries of the arrays with a branch to ensure you don't mess up...


Well, not exactly... :-)


There has been quite some work on eliminating this branch for managed languages. For example:


in this case it's obvious to the compiler that the boundary condition will never hit. At least the Microsoft JIT compiler (but I expect Java does similar things) will notice this and remove the check all together. WOW - that means no branch. Similarly, it will deal with other obvious cases.


If you run into trouble with lookups on managed languages - the key is to add a & 0x[something]FFF to your lookup function to make the boundary check predictable - and watch it going faster.


The result for this case


As data is distributed between 0 and 255 when array is sorted, around first half of the iterations will not enter the if-statement (if statement shared below).


Question is what make the above statement not execute in certain case as in case of sorted data? Here comes the "Branch predictor" a branch predictor is a digital circuit that tries to guess which way a branch (e.g. an if-then-else structure) will go before this is known for sure. The purpose of the branch predictor is to improve the flow in the instruction pipeline. Branch predictors play a critical role in achieving high effective performance!


Lets do some bench marking to understand it better


The performance of an if-statement depends on whether its condition has a predictable pattern. If the condition is always true or always false, the branch prediction logic in the processor will pick up the pattern. On the other hand, if the pattern is unpredictable, the if-statement will be much more expensive.


Let’s measure the performance of this loop with different conditions:


Here are the timings of the loop with different True-False patterns:


A “bad” true-false pattern can make an if-statement up to six times slower than a “good” pattern! Of course, which pattern is good and which is bad depends on the exact instructions generated by the compiler and on the specific processor.


So there is no doubt about impact of branch prediction on performance!


One way to avoid branch prediction errors is to build a lookup table, and index it using the data.  Stefan de Bruijn discussed that in his answer.


But in this case, we know values are in the range [0, 255] and we only care about values >= 128.  That means we can easily extract a single bit that will tell us whether we want a value or not: by shifting the data to the right 7 bits, we are left with a 0 bit or a 1 bit, and we only want to add the value when we have a 1 bit.  Let's call this bit the "decision bit".


By using the 0/1 value of the decision bit as an index into an array, we can make code that will be equally fast whether the data is sorted or not sorted.  Our code will always add a value, but when the decision bit is 0, we will add the value somewhere we don't care about.  Here's the code:


This code wastes half of the adds, but never has a branch prediction failure.  It's tremendously faster on random data than the version with an actual if statement.


But in my testing, an explicit lookup table was slightly faster than this, probably because indexing into a lookup table was slightly faster than bit shifting.  This shows how my code sets up and uses the lookup table (unimaginatively called lut for "LookUp Table" in the code).  Here's the C++ code:


In this case the lookup table was only 256 bytes, so it fit nicely in cache and all was fast.  This technique wouldn't work well if the data was 24-bit values and we only wanted half of them... the lookup table would be far too big to be practical.  On the other hand, we can combine the two techniques shown above: first shift the bits over, then index a lookup table.  For a 24-bit value that we only want the top half value, we could potentially shift the data right by 12 bits, and be left with a 12-bit value for a table index.  A 12-bit table index implies a table of 4096 values, which might be practical.


EDIT: One thing I forgot to put in.


The technique of indexing into an array, instead of using an if statement, can be used for deciding which pointer to use.  I saw a library that implemented binary trees, and instead of having two named pointers (pLeft and pRight or whatever) had a length-2 array of pointers, and used the "decision bit" technique to decide which one to follow.  For example, instead of:


this library would do something like:


Here's a link to this code: Red Black Trees, Eternally Confuzzled


In the sorted case, you can do better than relying on successful branch prediction or any branchless comparison trick: completely remove the branch.


Indeed, the array is partitioned in a contiguous zone with data < 128 and another with data >= 128. So you should find the partition point with a dichotomic search (using Lg(arraySize) = 15 comparisons), then do a straight accumulation from that point.


Something like (unchecked)


or, slightly more obfuscated


A yet faster approach, that gives an approximate solution for both sorted or unsorted is: sum= 3137536; (assuming a truly uniform distribution, 16384 samples with expected value 191.5) :-)


The above behavior is happening because of Branch prediction.


To understand branch prediction one must first understand Instruction Pipeline:


Any instruction is broken into sequence of steps so that different steps can be executed concurrently in parallel. This technique is known as instruction pipeline and this is used to increase throughput in modern processors. To understand this better please see this example on Wikipedia.


Generally modern processors have quite long pipelines, but for ease let's consider these 4 steps only.


4-stage pipeline in general for 2 instructions.



Moving back to the above question let's consider the following instructions:


Without branch prediction the following would occur:


To execute instruction B or instruction C the processor will have to wait till the instruction A doesn't reach till EX stage in the pipeline, as the decision to go to instruction B or instruction C depends on the result of instruction A. So the pipeline will look like this.


when if condition returns true:



When if condition returns false:



As a result of waiting for the result of instruction A, the total CPU cycles spent in the above case (without branch prediction; for both true and false) is 7.


So what is branch prediction?


Branch predictor will try to guess which way a branch (an if-then-else structure) will go before this is known for sure. It will not wait for the instruction A to reach the EX stage of the pipeline, but it will guess the decision and go onto that instruction (B or C in case of our example).


In case of a correct guess, the pipeline looks something like this:



If it is later detected that the guess was wrong then the partially executed instructions are discarded and the pipeline starts over with the correct branch, incurring a delay. 
The time that is wasted in case of a branch misprediction is equal to the number of stages in the pipeline from the fetch stage to the execute stage. Modern microprocessors tend to have quite long pipelines so that the misprediction delay is between 10 and 20 clock cycles. The longer the pipeline the greater the need for a good branch predictor.


In the OP's code, the first time when the conditional, the branch predictor does not have any information to base up prediction, so first time it will randomly choose the next instruction. Later in the for loop it can base the prediction on the history. 
For an array sorted in ascending order, there are three possibilities:


Let us assume that the predictor will always assume the true branch on the first run.


So in the first case it will always take the true branch since historically all its predictions are correct.
In the 2nd case, initially it will predict wrong, but after a few iterations it will predict correctly.
In the 3rd case it will initially predict correctly till the elements are less than 128. After which it will fail for some time and the correct itself when it see branch prediction failure in history. 


In all these cases the failure will be too less in number and as a result only few times it will need to discard the partially executed instructions and start over with the correct branch, resulting in less CPU cycles. 


But in case of random unsorted array, the prediction will need to discard the partially executed instructions and start over with the correct branch most of the time and result in more CPU cycles compared to the sorted array.


An official answer would be from


You can also see from this lovely diagram why the branch predictor gets confused.





Each element in the original code is a random value


so the predictor will change sides as the std::rand() blow.


On the other hand, once it's sorted, the predictor will first move into a state of strongly not taken and when the values change to the high value the predictor will in three runs through change all the way from strongly not taken to strongly taken.


In the same line (I think this was not highlighted by any answer) it's good to mention that sometimes (specially in software where the performance matters—like in the Linux kernel) you can find some if statements like the following:


or similarly:


Both likely() and unlikely() are in fact macros that are defined by using something like the GCC's __builtin_expect to help the compiler insert prediction code to favour the condition taking into account the information provided by the user. GCC supports other builtins that could change the behavior of the running program or emit low level instructions like clearing the cache, etc. See this documentation that goes through the available GCC's builtins.


Normally this kind of optimizations are mainly found in hard-real time applications or embedded systems where execution time matters and it's critical. For example, if you are checking for some error condition that only happens 1/10000000 times, then why not inform the compiler about this? This way, by default, the branch prediction would assume that the condition is false.


Frequently used Boolean operations in C++ produce many branches in compiled program. If these branches are inside loops and are hard to predict they can slow down execution significantly. Boolean variables are stored as 8-bit integers with the value 0 for false and 1 for true.


Boolean variables are overdetermined in the sense that all operators that have Boolean variables as input check if the inputs have any other value than 0 or 1, but operators that have Booleans as output can produce no other value than 0 or 1. This makes operations with Boolean variables as input less efficient than necessary.
Consider example:


This is typically implemented by the compiler in the following way:


This code is far from optimal. The branches may take a long time in case of mispredictions. The Boolean operations can be made much more efficient if it is known with certainty that the operands have no other values than 0 and 1. The reason why the compiler does not make such an assumption is that the variables might have other values if they are uninitialized or come from unknown sources. The above code can be optimized if a and b have been initialized to valid values or if they come from operators that produce Boolean output. The optimized code looks like this:


char is used instead of bool in order to make it possible to use the bitwise operators (& and |) instead of the Boolean operators (&& and ||). The bitwise operators are single instructions that take only one clock cycle. The OR operator (|) works even if a and b have other values than 0 or 1. The AND operator (&) and the EXCLUSIVE OR operator (^) may give inconsistent results if the operands have other values than 0 and 1.


~ can not be used for NOT. Instead, you can make a Boolean NOT on a variable which is known to be 0 or 1 by XOR'ing it with 1:


can be optimized to:


a && b cannot be replaced with a & b if b is an expression that should not be evaluated if a is false ( && will not evaluate b, & will). Likewise, a || b can not be replaced with a | b if b is an expression that should not be evaluated if a is true.


Using bitwise operators is more advantageous if the operands are variables than if the operands are comparisons:


is optimal in most cases (unless you expect the && expression to generate many branch mispredictions).


This question has already been answered excellently many times over. Still I'd like to draw the group's attention to yet another interesting analysis.


Recently this example (modified very slightly) was also used as a way to demonstrate how a piece of code can be profiled within the program itself on Windows. Along the way, the author also shows how to use the results to determine where the code is spending most of its time in both the sorted & unsorted case. Finally the piece also shows how to use a little known feature of the HAL (Hardware Abstraction Layer) to determine just how much branch misprediction is happening in the unsorted case.


The link is here:
http://www.geoffchappell.com/studies/windows/km/ntoskrnl/api/ex/profile/demo.htm


That's for sure!...


Branch Prediction makes the logic run slower because of the switching which happens in the code! It's like you going a straight street or a street with a lot of turnings, for sure the straight one gonna be done quicker!


If the array is sorted, your condition is false at the first step: data[c] >= 128, then becomes a true value for the whole way to the end of the street. That's how you get to the end of the logic faster. on the other hand, using unsorted array, you need alot of turning and processing which make your code run slower for sure...


Look at the image I created for you below, which street gonna be finished faster?





So programmatically, Branch Prediction causes the process be slower...


Also at the end, it's good to know we have 2 kinds of branch predictions that each gonna effects your code differently:


1. static


2. dynamic





Static branch prediction is used by the microprocessor the first time
  a conditional branch is encountered, and dynamic branch prediction is
  used for succeeding executions of the conditional branch code.


In order to effectively write your code to take advantage of these
  rules, when writing if-else or switch statements, check the most
  common cases first and work progressively down to the least common.
  Loops do not necessarily require any special ordering of code for
  static branch prediction, as only the condition of the loop iterator
  is normally used.


Branch-prediction gain!. It is important to understand, branch misprediction doesn't slow down programs. Cost of missed prediction is just as if branch prediction didn't exist and you waited for the evaluation of the expression to decide what code to run (further explanation in the next paragraph).


Whenever there's an if-else \ switch statement, the expression has to be evaluated to determine which block should be executed. In the assembly code generated by the compiler, conditional branch instructions are inserted. A branch instruction can cause a computer to begin executing a different instruction sequence and thus deviate from its default behavior of executing instructions in order (i.e. if the expression is false, the program skips the code of the if block) depending on some condition, which is the expression evaluation in our case.


That being said, the compiler tries to predict the outcome prior to it being actually evaluated. It will fetch instructions from the if block, if the expression turns out to be true, then wonderful! we gained the time it took to evaluate it and made progress in the code, if not then we are running the wrong code, the pipeline is flushed and the correct block is run. 


Visualization:
Lets say you need to pick route 1 or route 2. Waiting for your partner to check the map, you have stopped at ## and waited, or you could just pick route1 and if you were lucky (route 1 is the correct route), then great you didn't have to wait for your partner to check the map (you saved the time it would have taken him to check the map), otherwise you will just turn back. While flushing pipelines is super fast now-a-day taking this gamble is worthy. Predicting sorted data or a data that changes slowly is always easier and better than predicting fast changes. 


It's about branch prediction, what is it?


•Branch predictor is one of the ancient performance improving techniques which still finds 
relevance into modern architectures. While the simple prediction techniques provide fast 
lookup and power efficiency they suffer from high misprediction rate. 


•On the other hand, complex branch predictions –either neural based or variants of two-level branch prediction –provide better prediction accuracy but consume more power and complexity increases exponentially.


•In addition to this, in complex prediction techniques the time taken to predict the branches is itself very high –ranging from 2 to 5 cycles –which is comparable to the execution time of actual branches.   


•Branch prediction is essentially an optimization (minimization) problem where the emphasis is on to achieve lowest possible miss rate, low power consumption and low complexity with minimum resources. 


There really are three different kinds of branches: 


Forward conditional branches - based on a run-time condition, the PC (Program Counter) is changed to point to an address forward in the instruction stream. 


Backward conditional branches - the PC is changed to point backward in the instruction stream. The branch is based on some condition, such as branching backwards to the beginning of a program loop when a test at the end of the loop states the loop should be executed again. 


Unconditional branches - this includes jumps, procedure calls and returns that have no 
specific condition. For example, an unconditional jump instruction might be coded in assembly language as simply "jmp", and the instruction stream must immediately be directed to the target location pointed to by the jump instruction, whereas a conditional jump that might be coded as "jmpne" would redirect the instruction stream only if the result of a comparison of two values in a previous "compare" instructions shows the values to not be equal. (The segmented addressing scheme used by the x86 architecture adds extra complexity, since jumps can be either "near" (within a segment) or "far" (outside the segment). Each type has different effects on branch prediction algorithms.) 


Static/dynamic Branch Prediction : Static branch prediction is used by the microprocessor the first time a conditional branch is encountered, and dynamic branch prediction is used for succeeding executions of the conditional branch code.


Refrences:


https://en.wikipedia.org/wiki/Branch_predictor


http://www.geoffchappell.com/studies/windows/km/ntoskrnl/api/ex/profile/demo.htm


https://courses.cs.washington.edu/courses/csep548/06au/lectures/branchPred.pdf


https://web.njit.edu/~rlopes/Mod5.3.pdf






In Hidden Features of Java the top answer mentions Double Brace Initialization, with a very enticing syntax:


This idiom creates an anonymous inner class with just an instance initializer in it, which "can use any [...] methods in the containing scope".  


Main question: Is this as inefficient as it sounds?  Should its use be limited to one-off initializations?  (And of course showing off!)


Second question: The new HashSet must be the "this" used in the instance initializer ... can anyone shed light on the mechanism?  


Third question: Is this idiom too obscure to use in production code?


Summary: Very, very nice answers, thanks everyone. On question (3), people felt the syntax should be clear (though I'd recommend an occasional comment, especially if your code will pass on to developers who may not be familiar with it).  


On question (1), the generated code should run quickly. The extra .class files do cause jar file clutter, and slow program startup slightly (thanks to @coobird for measuring that). @Thilo pointed out that garbage collection can be affected, and the memory cost for the extra loaded classes may be a factor in some cases.  


Question (2) turned out to be most interesting to me. If I understand the answers, what's happening in DBI is that the anonymous inner class extends the class of the object being constructed by the new operator, and hence has a "this" value referencing the instance being constructed. Very neat.


Overall, DBI strikes me as something of an intellectual curiousity.  Coobird and others point out you can achieve the same effect with Arrays.asList, varargs methods, Google Collections, and the proposed Java 7 Collection literals.  Newer JVM languages like Scala, JRuby, and Groovy also offer concise notations for list construction, and interoperate well with Java.  Given that DBI clutters up the classpath, slows down class loading a bit, and makes the code a tad more obscure, I'd probably shy away from it. However, I plan to spring this on a friend who's just gotten his SCJP and loves good natured jousts about Java semantics!  ;-)  Thanks everyone!


7/2017: Baeldung has a good summary of double brace initialization and considers it an anti-pattern.


Here's the problem when I get too carried away with anonymous inner classes:


These are all classes which were generated when I was making a simple application, and used copious amounts of anonymous inner classes -- each class will be compiled into a separate class file.


The "double brace initialization", as already mentioned, is an anonymous inner class with a instance initialization block, which means that a new class is created for each "initialization", all for the purpose of usually making a single object.


Considering that the Java Virtual Machine will need to read all those classes when using them, that can lead to some time in the bytecode verfication process and such. Not to mention the increase in the needed disk space in order to store all those class files.


It seems as if there is a bit of overhead when utilizing double-brace initialization, so it's probably not such a good idea to go too overboard with it. But as Eddie has noted in the comments, it's not possible to be absolutely sure of the impact.


Just for reference, double brace initialization is the following:


It looks like a "hidden" feature of Java, but it is just a rewrite of:


So it's basically a instance initialization block that is part of an anonymous inner class.


Joshua Bloch's Collection Literals proposal for Project Coin was along the lines of:


Sadly, it didn't make its way into neither Java 7 nor 8 and was shelved indefinitely.


Experiment


Here's the simple experiment I've tested -- make 1000 ArrayLists with the elements "Hello" and "World!" added to them via the add method, using the two methods:


Method 1: Double Brace Initialization


Method 2: Instantiate an ArrayList and add


I created a simple program to write out a Java source file to perform 1000 initializations using the two methods:


Test 1:


Test 2:


Please note, that the elapsed time to initialize the 1000 ArrayLists and the 1000 anonymous inner classes extending ArrayList is checked using the System.currentTimeMillis, so the timer does not have a very high resolution. On my Windows system, the resolution is around 15-16 milliseconds.


The results for 10 runs of the two tests were the following:


As can be seen, the double brace initialization has a noticeable execution time of around 190 ms.


Meanwhile, the ArrayList initialization execution time came out to be 0 ms. Of course, the timer resolution should be taken into account, but it is likely to be under 15 ms.


So, there seems to be a noticeable difference in the execution time of the two methods. It does appear that there is indeed some overhead in the two initialization methods.


And yes, there were 1000 .class files generated by compiling the Test1 double brace initialization test program.


One property of this approach that has not been pointed out so far is that because you create inner classes, the whole containing class is captured in its scope. This means that as long as your Set is alive, it will retain a pointer to the containing instance (this$0) and keep that from being garbage-collected, which could be an issue.


This, and the fact that a new class gets created in the first place even though a regular HashSet would work just fine (or even better), makes me not want to use this construct (even though I really long for the syntactic sugar).


Second question: The new HashSet must be the "this" used in the instance initializer ... can anyone shed light on the mechanism? I'd have naively expected "this" to refer to the object initializing "flavors".


This is just how inner classes work. They get their own this, but they also have pointers to the parent instance, so that you can call methods on the containing object as well. In case of a naming conflict, the inner class (in your case HashSet) takes precedence, but you can prefix "this" with a classname to get the outer method as well.


To be clear on the anonymous subclass being created, you could define methods in there as well. For example override HashSet.add()


Taking the following test class:


and then decompiling the class file, I see:


This doesn't look terribly inefficient to me.  If I were worried about performance for something like this, I'd profile it.   And your question #2 is answered by the above code:  You're inside an implicit constructor (and instance initializer) for your inner class, so "this" refers to this inner class.


Yes, this syntax is obscure, but a comment can clarify obscure syntax usage.  To clarify the syntax, most people are familiar with a static initializer block (JLS 8.7 Static Initializers):


You can also use a similar syntax (without the word "static") for constructor usage (JLS 8.6 Instance Initializers), although I have never seen this used in production code.  This is much less commonly known.


If you don't have a default constructor, then the block of code between { and } is turned into a constructor by the compiler.  With this in mind, unravel the double brace code:


The block of code between the inner-most braces is turned into a constructor by the compiler.  The outer-most braces delimit the anonymous inner class.  To take this the final step of making everything non-anonymous:


For initialization purposes, I'd say there is no overhead whatsoever (or so small that it can be neglected).  However, every use of flavors will go not against HashSet but instead against MyHashSet.  There is probably a small (and quite possibly negligible) overhead to this.  But again, before I worried about it, I would profile it.


Again, to your question #2, the above code is the logical and explicit equivalent of double brace initialization, and it makes it obvious where "this" refers:  To the inner class that extends HashSet.


If you have questions about the details of instance initializers, check out the details in the JLS documentation.


leak prone


I've decided to chime in. The performance impact includes:  disk operation + unzip (for jar), class verification, perm-gen space (for Sun's Hotspot JVM). 
However, worst of all: it's leak prone. You can't simply return. 


So if the set escapes to any other part loaded by a different classloader and a reference is kept there, the entire tree of classes+classloader will be leaked. To avoid that, a copy to HashMap is necessary, new LinkedHashSet(new ArrayList(){{add("xxx);add("yyy");}}). Not so cute any more. 
I don't use the idiom, myself, instead it is like  new LinkedHashSet(Arrays.asList("xxx","YYY"));


Every time someone uses double brace initialisation, a kitten gets killed.


Apart from the syntax being rather unusual and not really idiomatic (taste is debatable, of course), you are unnecessarily creating two significant problems in your application, which I've just recently blogged about in more detail here.


Each time you use double brace initialisation a new class is made. E.g. this example:


... will produce these classes:


That's quite a bit of overhead for your classloader - for nothing! Of course it won't take much initialisation time if you do it once. But if you do this 20'000 times throughout your enterprise application... all that heap memory just for a bit of "syntax sugar"?


If you take the above code and return that map from a method, callers of that method might be unsuspectingly holding on to very heavy resources that cannot be garbage collected. Consider the following example:


The returned Map will now contain a reference to the enclosing instance of ReallyHeavyObject. You probably don't want to risk that:





Image from http://blog.jooq.org/2014/12/08/dont-be-clever-the-double-curly-braces-anti-pattern/


To answer your actual question, people have been using this syntax to pretend that Java has something like map literals, similar to the existing array literals:


Some people may find this syntactically stimulating.


Loading many classes can add some milliseconds to the start.  If the startup isn't so critical and you are look at the efficiency of classes after startup there is no difference.


prints


To create sets you can use a varargs factory method instead of double-brace initialisation:


The Google Collections library has lots of convenience methods like this, as well as loads of other useful functionality.    


As for the idiom's obscurity, I encounter it and use it in production code all the time. I'd be more concerned about programmers who get confused by the idiom being allowed to write production code.


Efficiency aside, I rarely find myself wishing for declarative collection creation outside of unit tests.  I do believe that the double brace syntax is very readable.


Another way to achieve the declarative construction of lists specifically is to use Arrays.asList(T ...) like so:


The limitation of this approach is of course that you cannot control the specific type of list to be generated.


There's generally nothing particularly inefficient about it. It doesn't generally matter to the JVM that you've made a subclass and added a constructor to it-- that's a normal, everyday thing to do in an object-oriented language. I can think of quite contrived cases where you could cause an inefficiency by doing this (e.g. you have a repeatedly-called method that ends up taking a mixture of different classes because of this subclass, whereas ordinary the class passed in would be totally predictable-- in the latter case, the JIT compiler could make optimisations that are not feasible in the first). But really, I think the cases where it'll matter are very contrived.


I'd see the issue more from the point of view of whether you want to "clutter things up" with lots of anonymous classes. As a rough guide, consider using the idiom no more than you'd use, say, anonymous classes for event handlers.


In (2), you're inside the constructor of an object, so "this" refers to the object you're constructing. That's no different to any other constructor.


As for (3), that really depends on who's maintaining your code, I guess. If you don't know this in advance, then a benchmark that I would suggest using is "do you see this in the source code to the JDK?" (in this case, I don't recall seeing many anonymous initialisers, and certainly not in cases where that's the only content of the anonymous class). In most moderately sized projects, I'd argue you're really going to need your programmers to understand the JDK source at some point or other, so any syntax or idiom used there is "fair game". Beyond that, I'd say, train people on that syntax if you have control of who's maintaining the code, else comment or avoid.


I was researching this and decided to do a more in depth test than the one provided by the valid answer.


Here is the code: https://gist.github.com/4368924


and this is my conclusion


I was surprised to find that in most of the run tests the internal initiation was actually faster (almost double in some cases). When working with large numbers the benefit seems to fade away. 


Interestingly, the case that creates 3 objects on the loop loses it's benefit rans out sooner than on the other cases. I am not sure why this is happening and more testing should be done to reach any conclusions. Creating concrete implementations may help to avoid the class definition to be reloaded (if that's what's happening)


However, it is clear that not much overhead it observed in most cases for the single item building, even with large numbers.


One set back would be the fact that each of the double brace initiations creates a new class file that adds a whole disk block to the size of our application (or about 1k when compressed). A small footprint, but if it's used in many places it could potentially have an impact. Use this 1000 times and you are potentially adding a whole MiB to you applicaiton, which may be concerning on an embedded environment.


My conclusion? It can be ok to use as long as it is not abused.


Let me know what you think :)


I second Nat's answer, except I would use a loop instead of creating and immediately tossing the implicit List from asList(elements):


While this syntax can be convenient, it also adds a lot of this$0 references as these become nested and it can be difficult to step debug into the initializers unless breakpoints are set on each one. For that reason, I only recommend using this for banal setters, especially set to constants, and places where anonymous subclasses don't matter (like no serialization involved).


Mario Gleichman describes how to use Java 1.5 generic functions to simulate Scala List literals, though sadly you wind up with immutable Lists.


He defines this class:


and uses it thusly:


Google Collections, now part of Guava supports a similar idea for list construction.  In this interview, Jared Levy says:


[...] the most heavily-used features, which appear in almost every Java class I write, are static methods that reduce the number of repetitive keystrokes in your Java code. It's so convenient being able to enter commands like the following:


Map<OneClassWithALongName, AnotherClassWithALongName> = Maps.newHashMap();


List<String> animals = Lists.immutableList("cat", "dog", "horse");


7/10/2014: If only it could be as simple as Python's:


animals = ['cat', 'dog', 'horse']


1) This will call add() for each member. If you can find a more efficient way to put items into a hash set, then use that. Note that the inner class will likely generate garbage, if you're sensitive about that.


2) It seems to me as if the context is the object returned by "new," which is the HashSet.


3) If you need to ask... More likely: will the people who come after you know this or not? Is it easy to understand and explain? If you can answer "yes" to both, feel free to use it.


There's no legitimate reason to use this "trick". Guava provides nice immutable collections that include both static factories and builders, allowing you to populate your collection where it's declared in a clean, readable, and safe syntax.


The example in the question becomes:


Not only is this shorter and easier to read, but it avoids the numerous issues with the double-braced pattern described in other answers. Sure, it performs similarly to a directly-constructed HashMap, but it's dangerous and error-prone, and there are better options.


Any time you find yourself considering double-braced initialization you should re-examine your APIs or introduce new ones to properly address the issue, rather than take advantage of syntactic tricks.






I updated Eclipse with the new SDK tools (rev. 23), but now when Eclipse starts I receive the error:


This Android SDK requires Android Developer Toolkit version 23.0.0 or above. Current version is 22.6.3.v201404151837-1123206. Please update ADT to the latest version.


No updates were found with "Check for updates". If I try "Install new software", I can see version 23, but I can't upgrade due to the following error:


After download of the last ADT from the web site, it seems there's another problem.


With SDK Tools rev. 23 proguard is not installed, the folder SDK dir/tools/proguard is missing, and other tools are missing. This version contains several bugs.


Google has released ADT v23.0.2. This solved many problems of previous ADT version 23.


Step-by-step:





Note: When I installed the new version of ADT, I didn't include the new version of "Android Native Development Tools" package. Instead, I installed the rest of packages first, and then installed "Android Native Development Tools". For a reason, if I try to install all the new packages including "Android Native Development Tools", the installation fails.


If there is no "Remediation page", the only way to remove the ADT plugin from Eclipse is to go to menu Help → About Eclipse → Installation Details and uninstall from there. But there is a risk of uninstalling Eclipse itself.


Google response:


This is a packaging bug. The entire proguard file is missing. We'll have an update asap, but until then just copy it over from a previous version of the tools:


and copy over the following files:


So at the end if you started from a new ADT copy by hand the files :)


Edit: with the latest ADT release, the bundle should now work with auto-update, so install these new versions:


Don't try to upgrade from previous version because it doesn’t work at all.
If you have got problems with zipalign, it's now under build-tools and no more under tools/ so you can do a symbolic link or just copy it into the expected folder.


None of the other answers worked for me using the ADT bundle published on developer.android.com. 


I ended up downloading the latest version of Eclipse (not the ADT bundle) and then installing the ADT plugin via menu Help → Install new software → entering https://dl-ssl.google.com/android/eclipse (mentioned by @RED_). 


I also had to update my workspace to point to my previous workspace, and most things seemed to be restored.


On a side note: This seems like a good time to migrate to Android Studio...


NOTE: Use this approach with caution because this might break your Eclipse installation (see comments).


This might help you if you installed the ADT plugin manually. But if you are using the version of Eclipse from the Eclipse ADT Bundle the below steps could break your Eclipse installation, and you may not be able to use Eclipse again!


Go to


Menu Help → About Eclipse SDK → Installation Details.


Now you will see all 22.0 versions and then click Uninstall button at bottom.


After uninstallation goto:


Menu Help → Install New Software → enter http://dl-ssl.google.com/android/eclipse/


Then install all the things, and now it is ready.


I was updating my build server today and came across the same issue. It has been reported here:
https://code.google.com/p/android/issues/detail?id=72419


The fix is in progress and the work around according to the project manager is:


Please wait for an updated version within a day or two. Until then, your workaround is to do download one of


http://dl.google.com/android/android-sdk_r22.6.2-linux.tgz


http://dl.google.com/android/android-sdk_r22.6.2-windows.zip


http://dl.google.com/android/android-sdk_r22.6.2-macosx.zip


and copy over the following files:


[edit]
zipalign was missing for me too, check to see if you need to copy this as well


It works for me :)


If for some reason you installed an ADT preview and need to revert back to the current stable, you can't use the dialog to install "new" software since what you want is actually an older one. Instead do this:





is what they are saying about this:


OK, guys, sorry about all this trouble, and we apologize for the messed up releases. Here's the summary:


You can do one of two options:


Install Eclipse from eclipse.org and install ADT by pointing to the update site: https://dl-ssl.google.com/android/eclipse


Download bundles from here:


Starting with ADT bundle 23.0.2, you should be able to update to future versions of ADT.


Source: https://code.google.com/p/android/issues/detail?id=72912


I have done following to resolve an issue.


Go to http://developer.android.com/sdk/installing/installing-adt.html and download the latest ADT ZIP file (at the bottom of page).


Go to Eclipse → menu Help → About Eclipse → Installation details


Delete Android DDM, Android Development Tools, Hierarchy Viewer, Native Development Tools, TraceView, etc., 22.X version.


Menu Help* → Install New Software → Add → Archive → *Select the downloaded ZIP file in step 1.


Select all the latest version of all 23 which I have deleted in step 3 and accept the license agreement.


Restart Eclipse, and it fixes my issue.


Only helped:


If you install a new Eclipse version it will work.
Here's what I did:


There is a lot of confusion going around in this thread. There are two solutions depending on how you installed ADT.


If you installed the ADT plugin manually then I believe you can use the "Delete ADT" -> "Install New Software" approach.


If you are using the ADT Bundle then do not follow that solution! You will break Eclipse. Here is an update from a Google member - read #18: 


https://code.google.com/p/android/issues/detail?id=72912


You must download a new version of the ADT-Bundle (yep, it's frustrating!).


DO NOT DO THIS


Warning: Please see the comments below this answer. These steps have had a negative impact for many people.


I hope it helps!





After trying the approaches in other answers without success, I just installed a new bundle from http://developer.android.com/sdk/installing/index.html?pkg=adt and that worked fine.


Do the following:


With these steps, you should't have to reconfigure everything, and you won't need to spend time troubleshooting this BUG on this upgrade from Google Developers.


Good luck! ;-)


You need to uninstall the old version and install 23


uninstall:
Help > about Eclipse SDK > Installation Details 
select Android related packages to uninstall


And then install V23.


There is no way to update an existing ADT bundle that you might have downloaded.


You can do one of two options:


Install Eclipse from eclipse.org and install ADT by pointing to the update site: https://dl-ssl.google.com/android/eclipse


Download bundles from:


Linux 64 bit VM: http://dl.google.com/android/adt/adt-bundle-linux-x86_64-20140702.zip


Linux 32 bit VM: http://dl.google.com/android/adt/adt-bundle-linux-x86-20140702.zip


Mac: http://dl.google.com/android/adt/adt-bundle-mac-x86_64-20140702.zip


Windows 32 bit: http://dl.google.com/android/adt/adt-bundle-windows-x86-20140702.zip


Windows 64 bit: http://dl.google.com/android/adt/adt-bundle-windows-x86_64-20140702.zip


Starting with ADT bundle 23.0.2, you should be able to update to future versions of ADT.


I was getting the same "conflicting dependency" error on Mac OS X 10.9.3 and simply upgrading was not an option.  What finally worked was downloading the latest Eclipse ADT bundle zip file from developer.android.com, extracting it and moving only "eclipse" folder to the place where my old eclipse folder was. (extracting the Eclipse ADT bundle zip file will give you "eclipse" and "sdk" folders).


If you decide to go the same route, first make sure you know what your Workspace path is. This can be found in Preferences.  Then rename your old "eclipse" directory (not Eclipse.app) to something like eclipse-22.6.3, then move extracted "eclipse" folder into its place. Run new Eclipse.app inside, and when it asks you about Workspace, just enter the same path as you noted above.  Or it can also be set later in Preferences.


Maybe worth adding is that to re-enable Android SDK Manager and Android Virtual Device Manager choose Window -> Customize Perspective -> Command Groups Availability and select Android SDK and AVD Manager. This will add these 2 items to the "Window" menu item for the current perspective (Java).


I didn't move the extracted "sdk" folder, because I already had sdk folder in the same directory as eclipse, which I have already updated to the latest Android tools. But if it makes you feel safer, you can also rename your old sdk folder (for backup purposes) and move the freshly extracted one into its place.


I faced the same problem and solved it. You need to uninstall the Android plugin entirely from within Eclipse (from the "about" section..), including trace view..


Then added the ADT Plugin again (https://dl-ssl.google.com/android/eclipse/) and install it.


The problem is solved!


I guess it's a bug with the SDK manager or ADT Plugin update mechanism...


How to update from 22.xx.x to 23.0.2 (my solution).  This will beat the dependency issues.


I was suffering from this issue for days, and I have tried every single solution on this link, but no luck. I finally figured out a solution that actually works!


Please note that this solution works in Windows 7 (64 bit). It should probably work for other Windows operating systems.


Here we go:


download the latest ADT bundle from


http://developer.android.com/sdk/index.html#download


unzip it and open "eclipse" folder --> "plugins" folder


Now go to your old eclipse and open "eclipse" folder --> "plugins" folder, and copy everything inside.


Now paste them into the "plugins" folder of the (NEW ECLIPSE), but DO NOT overwrite anything.


While inside of the "plugins" folder of your new Eclipse, do the search. Type in 22. (notice 22 with a dot) and hit enter.


The search result will show up all the files or folders with .....22.6...... For example,


Highlight all of these files/folders and hit delete key.


Make sure to update your old API/SDK to the latest version and load this sdk directory to work with your new eclipse.


or


You can watch this video, which shows you how to move all your SDK/API to your new SDK folder.


Link: https://www.youtube.com/watch?v=jPZpJdnbbN0


I have not tried to update from any other ADT versions, but I think it should work for any old ADT versions too.


Don't forget to backup stuff before attempting.


What I have just found is that you need to update your ADT plugin in your Eclipse (whether stand alone or ADT Bundle) before updating your build tool.


If your Eclipse installation points to the most recent Build Tool and your Eclipse is having ADT 22.x, it will show those errors.


What worked for me: (on Ubuntu 14.04 64-bit) 


You may not have an older copy of Eclipse and Build tools, in that case you can uninstall latest build tool from SDK Manager and install the older copy.
Once everything starts working fine, do the above steps.


I am trying to upload older copies of such bundles somewhere on the Internet, will update the links here, once I am done uploading.


I found these instructions in a comment.


Download the newest version of ADT and use your existing workspace.  This is actually the least pain-full upgrade you'll ever do.  It didn't mess with the .android folder so I still had my original debug key.  Only things missing were a couple of add ons I hardly ever use and they are easily installed into the new version.  


Note don't install into your existing adt folder create a new folder so you can still fall back if the new install doesn't work.


On ADT-bundled Eclipse I had to first uninstall the ADT and then do a fresh install.


To remove the ADT plugin from Eclipse:


For me it helped to delete Android 4.4W which is also API 20 and might be a cause for the conflict. So only install Android 4.4W or Android L until they fix it.


And (again this might only be for me) it only works in Android Studio not in Eclipse ...


I had to delete ADT and install it again.


However be warned, this caused me and one other person to have an annotations.jar missing errors in the Java Build path for certain projects, probably because it was trying to look for an old SDK, so upgrading projects is the next step I have to take.


The errors relate to libraries mostly, Google Play Services, Facebook SDK, ActionBarCompat.


For this step, you uninstall ADT, then put the URL back in to download them. The url is: https://dl-ssl.google.com/android/eclipse


I found a solution for the problem with "conflicting dependency". I don't have the same page of Daniel Díaz's response, but a page show "conflicting dependency", and I can't make anything.


The problem is that I'm not the owner of the file. Eclipse was installed in other session (on OS X). I have the right to read and write the Eclipse file, but I'm not the owner. Make a "chown" command on all Eclipse files to solve the problem. After, I have the same result as Daniel Diaz. 


I hope this helps someone.


WARNING


There is now an update for ADT 23.0.1, but the Windows and Linux scripts are messed up, so wait with the upgrade!


You could check for example tools/proguard/bin/*.sh in http://dl.google.com/android/android-sdk_r23.0.1-windows.zip.


I did this to solve the same issue (in OS X):


Hope it helps.


If Eclipse gives an error after uninstalling the ADT plugin from your Eclipse installation, try to edit file config.ini in the Eclipse folder → configuration. Find:


And change it to:


I hope it works for you too.


I simply went to my Android resources folder on my C:/ drive (C:/Android), deleted the 'eclipse' folder and all its contents. I downloaded Android Developer Tools once more and just moved over the 'eclipse' folder.


I started up and everything was fine; I had updated to version 23.


Hopefully this helps, possibly not suitable for everyone as some of you have Eclipse modifications but for someone who, like me, wanted a quick fix and get back to developing this seemed to be the easiest path.


I am using Eclipse v4.3 (Kepler), and this is how I solved my problem.


Goto menu Help → Install new software → click Add.


In the popup, give any name (I named it as Eclipse ADT Plugin), and in the link's place, use https://dl-ssl.google.com/android/eclipse/


Once you click OK, you will be displayed with new packages that will be installed and old packages that will be deleted. Don't worry about these packages. Click OK.


New packages will be installed, and this should solve your problem.






Is there some easy way to pad Strings in Java?


Seems like something that should be in some StringUtil-like API, but I can't find anything that does this.


Apache StringUtils has several methods: leftPad, rightPad, center and repeat. 


Edit: As others have mentioned and demonstrated in this answer, String.format() and the Formatter classes in the JDK are better options. Use them over the commons code.


Since Java 1.5, String.format() can be used to left/right pad a given string.


Padding to 10 characters:


output:


Display '*' for characters of password:


output has the same length as the password string:


In Guava, this is easy:


Something simple:


The value should be a string. convert it to string, if it's not. Like "" + 123 or Integer.toString(123)


Substring start from the value length char index until end length of padded:


More precise 


pad right:


pad left:


Have a look at org.apache.commons.lang.StringUtils#rightPad(String str, int size, char padChar).


But the algorithm is very simple (pad right up to size chars):


Besides Apache Commons, also see String.format which should be able to take care of simple padding (e.g. with spaces).


This took me a little while to figure out.
The real key is to read that Formatter documentation.


i know this thread is kind of old and the original question was for an easy solution but if it's supposed to be really fast, you should use a char array.


the formatter solution is not optimal. just building the format string creates 2 new strings.


apache's solution can be improved by initializing the sb with the target size so replacing below


with    


would prevent the sb's internal buffer from growing.


Here is another way to pad to the right:


You can reduce the per-call overhead by retaining the padding data, rather than rebuilding it every time:


As an alternative, you can make the result length a parameter to the pad(...) method. In that case do the adjustment of the hidden padding in that method instead of in the constructor.


(Hint: For extra credit, make it thread-safe! ;-)


you can use the built in StringBuilder append() and insert() methods,
for padding of variable string lengths:


For Example:


This works:


It will fill your String XXX up to 9 Chars with a whitespace. After that all Whitespaces will be replaced with a 0. You can change the whitespace and the 0 to whatever you want...


Let's me leave an answer for some cases that you need to give left/right padding (or prefix/suffix string or spaces) before you concatenate to another string and you don't want to test length or any if condition.


The same to the selected answer, I would prefer the StringUtils of Apache Commons but using this way:


Explain:


java.util.Formatter will do left and right padding. No need for odd third party dependencies (would you want to add them for something so trivial).


[I've left out the details and made this post 'community wiki' as it is not something I have a need for.]


@ck's and @Marlon Tarak's answers are the only ones to use a char[], which for applications that have several calls to padding methods per second is the best approach.  However, they don't take advantage of any array manipulation optimizations and are a little overwritten for my taste; this can be done with no loops at all.


Simple test method:


Outputs:


A lot of people have some very interesting techniques but I like to keep it simple so I go with this : 


A simple solution without any API will be as follows:


Java oneliners, no fancy library. 


Pad Left, don't limit


Pad Right, don't limit


Pad Left, limit to pad length


Pad Right, limit to pad length


All string operation usually needs to be very efficient - especially if you are working with big sets of data. I wanted something that's fast and flexible, similar to what you will get in plsql pad command. Also, I don't want to include a huge lib for just one small thing. With these considerations none of these solutions were satisfactory. This is the solutions I came up with, that had the best bench-marking results, if anybody can improve on it, please add your comment.


Found this on Dzone


Pad with zeros:


A simple solution would be:


How is this


String is "hello" and required padding is 15 with "0" left pad






I have the string 


I want to count the occurrences of '.' in an idiomatic way, preferably a one-liner.


(Previously I had expressed this constraint as "without a loop", in case you're wondering why everyone's trying to answer without using a loop).


My 'idiomatic one-liner' for this is:


Why write it yourself when it's already in commons lang?


Spring Framework's oneliner for this is:


How about this. It doesn't use regexp underneath so should be faster than some of the other solutions and won't use a loop.


Sooner or later, something has to loop. It's far simpler for you to write the (very simple) loop than to use something like split which is much more powerful than you need.


By all means encapsulate the loop in a separate method, e.g.


Then you don't need have the loop in your main code - but the loop has to be there somewhere.


Summarize other answer and what I know all ways to do this using a one-liner:


1) Using Apache Commons


2) Using Spring Framework's


3) Using replace


4) Using replaceAll (case 1)


5) Using replaceAll (case 2)


6) Using split


7)  Using Java8 (case 1)


8)  Using Java8 (case 2), may be better for unicode than case 1


9)   Using StringTokenizer


From comment: Be carefull for the StringTokenizer, for a.b.c.d it will work but for a...b.c....d or ...a.b.c.d or a....b......c.....d... or etc. it will not work. It just will count for . between characters just once


More info in github


Perfomance test (using JMH, mode = AverageTime, score 0.010 better then 0.351): 


I had an idea similar to Mladen, but the opposite...


ReplaceAll(".") would replace all characters.


PhiLho's solution uses ReplaceAll("[^.]",""), which does not need to be escaped, since [.] represents the character 'dot', not 'any character'.


My 'idiomatic one-liner' solution:


Have no idea why a solution that uses StringUtils is accepted. 


A shorter example is


here is a solution without a loop:


well, there is a loop,  but it is invisible :-)


-- Yonatan


I don't like the idea of allocating a new string for this purpose. And as the string already has a char array in the back where it stores it's value, String.charAt() is practically free.


does the trick, without additional allocations that need collection, in 1 line or less, with only J2SE.


Okay, inspired by Yonatan's solution, here's one which is purely recursive - the only library methods used are length() and charAt(), neither of which do any looping:


Whether recursion counts as looping depends on which exact definition you use, but it's probably as close as you'll get.


I don't know whether most JVMs do tail-recursion these days... if not you'll get the eponymous stack overflow for suitably long strings, of course.


Inspired by Jon Skeet, a non-loop version that wont blow your stack. Also useful starting point if you want to use the fork-join framework.


(Disclaimer: Not tested, not compiled, not sensible.)


Perhaps the best (single-threaded, no surrogate-pair support) way to write it:


Not sure about the efficiency of this, but it's the shortest code I could write without bringing in 3rd party libs:


Complete sample:


Call:


With java-8 you could also use streams to achieve this. Obviously there is an iteration behind the scenes, but you don't have to write it explicitly!


In case you're using Spring framework, you might also use "StringUtils" class.
The method would be "countOccurrencesOf".


You can use the split() function in just one line code 


While methods can hide it, there is no way to count without a loop (or recursion). You want to use a char[] for performance reasons though.


Using replaceAll (that is RE) does not sound like the best way to go.


Somewhere in the code, something has to loop. The only way around this is a complete unrolling of the loop:


...etc, but then you're the one doing the loop, manually, in the source editor - instead of the computer that will run it. See the pseudocode:


Here is a slightly different style recursion solution:


Why not just split on the character and then get the length of the resulting array. array length will always be number of instances + 1.  Right?


The following source code will give you no.of occurrences of a given string in a word entered by user :- 


Also possible to use reduce in Java 8 to solve this problem:


Output:


Using Eclipse Collections


If you have more than one character to count, you can use a CharBag as follows:


Note: I am a committer for Eclipse Collections.


Try this method:






I have a string, "004-034556", that I want to split into two strings:


That means the first string will contain the characters before '-', and the second string will contain the characters after '-'. I also want to check if the string has '-' in it. If not, I will throw an exception. How can I do this?


Just use the appropriate method: String#split().


Note that this takes a regular expression, so remember to escape special characters if necessary.


there are 12 characters with special meanings: the backslash \, the caret ^, the dollar sign $, the period or dot ., the vertical bar or pipe symbol |, the question mark ?, the asterisk or star *, the plus sign +, the opening parenthesis (, the closing parenthesis ), and the opening square bracket [, the opening curly brace {, These special characters are often called "metacharacters".


So, if you want to split on e.g. period/dot . which means "any character" in regex, use either backslash \ to escape the individual special character like so split("\\."), or use character class [] to represent literal character(s) like so split("[.]"), or use Pattern#quote() to escape the entire string like so split(Pattern.quote(".")).


To test beforehand if the string contains certain character(s), just use String#contains().


Note, this does not take a regular expression. For that, use String#matches() instead.


If you'd like to retain the split character in the resulting parts, then make use of positive lookaround. In case you want to have the split character to end up in left hand side, use positive lookbehind by prefixing ?<= group on the pattern.


In case you want to have the split character to end up in right hand side, use positive lookahead by prefixing ?= group on the pattern.


If you'd like to limit the number of resulting parts, then you can supply the desired number as 2nd argument of split() method. 


An alternative to processing the string directly would be to use a regular expression with capturing groups. This has the advantage that it makes it straightforward to imply more sophisticated constraints on the input. For example, the following splits the string into two parts, and ensures that both consist only of digits:


As the pattern is fixed in this instance, it can be compiled in advance and stored as a static member (initialised at class load time in the example). The regular expression is:


The parentheses denote the capturing groups; the string that matched that part of the regexp can be accessed by the Match.group() method, as shown. The \d matches and single decimal digit, and the + means "match one or more of the previous expression). The - has no special meaning, so just matches that character in the input. Note that you need to double-escape the backslashes when writing this as a Java string. Some other examples:


This will split your string into 2 parts.  The first element in the array will be the part containing the stuff before the -, and the 2nd element in the array will contain the part of your string after the -.


If the array length is not 2, then the string was not in the format: string-string.


Check out the split() method in the String class.


https://docs.oracle.com/javase/8/docs/api/java/lang/String.html#split-java.lang.String-int-


should do thing you want. String class has many method to operate with string. 


The requirements left room for interpretation. I recommend writing a method,


which encapsulate this function. Of course you can use String.split(..) as mentioned in the other answers for the implementation.


You should write some unit-tests for input strings and the desired results and behaviour.


Good test candidates should include:


With defining the according test results, you can specify the behaviour.


For example, if "-333" should return in [,333] or if it is an error.
Can "333-333-33" be separated in [333,333-33] or [333-333,33] or is it an error? And so on.


You can try like this also


Assuming, that


The easiest way is to use StringUtils#split(java.lang.String, char). That's more convenient than the one provided by Java out of the box if you don't need regular expressions. Like its manual says, it works like this:


I would recommend using commong-lang, since usually it contains a lot of stuff that's usable. However, if you don't need it for anything else than doing a split, then implementing yourself or escaping the regex is a better option.


Use org.apache.commons.lang.StringUtils' split method which can split strings based on the character or string you want to split.


Method signature: 


In your case, you want to split a string when there is a "-".


You can simply do as follows:


Output:


Assume that if - does not exists in your string, it returns the given string, and you will not get any exception.


With Java 8:


For simple use cases String.split() should do the job. If you use guava, there is also a Splitter class which allows chaining of different string operations and supports CharMatcher:


String Split with multiple characters using Regex


Output:


But do not expect the same output across all JDK versions. I have seen one bug which exists in some JDK versions where the first null string has been ignored. This bug is not present in the latest JDK version, but it exists in some versions between JDK 1.7 late versions and 1.8 early versions.


You can split a string by a line break by using the following statement:


You can split a string by a hyphen/character by using the following statement:


The fastest way, which also consumes the least resource could be:


One way to do this is to run through the String in a for-each loop and use the required split character.


Output:


Please don't use StringTokenizer class as it is a legacy class that is retained for compatibility reasons, and its use is discouraged in new code. And we can make use of the split method as suggested by others as well.


And as expected it will print:


In this answer I also want to point out one change that has taken place for split method in Java 8. The String#split() method makes use of Pattern.split, and now it will remove empty strings at the start of the result array. Notice this change in documentation for Java 8:


When there is a positive-width match at the beginning of the input
  sequence then an empty leading substring is included at the beginning
  of the resulting array. A zero-width match at the beginning however
  never produces such empty leading substring.


It means for the following example:


we will get three strings: [0, 0, 4] and not four as was the case in Java 7 and before. Also check this similar question.


You can use the Split().


Else,
You can use StringTokenizer.


Hope It Helps.. :)


Here are two ways two achieve it


WAY 1:
As you have to split two numbers by a special character you can use regex


WAY 2:Using string split method


You can use simply StringTokenizer to split string in two or more parts whether their is any type of delimiters:


Check out the split() method in the String class on javadoc.


https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#split(java.lang.String)


Here many examples for split string but I little code optimized.


As mentioned by everyone, split() is the best option which may be used in your case. An alternative method can be using substring().


To split a string, use String.split(regex):


output:


004
  034556


From the documentation:


public String[] split(String regex,int limit) Splits this string around matches of the given regular expression. The array returned by this method contains each
  substring of this string that is terminated by another substring that
  matches the given expression or is terminated by the end of the
  string. The substrings in the array are in the order in which they
  occur in this string. If the expression does not match any part of the
  input then the resulting array has just one element, namely this
  string.


So basically what you can do is something like this:


Output:


Output


http://pfhppl.in/?uid
   0SCQZ7W9DBB


0SCQZ7W9DBB


If you have special character then you can use Patter.quote. If you are simple have dash (-) then you shorten the code 


If you try to add other special character in place of dash (^) then the error will generate ArrayIndexOutOfBoundsException. For that you have to use Pattern.quote


Sometimes if you want to split string containing + then it won't split; instead you will get a runtime error. In that case, first replace + to _ and then split:






I am trying to use Notepad++ as my all-in-one tool edit, run, compile, etc.


I have JRE installed, and I have setup my path variable to the .../bin directory.


When I run my "Hello world" in Notepad++, I get this message:


I think the problem here is about versions; some version of Java may be old or too new.


The version number shown describes the version of the JRE the class file is compatible with.


The reported major numbers are:


(Source: Wikipedia)


To fix the actual problem you should try to either run the Java code with a newer version of Java JRE or specify the target parameter to the Java compiler to instruct the compiler to create code compatible with earlier Java versions. 


For example, in order to generate class files compatible with Java 1.4, use the following command line:


With newer versions of the Java compiler you are likely to get a warning about the bootstrap class path not being set. More information about this error is available in blog post New javac warning for setting an older source without bootclasspath.


java.lang.UnsupportedClassVersionError happens because of a higher JDK during compile time and lower JDK during runtime.


In Eclipse, I just went to menu command Window -> Preferences -> Java -> Compiler and then set "Compiler compliance level" to 1.6.


Don't worry, I got it solved.


It is actually simple - you need to install BOTH JRE / JDK with the same version.


JRE 6 -> JDK 6


JRE 7 -> JDK 7


And so on.


This error means you're trying to load a Java "class" file that was compiled with a newer version of Java than you have installed.


For example, your .class file could have been compiled for JDK 7, and you're trying to run it with JDK 6.


So the solution is to either:


Recompile the class if you have the source, using your local Java compiler (if you have one). 


javac FileName.java


For developers, this can happen if another developer checks in a .class file, and they've got a newer version of java than you have!


You are trying to run your program with a Java version that does not support the version in which the code was compiled. So basically you must have compiled your code with a higher version and trying to run it using a lower version.


As you are getting


and version 51.0 corresponds to J2SE 7 you have most probably compiled your code in Java 7 and trying to run it using a lower version. Check what java -version displays. It should be the Java 7 version. If not make appropriate changes in the PATH/JAVA_HOME. Or you can compile with the same version you are trying to run the code. If the configurations are confusing you can always give absolute path /home/user/jdk1.7.0_11/bin/javac and /home/user/jdk1.7.0_11/bin/java.


I had a similar situation on Mac, and the following process worked for me:


In the terminal, type


Then add this line in the file, and save


where version is the one on your computer, such as 1.7.0_25.


Exit the editor, then type the following command make it become effective


Then type java -version to check the result


What is .profile file?


.profile file is a hidden file. It is an optional file which tells the system which commands to run when the user whose profile file it is logs in. For example, if my username is bruno and there is a .profile file in /Users/bruno/, all of its contents will be executed during the log-in procedure.


Source: http://computers.tutsplus.com/tutorials/speed-up-your-terminal-workflow-with-command-aliases-and-profile--mac-30515


In Eclipse's menu Window -> Preferences -> Java -> Compiler check also "Configure Project Specific Settings".


If you stil have the error with same Java version: try to delete build folder of your project manually. Then restart Eclipse.


You can have some JAR library compiled in Java 7, and you have only Java 6 as Java Runtime. It  could happen with some new libraries.


I got the same problem with a project written in 1.7 and tried to execute in 1.6.


My solution in Eclipse:


Right click on your Project Properties -> Java Build Path -> Libraries


Select your JRE System Library and click Edit on the right, and choose the target JRE.


Now go to Java Compiler on the left, and change the Compiler compliance level to your target. 


That worked for me.


The most common issue is misconfiguration of your JAVA_HOME variable which should point to the right Java Development Kit library, if you've multiple installed.


To find where SDK Java folder is located, run the following commands:


To check which java (openjdk) you've installed, check via:


or:


To change it, use:


Prefix with sudo if required.


to select the alternative java version.


Or check which are available for install:


Prefix with sudo if required.


Then you can install, for example:


Prefix with sudo if required.


Install/upgrade appropriate package via:


The java-1.7.0-openjdk package contains just the Java Runtime Environment. If you want to develop Java programs then install the java-1.7.0-openjdk-devel package.


There is an OpenJDK 7 package in the FreeBSD Ports collection called openjdk7 which probably needs to be reconfigured.


See: OpenJDK wiki page.


Just install appropriate  Java SE Development Kit library from the Oracle site or install 


If you're experiencing this issue with Jenkins, see:


However selecting the right version of Java (newer) with update-alternatives should work.


When I installed JDK 1.7, the problem got solved.


I have faced the same problem when I was working with an Ant script to build my application.


I use Eclipse for my application development, and I changed the compiler version in build properties of the project. But that didn't work for me. Then I found out that I can provide the compiler version in the Ant script.


I modified the Ant script at the section where it compile Java files.


This worked for me to resolve the unsupported major minor issue.


As answered elsewhere by several people, the Java program is being run on an older version of Java than the one it was compiled it for. It needs to be "crosscompiled" for backward compatibility. To put it another way, there is a mismatch between source and target Java versions.


Changing options in Eclipse menus don't answer the original poster, who said he/she is not using Eclipse. On OpenJDK javac version 1.7, you can crosscompile for 1.6 if you use parameters -source and -target, plus provide the rt.jar -file of the target version (that is, the older one) at compile time. If you actually install the 1.6 JRE, you can point to its installation (for example, /usr/lib/jvm/java-6-openjdk-i386/jre/lib/rt.jar on Ubuntu, /usr/jdk/jdk1.6.0_60/jre/lib/rt.jar on SunOS apparently. Sorry, I don't know where it is on a Windows system). Like so:


It looks like you can just download rt.jar from the Internet, and point to it. This is not too elegant though:


Based on this...


In Eclipse, right click on project in package explorer:


Build Path -> Configure Build Path


Under:


Java Build Path -> Libraries -> Add Library -> JRE System Library -> Installed JREs -> Search.


Add the required JRE by selecting the library in the list available after the search is complete.


If you use Maven, set your Java compile level. Open a command line and write java -version for your compile level:





If you use IntelliJ IDEA, select project → File → Settings → Build Execution Deployment → Compiler → Java Compiler. Then change byte code as 1.7 like this image:





How do I fix it?


This error means that the JRE that is being used to execute your class code does not recognise the version of Java used. Usually because the version of Java that generated your class file (i.e. compiled it) is newer.


To fix it, you can either 


a) Compile your Java sources with the same, or older, version of the Java compiler as will be used to run it. i.e. install the appropriate JDK.


b) Compile your Java sources with the newer version of the Java compiler but in compatibility mode. i.e. use the -target parameter.


c) Run your compiled classes in a JRE that is the same, or newer, version as the JDK used to compile the classes.


You can check the versions you are currently using with
javac -version for the compiler, and java -version for the runtime.


Should I install the JDK, and setup my PATH variable to the JDK
  instead of JRE?


For compilation, certainly, install and configure the specific JDK that you want.


For runtime, you can use the one that comes with the JDK or a standalone JRE, but regardless, make sure that you have installed the right versions and that you have configured your PATH such that there are no surprises.


What is the difference between the PATH variable in JRE or JDK?


The PATH environment variable tells the command shell where to look for the command you type. When you type java, the command shell interpreter will look through all the locations specified in the PATH variable, from left to right, to find the appropriate java runtime executable to run. If you have multiple versions of Java installed - i.e. you have the java executable in multiple locations specified in the PATH variable, then the first one encountered when going from left to right will be the one that is executed.


The compiler command is javac and only comes with the JDK. The runtime command is java and comes with the JDK and is in the JRE.


It is likely that you have one version (51.0 = Java 7) of javac installed, and you also have the same version of java installed, but that another previous version of java is appearing earlier in the PATH and so is being invoked instead of the one you expect.


I had the same error message when running Ant from Eclipse, but the other solutions mentioned here didn't solve my problem. The funny thing was that running Ant from the Windows command line was running fine, so it had to be a configuration issue within Eclipse.


It turned out that under Eclipse you can specify the environment that Ant should be running with and this was set as a JRE instead of a JDK.


You have used a higher version of the JDK to compile and trying to run from a lower version of JDK/JRE.


To check this, see the version information:


They will be different and javac will have a higher version number.


To get around this, run using java from the JDK version or if you have a newer JRE/JDK that will work as well.


which javac will tell you the location, for example, /usr/bin/javac. Just run directly using /usr/bin/java <program>.


OR you can set the environment variable as a permanent solution.


If somebody is facing the same issue while using Maven, you can cross compile using the plug-in Maven Compiler.


Had this problem when I reverted to Java 6 and tried to run classes previously compiled with Java 7. What worked for me was Preferences > java > compiler --> set compliance level to 1.6 and crucially "configure project settings".. 


Today, this error message appeared in our Tomcat 7 on Ubuntu 12.04.2 LTS (Precise Pangolin):


/var/log/tomcat7/localhost.2014-04-08.log: 
  Apr 8, 2014 9:00:55 AM org.apache.catalina.core.StandardContext filterStart 
  SEVERE: Exception starting filter struts2 
  java.lang.UnsupportedClassVersionError: controller/ReqAccept : Unsupported major.minor version 51.0 (unable to load class controller.ReqAccept)


The Struts application is compiled with Java 7.


It turned out, someone uses "service tomcat [stop/start]" to restart Tomcat 7,


$ ps -ef | grep java
  tomcat7  31783 1 32 20:13 ? 00:00:03 /usr/lib/jvm/default-java/bin/java...
  $ /usr/lib/jvm/default-java/bin/java -version
  java version "1.6.0_27"


Which causes the "Unsupported major.minor version 51.0" error.


When we used "/etc/init.d/tomcat7 [stop/start]" to restart Tomcat 7, the problem was solved.


$ ps -ef | grep java
  tomcat7  31886 1 80 20:24 ? 00:00:10 /usr/local/java/jdk1.7.0_15/bin/java
  $ /usr/local/java/jdk1.7.0_15/bin/java -version
  java version "1.7.0_15"


Oh Mac OS X I was able to solve this problem by setting the JAVA_HOME variable:


Your Java file is compiled with a different version (higher compiler version) than the version (lower runtime version) you are trying to run it with.


It is basic understanding that classes compiled with lower versions are expected to run in the later higher versions. But the opposite (compiled with higher compiler version and trying to run it with lower runtime version) is quite not possible sometimes.


Hence you are shown this error, when trying to execute your program. Unsupported major.minor version x.x


Q: I have created an application in Java 7, but when my users try to
  run it they get an Unsupported major.minor version 51.0 error. What
  does this mean and what can I do about it?


A: If you compile an application using javac in Java 7, the resulting classfiles will have the 51.0 version number. Versions of
  Java prior to 7 do not recognize this number, so your users will have
  to upgrade to Java 7 prior to running your application. If you are not
  using any Java 7 APIs you can try to compile your application using
  javac -target 1.6 to create a 1.6-compatible classfile. If your
  application is deployed using webstart you can specify the minimum
  version required. For more information, see the docs on Java Web Start
  and JNLP here. This issue will go away once we trigger autoupdate to
  Java 7 for end-users currently having Java 6 on their desktops. The
  timeline for this is not yet determined, we want to give developers
  time to work out any issues between their code and JDK 7 first.


(Source: oracle.com.)


I had the problem whereby I was having to run a Maven compilation on my project from the command line in order to run my unit tests; if I made a change to the test class and let Eclipse automatically recompile it, then I got the "Unsupported major.minor version 51.0" error.


I do have both JDK6 and JDK7 installed, but all my JRE settings were pointing at 1.6, both in the pom and from the project properties page in Eclipse. No amount of Maven Update Project and/or refreshing solved this.


Finally I tried closing the project and re-opening it, and this seemed to fix it! HTH


You have compiled your Java class with JDK 7 and you are trying to run same class on JDK 6 .


First let's get some basics right...


JRE is a component in NetBeans/Eclipse/standalone that is going to provide you with libraries, JVM, Java plugins & Java web start. Note that it does not provide compliers or debuggers.


JDK is the superset of JRE along with compliers and debuggers.


So when you have your default library as a JRE instead of JDK, you are going to have a nice time importing stuff, but it won't compile.


Instead, set your path to JDK (I use NetBeans, and I set them using netbeans.conf in netbeans/etc/netbeans.conf and change the path).


I solved it. I ran:


The error is misleading, Unsupported major.minor version 51.0. This gives the impression that version 51 (Java 7) is not supported. And we should use Java 6.


The error should have been:


The current Java version, 50, is unsupported. Use Java version 7 (51:0 and greater) instead.`


Yet another way to fix this on Mac OS X with Homebrew installed, is this:






I was exploring RecyclerView and I was surprised to see that RecyclerView does not have onItemClickListener(). Because RecyclerView extends     


android.view.ViewGroup


and ListView extends 


android.widget.AbsListView


.  However I solved my problem by writing onClick in my RecyclerView.Adapter:


But still I want to know why Google removed onItemClickListener()? 


Is there a performance issue or something else?


tl;dr 2016 Use RxJava and a PublishSubject to expose an Observable for the clicks.


Original Post:


Since the introduction of ListView, onItemClickListener has been problematic. The moment you have a click listener for any of the internal elements the callback would not be triggered but it wasn't notified or well documented (if at all) so there was a lot of confusion and SO questions about it.


Given that RecyclerView takes it a step further and doesn't have a concept of a row/column, but rather an arbitrarily laid out amount of children, they have delegated the onClick to each one of them, or to programmer implementation.


Think of Recyclerview not as a ListView 1:1 replacement but rather as a more flexible component for complex use cases. And as you say, your solution is what google expected of you. Now you have an adapter who can delegate onClick to an interface passed on the constructor, which is the correct pattern for both ListView and Recyclerview.


and then on your adapter


Now look into that last piece of code: onCreateViewHolder(ViewGroup parent, int viewType) the signature already suggest different view types. For each one of them you'll require a different viewholder too, and subsequently each one of them can have a different set of clicks. Or you can just create a generic viewholder that takes any view and one onClickListener and applies accordingly. Or delegate up one level to the orchestrator so several fragments/activities have the same list with different click behaviour. Again, all flexibility is on your side.


It is a really needed component and fairly close to what our internal implementations and improvements to ListView were until now. It's good that Google finally acknowledges it.


I like this way and I'm using it


Inside 


Put 


And create this class anywhere you want it


I've read before that there is a better way but I like this way is easy and not complicated.


An alternative solution is the one proposed by Hugo Visser, an Android GDE. He made a licence-free class available for you to just drop in your code and use it.


Usage:


(it also support long item click)


Implementation (comments added by me):


also create a file values/ids.xml and put this in it:


This class works by attaching a RecyclerView.OnChildAttachStateChangeListener to the RecyclerView. This listener is notified every time a child is attached or detached from the RecyclerView. The code use this to append a tap/long click listener to the view. That listener ask the RecyclerView for the RecyclerView.ViewHolder which contains the position.


You could also adapt the code to give you back the holder itself if you need more.


Keep in mind that it's COMPLETELY fine to handle it in your adapter by setting on each view of your list a click listener, like other answer proposed. It's just not the most efficient thing to do (you create a new listener every time you reuse a view) but it works and in most cases it's not an issue.


About the Why RecyclerView does not have an onItemClickListener.


The RecyclerView is a toolbox, in contrast of the old ListView it has less build in features and more flexibility. The onItemClickListener is not the only feature being removed from ListView. But it has lot of listeners and method to extend it to your liking, it's far more powerful in the right hands ;).


In my opinion the most complex feature removed in RecyclerView is the Fast Scroll. Most of the other features can be easily re-implemented.


Android Recyclerview With onItemClickListener,
 Why we cant try this is working like ListView only.


Source : Link


And Set this to RecyclerView:


Thanks to @marmor, I updated my answer. 


I think it's a good solution to handle the onClick() in the ViewHolder class constructor and pass it to the parent class via OnItemClickListener interface.


MyAdapter.java


Usage of adapter in other classes:


MyFragment.java


Guys use this code in Your main activity.   Very Efficient Method


Here is your Adapter class.


After this you will get this override method in your activity.


> How RecyclerView is different from Listview?


How to put it all together example...


ViewHolder types


After reading @MLProgrammer-CiM's answer, here is my code:


As far as I understand MLProgrammer-CiM  answer, simply it's possible to just do this: 


I have done this way, its very simple:


Just add 1 Line for Clicked RecyclerView position:


Full code for ViewHolder class:


Hope this will help you.


I use this method to start an Intent from RecyclerView:


Here is a way to implement it quite easily if you have a list of POJOs and want to retrieve one on click from outside the adapter.


In your adapter, create a listener for the click events and a method to set it:


}


In your ViewHolder, implement onClickListener and create a class member to temporarily store the POJO the view is presenting, that way (this is an example, creating a setter would be better):


Back in your adapter, set the current POJO when the ViewHolder is bound (or to null if the current view doesn't have one):


That's it, now you can use it like this from your fragment/activity:


Following up MLProgrammer-CiM's excellent RxJava solution


Modify the original tl;dr as:


PublishSubject#asObservable() was removed.  Just return the PublishSubject which is an Observable.


See my approach on this:


First declare an interface like this:


Then create the adapter:


And now let's see how to integrate this from a fragment:


If you want to add onClick() to the child view of items, for example, a button in item, I found that you can do it easily in onCreateViewHolder() of your own RecyclerView.Adapter just like this:


i don't know whether it's a good way, but it works well. If anyone has a better idea, very glad to tell me and correct my answer! :)


This worked for me:


Yes you can


Here you can handle multiple onclick see below code and it is very efficient  


Modified my comment...


Check this one in which I have implemented all the things with a proper way


RecyclerViewHolder Class


Adapter


The interface


Instead of implementing interface View.OnClickListener inside view holder or creating and interface and implementing interface in your activity..
I used this code for simple on OnClickListener implementation.


use PlaceHolderView 


I wrote a library to handle android recycler view item click event. You can find whole tutorial in https://github.com/ChathuraHettiarachchi/RecycleClick


or to handle item long press you can use


Access the mainView of rowLayout(cell) for you RecyclerView and in your OnBindViewHolder write this code:


it worked for me. Hope it will help. Most simplest way.


Inside View Holder


Inside OnBindViewHolder()


And let me know, do you have any question about this solution ?


Easiest way to do this is as follows:


Declare global variable at start of Adapter class:


Then set the OnClickListener within the onBindViewHolder method:


All other answers are lame.






I am trying to create a mail sending application in Android. 


If I use: 


This will launch the built-in Android application; I'm trying to send the mail on button click directly without using this application.


Send e-mail in Android using the JavaMail API using Gmail authentication


Steps to create a sample Project:


MailSenderActivity.java


GMailSender.java


JSSE Provider 


JSSEProvider.java


ADD 3 jars found in the following link to your Android Project 


Click here - How to add External Jars


And don't forget to add this line in your manifest:


Just click below link to change account access for less secure apps
https://www.google.com/settings/security/lesssecureapps


Run the project and check your recipient mail account for the mail.
Cheers!


P.S. And don't forget that you cannot do network operation from any Activity in android.
Hence it is recommended to use AsyncTask or IntentService to avoid network on main thread exception.


Jar files: https://code.google.com/archive/p/javamail-android/


Thank you for your valuable information. Code is working fine. I am able to add attachment also by adding following code.


Could not connect to SMTP host:
  smtp.gmail.com, port: 465


Add this line in your manifest:


You can use JavaMail API to handle your email tasks. JavaMail API is available in JavaEE package and its jar is available for download. Sadly it cannot be used directly in an Android application since it uses AWT components which are completely incompatible  in Android.


You can find the Android port for JavaMail at the following location:
http://code.google.com/p/javamail-android/


Add the jars to your application and use the SMTP method


In order to help those getting a Network On Main Thread Exception with an SDK Target >9. This is using droopie's code above but will work similarly for any.


You can use AsyncTask as below


Using SMTP is one way to go, and the others have already pointed out ways how to do it. Just note that while doing this, you completely circumvent the built in mail app, and you will have to provide the address of the SMTP server, the user name and password for that server, either statically in your code, or query it from the user.


Another way would involve a simple server side script, like php, that takes some URL parameters and uses them to send a mail. This way, you only need to make an HTTP request from the device (easily possible with the built in libraries) and don't need to store the SMTP login data on the device. This is one more indirection compared to direct SMTP usage, but because it's so very easy to make HTTP request and send mails from PHP, it might even be simpler than the direct way.


If the mail shall be send from the users default mail account that he already registered with the phone, you'd have to take some other approach. If you have enough time and experience, you might want to check the source code of the Android Email application to see if it offers some entry point to send a mail without user interaction (I don't know, but maybe there is one).


Maybe you even find a way to query the users account details (so you can use them for SMTP), though I highly doubt that this is possible, because it would be a huge security risk and Android is built rather securely.


here is an alt version that also works for me and has attachments (posted already above but complete version unlike the source link, which people posted they cant get it to work since its missing data)


and to call it in an activity...


100% working code with demo You can also send multiple email using this answer.


Download Project HERE


Step 1 :  Download mail,activation,additionnal jar files and add in your project libs folder in android studio. I added a screen shot see below Download link





Login with gmail (using your from mail) and TURN ON  toggle button LINK 


Most of the people forget about this step i hope you will not.


Step 2 :  After completing this process.  Copy and past this classes into your project.


GMail.java


SendMailTask.java


Step 3 :
Now you can change this  class according to your needs also you can send multiple mail using this class. i provide xml and java file both.


activity_mail.xml


SendMailActivity.java


Note Dont forget to add internet permission in your AndroidManifest.xml file


<uses-permission android:name="android.permission.INTERNET"/>


Hope it work if it not then just comment down below.


Word of warning if using "smtp.gmail.com" as the default smtp server. 


Google will force you to change your linked email account password frequently due to their over zealous "suspicious activity" polices. In essence it treats repeated smtp requests from different countries within a short time frame as "suspicious activity". As they assume you (the email account holder) can only be in one country at a time.


When google systems detect "suspicious activity" it will prevent further emails until you change the password. As you will have hard coded the password into the app you have to re-release the app each time this happens, not ideal. This happened 3 times in a week to me, I even stored the password on another server and dynamically fetched the password each time google forced me to change it.


So I recommend using one of the many free smtp providers instead of "smtp.gmail.com" to avoid this security problem. Use the same code but change "smtp.gmail.com" to your new smtp forwarding host.


Edit: JavaMail 1.5.5 claims to support Android, so you shouldn't need anything else.



I've ported the latest JavaMail (1.5.4) to Android. It's available in Maven Central, just add the following to build.gradle~~


You can then follow the official tutorial.


Source code is available here: https://bitbucket.org/artbristol/javamail-forked-android





GmailBackground is small library to send an email in background without user interaction :


Usage:


Configuration:


Permissions:


Also for attachments, you need to set READ_EXTERNAL_STORAGE permission:


Source


(I've tested it myself)


For sending a mail with attachment..


Did you consider using Apache Commons Net ? Since 3.3, just one jar (and you can depend on it using gradle or maven) and you're done : http://blog.dahanne.net/2013/06/17/sending-a-mail-in-java-and-android-with-apache-commons-net/


Those who are getting ClassDefNotFoundError try to move that Three jar files to lib folder of your Project,it worked for me!!


I am unable to run Vinayak B's code. Finally i solved this issue by following :


1.Using this 


2.Applying AsyncTask.


3.Changing security issue of sender gmail account.(Change to "TURN ON") in this


Without user intervention, you can send as follows:


Send email from client apk. Here mail.jar, activation.jar is required to send java email. If these jars are added, it might increase the APK Size. 


Alternatively, You can use a web-service at the server side code, which will use the same mail.jar and activation.jar to send email. You can call the web-service via asynctask and send email. Refer same link. 


(But, you will need to know the credentials of the mail account)


In case that you are demanded to keep the jar library as small as possible, you can include the SMTP/POP3/IMAP function separately to avoid the "too many methods in the dex" problem. 


You can choose the wanted jar libraries from the javanet web page, for example, mailapi.jar + imap.jar can enable you to access icloud, hotmail mail server in IMAP protocol. (with the help of additional.jar and activation.jar)


I tried using the code that @Vinayak B submitted. However I'm getting an error saying: No provider for smtp


I created a new question for this with more information HERE


I was able to fix it myself after all. I had to use an other mail.jar
and I had to make sure my "access for less secure apps" was turned on.


I hope this helps anyone who has the same problem. With this done, this piece of code works on the google glass too.


All the code provided in the other answers is correct and is working fine, but a bit messy, so I decided to publish a library (still in development though) to use it in a easier way: AndroidMail.


You have just to create a MailSender, build a mail and send it (already handled in background with an AsyncTask).


You can receive a notification for the email sent and it has also the support for different Recipients types (TO, CC and BCC), attachments and html:


You can get it via Gradle or Maven:


Please let me know if you have any issue with it! :)


These sources explain to you step by step what actually each code line does:


Sending email with attachment using JavaMail API


Send e-mail with attachment in Java


Download attachments in e-mail messages using JavaMail


To add attachment, don't forget to add. 






I want to INSERT a record in a database (which is Microsoft SQL Server in my case) using JDBC in Java. At the same time, I want to obtain the insert ID. How can I achieve this using JDBC API?


If it is an auto generated key, then you can use Statement#getGeneratedKeys() for this. You need to call it on the same Statement as the one being used for the INSERT. You first need to create the statement using Statement.RETURN_GENERATED_KEYS to notify the JDBC driver to return the keys. 


Here's a basic example:


Note that you're dependent on the JDBC driver whether it works. Currently, most of the last versions will do, but if I am correct, Oracle JDBC driver is still somewhat troublesome with this. MySQL and DB2 already supported it for ages. PostgreSQL started to support it short ago. No wording about MSSQL as I've never used it.


For Oracle, you can invoke a CallableStatement with a RETURNING clause or a SELECT CURRVAL(sequencename) (or whatever DB-specific syntax to do so) directly after the INSERT in the same transaction to obtain the last generated key. See also this answer.


I'm hitting Microsoft SQL Server 2008 R2 from a single-threaded JDBC-based application and pulling back the last ID without using the RETURN_GENERATED_KEYS property or any PreparedStatement.  Looks something like this:


This blog post nicely isolates three main SQL Server "last ID" options: 
http://msjawahar.wordpress.com/2008/01/25/how-to-find-the-last-identity-value-inserted-in-the-sql-server/ - haven't needed the other two yet.


Create Generated Column


Pass this geneated Column to your statement


Use ResultSet object to fetch the GeneratedKeys on Statement


According to 'Unsupported feature' error with using Statement.RETURN_GENERATED_KEYS, Try this:  


Where BRANCHID is the auto generated id


I'm using SQLServer 2008, but I have a development limitation: I cannot use a new driver for it, I have to use "com.microsoft.jdbc.sqlserver.SQLServerDriver" (I cannot use "com.microsoft.sqlserver.jdbc.SQLServerDriver").


That's why the solution conn.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS) threw a java.lang.AbstractMethodError for me.
In this situation, a possible solution I found is the old one suggested by Microsoft:
How To Retrieve @@IDENTITY Value Using JDBC


This solution worked for me!


I hope this helps!






When i try to compile this: 


I get these errors: 


it seems to me that i initialized them at the top of the method. Whats going wrong? 


You declared them, but you didn't initialize them. Initializing them is setting them equal to a value:


You get the error because you haven't initialized the variables, but you increment them (e.g., a++) in the for loop.


Local variables do not get default values. Their initial values are undefined with out assigning values by some means. Before you can use local variables they must be initialized.


There is a big difference when you declare a variable at class level (as a member ie. as a field) and at method level.


If you declare a field at class level they get default values according to their type. If you declare a variable at method level or as a block (means anycode inside {}) do not get any values and remain undefined until somehow they get some starting values ie some values assigned to them.


If they were declared as fields of the class then they would be really initialized with 0.


You're a bit confused because if you write:


Then this code will print "0". It's because a special constructor will be called when you create new instance of Clazz. At first super () will be called, then field a will be initialized implicitly, and then line b = 0 will be executed.


You declared them, but not initialized.


You declared them, but didn't initialize them with a value. Add something like this :


You haven't initialised a and b, only declared them.  There is a subtle difference.


At least this is for C++, I presume Java is the same concept.


You declared them at the start of the method, but you never initialized them. Initializing would be setting them equal to a value, such as:


You declared them but did not provide them with an intial value - thus, they're unintialized.  Try something like:


and the warnings should go away.


Imagine what happens if x[l] is neither 0 nor 1 in the loop. In that case a and b will never be assigned to and have an undefined value.
You must initialize them both with some value, for example 0.


Set variable "a" to some value like this,


Declaring and initialzing are both different. 


Good Luck






I'm packaging a Java library as a JAR, and it's throwing many java.lang.IncompatibleClassChangeErrors when I try to invoke methods from it. These errors seem to appear at random. What kinds of problems could be causing this error?


This means that you have made some incompatible binary changes to the library without recompiling the client code.  Java Language Specification §13 details all such changes, most prominently, changing non-static non-private fields/methods to be static or vice versa.


Recompile the client code against the new library, and you should be good to go.


UPDATE: If you publish a public library, you should avoid making incompatible binary changes as much as possible to preserve what's known as "binary backward compatibility".  Updating dependency jars alone ideally shouldn't break the application or the build.


Your newly packaged library is not backward binary compatible (BC) with old version. For this reason some of the library clients that are not recompiled may throw the exception.


This is a complete list of changes in Java library API that may cause clients built with an old version of the library to throw java.lang.IncompatibleClassChangeError if they run on a new one (i.e. breaking BC):


Note: There are many other exceptions caused by other incompatible changes: NoSuchFieldError, NoSuchMethodError, IllegalAccessError, InstantiationError, VerifyError, NoClassDefFoundError and AbstractMethodError.


The better paper about BC is "Evolving Java-based APIs 2: Achieving API Binary Compatibility" written by Jim des Rivières.


There are also some automatic tools to detect such changes:


Usage of japi-compliance-checker for your library:


Usage of clirr tool:


Good luck!


While these answers are all correct, resolving the problem is often more difficult.  It's generally the result of two mildly different versions of the same dependency on the classpath, and is almost always caused by either a different superclass than was originally compiled against being on the classpath or some import of the transitive closure being different, but generally at class instantiation and constructor invocation.  (After successful class loading and ctor invocation, you'll get NoSuchMethodException or whatnot.)


If the behavior appears random, it's likely the result of a multithreaded program classloading different transitive dependencies based on what code got hit first. 


To resolve these, try launching the VM with -verbose as an argument, then look at the classes that were being loaded when the exception occurs.  You should see some surprising information. For instance, having multiple copies of the same dependency and versions you never expected or would have accepted if you knew they were being included.


Resolving duplicate jars with Maven is best done with a combination of the maven-dependency-plugin and maven-enforcer-plugin under Maven (or SBT's Dependency Graph Plugin, then adding those jars to a  section of your top-level POM or as imported dependency elements in SBT.


Good luck!


I have also discovered that, when using JNI, invoking a Java method from C++, if you pass parameters to the invoked Java method in the wrong order, you will get this error when you attempt to use the parameters inside the called method (because they won't be the right type).  I was initially taken aback that JNI does not do this checking for you as part of the class signature checking when you invoke the method, but I assume they don't do this kind of checking because you may be passing polymorphic parameters and they have to assume you know what you are doing.


Example C++ JNI Code:


Example Java Code:


I had the same issue, and later I figured out that I am running the application on Java version 1.4 while the application is compiled on version 6.


Actually, the reason was of having a duplicate library, one is located within the classpath and the other one is included inside a jar file that is located within the classpath.


Another situation where this error can appear is with Emma Code Coverage.


This happens when assigning an Object to an interface. I guess this has something to do with the Object being instrumented and not binary compatible anymore.


http://sourceforge.net/tracker/?func=detail&aid=3178921&group_id=177969&atid=883351


Fortunately this problem doesn't happen with Cobertura, so I've added cobertura-maven-plugin in my reporting plugins of my pom.xml


I've faced this issue while undeploying and redeploying a war with glassfish. My class structure was like this,


and it was changed to 


After stopping and restarting the domain, it worked out fine. 
I was using glassfish 3.1.43


I have a web application that deploys perfectly fine on my local machine's tomcat(8.0.20). However, when I put it into the qa environment (tomcat - 8.0.20), it kept on giving me the IncompatibleClassChangeError and it was complaining that I was extending on an interface. This interface was changed to an abstract class. And I compiled the parent and child classes and still I kept on getting the same issue. Finally, I wanted to debug, so, I changed the version on the parent to x.0.1-SNAPSHOT and then compiled everything and now it is working. If someone is still hitting the problem after following the answers given here, please make sure the versions in your pom.xml are also correct. Change the versions to see if that works. If so, then fix the version problem.


In my case, I ran into this error this way. pom.xml of my project defined two dependencies A and B. And both A and B defined dependency on same artifact (call it C) but different versions of it (C.1 and C.2). When this happens, for each class in C maven can only select one version of the class from the two versions (while building an uber-jar). It will select the "nearest" version based on its dependency mediation rules and will output a warning "We have a duplicate class..." If a method/class signature changes between the versions, it can cause a java.lang.IncompatibleClassChangeError exception if the incorrect version is used at runtime.


Advanced: If A must use v1 of C and B must use v2 of C, then we must relocate C in A and B's poms to avoid class conflict (we have a duplicate class warning) when building the final  project that depends on both A and B.


Please check if your code doesnt consist of two module projects that have the same classes names and packages definition. For example this could happen if someone uses copy-paste to create new implementation of interface based on previous implementation.


If this is a record of possible occurences of this error then:


I just got this error on WAS (8.5.0.1), during the CXF (2.6.0) loading of the spring (3.1.1_release) configuration where a BeanInstantiationException rolled up a CXF ExtensionException, rolling up a IncompatibleClassChangeError. The following snippet shows the gist of the stack trace:


In this case, the solution was to change the classpath order of the module in my war file. That is, open up the war application in the WAS console under and select the client module(s). In the module configuration, set the class-loading to be "parent last".


This is found in the WAS console:


Documenting another scenario after burning way too much time.  


Make sure you don't have a dependency jar that has a class with an EJB annotation on it.


We had a common jar file that had an @local annotation.  That class was later moved out of that common project and into our main ejb jar project. Our ejb jar and our common jar are both bundled within an ear.  The version of our common jar dependency was not updated. Thus 2 classes trying to be something with incompatible changes.


All of the above - for whatever reason I was doing some big refactor and starting to get this.  I renamed the package my interface was in and that cleared it. Hope that helps.


My answer, I believe, will be Intellij specific.  


I had rebuilt clean, even going as far as to manually delete the "out" and "target" dirs.  Intellij has a "invalidate caches and restart", which sometimes clears odd errors. This time it didn't work. The dependency versions all looked correct in the project settings->modules menu.


The final answer was to manually delete my problem dependency from my local maven repo.  An old version of bouncycastle was the culprit(I knew I had just changed versions and that would be the problem) and although the old version showed up no where in what was being built, it solved my problem.  I was using intellij version 14 and then upgraded to 15 during this process. 


For some reason the same exception is also thrown when using JNI and passing the jclass argument instead of the jobject when calling a Call*Method().


This is similar to the answer from Ogre Psalm33.


I know it is a bit late to answer this question 5 years after being asked but this is one of the top hits when searching for java.lang.IncompatibleClassChangeError so I wanted to document this special case.


Adding my 2 cents .If you are using scala and sbt and scala-logging as dependency ;then this can happen because scala-logging's earlier version had the name scala-logging-api.So;essentially the dependency resolutions do not happen because of different names leading to runtime errors while launching the scala application.


An additional cause of this issue, is if you have Instant Run enabled for Android Studio.


If you find you start getting this error, turn off Instant Run.


Instant Run modifies a large number of things during development, to make it quicker to provide updates to your running App. Hence instant run. When it works, it is really useful. However, when an issue such as this strikes, the best thing to do is to turn off Instant Run until the next version of Android Studio releases.






Can you explain to me the output of this Java code?


The output is 20 in both cases


Does this help?


++a increments and then uses the variable.
a++ uses and then increments the variable.


If you have


and you do


@codaddict explains your particular snippet.


is


Working: increment a to 6 (current value 6) + increment a to 7 (current value 7). Sum is 13 now add it to current value of a (=7) and then increment a to 8. Sum is 20 and value of a after the assignment completes is 8.


is


Working: At the start value of a is 5. Use it in the addition and then increment it to 6 (current value 6). Increment a from current value 6 to 7 to get other operand of +. Sum is 12 and current value of a is 7. Next increment a from 7 to 8 (current value = 8) and add it to previous sum 12 to get 20. 


++a increments a before it is evaluated.
a++ evaluates a and then increments it.


Related to your expression given:


The parenteses I used above are implicitly used by Java. If you look at the terms this way you can easily see, that they are both the same as they are commutative.


In the above example 


In both cases it first calculates value, but in post-increment it holds old value and after calculating returns it


++a


a++


when a is 5, then a++ gives a 5 to the expression and increments a afterwards, while ++a increments a before passing the number to the expression (which gives a 6 to the expression in this case).


So you calculate


I believe however if you combine all of your statements and run it in Java 8.1 you will get a different answer, at least that's what my experience says.


The code will work like this:


Presuming that you meant


This evaluates to:


so i is 6 + 7 + 7 = 20 and so 20 is printed.


so i is 5 + 7 + 8 = 20 and so 20 is printed again.


and after all of the right hand side is evaluated (including setting a to 8) THEN a is set to 6 + 7 + 7 = 20 and so 20 is printed a final time.


pre-increment and post increment are equivalent if not in an expression 


is


Working: pre/post increment has "right to left" Associativity , and pre has precedence over post , so first of all pre increment will be solve as (++a + ++a) => 7 + 6 . then a=7 is provided to post increment => 7 + 6 + 7 =20 and a =8.


is


Working: pre/post increment has "right to left" Associativity , and pre has precedence over post , so first of all pre increment will be solve as (++a + ++a) => 7 + 6.then a=7 is provided to post increment => 7 + 7 + 6 =20 and a =8.


++a is prefix increment operator:


a++ is postfix increment operator:


Once you remember the rules, EZ for ya to calculate everything!


I believe you are executing all these statements differently 

executing together will result => 38 ,29 


Just refer these principles and that image and you would be pro in a matter of minutes.


Principle:- 


1.) When the unary operators ++ and -- are used in prefix notation, the value of the variable increments/decrements just before the variable is used in an expression.


2.) When the unary operators ++ and -- are used in postfix notation, the value of the variable increments/decrements just after the variable is used in an expression.


Example:- The evaluation of the expression in image starts from left to right. Assume a to be 10.









I have a sentence that is passed in as a string and I am doing a replace on the word "and" and I want to replace it with " ".  And it's not replacing the word "and" with white space.  Below is an example of my logic.  And when I debug this the logic does fall into the sentence.replace.


Is there something I am missing here.


And when I debug this the logic does fall into the sentence.replace.


Yes, and then you discard the return value.


Strings in Java are immutable - when you call replace, it doesn't change the contents of the existing string - it returns a new string with the modifications. So you want:


This applies to all the methods in String (substring, toLowerCase etc). None of them change the contents of the string.


Note that you don't really need to do this in a condition - after all, if the sentence doesn't contain "and", it does no harm to perform the replacement:


Strings are immutable, meaning their contents cannot change. When you call replace(this,that) you end up with a totally new String. If you want to keep this new copy, you need to assign it to a variable. You can overwrite the old reference (a la sentence = sentence.replace(this,that) or a new reference as seen below:


As an aside, note that I've removed the contains() check, as it is an unnecessary call here. If it didn't contain it, the replace will just fail to make any replacements. You'd only want that contains method if what you're replacing was different than the actual condition you're checking. 


You aren't doing anything with the return value of replace. You'll need to assign the result of the method, which is the new String:


A String is immutable in java. Methods like replace return a new String.


Your contains test is unnecessary: replace will just no-op if there aren't instances of the text to replace.


You should re-assign the result of the replacement, like this:


Be aware that the String class is immutable, meaning that all of its methods return a new string and never modify the original string in-place, so the result of invoking a method in an instance of String must be assigned to a variable or used immediately for the change to take effect.






Is there an easy way to read a single char from the console as the user is typing it in Java? Is it possible? I've tried with these methods but they all wait for the user to press enter key:


I'm starting to think that System.in is not aware of the user input until enter is pressed.


What you want to do is put the console into "raw" mode (line editing bypassed and no enter key required) as opposed to "cooked" mode (line editing with enter key required.)  On UNIX systems, the 'stty' command can change modes.


Now, with respect to Java... see Non blocking console input in Python and Java.  Excerpt:


If your program must be console based,
  you have to switch your terminal out
  of line mode into character mode, and
  remember to restore it before your
  program quits. There is no portable
  way to do this across operating
  systems.


One of the suggestions is to use JNI.  Again, that's not very portable.  Another suggestion at the end of the thread, and in common with the post above, is to look at using jCurses.


You need to knock your console into raw mode. There is no built-in platform-independent way of getting there. jCurses might be interesting, though.


On a unix system, this might work:


For example, if you want to take into account the time between keystrokes, here's sample code to get there.


There is no portable way to read raw characters from a Java console.


Some platform-dependent workarounds have been presented above. But to be really portable, you'd have to abandon console mode and use a windowing mode, e.g. AWT or Swing.


I have written a Java class RawConsoleInput that uses JNA to call operating system functions of Windows and Unix/Linux.


It supports non-blocking input and mixing raw mode and normal line mode input.






I have code where I schedule a task using java.util.timer. I was looking around and saw ExecutorService can do the same. So this question here, have you used Timer and ExecutorService to schedule tasks, what is the benefit of one using over another?


Also wanted to check if anyone had used the Timer class and ran into any issues which the ExecutorService solved for them.


According to Java Concurrency in Practice:


If you can use ScheduledThreadExecutor instead of Timer, do so.


One more thing... while ScheduledThreadExecutor isn't available in Java 1.4 library, there is a Backport of JSR 166 (java.util.concurrent) to Java 1.2, 1.3, 1.4, which has the ScheduledThreadExecutor class.


If it's available to you, then it's difficult to think of a reason not to use the Java 5 executor framework. Calling:


will give you a ScheduledExecutorService with similar functionality to Timer (i.e. it will be single-threaded) but whose access may be slightly more scalable (under the hood, it uses concurrent structures rather than complete synchronization as with the Timer class). Using a ScheduledExecutorService also gives you advantages such as:


About the only reasons for sticking to Timer I can think of are:


ExecutorService is newer and more general.  A timer is just a thread that periodically runs stuff you have scheduled for it.


An ExecutorService may be a thread pool, or even spread out across other systems in a cluster and do things like one-off batch execution, etc...


Just look at what each offers to decide.


Here's some more good practices around Timer use:


http://tech.puredanger.com/2008/09/22/timer-rules/


In general, I'd use Timer for quick and dirty stuff and Executor for more robust usage.


My reason for sometimes preferring Timer over Executors.newSingleThreadScheduledExecutor() is that I get much cleaner code when I need the timer to execute on daemon threads.


compare 


with 


I do this when I don't need the robustness of an executorservice.


From oralce documentation page on ScheduledThreadPoolExecutor


A ThreadPoolExecutor that can additionally schedule commands to run after a given delay, or to execute periodically. This class is preferable to Timer when multiple worker threads are needed, or when the additional flexibility or capabilities of ThreadPoolExecutor (which this class extends) are required.


ExecutorService/ThreadPoolExecutor or ScheduledThreadPoolExecutor is obvious choice when you have multiple worker threads. 


Pros of ExecutorService over Timer


ThreadPoolExecutor provides better API for management of Thread life cycle.


Thread pools address two different problems: they usually provide improved performance when executing large numbers of asynchronous tasks, due to reduced per-task invocation overhead, and they provide a means of bounding and managing the resources, including threads, consumed when executing a collection of tasks. Each ThreadPoolExecutor also maintains some basic statistics, such as the number of completed tasks


Few advantages:


a. You can create/manage/control life cycle of Threads & optimize thread creation cost overheads


b. You can control processing of tasks ( Work Stealing, ForkJoinPool, invokeAll) etc.


c. You can monitor the progress and health of threads


d. Provides better exception handling mechanism 






I have added three methods with parameters:


When I am calling doSomething(null) , then compiler throws error as ambiguous methods. So is the issue because Integer and char[] methods or Integer and Object methods?


Java will always try to use the most specific applicable version of a method that's available (see JLS §15.12.2).


Object, char[] and Integer can all take null as a valid value. Therefore all 3 version are applicable, so Java will have to find the most specific one.


Since Object is the super-type of char[], the array version is more specific than the Object-version. So if only those two methods exist, the char[] version will be chosen.


When both the char[] and Integer versions are available, then both of them are more specific than Object but none is more specific than the other, so Java can't decide which one to call. In this case you'll have to explicitly mention which one you want to call by casting the argument to the appropriate type.


Note that in practice this problem occurs far more seldom than one might think. The reason for this is that it only happens when you're explicitly calling a method with null or with a variable of a rather un-specific type (such as Object).


On the contrary, the following invocation would be perfectly unambiguous:


Although you're still passing the value null, Java knows exactly which method to call, since it will take the type of the variable into account.


Each pair of these three methods is ambiguous by itself when called with a null argument. Because each parameter type is a reference type. 


The following are the three ways to call one specific method of yours with null.


May I suggest to remove this ambiguity if you actually plan to call these methods with null arguments. Such a design invites errors in the future.


null is a valid value for any of the three types; so the compiler cannot decide which function to use. Use something like doSomething((Object)null) or doSomething((Integer)null) instead.


Every class in Java extends Object class.Even Integer class also extends Object. Hence both Object and Integer are considered as Object instance. So when you pass null as a parameter than compiler gets confused that which object method to call i.e. With parameter Object or parameter Integer since they both are object and their reference can be null. But the primitives in java does not extends Object.


I Have tried this and when there is exactly one pair of overloaded method and one of them has a parameter type Object then the compiler will always select the method with more specific type.  But when there is more than one specific type, then the compiler throws an ambiguous method error. 


Since this is a compile time event, this can only happen when one intentionally passes null to this method.  If this is done intentionally then it is better to overload this method again with no parameter or create another method altogether.  






I've tried both the example in Oracle's Java Tutorials. They both compile fine, but at run-time, both come up with this error:


I think I might have the Main.java file in the wrong folder. Here is the directory hierarchy:


And here is Main.java:


What am I doing wrong here?


UPDATE


After I put put the Main class into the graphics package (I added package graphics; to it), set the classpath to "_test" (folder containing graphics), compiled it, and ran it using java graphics.Main (from the command line), it worked.


Really late UPDATE #2


I wasn't using Eclipse (just Notepad++ and the JDK), and the above update solved my problem. However, it seems that many of these answers are for Eclipse and IntelliJ, but they have similar concepts.


After you compile your code, you end up with .class files for each class in your program. These binary files are the bytecode that Java interprets to execute your program. The NoClassDefFoundError indicates that the classloader (in this case java.net.URLClassLoader), which is responsible for dynamically loading classes, cannot find the .class file for the class that you're trying to use. 


Your code wouldn't compile if the required classes weren't present (unless classes are loaded with reflection), so usually this exception means that your classpath doesn't include the required classes. Remember that the classloader (specifically java.net.URLClassLoader) will look for classes in package a.b.c in folder a/b/c/ in each entry in your classpath. NoClassDefFoundError can also indicate that you're missing a transitive dependency of a .jar file that you've compiled against and you're trying to use.


For example, if you had a class com.example.Foo, after compiling you would have a class file Foo.class. Say for example your working directory is .../project/. That class file must be placed in .../project/com/example, and you would set your classpath to .../project/.


Side note: I would recommend taking advantage of the amazing tooling that exists for Java and JVM languages. Modern IDE's like Eclipse and IDEA and build management tools like Maven or Gradle will help you not have to worry about classpaths (as much) and focus on the code! That said, this link explains how to set the classpath when you execute on the command line.


I'd like to correct the perspective of others on NoClassDefFoundError.


NoClassDefFoundError can occur for multiple reasons like


In the original question, it was the first case which can be corrected by setting CLASSPATH to the referenced classes jar file or to its package folder. 


What it means by saying "available in compile time"? 


What it means by saying "not available at compile time"?


NoClassDefFoundError means that the class is present in the classpath at Compile time, but it doesn't exist in the classpath at Runtime.


If you're using Eclipse, make sure you have the shapes, linepoints and the spaceobjects as entries in the .classpath file.


If you are getting NoClassDefFoundError for some external jar file that you have added to the project, try adding the jar file in lib folder and add it to the classpath by Properties >> Java Build Path >> Add Variable >> Configure Variables >> New Variable Entry. And rebuild.


if you got one of these error while compiling and running:


NoClassDefFoundError


Error: Could not find or load main class hello


Exception in thread "main" java.lang.NoClassDefFoundError: javaTest/test/hello (
wrong name: test/hello)
    at java.lang.ClassLoader.defineClass1(Native Method)
    at java.lang.ClassLoader.defineClass(Unknown Source)
    at java.security.SecureClassLoader.defineClass(Unknown Source)
    at java.net.URLClassLoader.defineClass(Unknown Source)
    at java.net.URLClassLoader.access$100(Unknown Source)
    at java.net.URLClassLoader$1.run(Unknown Source)
    at java.net.URLClassLoader$1.run(Unknown Source)
    at java.security.AccessController.doPrivileged(Native Method)
    at java.net.URLClassLoader.findClass(Unknown Source)
    at java.lang.ClassLoader.loadClass(Unknown Source)
    at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)
    at java.lang.ClassLoader.loadClass(Unknown Source)
    at sun.launcher.LauncherHelper.checkAndLoadMain(Unknown Source)


-------------------------- SOLUTIION -----------------------


the problem is mostly in packages orgnization. You should arrange your classes in folders properly regarding to the package classifications in your source code.


indicates, that something was found at compiletime but not at runtime. maybe you just have to add it to the classpath.


This sometimes occur in IntelliJ IDEA after a major refactoring.


Right click on your project and select -> Compile Module, and then re-start the project and it should work again.


No Class Definition Exception occurs when the intended class is not found in the Class Path.
At Compile Time Class : Class was generated from Java Compiler, But Somehow
at Run Time the Dependent Class is not found.


Lets go through one Simple Example :


}


Now Lets assume that the above two Java Source Code are placed in some Folder let say "NoClassDefinationFoundExceptionDemo"


Now open a shell(Assuming Java is already being setup correctly)


NoClassDefFoundError in Java:


Definition: 


NoClassDefFoundError will come if a class was present during compile time but not available in java classpath during runtime. Normally you will see below line in log when you get NoClassDefFoundError:
Exception in thread "main" java.lang.NoClassDefFoundError


Possible Causes:


The class is not available in Java Classpath.


You might be running your program using jar command and class was not defined in manifest file's ClassPath attribute.


Any start-up script is overriding Classpath environment variable.


Because NoClassDefFoundError is a subclass of java.lang.LinkageError it can also come if one of it dependency like native library may not available.


Check for java.lang.ExceptionInInitializerError in your log file. NoClassDefFoundError due to the failure of static initialization is quite common.


If you are working in J2EE environment than the visibility of Class among multiple Classloader can also cause java.lang.NoClassDefFoundError, see examples and scenario section for detailed discussion.


Possible Resolutions:


Verify that all required Java classes are included in the application’s classpath. The most common mistake is not to include all the necessary classes, before starting to execute a Java application that has dependencies on some external libraries.


The classpath of the application is correct, but the Classpath environment variable is overridden before the application’s execution.


Verify that the aforementioned ExceptionInInitializerError does not appear in the stack trace of your application.


Resources: 


3 ways to solve java.lang.NoClassDefFoundError in Java J2EE


java.lang.NoClassDefFoundError – How to solve No Class Def Found Error



If your project is in a package like com.blahcode and your class is called Main, the compiled files may be output in a directory structure like ./out/com/blahcode/Main.class. This is especially true for IntelliJ IDEA.


When trying to run from a shell or cmd, you need to cd to that which contains com as a sub-directory.


Make sure that you type the class name correctly. I was getting this error because I didn't start the class name with an upper case letter


After working on a NetBeans project for many months, I suddenly got the NoClassDefFoundError message shortly after getting a "Low Memory" alert. Doing a Clean rebuild didn't help, but closing Netbeans altogether and reopening the project there were no error reports.


This answer is specific to a java.lang.NoClassDefFoundError happening in a service:


My team recently saw this error after upgrading an rpm that supplied a service.  The rpm and the software inside of it had been built with Maven, so it seemed that we had a compile time dependency that had just not gotten included in the rpm.  


However, when investigating, the class that was not found was in the same module as several of the classes in the stack trace.  Furthermore, this was not a module that had only been recently added to the build.  These facts indicated it might not be a Maven dependency issue.


The eventual solution: Restart the service!


It appears that the rpm upgrade invalidated the service's file handle on the underlying jar file.  The service then saw a class that had not been loaded into memory, searched for it among its list of jar file handles, and failed to find it because the file handle that it could load the class from had been invalidated.  Restarting the service forced it to reload all of its file handles, which then allowed it to load that class that had not been found in memory right after the rpm upgrade.


Hope that specific case helps someone.


Well..i had the same error after add to classpath. The solution i found was delete the bin folder for my project. After that the folder was created automatically only with the manifest file...and then the error is gone.


I hope it help.


My two cents in this chain:


Ensure that the classpath contains full paths (/home/user/lib/some_lib.jar instead of ~/lib/some_lib.jar) otherwise you can still face NoClassDefFoundError error.


I get NoClassFoundError when classes loaded by the runtime class loader cannot access classes already loaded by the java rootloader.  Because the different class loaders are in different security domains (according to java) the jvm won't allow classes already loaded by the rootloader to be resolved in the runtime loader address space.


Run your program with 'java -javaagent:tracer.jar [YOUR java ARGS]'


It produces output showing the loaded class, and the loader env that loaded the class.  It's very helpful tracing why a class cannot be resolved.


It happens a lot with my genymotion devices.
Make sure you have a good amount of memory available on your drive where Genymotion is installed.


It happened to me in Android Studio.


The solution that worked for me:
just restart the studio.


I had the same issue with my Android development using Android studio.
Solutions provided are general and did not help me ( at least for me).
After hours of research I found following solution and may help to android developers who are doing development using android studio.
modify the setting as below
Preferences ->Build, Execution, Deployment -> Instant Run -> un-check the first option.


With this change I am up and running. 
Hope this will help my dev friends.


check that if you have a static handler in your class, if so, pls remove it or change your code, cause static handler only could be initiated in main thread, the crash could be triggered in this way:


1.firstly create the instance of class in a non-main thread and catch the crash.


2.then call the field method of Class in main thread, you will get the NoClassDefFoundError.


here is the test code:


}


in your onCrete method of Main activity, add test code part:


there is a simple way to fix it using a handlerThread to init handler:  


If you are using more than one module, you should have 


dexOptions {
        preDexLibraries = false
    }


in your build file.


I encountered this problem when working with Apache Axis. Spent hours messing with the classpath/build configuration based on most of the feedback here and in similar threads. Turns out I was missing the necessary supporting XML libraries for certain web service transactions. Added them to the project and all became well


these are extra in my code i removed them 


}


}


then add it into mainfest file and in application tag


after this in your main activity remove appcompactactivity if required and extend your class with activity it will works then.






At work today, I came across the volatile keyword in Java. Not being very familiar with it, I found this explanation: 


Java theory and practice: Managing volatility


Given the detail in which that article explains the keyword in question, do you ever use it or could you ever see a case in which you could use this keyword in the correct manner?


volatile has semantics for memory visibility. Basically, the value of a volatile field becomes visible to all readers (other threads in particular) after a write operation completes on it. Without volatile, readers could see some non-updated value.


To answer your question: Yes, I use a volatile variable to control whether some code continues a loop. The loop tests the volatile value and continues if it is true. The condition can be set to false by calling a "stop" method. The loop sees false and terminates when it tests the value after the stop method completes execution.


The book "Java Concurrency in Practice," which I highly recommend, gives a good explanation of volatile. This book is written by the same person who wrote the IBM article that is referenced in the question (in fact, he cites his book at the bottom of that article). My use of volatile is what his article calls the "pattern 1 status flag."


If you want to learn more about how volatile works under the hood, read up on the Java memory model. If you want to go beyond that level, check out a good computer architecture book like Hennessy & Patterson and read about cache coherence and cache consistency.


“… the volatile modifier guarantees that any thread that reads a field will see the most recently written value.” - Josh Bloch
If you are thinking about using volatile, read up on the package java.util.concurrent which deals with atomic behaviour.
The Wikipedia post on a Singleton Pattern shows volatile in use.


Important point about volatile: 


source


Example usage of volatile: 


We are creating instance lazily at the time of first request comes.


If we do not make the _instance variable volatile than the Thread which is creating instance of Singleton is not able to communicate other thread, that instance has been created until it comes out of the Singleton block, so if Thread A is creating Singleton instance and just after creation lost the CPU, all other thread will not be able to see value of _instance as not null and they will believe its still null.  


Why? because reader threads are not doing any locking and until writer thread comes out of synchronized block, memory will not be synchronized and value of _instance will not be updated in main memory. With Volatile keyword in Java this is handled by Java himself and such updates will be visible by all reader threads.  


Conclusion: volatile keyword is also used to communicate content of memory between threads.  


Example usage of without volatile:


The code above is not thread-safe. Although it checks the value of instance once again within the synchronized block (for performance reasons), the JIT compiler can rearrange the bytecode in a way that the reference to instance is set before the constructor has finished its execution. This means the method getInstance() returns an object that may not have been initialized completely. To make the code thread-safe, the keyword volatile can be used since Java 5 for the instance variable. Variables that are marked as volatile get only visible to other threads once the constructor of the object has finished its execution completely.
Source





volatile usage in java
The fail-fast iterators are typically implemented using a volatile counter on the list object.


The implementation of fail-safe iterators is typically light-weight.  They typically rely on properties of the specific list implementation's data structures.  There is no general pattern.   


volatile is very useful to stop threads.


Not that you should be writing your own threads, Java 1.6 has a lot of nice thread pools.  But if you are sure you need a thread, you'll need to know how to stop it.


The pattern I use for threads is:


Notice how there's no need for synchronization


When is volatile enough?


If two threads are both reading and writing to a shared variable, then using the volatile keyword for that is not enough. You need to use synchronization in that case to guarantee that the reading and writing of the variable is atomic.


But in case one thread reads and writes the value of a volatile variable, and other threads only read the variable, then the reading threads are guaranteed to see the latest value written to the volatile variable. Without making the variable volatile, this would not be guaranteed.


Performance considerations of using volatile:


Reading and writing of volatile variables causes the variable to be read or written to main memory. Reading from and writing to main memory is more expensive than accessing the CPU cache. Accessing volatile variables also prevent instruction reordering which is a normal performance enhancement technique. Thus, you should only use volatile variables when you really need to enforce visibility of variables.


One common example for using volatile is to use a volatile boolean variable as a flag to terminate a thread.  If you've started a thread, and you want to be able to safely interrupt it from a different thread, you can have the thread periodically check a flag.  To stop it, set the flag to true.  By making the flag volatile, you can ensure that the thread that is checking it will see it has been set the next time it checks it without having to even use a synchronized block.


No one has mentioned the treatment of read and write operation for long and double variable type. Reads and writes are atomic operations for reference variables and for most primitive variables, except for long and double variable types, which must use the volatile keyword to be atomic operations. @link


Yes, volatile must be used whenever you want a mutable variable to be accessed by multiple threads. It is not very common usecase because typically you need to perform more than a single atomic operation (e.g. check the variable state before modifying it), in which case you would use a synchronized block instead.


IMO two important scenarios other than stopping thread in which volatile keyword is used are 


You'll need to use 'volatile' keyword, or 'synchronized' and any other concurrency control tools and techniques you might have at your disposal if you are developing a multithreaded application. Example of such application is desktop apps.


If you are developing an application that would be deployed to application server (Tomcat, JBoss AS, Glassfish, etc) you don't have to handle concurrency control yourself as it already addressed by the application server. In fact, if I remembered correctly the Java EE standard prohibit any concurrency control in servlets and EJBs, since it is part of the 'infrastructure' layer which you supposed to be freed from handling it. You only do concurrency control in such app if you're implementing singleton objects. This even already addressed if you knit your components using frameworkd like Spring.


So, in most cases of Java development where the application is a web application and using IoC framework like Spring or EJB, you wouldn't need to use 'volatile'.


volatile only guarantees that all threads, even themselves, are incrementing. For example: a counter sees the same face of the variable at the same time. It is not used instead of synchronized or atomic or other stuff, it completely makes the reads synchronized. Please do not compare it with other java keywords. As the example shows below volatile variable operations are also atomic they fail or succeed at once.


Even you put volatile or not results will always differ. But if you use AtomicInteger as below results will be always same. This is same with synchronized also.


Yes, I use it quite a lot - it can be very useful for multi-threaded code.  The article you pointed to is a good one.  Though there are two important things to bear in mind:


Absolutely, yes. (And not just in Java, but also in C#.) There are times when you need to get or set a value that is guaranteed to be an atomic operation on your given platform, an int or boolean, for example, but do not require the overhead of thread locking. The volatile keyword allows you to ensure that when you read the value that you get the current value and not a cached value that was just made obsolete by a write on another thread.


Every thread accessing a volatile field will read its current value before continuing, instead of (potentially) using a cached value.


Only member variable can be volatile or transient.


The     volatile key when used with a variable, will make sure that threads reading this variable will see the same value . Now if you have multiple threads reading and writing to a variable, making the variable volatile will not be enough and data will be corrupted . Image threads have read the same value but each one has done some chages (say incremented a counter) , when writing back to the memory, data integrity is violated . That is why it is necessary to make the varible synchronized (diffrent ways are possible)


If the changes are done by 1 thread and the others need just to read this value, the volatile will be suitable.


From oracle documentation page, the need for volatile variable arises to fix memory consistency issues:


Using volatile variables reduces the risk of memory consistency errors, because any write to a volatile variable establishes a happens-before relationship with subsequent reads of that same variable. 


This means that changes to a volatile variable are always visible to other threads. It also means that when a thread reads a volatile variable, it sees not just the latest change to the volatile, but also the side effects of the code that led up the change.


As explained in Peter Parker answer, in absence of volatile modifier, each thread's stack may have their own copy of variable. By making the variable as volatile, memory consistency issues have been fixed. 


Have a look at jenkov tutorial page for better understanding. 


Have a look at related SE question for some more details on volatile & use cases to use volatile:


Difference between volatile and synchronized in Java


One practical use case:


You have many threads, which need to print current time in a particular format for example : java.text.SimpleDateFormat("HH-mm-ss"). Yon can have one class, which converts current time into SimpleDateFormat and updated the variable for every one second. All other threads can simply use this volatile variable to print current time in log files.  


Volatile Variables are light-weight synchronization. When visibility of latest data among all threads is requirement and atomicity can be compromised , in such situations Volatile Variables must be preferred. Read on volatile variables always return most recent write done by any thread since they are neither cached in registers nor in caches where other processors can not see. Volatile is Lock-Free. I use volatile, when scenario meets criteria as mentioned above. For more Lock free and Lock based strategies.


There are two different uses of volatile keyword.


Prevents JVM from reading values in register, and forces its
  value to be read from memory.


A busy flag is used to prevent a thread from continuing while the device is busy and the flag is not protected by a lock:


The testing thread will continue when another thread turns off the busy flag:


However, since busy is accessed frequently in the testing thread, the JVM may optimize the test by placing the value of busy in a register, then test the contents of the register without reading the value of busy in memory before every test. The testing thread would never see busy change and the other thread would only change the value of busy in memory, resulting in deadlock. Declaring the busy flag as volatile forces its value to be read before each test.


Reduces the risk of memory consistency errors.


Using volatile variables reduces the risk of memory consistency errors, because any write to a volatile variable establishes a
"happens-before" relationship with subsequent reads of that same variable. This means that changes to a volatile variable are always visible to other threads.


The technique of reading, writing without memory consistency errors is called atomic action.


An atomic action is one that effectively happens all at once. An atomic action cannot stop in the middle: it either happens completely, or it doesn't happen at all. No side effects of an atomic action are visible until the action is complete.


Below are actions you can specify that are atomic:


Cheers!


A Volatile variable is modified asynchronously by concurrently running threads in a Java application. It is not allowed to have a local copy of a variable that is different from the value currently held in "main" memory. Effectively, a variable declared volatile must have its data synchronized across all threads, so that whenever you access or update the variable in any thread, all other threads immediately see the same value. Of course, it is likely that volatile variables have a higher access and update overhead than "plain" variables, since the reason threads can have their own copy of data is for better efficiency.


When a field is declared volatile, the compiler and runtime  are  put on  notice  that  this  variable  is shared  and  that  operations  on  it  should  not  be  reordered  with  other memory operations.Volatile variables  are  not  cached  in  registers  or  in  caches  where  they  are  hidden  from  other processors, so a read of a volatile variable always returns the most recent write by any thread.


for reference, refer this http://techno-terminal.blogspot.in/2015/11/what-are-volatile-variables.html






I'm getting a NoSuchMethodError error when running my Java program.  What's wrong and how do I fix it?


Without any more information it is difficult to pinpoint the problem, but the root cause is that you most likely have compiled a class against a different version of the class that is missing a method, than the one you are using when running it.


Look at the stack trace ... If the exception appears when calling a method on an object in a library, you are most likely using separate versions of the library when compiling and running. Make sure you have the right version both places.


If the exception appears when calling a method on objects instantiated by classes you made, then your build process seems to be faulty. Make sure the class files that you are actually running are updated when you compile.


I feel your pain.  You can learn programming out of a book, but when it comes to working with Eclipse or Visual Studio, its a ^&^&'n nightmare to do something simple like add a library.  Everybody expects you to know how to use it and if you don't they downvote your question.  The problem is, if you don't work in an office or know anyone who you can ask these questions, then its almost impossible to figure this stuff out.  Anyway...


I was having your problem, and this is how I fixed it.  The following steps are a working way to add a library.  I had done the first two steps right, but I hadn't done the last one by dragging the ".jar" file direct from the file system into the "lib" folder on my eclipse project.  Additionally, I had to remove the previous version of the library from both the build path and the "lib" folder.


If anyone knows of a more proper way to add/update a library, please chime in.











Note that in the case of reflection, you get an NoSuchMethodException, while with non-reflective code, you get NoSuchMethodError. I tend to go looking in very different places when confronted with one versus the other.


If you have access to change the JVM parameters, adding verbose output should allow you to see what classes are being loaded from what JARs.


When your program is run, the JVM should dump to standard out information such as:


...


[Loaded junit.framework.Assert from file:/C:/Program%20Files/junit3.8.2/junit.jar]


...


This is usually caused when using a build system like Apache Ant that only compiles java files when the java file is newer than the class file.  If a method signature changes and classes were using the old version things may not be compiled correctly.  The usual fix is to do a full rebuild (usually "ant clean" then "ant").  


Sometimes this can also be caused when compiling against one version of a library but running against a different version.


This can also be the result of using reflection.  If you have code that reflects on a class and extracts a method by name (eg: with Class.getDeclaredMethod("someMethodName", .....)) then any time that method name changes, such as during a refactor, you will need to remember to update the parameters to the reflection method to match the new method signature, or the getDeclaredMethod call will throw a NoSuchMethodException.


If this is the reason, then the stack trace should show the point that the reflection method is invoked, and you'll just need to update the parameters to match the actual method signature.  


In my experience, this comes up occasionally when unit testing private methods/fields, and using a TestUtilities class to extract fields for test verification.  (Generally with legacy code that wasn't designed with unit testing in mind.)


If using maven or another framework, and you get this error randomly almost, try "clean install", especially if you wrote the object and you know it has the method.  Worked for me.


If you are writing a webapp, ensure that you don't have conflicting versions of a jar in your container's global library directory and also in your app. You may not necessarily know which jar is being used by the classloader.


e.g.  


These problems are caused by the use of the same object at the same two classes.
Objects used does not contain new method has been added that the new object class contains.


ex:


These problems are caused by the concomitant 02 similar class (1 in src, 1 in jar file here is gateway.jar)


It means the respective method is not present in the class: 


For me it happened because I changed argument type in function, from Object a, to String a. I could resolve it with clean and build again


I ran into a similar problem when I was changing method signatures in my application. 
Cleaning and rebuilding my project resolved the "NoSuchMethodError".


Above answer explains very well ..just to add one thing
If you are using using eclipse use ctrl+shift+T and enter package structure of class (e.g. : gateway.smpp.PDUEventListener ), you will find all jars/projects where it's present. Remove unnecessary jars from classpath or add above in class path. Now it will pick up correct one. 


I have just solved this error by restarting my Eclipse and run the applcation.
The reason for my case may because I replace my source files without closing my project or Eclipse.
Which caused different version of classes I was using.


I ran into similar issue.


Finally I identified the root cause was changing the data type of variable. 


We are supposed to rebundle the jar by including only the modified classes. As there was no change in ReportGeneration.java I was only including the Employee.class in Jar file. I had to include the ReportGeneration.class file in the jar to solve the issue.


I've had the same problem. This is also caused when there is an ambiguity in classes. My program was trying to invoke a method which was present in two JAR files present in the same location / class path. Delete one JAR file or execute your code such that only one JAR file is used. Check that you are not using same JAR or different versions of the same JAR that contain the same class.


DISP_E_EXCEPTION [step] [] [Z-JAVA-105  Java exception java.lang.NoSuchMethodError(com.example.yourmethod)]


To answer the original question. According to java docs here:


"NoSuchMethodError" Thrown if an application tries to call a specified method of a class (either static or instance), and that class no longer has a definition of that method.


Normally, this error is caught by the compiler; this error can only occur at run time if the definition of a class has incompatibly changed. 


If your file name is different than the class name which contain main method then it may be the possibility that this error may cause.






How do I import a jar in Eclipse?


You can add a jar in Eclipse by right-clicking on the Project → Build Path → Configure Build Path. Under Libraries tab, click Add Jars or Add External JARs and give the Jar. A quick demo here.





The above solution is obviously a "Quick" one. However, if you are working on a project where you need to commit files to the source control repository, I would recommend adding Jar files to a dedicated library folder within your source control repository and referencing few or all of them as mentioned above.


Adding external Jar is not smart in case you want to change the project location in filesystem.


The best way is to add the jar to build path so your project will compile if exported:


Create a folder called lib in your project folder.


copy to this folder all the jar files you need.


Refresh your project in eclipse.


Select all the jar files, then right click on one of them and select Build Path -> Add to Build Path


Two choices:


1/ From the project:





2/ If you have already other jar imported, from the directory "References Libraries":





Both will lead you to this screen where you can mange your libraries:





Here are the steps:


click File > Import. The Import window opens.


Under Select an import source, click J2EE > App Client JAR file.


Click Next.


In the Application Client file field, enter the location and name of the application client JAR file that you want to import. You can click the Browse button to select the JAR file from the file system.


In the Application Client project field, type a new project name or select an application client project from the drop-down list. If you type a new name in this field, the application client project will be created based on the version of the application client JAR file, and it will use the default location.


In the Target runtime drop-down list, select the application server that you want to target for your development. This selection affects the run time settings by modifying the class path entries for the project.


If you want to add the new module to an enterprise application project, select the Add project to an EAR check box and then select an existing enterprise application project from the list or create a new one by clicking New.


Note: If you type a new enterprise application project name, the enterprise application project will be created in the default location with the lowest compatible J2EE version based on the version of the project being created. If you want to specify a different version or a different location for the enterprise application, you must use the New Enterprise Application Project wizard.


Click Finish to import the application client JAR file.


Just a comment on importing jars into Eclipse (plug-in development) projects:


In case you are developing Eclipse plug-ins, it makes sense to use Eclipse's native bundling mechanism instead of just importing the jar into a plug-in project. Eclipse (or better its underlying OSGi runtime, Equinox) uses so-called bundles which contain some more information than plain jars (e.g., version infos, dependencies to other bundles, exported packages; see the MANIFEST.MF file). Because of this information, OSGi bundles can be dynamically loaded/unloaded and there is automatic dependency resolution available in an OSGi/Eclipse runtime. Hence, using OSGi bundles instead of plain jars (contained inside another OSGi bundle) has some advantages. 


(BTW: Eclipse plug-ins are the same thing as OSGi bundles.)


There is a good chance that somebody already bundled a certain (3rd party) library as an OSGi bundle. You might want to take a look at the following bundle repositories:


Eclipse -> Preferences -> Java -> Build Path -> User Libraries -> New(Name it) -> Add external Jars


(I recommend dragging your new libraries into the eclipse  folder before any of these steps to keep everything together, that way if you reinstall Eclipse or your OS you won't have to rwlink anything except the JDK) Now select the jar files you want. Click OK. 


Right click on your project and choose Build Path -> Add Library


FYI just code and then right click and Source->Organize Imports






This question already has an answer here:


I am trying to parse this date with SimpleDateFormat and it is not working:


If I try this code with strDate="2008-10-14", I have a positive answer. What's the problem? How can I parse this format?


PS. I got this date from a jDatePicker and there is no instruction on how modify the date format I get when the user chooses a date.


You cannot expect to parse a date with a SimpleDateFormat that is set up with a different format.  


To parse your "Thu Jun 18 20:56:02 EDT 2009" date string you need a SimpleDateFormat like this (roughly):


Use this to parse the string into a Date, and then your other SimpleDateFormat to turn that Date into the format you want.


JavaDoc: http://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html


The problem is that you have a date formatted like this:


But are using a SimpleDateFormat that is:


The two formats don't agree.  You need to construct a SimpleDateFormat that matches the layout of the string you're trying to parse into a Date.  Lining things up to make it easy to see, you want a SimpleDateFormat like this:


Check the JavaDoc page I linked to and see how the characters are used.


We now have a more modern way to do this work.


The java.time framework is bundled with Java 8 and later. See Tutorial. These new classes are inspired by Joda-Time, defined by JSR 310, and extended by the ThreeTen-Extra project. They are a vast improvement over the troublesome old classes, java.util.Date/.Calendar et al.


Note that the 3-4 letter codes like EDT are neither standardized nor unique. Avoid them whenever possible. Learn to use ISO 8601 standard formats instead. The java.time framework may take a stab at translating, but many of the commonly used codes have duplicate values.


By the way, note how java.time by default generates strings using the ISO 8601 formats but extended by appending the name of the time zone in brackets.


Dump to console.


When run.


zdt : 2009-06-18T20:56:02-04:00[America/New_York]


For fun let's adjust to the India time zone.


zdtKolkata : 2009-06-19T06:26:02+05:30[Asia/Kolkata]


If you really need a java.util.Date object for use with classes not yet updated to the java.time types, convert. Note that you are losing the assigned time zone, but have the same moment automatically adjusted to UTC.


How about getSelectedDate? Anyway, specifically on your code question, the problem is with this line:


The string that goes in the constructor has to match the format of the date. The documentation for how to do that is here. Looks like  you need something close to "EEE MMM d HH:mm:ss zzz yyyy" 


In response to:
"How to convert Tue Sep 13 2016 00:00:00 GMT-0500 (Hora de verano central (México)) to dd-MM-yy in Java?", it was marked how duplicate


Try this:
With java.util.Date, java.text.SimpleDateFormat, it's a simple solution. 






Consider the following example.


Now, in Java, String objects are immutable. Then how come the object str can be assigned value "Help!". Isn't this contradicting the immutability of strings in Java? Can anybody please explain me the exact concept of immutability?


Edit:


Ok. I am now getting it, but just one follow-up question. What about the following code: 


Does this mean that two objects are created again ("Mississippi" and "M!ss!ss!pp!") and the reference str points to a different object after replace() method? 


str is not an object, it's a reference to an object. "Hello" and "Help!" are two distinct String objects. Thus, str points to a string. You can change what it points to, but not that which it points at.


Take this code, for example:


Now, there is nothing1 we could do to s1 that would affect the value of s2. They refer to the same object - the string "Hello" - but that object is immutable and thus cannot be altered. 


If we do something like this:


Here we see the difference between mutating an object, and changing a reference. s2 still points to the same object as we initially set s1 to point to. Setting s1 to "Help!" only changes the reference, while the String object it originally referred to remains unchanged. 


If strings were mutable, we could do something like this: 


Edit to respond to OP's edit:


If you look at the source code for String.replace(char,char) (also available in src.zip in your JDK installation directory -- a pro tip is to look there whenever you wonder how something really works) you can see that what it does is the following:


So yes, "Mississippi".replace('i', '!') creates a new String object. Again, the following holds:


Your homework for now is to see what the above code does if you change s1 = s1.replace('i', '!'); to s1 = s1.replace('Q', '!'); :)


1 Actually, it is possible to mutate strings (and other immutable objects). It requires reflection and is very, very dangerous and should never ever be used unless you're actually interested in destroying the program.


The object that str references can change, but the actual String objects themselves cannot.


The String objects containing the string "Hello" and "Help!" cannot change their values, hence they are immutable.


The immutability of String objects does not mean that the references pointing to the object cannot change.


One way that one can prevent the str reference from changing is to declare it as final:


Now, trying to assign another String to STR will cause a compile error.


Light_handle I recommend you take a read of Cup Size -- a story about variables and Pass-by-Value Please (Cup Size continued). This will help a lot when reading the posts above. 


Have you read them? Yes. Good. 


This creates a new "remote control" called "str" and sets that to the value new String() (or "").


e.g. in memory this creates:


This then changes the remote control "str" but does not modify the original string "".


e.g. in memory this creates:


This then changes the remote control "str" but does not modify the original string "" or the object that the remote control currently points to.


e.g. in memory this creates:


The string object that was first referenced by str was not altered, all that you did was make str refer to a new string object.


Lets break it into some parts


This Statement creates string containing hello and occupy space in memory i.e. in Constant String Pool and and assigned it to reference object s1


This statement assigns the same string hello to new reference s2


Both references are pointing to the same string so output the same value as follows.


Though String is immutable, assignment can be possible so the s1 will now refer to new value stack.


But what about s2 object which is pointing to hello it will be as it is.


Since String is immutable Java Virtual Machine won't allow us to modify string s1 by its method. It will create all new String object in pool as follows.


Note if String would be mutable then the output would have been 


Now you might be surprised why String has such methods like concat() to modify. Following snippet will clear your confusion.    


Here we are assigning modified value of string back to s1 reference.


That's why Java decided String to be a final class Otherwise anyone can modify and change the value of string.
Hope this will help little bit.


The String will not change, the reference to it will.  You are confusing immutability with the concept of final fields.  If a field is declared as final, once it has been assigned, it cannot be reassigned.


Regarding the replace part of your question, try this:


Immutability implies that the value of an instantiated object cannot change, you can never turn "Hello" into "Help!".


The variable str is a reference to an object, when you assign a new value to str you aren't changing the value of the object it references, you are referencing a different object.


Though java tries to ignore it, str is nothing more than a pointer. This means that when you first write str = "Hello";, you create an object that str points to. When you reassign str by writing str = "Help!";, a new object is created and the old "Hello" object gets garbage collected whenever java feels like it.


Use:


If you see here I use the concat method to change the original string, that is, "New String" with a string " Added String", but still I got the output as previous, hence it proves that you can not change the reference of object of String class, but if you do this thing by StringBuilder class it will work. It is listed below.


String class is immutable, and you can not change value of immutable object.
But in case of String, if you change the value of string than it will create new string in string pool and than your string reference to that value not the older one. so by this way string is immutable.
Lets take your example,


it will create one string "Mississippi" and will add it to String pool
so now str is pointing to Mississippi.


But after above operation,
one another string will be created "M!ss!ss!pp!"
and it will be add to String pool. and 
now str is pointing to M!ss!ss!pp!, not Mississippi.


so by this way when you will alter value of string object it will create one more object and will add it to string pool.


Lets have one more example 


this above three line will add three objects of string to string pool.
1) Hello
2) World
3) HelloWorld


String in Java in Immutable and Final just mean it can't be changed or modified:


Case 1:


Output: ABC


Reason: The object reference str is not changed in fact a new object
  "DEF" is created which is in the pool and have no reference at all
  (i.e lost).


Case 2:


Output: ABCDEF


Reason: In this case str is now referring to a new object "ABCDEF"
  hence it prints ABCDEF i.e. previous str object "ABC" is lost in pool with no reference.


Like Linus Tolvards said:


Talk is cheap. Show me the code


Take a look at this:


The output is


So, remember two things:


For those wondering how to break String immutability in Java...


Code


Output


String is immutable. Which means that we can only change the reference.


In Java, objects are generally accessed by references. In your piece of code str is a reference which is first assigned to "Hello" (an automatic created object or fetched from constant pool) and then you assigned another object "Help!" to same reference. A point to note is the reference is the same and modified, but objects are different. One more thing in your code you accessed three objects,


Calling new String() creates a new object even if it exists in string pool, so generally it should not be used. To put a string created from new String () into string pool you can try the intern() method.


I hope this helps.


Immutability I can say is that you cannot change the String itself. Suppose you have String x, the value of which is "abc". Now you cannot change the String, that is, you cannot change any character/s in "abc".


If you have to change any character/s in the String, you can use a character array and mutate it or use StringBuilder.


Output:


Or you can try:


This will show how the hashcode changes.


String is immutable means that you cannot change the object itself, but you can change the reference to the object. When you called a = "ty", you are actually changing the reference of a to a new object created by the String literal "ty". Changing an object means to use its methods to change one of its fields (or the fields are public and not final, so that they can be updated from outside without accessing them via methods), for example:


While in an immutable class (declared as final, to prevent modification via inheritance)(its methods cannot modify its fields, and also the fields are always private and recommended to be final), for example String, you cannot change the current String but you can return a new String, i.e:


Here immutability means that instance can point to other reference but the original content of the string would not be modified at the original reference.
Let me explain by first example given by you.
First str is pointing to "Hello" ,its Ok upto this.
Second time its pointing to "Help!". 
Here str started  pointing to "Help!" and the reference of "Hello" string is lost and we can not get that back.


In fact when str would try to modify the existing content,then another new string will be generated and str will start to point at that reference.
So we see that string at original reference is not modified but that is safe at its reference and instance of object started pointing at different reference so immutability is conserve.


Super late to the answer, but wanted to put a concise message from author of the String class in Java 


Strings are constant; their values cannot be changed after they are
  created. String buffers support mutable strings. Because String
  objects are immutable they can be shared.


It can be derived from this documentation that anything that changes string, returns different object (which could be new or interned and old).
The not so subtle hint about this should come from the function signature.
Think about it, 'Why did they make a function on an object return an object instead of status?'.


Also one more source which makes this behaviour explicit (From replace function documentation)


Returns a new string resulting from replacing all occurrences of
  oldChar in this string with newChar.


Source: https://docs.oracle.com/javase/7/docs/api/java/lang/String.html#replace(char,%20char)


Source: JavaDoc of String.


The Object string - methods itself is made to be "immutable".
This action produces no changes: "letters.replace("bbb", "aaa");" 


But assigning data does cause changes to the Strings content to change:


//The hashcode of the string Object doesn't change.






It is much more convenient and cleaner to use a single statement like


than to import a bunch of individual classes


What is wrong with using a wildcard in the import statement?


The only problem with it is that it clutters your local namespace.  For example, let's say that you're writing a Swing app, and so need java.awt.Event, and are also interfacing with the company's calendaring system, which has com.mycompany.calendar.Event.  If you import both using the wildcard method, one of these three things happens:


The advantage of explicitly listing all imports is that I can tell at a glance which class you meant to use, which simply makes reading the code that much easier. If you're just doing a quick one-off thing, there's nothing explicitly wrong, but future maintainers will thank you for your clarity otherwise.


Here's a vote for star imports.  An import statement is intended to import a package, not a class.  It is much cleaner to import entire packages; the issues identified here (e.g. java.sql.Date vs java.util.Date) are easily remedied by other means, not really addressed by specific imports and certainly do not justify insanely pedantic imports on all classes.  There is nothing more disconcerting than opening a source file and having to page through 100 import statements.


Doing specific imports makes refactoring more difficult; if you remove/rename a class, you need to remove all of its specific imports.  If you switch an implementation to a different class in the same package, you have to go fix the imports.  While these extra steps can be automated, they are really productivity hits for no real gain.


If Eclipse didn't do class imports by default, everyone would still be doing star imports.  I'm sorry, but there's really no rational justification for doing specific imports. 


Here's how to deal with class conflicts:


please see my article Import on Demand is Evil


In short, the biggest problem is that your code can break when a class is added to a package you import. For example:


In Java 1.1, this was fine; List was found in java.awt and there was no conflict.


Now suppose you check in your perfectly working code, and a year later someone else brings it out to edit it, and is using Java 1.2.


Java 1.2 added an interface named List to java.util. BOOM! Conflict. The perfectly working code no longer works.


This is an EVIL language feature. There is NO reason that code should stop compiling just because a type is added to a package...


In addition, it makes it difficult for a reader to determine which "Foo" you're using.


It's not bad to use a wild card with a Java import statement.


In Clean Code, Robert C. Martin actually recommends using them to avoid long import lists.


Here is the recommendation:


J1: Avoid Long Import Lists by Using
  Wildcards


If you use two or more classes from a
  package, then import the whole package
  with


import package.*;


Long lists of imports are daunting to
  the reader. We don’t want to clutter
  up the tops of our modules with 80
  lines of imports. Rather we want the
  imports to be a concise statement
  about which packages we collaborate
  with.


Specific imports are hard
  dependencies, whereas wildcard imports
  are not. If you specifically import a
  class, then that class must exist. But
  if you import a package with a
  wildcard, no particular classes need
  to exist. The import statement simply
  adds the package to the search path
  when hunting for names. So no true
  dependency is created by such imports,
  and they therefore serve to keep our
  modules less coupled.


There are times when the long list of
  specific imports can be useful. For
  example, if you are dealing with
  legacy code and you want to find out
  what classes you need to build mocks
  and stubs for, you can walk down the
  list of specific imports to find out
  the true qualified names of all those
  classes and then put the appropriate
  stubs in place. However, this use for
  specific imports is very rare.
  Furthermore, most modern IDEs will
  allow you to convert the wildcarded
  imports to a list of specific imports
  with a single command. So even in the
  legacy case it’s better to import
  wildcards.


Wildcard imports can sometimes cause
  name conflicts and ambiguities. Two
  classes with the same name, but in
  different packages, will need to be
  specifically imported, or at least
  specifically qualified when used. This
  can be a nuisance but is rare enough
  that using wildcard imports is still
  generally better than specific
  imports.


It clutters your namespace, requiring you to fully specify any classnames that are ambiguous. The most common occurence of this is with:


It also helps make your dependencies concrete, as all of your dependencies are listed at the top of the file.


Performance: No impact on performance as byte code is same.
though it will lead to some compile overheads.


Compilation: on my personal machine, Compiling a blank class without importing anything takes 100 ms but same class when import java.* takes 170 ms.


Most places I've worked that use any significant amount of Java make explicit imports part of the coding standard.  I sometimes still use * for quick prototyping and then expand the import lists (some IDEs will do this for you as well) when productizing the code.


I prefer specific imports, because it allows me to see all the external references used in the file without looking at the whole file.  (Yes, I know it won't necessarily show fully qualified references.  But I avoid them whenever possible.)


In a previous project I found that changing from *-imports to specific imports reduced compilation time by half (from about 10 minutes to about 5 minutes). The *-import makes the compiler search each of the packages listed for a class matching the one you used. While this time can be small, it adds up for large projects.


A side affect of the *-import was that developers would copy and paste common import lines rather than think about what they needed.


In DDD book


In whatever development technology the implementation will be based on, look for ways of minimizing the
  work of refactoring MODULES . In Java, there is no escape from importing into individual classes, but you
  can at least import entire packages at a time, reflecting the intention that packages are highly cohesive units
  while simultaneously reducing the effort of changing package names.


And if it clutters local namespace its not your fault - blame the size of the package.


The most important one is that importing java.awt.* can make your program incompatible with a future Java version: 


Suppose that you have a class named "ABC", you're using JDK 8 and you import java.util.*. Now, suppose that Java 9 comes out, and it has a new class in package java.util that by coincidence also happens to be called "ABC". Your program now will not compile on Java 9, because the compiler doesn't know if with the name "ABC" you mean your own class or the new class in java.awt. 


You won't have that problem when you import only those classes explicitly from java.awt that you actually use. 


Resources:


Java Imports






This question already has an answer here:


I switched lecturers today and he stated using a weird code to me. (He said it's better to use .equals and when I asked why, he answered "because it is!")


So here's an example:


Instead of what I'm used to:


What's the difference between the two. And why is his way (using .equals) better?


Found this on a quick search but I can't really make sense of that answer:


In Java, == always just compares two references (for non-primitives, that is) - i.e. it tests whether the two operands refer to the same object.


However, the equals method can be overridden - so two distinct objects can still be equal.


For example:


Additionally, it's worth being aware that any two equal string constants (primarily string literals, but also combinations of string constants via concatenation) will end up referring to the same string. For example:


Here x and y are references to the same string, because y is a compile-time constant equal to "hello".


The == operator compares if the objects are the same instance. The equals() oerator compares the state of the objects (e.g. if all attributes are equal). You can even override the equals() method to define yourself when an object is equal to another.


If you and I each walk into the bank, each open a brand new account, and each deposit $100, then...


(Assuming appropriate definitions of the Account class, of course. ;-)


== is an operator. equals is a method defined in the Object class


== checks if two objects have the same address in the memory and for primitive it checks if they have the same value.equals method on the other hand checks if the two objects which are being compared have an equal value(depending on how ofcourse the equals method has been implemented for the objects. equals method cannot be applied on primitives(which means that 
if a is a primitive a.equals(someobject) is not allowed, however someobject.equals(a) is allowed).


== operator compares two object references to check whether they refer to same instance. This also, will return true on successful match.for example


above example ==  is a reference comparison i.e. both objects point to the same memory location


String equals() is  evaluates to the comparison of values in the objects.


above  example It compares the content of the strings. It will return true if string matches, else returns false.


In Java, when the “==” operator is used to compare 2 objects, it checks to see if the objects refer to the same place in memory. EX:


Even though the strings have the same exact characters (“xyz”), The code above will actually output:
 obj1==obj2 is FALSE


Java String class actually overrides the default equals() implementation in the Object class – and it overrides the method so that it checks only the values of the strings, not their locations in memory. This means that if you call the equals() method to compare 2 String objects, then as long as the actual sequence of characters is equal, both objects are considered equal. 


This code will output the following:


obj1==obj2 is TRUE


Here in this code u can campare the both '==' and '.equals'


here .equals is used to compare the reference objects and '==' is used to compare state of objects..


(1) == can be be applied for both primitives and object types, but equals() method can be applied for only object types.


(2) == cannot be overridden for content comparison, but equals method can be overridden for content comparison(ex; String class, wrapper classes, collection classes).


(3) == gives incomparable types error when try to apply for heterogeneous types , where as equals method returns false.


The equals( ) method and the == operator perform two different operations. The equals( ) method compares the characters inside a String object. The == operator compares two object references to see whether they refer to the same instance. The following program shows how two different String objects can contain the same characters, but references to these objects will not compare as equal:


The variable s1 refers to the String instance created by “Hello”. The object referred to by
s2 is created with s1 as an initializer. Thus, the contents of the two String objects are identical,
but they are distinct objects. This means that s1 and s2 do not refer to the same objects and
are, therefore, not ==, as is shown here by the output of the preceding example:


Lets say that "==" operator returns true if both both operands belong to same object but when it will return true as we can't assign a single object multiple values


Now when this happens practically speaking, If its not happen then why this is == compares functionality....


Here is a simple interpretation about your problem:


== (equal to) used to evaluate arithmetic expression


where as


equals() method used to compare string


Therefore, it its better to use == for numeric operations & equals() method for String related operations. So, for comparison of objects the equals() method would be right choice.






I attempted to create a calculator, but I can not get it to work because I don't know how to get user input.


How can I get the user input in Java?


One of the simplest ways is to use a Scanner object as follows:


You can use any of the following options based on the requirements.


The readLine method from the DataInputStream class has been deprecated. To get String value, you should use the previous solution with BufferedReader


Apparently, this method does not work well in some IDEs.


You can use the Scanner class or the Console class


You can get user input using BufferedReader.


It will store a String value in accStr so you have to parse it to an int using Integer.parseInt.


Here is how you can get the keyboard inputs:


You can make a simple program to ask for user's name and print what ever the reply use inputs.


Or ask user to enter two numbers and you can add, multiply, subtract, or divide those numbers and print the answers for user inputs just like a behavior of a calculator.


So there you need Scanner class. You have to import java.util.Scanner; and in the code you need to use 


Input is a variable name.


See how this differs: input.next();, i = input.nextInt();, d = input.nextDouble();


According to a String, int and a double varies same way for the rest. Don't forget the import statement at the top of your code.


Also see the blog post "Scanner class and getting User Inputs".


To read a line or a string, you can use a BufferedReader object combined with an InputStreamReader one as follows:


Here, the program asks the user to enter a number. After that, the program prints the digits of the number and the sum of the digits.


Use the System class to get the input.


http://fresh2refresh.com/java-tutorial/java-input-output/ :


We need three objects,


BufferedReader


Here is your program from the question using java.util.Scanner:


Just one extra detail.  If you don't want to risk a memory/resource leak, you should close the scanner stream when you are finished:


Note that java 1.7 and later catch this as a compile warning (don't ask how I know that  :-)


Add throws IOException beside main(), then


It is very simple to get input in java, all you have to do is:


You can get user input like this using a BufferedReader: 


This is how you apply them


So when the user types in his name into the console, "String name" will store that information.


If it is a number you want to store, the code will look like this:


Hop this helps!


Can be something like this...


Here is a more developed version of the accepted answer that addresses two common needs:


Code


Example


Note that without nextLine(), the bad input will trigger the same exception repeatedly in an infinite loop.  You might want to use next() instead depending on the circumstance, but know that input like this has spaces will generate multiple exceptions.


This is a simple code that uses the System.in.read() function. This code just writes out whatever was typed. You can get rid of the while loop if you just want to take input once, and you could store answers in a character array if you so choose.


I like the following: 


and for example, I would do:






I'm looking for a simple commons method or operator that allows me to repeat some String n times. I know I could write this using a for loop, but I wish to avoid for loops whenever necessary and a simple direct method should exist somewhere.


Related to:


repeat string javascript
Create NSString by repeating another string a given number of times


Edited


I try to avoid for loops when they are not completely necessary because:


They add to the number of lines of code even if they are tucked away in another function.


Someone reading my code has to figure out what I am doing in that for loop. Even if it is commented and has meaningful variables names, they still have to make sure it is not doing anything "clever".


Programmers love to put clever things in for loops, even if I write it to "only do what it is intended to do", that does not preclude someone coming along and adding some additional clever "fix".


They are very often easy to get wrong. For loops involving indexes tend to generate off by one bugs.


For loops often reuse the same variables, increasing the chance of really hard to find scoping bugs.


For loops increase the number of places a bug hunter has to look.


This is as simple as it gets:


In Java 8 there is an even easier way:


Here is the shortest version (Java 1.5+ required):


Where n is the number of times you want to repeat the string and s is the string to repeat.


No imports or libraries needed.


Commons Lang StringUtils.repeat()


Usage:


Java 8's String.join provides a tidy way to do this in conjunction with Collections.nCopies:


Here's a way to do it using only standard String functions and no explicit loops:


If you're like me and want to use Google Guava and not Apache Commons. You can use the repeat method in the Guava Strings class.


With java-8, you can also use Stream.generate.


and you can wrap it in a simple utility method if needed:


So you want to avoid loops?


Here you have it:


(of course I know this is ugly and inefficient, but it doesn't have loops :-p)


You want it simpler and prettier? use jython:


Edit: let's optimize it a little bit :-D


Edit2: I've done a quick and dirty benchmark for the 4 main alternatives, but I don't have time to run it several times to get the means and plot the times for several inputs... So here's the code if anybody wants to try it:


It takes 2 arguments, the first is the number of iterations (each function run with repeat times arg from 1..n) and the second is the string to repeat.


So far, a quick inspection of the times running with different inputs leaves the ranking something like this (better to worse):


I wouldn't ever guessed that the recursive function was faster than the for loop :-o


Have fun(ctional xD).


This contains less characters than your question


based on fortran's answer, this is a recusive version that uses a StringBuilder:


using Dollar is simple as typing:


PS: repeat works also for array, List, Set, etc


I wanted a function to create a comma-delimited list of question marks for JDBC purposes, and found this post. So, I decided to take two variants and see which one performed better. After 1 million iterations, the garden-variety StringBuilder took 2 seconds (fun1), and the cryptic supposedly more optimal version (fun2) took 30 seconds. What's the point of being cryptic again?


using only JRE classes (System.arraycopy) and trying to minimize the number of temp objects you can write something like:


EDIT


and without loops you can try with:


EDIT 2


using Collections is even shorter:


however I still like the first version.


Nearly every answer proposes a static function as a solution, but thinking Object-Oriented (for reusability-purposes and clarity) I came up with a Solution via Delegation through the CharSequence-Interface (which also opens up usability on mutable CharSequence-Classes).


The following Class can be used either with or without Separator-String/CharSequence and each call to "toString()" builds the final repeated String.
The Input/Separator are not only limited to String-Class, but can be every Class which implements CharSequence (e.g. StringBuilder, StringBuffer, etc)!


If you are worried about performance, just use a StringBuilder inside the loop and do a .toString() on exit of the Loop. Heck, write your own Util Class and reuse it. 5 Lines of code max.


I really enjoy this question. There is a lot of knowledge and styles. So I can't leave it without show my rock and roll  ;)


Do you like it?


Simple loop


Using recursion, you can do the following (using ternary operators, one line max):


I know, it's ugly and probably not efficient, but it's one line!


for the sake of readability and portability:


Despite your desire not to use loops, I think you should use a loop.


Your reasons for not using a for loop are not good ones.  In response to your criticisms:


Try this out:    


I created a recursive method that do the same thing you want.. feel free to use this...


i have the same answer on Can I multiply strings in java to repeat sequences?


If speed is your concern, then you should use as less memory copying as possible. Thus it is required to work with arrays of chars.


To test speed, a similar optimal method using StirngBuilder is like this:


and the code to test it:


And here the run results from my system:


Note that the test for loop is to kick in JIT and have optimal results.


here is the latest Stringutils.java StringUtils.java


it doesn't even need to be this big, can be made into this, and can be copied and pasted 
into a utility class in your project.


So e5, I think the best way to do this would be to simply use the above mentioned code,or any of the answers here. but commons lang is just too big if it's a small project


Not the shortest, but (i think) the fastest way is to use the StringBuilder:


Sometimes simple is best.  Everyone reading the code can see what's happening.


And the compiler will do the fancy stuff with StringBuilder behind the scenes for you.


This is how I did it without using loop:


Here is a simple way to repeat a star a number of times (up to some known maximum):






What are the differences between a HashMap and a Hashtable in Java?


Which is more efficient for non-threaded applications?


There are several differences between HashMap and Hashtable in Java:


Hashtable is synchronized, whereas HashMap is not.  This makes HashMap better for non-threaded applications, as unsynchronized Objects typically perform better than synchronized ones.


Hashtable does not allow null keys or values.  HashMap allows one null key and any number of null values.


One of HashMap's subclasses is LinkedHashMap, so in the event that you'd want predictable iteration order (which is insertion order by default), you could easily swap out the HashMap for a LinkedHashMap.  This wouldn't be as easy if you were using Hashtable.


Since synchronization is not an issue for you, I'd recommend HashMap. If synchronization becomes an issue, you may also look at ConcurrentHashMap.


Note, that a lot of the answers state that Hashtable is synchronised.  In practice this buys you very little.  The synchronization is on the accessor / mutator methods will stop two threads adding or removing from the map concurrently, but in the real world you will often need additional synchronisation.


A very common idiom is to "check then put" - i.e. look for an entry in the Map, and add it if it does not already exist.  This is not in any way an atomic operation whether you use Hashtable or HashMap.  


An equivalently synchronised HashMap can be obtained by:


But to correctly implement this logic you need additional synchronisation of the form:


Even iterating over a Hashtable's entries (or a HashMap obtained by Collections.synchronizedMap) is not thread safe unless you also guard the Map from being modified through additional synchronization.


Implementations of the ConcurrentMap interface (for example ConcurrentHashMap) solve some of this by including thread safe check-then-act semantics such as:


No one's mentioned the fact that Hashtable is not part of the Java Collections Framework - it just provides a similar API. Also, Hashtable is considered legacy code. There's nothing about Hashtable that can't be done using HashMap or derivations of HashMap, so for new code, I don't see any justification for going back to Hashtable.


This question is often asked in interview to check whether candidate understands correct usage of collection classes and is aware of alternative solutions available.


Note on Some Important Terms    


HashMap can be synchronized by


Map m = Collections.synchronizeMap(hashMap);


Map provides Collection views instead of direct support for iteration
 via Enumeration objects. Collection views greatly enhance the
 expressiveness of the interface, as discussed later in this section.
 Map allows you to iterate over keys, values, or key-value pairs;
 Hashtable does not provide the third option. Map provides a safe way
 to remove entries in the midst of iteration; Hashtable did not.
 Finally, Map fixes a minor deficiency in the Hashtable interface.
 Hashtable has a method called contains, which returns true if the
 Hashtable contains a given value. Given its name, you'd expect this
 method to return true if the Hashtable contained a given key, because
 the key is the primary access mechanism for a Hashtable. The Map
 interface eliminates this source of confusion by renaming the method
 containsValue. Also, this improves the interface's consistency —
 containsValue parallels containsKey.


The Map Interface


Keep in mind that HashTable was legacy class before Java Collections Framework (JCF) was introduced and was later retrofitted to implement the Map interface. So was Vector and Stack. 


Therefore, always stay away from them in new code since there always better alternative in the JCF as others had pointed out.


Here is the Java collection cheat sheet that you will find useful. Notice the gray block contains the legacy class HashTable,Vector and Stack.





HashMap: An implementation of the Map interface that uses hash codes to index an array.
Hashtable: Hi, 1998 called. They want their collections API back.


Seriously though, you're better off staying away from Hashtable altogether. For single-threaded apps, you don't need the extra overhead of syncrhonisation. For highly concurrent apps, the paranoid synchronisation might lead to starvation, deadlocks, or unnecessary garbage collection pauses. Like Tim Howland pointed out, you might use ConcurrentHashMap instead.


In addition to what izb said, HashMap allows null values, whereas the Hashtable does not.


Also note that Hashtable extends the Dictionary class, which as the Javadocs state, is obsolete and has been replaced by the Map interface.


Take a look at this chart. It provides comparisons between different data structures along with HashMap and Hashtable. The comparison is precise, clear and easy to understand.


Java Collection Matrix


Hashtable is similar to the HashMap and has a similar interface. It is recommended that you use HashMap, unless you require support for legacy applications or you need synchronisation, as the Hashtables methods are synchronised. So in your case as you are not multi-threading, HashMaps are your best bet.


Another key difference between hashtable and hashmap is that Iterator in the HashMap is  fail-fast  while the enumerator for the Hashtable is not and throw ConcurrentModificationException if any other Thread modifies the map structurally  by adding or removing any element except Iterator's own remove()  method. But this is not a guaranteed behavior and will be done by JVM on best effort."


My source: http://javarevisited.blogspot.com/2010/10/difference-between-hashmap-and.html


Beside all the other important aspects already mentioned here, Collections API (e.g. Map interface) is being modified all the time to conform to the "latest and greatest" additions to Java spec.


For example, compare Java 5 Map iterating:


versus the old Hashtable approach:


In Java 1.8 we are also promised to be able to construct and access HashMaps like in good old scripting languages:


Update: No, they won't land in 1.8... :(


Are Project Coin's collection enhancements going to be in JDK8?


HashTable is synchronized, if you are using it in a single thread you can use HashMap, which is an unsynchronized version. Unsynchronized objects are often a little more performant. By the way if multiple threads access a HashMap concurrently, and at least one of the threads modifies the map structurally, it must be synchronized externally. 
Youn can wrap a unsynchronized map in a synchronized one using :


HashTable can only contain non-null object as a key or as a value. HashMap can contain one null key and null values.


The iterators returned by Map are fail-fast, if the map is structurally modified at any time after the iterator is created, in any way except through the iterator's own remove method, the iterator will throw a ConcurrentModificationException. Thus, in the face of concurrent modification, the iterator fails quickly and cleanly, rather than risking arbitrary, non-deterministic behavior at an undetermined time in the future. Whereas the Enumerations returned by Hashtable's keys and elements methods are not fail-fast. 


HashTable and HashMap are member of the Java Collections Framework (since Java 2 platform v1.2, HashTable was retrofitted to implement the Map interface).


HashTable is considered legacy code, the documentation advise to use ConcurrentHashMap in place of Hashtable if a thread-safe highly-concurrent implementation is desired.


HashMap doesn't guarantee the order in which elements are returned. For HashTable I guess it's the same but I'm not entirely sure, I don't find ressource that clearly state that.


HashMap and Hashtable have significant algorithmic differences as well. No one has mentioned this before so that's why I am bringing it up. HashMap will construct a hash table with power of two size, increase it dynamically such that you have at most about eight elements (collisions) in any bucket and will stir the elements very well for general element types. However, the Hashtable implementation provides better and finer control over the hashing if you know what you are doing, namely you can fix the table size using e.g. the closest prime number to your values domain size and this will result in better performance than HashMap i.e. less collisions for some cases.


Separate from the obvious differences discussed extensively in this question, I see the Hashtable as a "manual drive" car where you have better control over the hashing and the HashMap as the "automatic drive" counterpart that will generally perform well.


Hashtable is synchronized, whereas HashMap isn't. That makes Hashtable slower than Hashmap.


For non-threaded apps, use HashMap since they are otherwise the same in terms of functionality.


Differences between HashMap and Hashtable in Java:


1) Thread Safe


2) Inherited From


3) Null Keys And Null Values


4) Traversal


5) Fail-Fast Vs Fail-Safe


6) Performance


7) Legacy Class


8) Member Of Java Collection Framework





Which is more efficient for non-threaded applications?


Hashtable is synchronized, whereas HashMap is not.


This makes HashMap better for non-threaded applications, as unsynchronized Objects typically perform better than synchronized ones.


Based on the info here, I'd recommend going with HashMap.  I think the biggest advantage is that Java will prevent you from modifying it while you are iterating over it, unless you do it through the iterator.


For threaded apps, you can often get away with ConcurrentHashMap- depends on your performance requirements.


Difference between HashMap and HashTable / HashMap vs HashTable 


Synchronization or Thread Safe :  This is the most important difference between two . HashMap is non synchronized and not thread safe.On the other hand, HashTable is thread safe and synchronized.
When to use HashMap ?  answer is if your application do not require any multi-threading task, in other words hashmap is better for non-threading applications. HashTable should be used in multithreading applications.


Null keys and null values :  Hashmap allows one null key and any number of null values, while Hashtable do not allow null keys and null values in the HashTable object.


Iterating the values:  Hashmap object values are iterated by using iterator .HashTable is the only class other than vector which uses enumerator to iterate the values of HashTable object.


Fail-fast iterator  : The iterator in Hashmap is fail-fast iterator while the enumerator for Hashtable is not.
According to Oracle Docs,  if the Hashtable is structurally modified at any time after the iterator is created in any way except the iterator's own remove method , then the iterator will throw ConcurrentModification Exception.
Structural modification means adding or removing elements from the Collection object (here hashmap or hashtable) . Thus the enumerations returned by the Hashtable keys and elements methods are not fail fast.We have already explained the difference between iterator and enumeration.


Performance :  Hashmap is much faster and uses less memory than Hashtable as former is unsynchronized . Unsynchronized objects are often much better in performance in compare to synchronized  object like Hashtable in single threaded environment.


Superclass and Legacy :  Hashtable is a subclass of Dictionary class which is now obsolete in Jdk 1.7 ,so ,it is not used anymore. It is better off externally synchronizing a HashMap or using a ConcurrentMap implementation (e.g ConcurrentHashMap).HashMap is the subclass of the AbstractMap class. Although Hashtable and HashMap has different superclasses but they both are implementations of the "Map"  abstract data type.


Apart from the differences already mentioned, it should be noted that since Java 8, HashMap dynamically replaces the Nodes (linked list) used in each bucket with TreeNodes (red-black tree), so that even if high hash collisions exist, the worst case when searching is


O(log(n)) for HashMap Vs O(n) in Hashtable.


*The aforementioned improvement has not been applied to Hashtable yet, but only to HashMap, LinkedHashMap, and ConcurrentHashMap.


FYI, currently,


There are 5 basic differentiations with HashTable and HashMaps. 


1.Hashmap and HashTable both store key and value. 


2.Hashmap can store one key as null. Hashtable can't store null.


3.HashMap is not synchronized but Hashtable is synchronized. 


4.HashMap can be synchronized with Collection.SyncronizedMap(map)


My small contribution :


First and most significant different between Hashtable and HashMap is that, HashMap is not thread-safe  while Hashtable is a thread-safe collection.


Second important difference between Hashtable and HashMap is performance, since HashMap is not synchronized it perform better than Hashtable.


Third difference on Hashtable vs HashMap is that Hashtable is obsolete class and you should be using ConcurrentHashMap in place of Hashtable in Java.


There is many good answer already posted. I'm adding few new points and summarizing it.


HashMap and Hashtable both are used to store data in key and value form. Both are using hashing technique to store unique keys.
But there are many differences between HashMap and Hashtable classes that are given below.


HashMap 


1) HashMap is non synchronized. It is not-thread safe and can't be shared between many threads without proper synchronization code.
2) HashMap allows one null key and multiple null values.
3) HashMap is a new class introduced in JDK 1.2.
4) HashMap is fast.
5) We can make the HashMap as synchronized by calling this code
Map m = Collections.synchronizedMap(HashMap);
6) HashMap is traversed by Iterator.
7) Iterator in HashMap is fail-fast.
8) HashMap inherits AbstractMap class.    


Hashtable


1) Hashtable is synchronized. It is thread-safe and can be shared with many threads.
2) Hashtable doesn't allow any null key or value.
3) Hashtable is a legacy class.
4) Hashtable is slow.
5) Hashtable is internally synchronized and can't be unsynchronized.
6) Hashtable is traversed by Enumerator and Iterator.
7) Enumerator in Hashtable is not fail-fast.
8) Hashtable inherits Dictionary class.


Further reading What is difference between HashMap and Hashtable in Java?





HashTable is a legacy class in the jdk that shouldn't be used anymore. Replace usages of it with ConcurrentHashMap. If you don't require thread safety, use HashMap which isn't threadsafe but faster and uses less memory.


1)Hashtable is synchronized whereas hashmap is not.
2)Another difference is that iterator in the HashMap is fail-safe while the enumerator for the Hashtable isn't. If you change the map while iterating, you'll know.


3)HashMap permits null values in it, while Hashtable doesn't.


HashMap:- It is a class available inside java.util package and it is used to store the element in key and value format.


Hashtable:-It is a legacy class which is being recognized inside collection framework


HashMap and HashTable 


1) Hashtable and Hashmap implement the java.util.Map interface
2) Both Hashmap and Hashtable is the hash based collection. and working on hashing.
so these are similarity of HashMap and HashTable.    


1) First difference is HashMap is not thread safe While HashTable is ThreadSafe
2) HashMap is performance wise better because it is not thread safe. while Hashtable performance wise is not better because it is thread safe. so multiple thread can not access Hashtable at the same time.


HashMaps gives you freedom of synchronization and debugging is lot more easier


HashMap is emulated and therefore usable in GWT client code whereas Hashtable is not.


HashMap is a class  used to store the element in key and value format.it is not thread safe.
because it is not synchronized .where as Hashtable is synchronized.Hashmap permits null but hastable doesn't permit null.






What is the main difference between next() and nextLine()?
My main goal is to read the all text using a Scanner which may be "connected" to any source (file for example).


Which one should I choose and why?


I always prefer to read input using nextLine() and then parse the string.


Using next() will only return what comes before a space. nextLine() automatically moves the scanner down after returning the current line.


A useful tool for parsing data from nextLine() would be str.split("\\s+").


For more information regarding the Scanner class or String class refer to the following links.


Scanner: http://docs.oracle.com/javase/7/docs/api/java/util/Scanner.html


String: http://docs.oracle.com/javase/7/docs/api/java/lang/String.html


next() can read the input only till the space. It can't read two words separated by a space. Also, next() places the cursor in the same line after reading the input.


nextLine() reads input including space between the words (that is, it reads till the end of line \n). Once the input is read, nextLine() positions the cursor in the next line.


For reading the entire line you can use nextLine().


From JavaDoc: 


So in case of "small example<eol>text" next() should return "small" and nextLine() should return "small example"


What i have noticed apart from  next() scans only upto space where as nextLine() scans the entire line is that next waits till it gets a complete token where as nextLine() does not wait for complete token, when ever '\n' is obtained(i.e when you press enter key) the scanner cursor moves to the next line and returns the previous line skipped. It does not check for the whether you have given complete input or not, even it will take an empty string where as next() does not take empty string


Try this program by changing the next() and nextLine() in for loop, go on pressing '\n' that is enter key without any input, you can find that using nextLine() method it terminates after pressing given number of cases where as next() doesnot terminate untill you provide and input to it for the given number of cases.


From javadocs


next() Returns the next token if it matches the pattern constructed from the specified string.
nextLine() Advances this scanner past the current line and returns the input that was skipped.


Which one you choose depends which suits your needs best. If it were me reading a whole file I would go for nextLine until I had all the file.


In short: if you are inputting a string array of length t, then Scanner#nextLine() expects t lines, each entry in the string array is differentiated from the other by enter key.And Scanner#next() will keep taking inputs till you press enter but stores string(word) inside the array, which is separated by whitespace.


Lets have a look at following snippet of code 


when I run above snippet of code in my IDE (lets say for string length 2),it does not matter whether I enter my string as


Input as :- abcd abcd  or


Input as :- 


abcd


abcd 


Output will be like
abcd


abcd


But if in same code we replace next() method by nextLine()


Then if you enter input on prompt as -
abcd abcd 


Output is :-


abcd abcd


and if you enter the input on prompt as 
abcd (and if you press enter to enter next abcd in another line, the input prompt will just exit and you will get the output)


Output is:-


abcd 


For this question, the key point is to find where the method will stop and where is the cursor after calling the methods. All methods will read information (does not include whitespace) between the cursor position and the next default delimiters(whitespace, tab, \n--created by pressing Enter) and the cursor stops before the delimiters, except for the nextLine(), which reads information (including whitespace created by delimiters) between the cursor position and \n and the cursor stops behind \n.


For example:
( | representing the current cursor position; 
_ representing whitespace;
stream in Bold the information got by the calling method)


23_24_25_26_27\n


Call nextInt();    read 23|_24_25_26_27\n


Call nextDouble(); read 23_24|_25_26_27\n


Call next();       read 23_24_25|_26_27\n


Call nextLine();   read 23_24_25_26_27\n|


After this, the method should be called depending on your requirement.  


From the documentation for Scanner:


A Scanner breaks its input into tokens using a delimiter pattern, which by default matches whitespace.


From the documentation for next():


A complete token is preceded and followed by input that matches the delimiter pattern.


next() and nextLine() methods are associated with Scanner and is used for getting String inputs. Their differences are...


next() can read the input only till the space. It can't read two words separated by space. Also, next() places the cursor in the same line after reading the input.


nextLine() reads input including space between the words (that is, it reads till the end of line \n). Once the input is read, nextLine() positions the cursor in the next line.


Output:


enter string for c
abc def
c is abc


enter string for d


d is  def


If you use nextLine() instead of next() then 


Output:


enter string for c


ABC DEF
c is ABC DEF
enter string for d


GHI
d is GHI


Just for another example of Scanner.next() and nextLine() is that  like below :
nextLine() does not let user type while next() makes Scanner wait and read the input.






I've got a nested loop construct like this:


Now how can I break out of both loops. I've looked at similar questions, but none concerns Java specifically. I couldn't apply these solutions because most used gotos.


I don't want to put the inner loop in a different method.


Update: I don't want to rerun the loops, when breaking I'm finished with the execution of the loop block.


(EDIT: Like other answerers, I'd definitely prefer to put the inner loop in a different method. This answer just shows how the requirements in the question can be met.)


You can use break with a label for the outer loop. For example:


This prints:


Technically the correct answer is to label the outer loop. In practice if you want to exit at any point inside an inner loop then you would be better off externalizing the code into a method (a static method if needs be) and then call it.


That would pay off for readability. 


The code would become something like that: 


Matching the example for the accepted answer:


You can use a named block around the loops:


I never use labels. It seems like a bad practice to get into. Here's what I would do:


You can use labels:


maybe with a function?


You can use a temporary variable:


Depending on your function, you can also exit/return from the inner loop:


If you don't like breaks and gotos, you can use a "traditional" for loop instead the for-in, with an extra abort condition:


I needed to do a similar thing, but I chose not to use the enhanced for loop to do it.


I prefer to add an explicit "exit" to the loop tests.  It makes it clear to 
any casual reader that the loop may terminate early.


Java 8 Stream solution:


You can break from all loops without using any label: and flags.


It's just tricky solution.


Here condition1 is the condition which is used to break from loop K and J.
And condition2 is the condition which is used to break from loop K , J and I.


For example:


Like @1800 INFORMATION suggestion, use the condition that breaks the inner loop as a condition on the outer loop:


Another one solution, mentioned without example (it actually works in prod code).


Of course break exception should be internal, private and accelerated with no-stack-trace:


Rather unusual approach but in terms of code length (not performance) this is the easiest thing you could do:


Best and Easy Method..


Rather for a long I was thinking to share this type of answer for this type of question. 


Usually such cases are come in scope of a more meaningful logic, let's say some searching or manipulating over some of the iterated 'for'-objects in question, so I usually use the functional approach:


Major cons:


The pros: 


So it is just handling the case via a different approach.


Basically a question to the author of this question: what do you consider of this approach? 


Use Labels.


Refer this article
http://javarevisited.blogspot.com/2012/05/break-continue-and-lablel-in-loop-java.html


Even creating a flag for outer loop and checking that after each execution of inner loop can be the answer.


Like this :


If it is inside some function why don't you just return it: 


for (int j = 0; j < 5; j++) //inner loop should be replaced with 
    for (int j = 0; j < 5 && !exitloops; j++).


Here, in this case complete nested loops should be exit if condition is True . But if we use  exitloops only to the upper loop 


Then inner loop will continues, because there is no extra flag that notify this inner loop to exit. 


Example : if i = 3 and j=2 then condition is false.  But in next iteration of inner loop j=3  then condition (i*j) become 9 which is true but inner loop will be continue till j become 5.


So, it must use exitloops to the inner loops too.


I wanted to answer this question but was marked as a duplicate which prevents me from posting as well. So posting it here instead !


If its a new implementation you can try re-writing the logic as
  if-else_if-else statements.


Otherwise you can try setting a flag when that special condition has
  occured and check for that flag in each of your loop-conditions.


If you are simply porting the logic from one programming language to java and just want to get the thing working you can try using labels 


Demo for break continue lable,
so java keyword "break continue" have default value,it's the "Nearest Loop" ,Toady a few years after use Java ,i just get it !


it's seem used rare,but useful


You can do one thing


1.) set a local variable to false


2.) set that variable true in first loop , when you want to break out


3.) then you can check in outer loop ,that whether the condition is set then break from outer loop as well.


Well it quite seemed a simple way for me to put it like this.


For some cases, We can use while loop effectively here.


You just use label for breaking inner loops


Check if the inner loop is exited with an if statement, by checking the inner loop's variable. You could also create another variable such as a boolean to check if the inner loop is exited. 


In this example it uses the inner loop's variable to check if it has been exited:


Use condition as a flag for when you are done processing. Then the inner loop only continues on while the condition has not been met. Either way the outer loop will keep on chuggin'. 


I feel using labels makes the code seem very much like a goto statement. This is just a thought. Why don't we throw an exception at the inner for loop and encapsulate the two for loops with a try catch block. Something like


Just a thought. I prefer this code since it gives me better loggability (Like that's a word) for me when this is being run in production or something.






I'm attempting to compile Java 1.4 code that was created by IBM's WSDL2Java on Java5 without recreating the stubs and saw this error in Eclipse. I'm under the assumption that the stubs created should just compile as long as the runtime jars are available (they are).


Access restriction: The type QName is not accessible due to restriction on required library C:\Program Files\Java\jdk1.5.0_16\jre\lib\rt.jar


The full classname is javax.xml.namespace.QName


What exactly is going on here? 


Is this a case where I am trying to refactor a pig from sausage? Am I better off recreating the stubs?


There's another solution that also works. I found it on this forum: 


This works because you have multiple classes in different jar files. Removing and re-adding the JRE lib will make the right classes be first.
If you want a fundamental solution make sure you exclude the jar files with the same classes.


For me I have: javax.xml.soap.SOAPPart in three different jars: axis-saaj-1.4.jar, saaj-api-1.3.jar and the rt.jar


http://www.digizol.com/2008/09/eclipse-access-restriction-on-library.html worked best for me. 


On Windows: Windows -> Preferences -> Java -> Compiler -> Errors/Warnings
-> Deprecated and restricted API -> Forbidden reference (access rules): -> change to warning


On Mac OS X/Linux: Eclipse -> Preferences -> Java -> Compiler -> Errors/Warnings
-> Deprecated and restricted API -> Forbidden reference (access rules): -> change to warning


I met the same problem. I found the answer in the website:http://www.17ext.com.
First,delete the JRE System Libraries. Then,import JRE System Libraries again.  


I don't know why.However it fixed my problem,hope it can help you.


My guess is that you are trying to replace a standard class which ships with Java 5 with one in a library you have.


This is not allowed under the terms of the license agreement, however AFAIK it wasn't enforced until Java 5.


I have seen this with QName before and I "fixed" it by removing the class from the jar I had.


EDIT
http://www.manpagez.com/man/1/java/ notes for the option "-Xbootclasspath:" 


"Applications that use this option for the purpose of overriding a class in rt.jar should not be deployed as doing  so would contravene the Java 2 Runtime Environment binary code license."


The http://www.idt.mdh.se/rc/sumo/aJile/Uppackat/jre/LICENSE 


"Java Technology Restrictions. You may not modify the Java
Platform Interface ("JPI", identified as classes contained
within the "java" package or any subpackages of the "java"
package), by creating additional classes within the JPI or
otherwise causing the addition to or modification of the
classes in the JPI.  In the event that you create an
additional class and associated API(s) which (i) extends
the functionality of the Java platform, and (ii) is exposed
to third party software developers for the purpose of
developing additional software which invokes such
additional API, you must promptly publish broadly an
accurate specification for such API for free use by all
developers.  You may not create, or authorize your
licensees to create, additional classes, interfaces, or
subpackages that are in any way identified as "java",
"javax", "sun" or similar convention as specified by Sun in
any naming convention designation."


I have been getting this error too, but my project is built on the command line using Maven and the tycho compiler (it's a set of OSGi plugins). After masses of sifting through people having the same problem but fixing it in Eclipse rather than on the command line, I found a message on the Tycho developer forum that answered my question, using configuration in pom.xml to ignore the compiler warning about the access restriction:


More information can be found in the Tycho FAQ. This took me AGES to work out, so I figured I would assist anyone else trying to fix these access restriction errors from the command line by posting this answer.


I just had this problem too. Apparently I had set the JRE to 1.5 instead of 1.6 in my build path.


In addition to Nels Beckman's solution, I have the following tips:


Under Configure Build Path, I had to rearrange the order of my entries under Order and Export.


Additionally, as an Eclipse PDE developer, I needed to rearrange the order of my dependencies in my MANIFEST.MF, adding the problematic package as first on the list.


Playing with these dials, along with running Project > Clean in between, I was able to resolve these warnings.


Sorry for updating an old POST. I got the reported problem and I solved it as said below.


Assuming you are using Eclipse + m2e maven plugin, if you get this access restriction error, right click on the project/module in which you have the error --> Properties --> Build Path --> Library --> Replace JDK/JRE to the one that is used in eclipse workspace.


I followed the above steps and the issue is resolved.


In the case you are sure that you should be able to access given class, than this can mean you added several jars to your project containing classes with identical names (or paths) but different content and they are overshadowing each other (typically an old custom build jar contains built-in older version of a 3rd party library).


For example when you add a jar implementing:


but also an older version implementing only:


Everything works fine in the code editor but fails during the compilation if the "old" library overshadows the new one - d2 suddenly turns out "missing or inaccessible" even when it is there.


The solution is a to check the order of compile-time libraries and make sure that the one with correct implementation goes first.


Go to the Java Build Path in the project properties. Remove the existing JRE System Library 
Then Add it again i.e. Add Library-->JRE Lib--select jre--->Finish.
Lastly select order and export tab select JRE Lib and move on top. That's it.


Just change the order of build path libraries of your project. Right click on project>Build Path> Configure Build Path>Select Order and Export(Tab)>Change the order of the entries. I hope moving the "JRE System library" to the bottom will work. It worked so for me. Easy and simple....!!!


In my case there was a mismatch between the build path JRE and installed JRE on execution environment. I moved into Project > Properties > Java compiler. There was a warning message at the bottom.


I clicked on the links 'Installed JRE', 'Execution environment', 'Java build path' and changed the JDK version to 1.7 and the warning disappeared.


for me this how I solve it:


under Libraries





Note: make sure that in Eclipse / Preferences (NOT the project) / Java / Installed JRE  ,that the jdk points to the JDK folder not the JRE C:\Program Files\Java\jdk1.8.0_74





Adding a right JRE System through build path is the solution but your eclipse still may have the error.
To solve that go to Java Build path --> Order and Export and move your JRE system library on the top. This has solved my problem.






If I try to assign a value to a variable in a class, but outside a method I get an error.


but, if I initialize it during the creation, it works.


Inside a method, it works in both cases.


you need to do


as statements have to appear in a block of code.


In this case, the block is an initailiser block which is added to every constructor (or the default constructor in this case) It is run after any call to super() and before the main block of code in any constructor.


BTW: You can have a static initialiser block with static { } which is called when the class is initialised.


e.g.


Because the assignments are statements and statements are allowed only inside blocks of code(methods, constructors, static initializers, etc.)


Outside of these only declarations are allowed. 


This :  


is a declaration with an initializer. That's why is accepted


A more general answer would be that the class body is about declarations, not statements. There is special provision for statements occuring in class body, but they have to be marked explicitly as either class initializers or instance initializers.


In Java, when defining a class, you can define variables with default values and add methods. Any executable code (such as assignments) MUST be contained in a method.


This is the way java works, you cannot add non-declaration code (sorry i don't know the correct term) inside the class, that code should be inside methods. 


I think terminology-wise, couple of other answers are slightly off. Declarations are also statements. In fact, they are called "declaration statements", which are one of the three kinds of statements. An assignment statement is one form of "expression statement" and can be used only in constructs such as methods, constructors, and initializers. Check out the Statements section in this Oracle's tutorial link.


Methods have the responsibility to perform mutations on the member variables.  If the member variable needs to be initialized, java provides a way to do it during construction, class definition (latter case). But the mutation cannot be performed during definition.(former case).  It is usually done at the method level.


Objects are meant to hold the state, while methods are meant to operate on that state. 






Given a JTable with a column of type Boolean.class, the default renderer is a JCheckBox. It's easy enough to select individual cells based on a user selection, but it may be convenient to select all or none of the check boxes, too. These recent examples mentioned using JCheckBox in the table header, but the implementation was awkward and unappealing. If I don't need to sort the column, how can I put a well-behaved control in the JTableHeader?


Addendum: For convenience, I've added my sscce as an answer, but I'd be pleased to accept an answer that addresses the well-behaved aspect of the problem.


There are two parts of the problem (as I see it :-)


Usability: inventing UI-interaction/elements is prone to confusing users. In no particular order:


So even if interaction analysis comes out with a clear we-do-need/want-it, 


Technical aspects


The article How to Use Tables: Using Custom Renderers offers TableSorter as an example of how to detect mouse events on a column header. Using a similar approach, SelectAllHeader extends JToggleButton and implements TableCellRenderer in the example below to achieve a similar effect. A TableModelListener is used to condition the toggle button when all the check boxes are in a uniform state.








Use a custom TableCellRenderer:


Please note that components with popupmenu (e.g. JComboBox or JMenu) don't work well. See: JComboBox fails to expand in JTable TableHeader).
But you can use a MenuButton in the TableHeader:









Can anyone recommend a simple API that will allow me to use read a CSV input file, do some simple transformations, and then write it.


A quick google has found http://flatpack.sourceforge.net/ which looks promising.


I just wanted to check what others are using before I couple myself to this API.


check out the one from apache.


I've used OpenCSV in the past. 


String fileName = "data.csv";
CSVReader reader = new CSVReader(new FileReader(fileName ));


// if the first line is the header
String[] header = reader.readNext();
// iterate over reader.readNext until it returns null
String[] line = reader.readNext();



Update: The code in this answer is for Super CSV 1.52. Updated code examples for Super CSV 2.4.0 can be found at the project website:
http://super-csv.github.io/super-csv/index.html


The SuperCSV project directly supports the parsing and structured manipulation of CSV cells. From http://super-csv.github.io/super-csv/examples_reading.html you'll find e.g. 


given a class


and that you have a CSV file with a header. Let's assume the following content


You can then create an instance of the UserBean and populate it with values from the second line of the file with the following code


using the following "manipulation specification" 


Reading CSV format description makes me feel that using 3rd party library would be less headache than writing it myself:


Wikipedia lists 10 or something known libraries:


I compared libs listed using some kind of check list. OpenCSV turned out a winner to me (YMMV) with the following results:


We use JavaCSV, it works pretty well


For the last enterprise application I worked on that needed to handle a notable amount of CSV -- a couple of months ago -- I used SuperCSV at sourceforge and found it simple, robust and problem-free.


You can use csvreader api & download from following location:


http://sourceforge.net/projects/javacsv/files/JavaCsv/JavaCsv%202.1/javacsv2.1.zip/download


or


http://sourceforge.net/projects/javacsv/


Use the following code:


Write / Append to CSV file


Code:


There is also CSV/Excel Utility. It assumes all thos data is table-like and delivers data from Iterators.


The CSV format sounds easy enough for StringTokenizer but it can become more complicated.
Here in Germany a semicolon is used as a delimiter and cells containing delimiters need to be escaped. You're not going to handle that easily with StringTokenizer.


I would go for http://sourceforge.net/projects/javacsv


If you intend to read csv from excel, then there are some interesting corner cases.  I can't remember them all, but the apache commons csv was not capable of handling it correctly (with, for example, urls).


Be sure to test excel output with quotes and commas and slashes all over the place.


Use 


String[] myValues = String.split(",");






I have a proprietary jar that I want to add to my pom as a dependency.


But I don't want to add it to a repository. The reason is that I want my usual maven commands such as mvn compile, etc, to work out of the box. (Without demanding from the developers a to add it to some repository by themselves).


I want the jar to be in a 3rdparty lib in source control, and link to it by relative path from the pom.xml file.


Can this be done? How?


I want the jar to be in a 3rdparty lib in source control, and link to it by relative path from the pom.xml file.


If you really want this (understand, if you can't use a corporate repository), then my advice would be to use a "file repository" local to the project and to not use a system scoped dependency. The system scoped  should be avoided, such dependencies don't work well in many situation (e.g. in assembly), they cause more troubles than benefits. 


So, instead, declare a repository local to the project:


Install your third party lib in there using install:install-file with the localRepositoryPath parameter:








Using the system scope. ${basedir} is the directory of your pom.


However it is advisable that you install your jar in the repository, and not commit it to the SCM - after all that's what maven tries to eliminate.


This is another method in addition to my previous answer at Can I add jars to maven 2 build classpath without installing them? 


This will get around the limit when using multi-module builds especially if the downloaded JAR is referenced in child projects outside of the parent.  This also reduces the setup work by creating the POM and the SHA1 files as part of the build.  It also allows the file to reside anywhere in the project without fixing the names or following the maven repository structure.


This uses the maven-install-plugin.  For this to work, you need to set up a multi-module project and have a new project representing the build to install files into the local repository and ensure that one is first.


You multi-module project pom.xml would look like this:


The repository/pom.xml file will then contain the definitions to load up the JARs that are part of your project.  The following are some snippets of the pom.xml file.


The pom packaging prevents this from doing any tests or compile or generating any jar file.  The meat of the pom.xml is in the build section where the maven-install-plugin is used.


To install more than one file, just add more executions.


I've previously written about a pattern for doing this.


It is very similar to the solution proposed by Pascal, though it moves all such dependencies into a dedicated repository module so that you don't have to repeat it everywhere the dependency is used if it is a multi-module build.


Basically, add this to the pom.xml:


we switched to gradle and this works much better in gradle ;).  we just specify a folder we can drop jars into for temporary situations like that.  We still have most of our jars defined i the typicaly dependency management section(ie. the same as maven).  This is just one more dependency we define.


so basically now we can just drop any jar we want into our lib dir for temporary testing if it is not a in maven repository somewhere.


This is working for me:
Let's say I have this dependency


Then, add the class-path for your system dependency manually like this


Full config:


One small addition to the solution posted by Pascal


When I followed this route, I got an error in maven while installing ojdbc jar.


After adding -DpomFile, the problem was resolved.


You can use eclipse to generate a runnable Jar :
Export/Runable Jar file






In this case, the MAX is only 5, so I could check the duplicates one by one, but how could I do this in a simpler way? For example, what if the MAX has a value of 20?
Thanks.


The simplest way would be to create a list of the possible numbers (1..20 or whatever) and then shuffle them with Collections.shuffle. Then just take however many elements you want. This is great if your range is equal to the number of elements you need in the end (e.g. for shuffling a deck of cards).


That doesn't work so well if you want (say) 10 random elements in the range 1..10,000 - you'd end up doing a lot of work unnecessarily. At that point, it's probably better to keep a set of values you've generated so far, and just keep generating numbers in a loop until the next one isn't already present:


Be careful with the set choice though - I've very deliberately used LinkedHashSet as it maintains insertion order, which we care about here.


Yet another option is to always make progress, by reducing the range each time and compensating for existing values. So for example, suppose you wanted 3 values in the range 0..9. On the first iteration you'd generate any number in the range 0..9 - let's say you generate a 4.


On the second iteration you'd then generate a number in the range 0..8. If the generated number is less than 4, you'd keep it as is... otherwise you add one to it. That gets you a result range of 0..9 without 4. Suppose we get 7 that way.


On the third iteration you'd generate a number in the range 0..7. If the generated number is less than 4, you'd keep it as is. If it's 4 or 5, you'd add one. If it's 6 or 7, you'd add two. That way the result range is 0..9 without 4 or 6.


Here's how I'd do it


As the esteemed Mr Skeet has pointed out:
If n is the number of randomly selected numbers you wish to choose and N is the total sample space of numbers available for selection:  


The most efficient, basic way to have non-repeating random numbers is explained by this pseudo-code.  There is no need to have nested loops or hashed lookups:


Suppose first iteration generated random number 3 to start (from 0 - 19).  This would make results[0] = mapping[3], i.e., the value 3.  We'd then assign mapping[3] to 19.


In the next iteration, the random number was 5 (from 0 - 18).  This would make results[1] = mapping[5], i.e., the value 5.  We'd then assign mapping[5] to 18.


Now suppose the next iteration chose 3 again (from 0 - 17).  results[2] would be assigned the value of mapping[3], but now, this value is not 3, but 19.  


This same protection persists for all numbers, even if you got the same number 5 times in a row.  E.g., if the random number generator gave you 0 five times in a row, the results would be: [ 0, 19, 18, 17, 16 ].


You would never get the same number twice.


Generating all the indices of a sequence is generally a bad idea, as it might take a lot of time, especially if the ratio of the numbers to be chosen to MAX is low (the complexity becomes dominated by O(MAX)). This gets worse if the ratio of the numbers to be chosen to MAX approaches one, as then removing the chosen indices from the sequence of all also becomes expensive (we approach O(MAX^2/2)). But for small numbers, this generally works well and is not particularly error-prone.


Filtering the generated indices by using a collection is also a bad idea, as some time is spent in inserting the indices into the sequence, and progress is not guaranteed as the same random number can be drawn several times (but for large enough MAX it is unlikely). This could be close to complexity O(k n log^2(n)/2), ignoring the duplicates and assuming the collection uses a tree for efficient lookup (but with a significant constant cost k of allocating the tree nodes and possibly having to rebalance).


Another option is to generate the random values uniquely from the beginning, guaranteeing progress is being made. That means in the first round, a random index in [0, MAX] is generated:


In the second round, only [0, MAX - 1] is generated (as one item was already selected):


The values of the indices then need to be adjusted: if the second index falls in the second half of the sequence (after the first index), it needs to be incremented to account for the gap. We can implement this as a loop, allowing us to select arbitrary number of unique items.


For short sequences, this is quite fast O(n^2/2) algorithm:


Where n_select_num is your 5 and n_number_num is your MAX. The n_Rand(x) returns random integers in [0, x] (inclusive). This can be made a bit faster if selecting a lot of items (e.g. not 5 but 500) by using binary search to find the insertion point. To do that, we need to make sure that we meet the requirements.


We will do binary search with the comparison n + j < rand_num[j] which is the same as n < rand_num[j] - j. We need to show that rand_num[j] - j is still a sorted sequence for a sorted sequence rand_num[j]. This is fortunately easily shown, as the lowest distance between two elements of the original rand_num is one (the generated numbers are unique, so there is always difference of at least 1). At the same time, if we subtract the indices j from all the elements rand_num[j], the differences in index are exactly 1. So in the "worst" case, we get a constant sequence - but never decreasing. The binary search can therefore be used, yielding O(n log(n)) algorithm:


And finally:


I have tested this on three benchmarks. First, 3 numbers were chosen out of 7 items, and a histogram of the items chosen was accumulated over 10,000 runs:


This shows that each of the 7 items was chosen approximately the same number of times, and there is no apparent bias caused by the algorithm. All the sequences were also checked for correctness (uniqueness of contents).


The second benchmark involved choosing 7 numbers out of 5000 items. The time of several versions of the algorithm was accumulated over 10,000,000 runs. The results are denoted in comments in the code as b1. The simple version of the algorithm is slightly faster.


The third benchmark involved choosing 700 numbers out of 5000 items. The time of several versions of the algorithm was again accumulated, this time over 10,000 runs. The results are denoted in comments in the code as b2. The binary search version of the algorithm is now more than two times faster than the simple one.


The second method starts being faster for choosing more than cca 75 items on my machine (note that the complexity of either algorithm does not depend on the number of items, MAX).


It is worth mentioning that the above algorithms generate the random numbers in ascending order. But it would be simple to add another array to which the numbers would be saved in the order in which they were generated, and returning that instead (at negligible additional cost O(n)). It is not necessary to shuffle the output: that would be much slower.


Note that the sources are in C++, I don't have Java on my machine, but the concept should be clear.


EDIT:


For amusement, I have also implemented the approach that generates a list with all the indices 0 .. MAX, chooses them randomly and removes them from the list to guarantee uniqueness. Since I've chosen quite high MAX (5000), the performance is catastrophic:


I have also implemented the approach with a set (a C++ collection), which actually comes second on benchmark b2, being only about 50% slower than the approach with the binary search. That is understandable, as the set uses a binary tree, where the insertion cost is similar to binary search. The only difference is the chance of getting duplicate items, which slows down the progress.


Full source code is here.


Another approach which allows you to specify how many numbers you want with size and the min and max values of the returned numbers


To use it returning 7 numbers between 0 and 25.


You could use one of the classes implementing the Set interface (API), and then each number you generate, use Set.add() to insert it.


If the return value is false, you know the number has already been generated before.


Instead of doing all this create a LinkedHashSet object and random numbers to it by Math.random() function .... if any duplicated entry occurs the LinkedHashSet object won't add that number to its List ... Since in this Collection Class no duplicate values are allowed .. in the end u get a list of random numbers having no duplicated values .... :D


There is another way of doing "random" ordered numbers with LFSR, take a look at: 


http://en.wikipedia.org/wiki/Linear_feedback_shift_register


with this technique you can achieve the ordered random number by index and making sure the values are not duplicated.


But these are not TRUE random numbers because the random generation is deterministic.


But depending your case you can use this technique reducing the amount of processing on random number generation when using shuffling.


Here a LFSR algorithm in java, (I took it somewhere I don't remeber):


Your problem seems to reduce to choose k elements at random from a collection of n elements.  The Collections.shuffle answer is thus correct, but as pointed out inefficient: its O(n).  


Wikipedia: Fisher–Yates shuffle has a O(k) version when the array already exists.  In your case, there is no array of elements and creating the array of elements could be very expensive, say if max were 10000000 instead of 20.  


The shuffle algorithm involves initializing an array of size n where every element is equal to its index, picking k random numbers each number in a range with the max one less than the previous range, then swapping elements towards the end of the array.  


You can do the same operation in O(k) time with a hashmap although I admit its kind of a pain.  Note that this is only worthwhile if k is much less than n.  (ie k ~ lg(n) or so), otherwise you should use the shuffle directly.  


You will use your hashmap as an efficient representation of the backing array in the shuffle algorithm.  Any element of the array that is equal to its index need not appear in the map.  This allows you to represent an array of size n in constant time, there is no time spent initializing it.  


Pick k random numbers: the first is in the range 0 to n-1, the second 0 to n-2, the third 0 to n-3 and so on, thru n-k.  


Treat your random numbers as a set of swaps.  The first random index swaps to the final position.  The second random index swaps to the second to last position.  However, instead of working against a backing array, work against your hashmap.  Your hashmap will store every item that is out of position.  





There is algorithm of card batch: you create ordered array of numbers (the "card batch") and in every iteration you select a number at random position from it (removing the selected number from the "card batch" of course).


Here is an efficient solution for fast creation of a randomized array. After randomization you can simply pick the n-th element e of the array, increment n and return e. This solution has O(1) for getting a random number and O(n) for initialization, but as a tradeoff requires a good amount of memory if n gets large enough.


There is a more efficient and less cumbersome solution for integers than a Collections.shuffle.


The problem is the same as successively picking items from only the un-picked items in a set and setting them in order somewhere else. This is exactly like randomly dealing cards or drawing winning raffle tickets from a hat or bin. 


This algorithm works for loading any array and achieving a random order at the end of the load. It also works for adding into a List collection (or any other indexed collection) and achieving a random sequence in the collection at the end of the adds. 


It can be done with a single array, created once, or a numerically ordered collectio, such as a List, in place. For an array, the initial array size needs to be the exact size to contain all the intended values. If you don't know how many values might occur in advance, using a numerically orderred collection, such as an ArrayList or List, where the size is not immutable, will also work. It will work universally for an array of any size up to Integer.MAX_VALUE which is just over 2,000,000,000. List objects will have the same index limits. Your machine may run out of memory before you get to an array of that size. It may be more efficient to load an array typed to the object types and convert it to some collection, after loading the array. This is especially true if the target collection is not numerically indexed. 


This algorithm, exactly as written, will create a very even distribution where there are no duplicates. One aspect that is VERY IMPORTANT is that it has to be possible for the insertion of the next item to occur up to the current size + 1. Thus, for the second item, it could be possible to store it in location 0 or location 1. For the 20th item, it could be possible to store it in any location, 0 through 19. It is just as possible the first item to stay in location 0 as it is for it to end up in any other location. It is just as possible for the next new item to go anywhere, including the next new location. 


The randomness of the sequence will be as random as the randomness of the random number generator.


This algorithm can also be used to load reference types into random locations in an array. Since this works with an array, it can also work with collections. That means you don't have to create the collection and then shuffle it or have it ordered on whatever orders the objects being inserted. The collection need only have the ability to insert an item anywhere in the collection or append it.


My preliminary code, using only fundamentals.
This class gives you an array filled with no duplicating numbers, ranging from 1 to the size of the array.
The only outside help is to generate a random number.
The conditional, index == count in the while loop, is the tricky part, and what makes this method work.
Essentially, it's asking: The random number is not equal to the array's element, but is this array element the next in line for a number?  


It really all depends on exactly WHAT you need the random generation for, but here's my take.


First, create a standalone method for generating the random number.
Be sure to allow for limits.


Next, you will want to create a very simple decision structure that compares values.  This can be done in one of two ways.  If you have a very limited amount of numbers to verify, a simple IF statement will suffice:


The above compares int1 to int2 through int5, as well as making sure that there are no zeroes in the randoms.


With these two methods in place, we can do the following:


Followed By:


If you have a longer list to verify, then a more complex method will yield better results both in clarity of code and in processing resources.


Hope this helps.  This site has helped me so much, I felt obliged to at least TRY to help as well.






How could I read input from the console using the Scanner class? Something like this:


Basically, all I want to do is have the scanner read an input for the username, and assign the input to a String variable.


A simple example to illustrate how java.util.Scanner works would be reading a single integer from System.in. It's really quite simple.


To retrieve a username I would probably use sc.nextLine().


You could also use next(String pattern) if you want more control over the input, or just validate the username variable.


You'll find more information on their implementation in the API Documentation for java.util.Scanner


Reading Data From Console


BufferedReader is synchronized, so read operations on a BufferedReader can be safely done from multiple threads. The buffer size may be specified, or the default size(8192) may be used. The default is large enough for most purposes.


readLine() « just read data as line by line from the stream of source. A line is considered to be terminated by any one these \n, \r (or) \r\n


Scanner breaks its input into tokens using a delimiter pattern, which by default matches whitespace(\s) and it is recognised by Character.isWhitespace.


« UNtill user enter data, scanning operation may block waiting for input.
« Use Scanner(BUFFER_SIZE = 1024) if you want to parse specific type of token from a stream.
« A scanner however is not thread safe, it has to be externally synchronized.


next()    « Finds and returns the next complete token from this scanner.
nextInt() « Scans the next token of the input as an int.


Code


Input's and outputs of Stream


There are several ways to get input from the user. Here in this program we will take Scanner Class to achieve the task. This Scanner class comes under java.util, hence the first line of the program is import java.util.Scanner; which allows the user to read values of various types in java. The import statement line should have to be in the first line the java program, and we proceed further for code. 


To access methods in Scanner class create a new scanner object as "in". Now we use a one of its method that is "next". "next" method gets the string of text that a user enters on the keyboard.


here I'm using in.nextLine(); to get the String which user enters.


Just another simple example, good luck!


You can make a simple program to ask for user's name and print what ever the reply use inputs.


Or ask user to enter two numbers and you can add, multiply, subtract, or divide those numbers and print the answers for user inputs just like a behavior of a calculator.


So there you need Scanner class. You have to import java.util.Scanner; and in the code you need to use 


Input is a variable name.


See how this differs: input.next();, i = input.nextInt();, d = input.nextDouble();


According to a String, int and a double varies same way for the rest. Don't forget the import statement at the top of your code.


Also see the blog post "Scanner class and getting User Inputs".


To read input:


To read input when you call a method with some arguments/parameters:


when user enters his/her username check for valid entry also.


Here is the complete class which performs required operation:


You can use the Scanner class in Java 


Their is simple way to read from the console.
Please find the below code :-


For detailed understanding please refer to the below documents.
Doc


Now lets talk about the detailed understanding of the Scanner Class Working :- 


This is the constructor for creating the Scanner Instance.
Here we are passing the InputStream reference which is nothing but a System.In. Here it opens the InputStream Pipe for console input.


By passing the System.in this code will opens the socket for reading from console.


you can flow this code:-  






When experiencing networking problems on client machines, I'd like to be able to run a few command lines and email the results of them to myself.


I've found Runtime.exec will allow me to execute arbitrary commands, but Collecting the results in a String is more interesting.


I realize I could redirect output to a file, and then read from the file, but my spidey sense is telling me there's a more elegant way of doing it.


Suggestions?


You need to capture both the std out and std err in the process. You can then write std out to a file/mail or similar.


See this article for more info, and in particular note the StreamGobbler mechanism that captures stdout/err in separate threads. This is essential to prevent blocking and is the source of numerous errors if you don't do it properly!


Use ProcessBuilder. After calling start() you'll get a Process object from which you can get the stderr and stdout streams.


UPDATE: ProcessBuilder gives you more control; You don't have to use it but I find it easier in the long run. Especially the ability to redirect stderr to stdout which means you only have to suck down one stream.


Use Plexus Utils, it is used by Maven to execut all external processes.


For processes that don't generate much output, I think this simple solution that utilizes Apache IOUtils is sufficient:


Caveat: However, if your process generates a lot of output, this approach may cause problems, as mentioned in the Process class JavaDoc:


The created subprocess does not have its own terminal or console. All its standard io (i.e. stdin, stdout, stderr) operations will be redirected to the parent process through three streams (getOutputStream(), getInputStream(), getErrorStream()). The parent process uses these streams to feed input to and get output from the subprocess. Because some native platforms only provide limited buffer size for standard input and output streams, failure to promptly write the input stream or read the output stream of the subprocess may cause the subprocess to block, and even deadlock.


Runtime.exec() returns a Process object, from which you can extract the output of whatever command you ran.


VerboseProcess utility class from jcabi-log can help you:


The only dependency you need:


This is my helper class been using for years. One small class. It has JavaWorld streamgobbler class to fix JVM resource leaks. Don't know if still valid for JVM6 and JVM7 but does not hurt. Helper can read output buffer for later use.


Here is an example reading output from .vbs script but similar works for linux sh scripts.


Using Runtime.exec gives you a process. You can these use getInputStream to get the stdout of this process, and put this input stream into a String, through a StringBuffer for example.






After answering a question about how to force-free objects in Java (the guy was clearing a 1.5GB HashMap) with System.gc(), I was told it's bad practice to call System.gc() manually, but the comments were not entirely convincing. In addition, no one seemed to dare to upvote, nor downvote my answer.


I was told there that it's bad practice, but then I was also told that garbage collector runs don't systematically stop the world anymore, and that it could also effectively be used by the JVM only as a hint, so I'm kind of at loss.


I do understand that the JVM usually knows better than you when it needs to reclaim memory. I also understand that worrying about a few kilobytes of data is silly. I also understand that even megabytes of data isn't what it was a few years back. But still, 1.5 gigabytes? And you know there's like 1.5 GB of data hanging around in memory; it's not like it's a shot in the dark. Is System.gc() systematically bad, or is there some point at which it becomes okay?


So the question is actually double:


The reason everyone always says to avoid System.gc() is that it is a pretty good indicator of fundamentally broken code.  Any code that depends on it for correctness is certainly broken; any that rely on it for performance are most likely broken.


You don't know what sort of garbage collector you are running under.  There are certainly some that do not "stop the world" as you assert, but some JVMs aren't that smart or for various reasons (perhaps they are on a phone?) don't do it.  You don't know what it's going to do.


Also, it's not guaranteed to do anything.  The JVM may just entirely ignore your request.


The combination of "you don't know what it will do," "you don't know if it will even help," and "you shouldn't need to call it anyway" are why people are so forceful in saying that generally you shouldn't call it.  I think it's a case of "if you need to ask whether you should be using this, you shouldn't"


EDIT to address a few concerns from the other thread:


After reading the thread you linked, there's a few more things I'd like to point out.
First, someone suggested that calling gc() may return memory to the system.  That's certainly not necessarily true - the Java heap itself grows independently of Java allocations.  


As in, the JVM will hold memory (many tens of megabytes) and grow the heap as necessary.  It doesn't necessarily return that memory to the system even when you free Java objects; it is perfectly free to hold on to the allocated memory to use for future Java allocations.


To show that it's possible that System.gc() does nothing, view:


http://bugs.sun.com/view_bug.do?bug_id=6668279


and in particular that there's a -XX:DisableExplicitGC VM option.


It has already been explained that calling system.gc() may do nothing, and that any code that "needs" the garbage collector to run is broken.


However, the pragmatic reason that it is bad practice to call System.gc() is that it is inefficient.  And in the worst case, it is horribly inefficient!  Let me explain.


A typical GC algorithm identifies garbage by traversing all non-garbage objects in the heap, and inferring that any object not visited must be garbage.  From this, we can model the total work of of a garbage collection consists of one part that is proportional to the amount of live data, and another part that is proportional to the amount of garbage; i.e. work = (live * W1 + garbage * W2).  


Now suppose that you do the following in a single-threaded application.


The first call will (we predict) do (live * W1 + garbage * W2) work, and get rid of the outstanding garbage.


The second call will do (live* W1 + 0 * W2) work and reclaim nothing.  In other words we have done (live * W1) work and achieved absolutely nothing.


We can model the efficiency of the collector as the amount of work needed to collect a unit of garbage; i.e. efficiency = (live * W1 + garbage * W2) / garbage.  So to make the GC as efficient as possible, we need to maximize the value of garbage when we run the GC; i.e. wait until the heap is full.  (And also, make the heap as big as possible.  But that is a separate topic.)


If the application does not interfere (by calling System.gc()), the GC will wait until the heap is full before running, resulting in efficient collection of garbage1.  But if the application forces the GC to run, the chances are that the heap won't be full, and the result will be that garbage is collected inefficiently.  And the more often the application forces GC, the more inefficient the GC becomes.


Note: the above explanation glosses over the fact that a typical modern GC partitions the heap into "spaces", the GC may dynamically expand the heap, the application's working set of non-garbage objects may vary and so on.  Even so, the same basic principal applies across the board to all true garbage collectors2.  It is inefficient to force the GC to run.


1 - This is how the "throughput" collector works.  Concurrent collectors such as CMS and G1 use different criteria to decide when to start the garbage collector.


2 - I'm also excluding memory managers that use reference counting exclusively, but no current Java implementation uses that approach ... for good reason.


Lots of people seem to be telling you not to do this. I disagree. If, after a large loading process like loading a level, you believe that:


there is no harm in calling System.gc().  I look at it like the c/c++ inline keyword. It's just a hint to the gc that you, the developer, have decided that time/performance is not as important as it usually is and that some of it could be used reclaiming memory.


Advice to not rely on it doing anything is correct. Don't rely on it working, but giving the hint that now is an acceptable time to collect is perfectly fine. I'd rather waste time at a point in the code where it doesn't matter (loading screen) than when the user is  actively interacting with the program (like during a level of a game.)


There is one time when i will force collection: when attempting to find out is a particular object leaks (either native code or large, complex callback interaction. Oh and any UI component that so much as glances at Matlab.) This should never be used in production code.


People have been doing a good job explaining why NOT to use, so I will tell you a couple situations where you should use it:


(The following comments apply to Hotspot running on Linux with the CMS collector, where I feel confident saying that System.gc() does in fact always invoke a full garbage collection).


After the initial work of starting up your application, you may be a terrible state of memory usage. Half your tenured generation could be full of garbage, meaning that you are that much closer to your first CMS. In applications where that matters, it is not a bad idea to call System.gc() to "reset" your heap to the starting state of live data.


Along the same lines as #1, if you monitor your heap usage closely, you want to have an accurate reading of what your baseline memory usage is. If the first 2 minutes of your application's uptime is all initialization, your data is going to be messed up unless you force (ahem... "suggest") the full gc up front. 


You may have an application that is designed to never promote anything to the tenured generation while it is running. But maybe you need to initialize some data up-front that is not-so-huge as to automatically get moved to the tenured generation. Unless you call System.gc() after everything is set up, your data could sit in the new generation until the time comes for it to get promoted. All of a sudden your super-duper low-latency, low-GC application gets hit with a HUGE (relatively speaking, of course) latency penalty for promoting those objects during normal operations.


It is sometimes useful to have a System.gc call available in a production application for verifying the existence of a memory leak. If you know that the set of live data at time X should exist in a certain ratio to the set of live data at time Y, then it could be useful to call System.gc() a time X and time Y and compare memory usage.


GC efficiency relies on a number of heuristics. For instance, a common heuristic is that write accesses to objects usually occur on objects which were created not long ago. Another is that many objects are very short-lived (some objects will be used for a long time, but many will be discarded a few microseconds after their creation).


Calling System.gc() is like kicking the GC. It means: "all those carefully tuned parameters, those smart organizations, all the effort you just put into allocating and managing the objects such that things go smoothly, well, just drop the whole lot, and start from scratch". It may improve performance, but most of the time it just degrades performance.


To use System.gc() reliably(*) you need to know how the GC operates in all its fine details. Such details tend to change quite a bit if you use a JVM from another vendor, or the next version from the same vendor, or the same JVM but with slightly different command-line options. So it is rarely a good idea, unless you want to address a specific issue in which you control all those parameters. Hence the notion of "bad practice": that's not forbidden, the method exists, but it rarely pays off.


(*) I am talking about efficiency here. System.gc() will never break a correct Java program. It will neither conjure extra memory that the JVM could not have obtained otherwise: before throwing an OutOfMemoryError, the JVM does the job of System.gc(), even if as a last resort.


This is a very bothersome question, and I feel contributes to many being opposed to Java despite how useful of a language it is.


The fact that you can't trust "System.gc" to do anything is incredibly daunting and can easily invoke "Fear, Uncertainty, Doubt" feel to the language.


In many cases, it is nice to deal with memory spikes that you cause on purpose before an important event occurs, which would cause users to think your program is badly designed/unresponsive.


Having ability to control the garbage collection would be very a great education tool, in turn improving people's understanding how the garbage collection works and how to make programs exploit it's default behavior as well as controlled behavior.


Let me review the arguments of this thread.


Often, the program may not be doing anything and you know it's not doing anything because of the way it was designed. For instance, it might be doing some kind of long wait with a large wait message box, and at the end it may as well add a call to collect garbage because the time to run it will take a really small fraction of the time of the long wait but will avoid gc from acting up in the middle of a more important operation.


I disagree, it doesn't matter what garbage collector you have. Its' job is to track garbage and clean it. 


By calling the gc during times where usage is less critical, you reduce odds of it running when your life relies on the specific code being run but instead it decides to collect garbage. 


Sure, it might not behave the way you want or expect, but when you do want to call it, you know nothing is happening, and user is willing to tolerate slowness/downtime. If the System.gc works, great! If it doesn't, at least you tried. There's simply no down side unless the garbage collector has inherent side effects that do something horribly unexpected to how a garbage collector is suppose to behave if invoked manually, and this by itself causes distrust.


It is a use case that cannot be achieved reliably, but could be if the system was designed that way. It's like making a traffic light and making it so that some/all of the traffic lights' buttons don't do anything, it makes you question why the button is there to begin with, javascript doesn't have garbage collection function so we don't scrutinize it as much for it.


what is a "hint"? what is "ignore"? a computer cannot simply take hints or ignore something, there are strict behavior paths it takes that may be dynamic that are guided by the intent of the system. A proper answer would include what the garbage collector is actually doing, at implementation level, that causes it to not perform collection when you request it. Is the feature simply a nop? Is there some kind of conditions that must me met? What are these conditions?


As it stands, Java's GC often seems like a monster that you just don't trust. You don't know when it's going to come or go, you don't know what it's going to do, how it's going to do it. I can imagine some experts having better idea of how  their Garbage Collection works on per-instruction basis, but vast majority simply hopes it "just works", and having to trust an opaque-seeming algorithm to do work for you is frustrating.


There is a big gap between reading about something or being taught something, and actually seeing the implementation of it, the differences across systems, and being able to play with it without having to look at the source code. This creates confidence and feeling of mastery/understanding/control.


To summarize, there is an inherent problem with the answers "this feature might not do anything, and I won't go into details how to tell when it does do something and when it doesn't and why it won't or will, often implying that it is simply against the philosophy to try to do it, even if the intent behind it is reasonable".


It might be okay for Java GC to behave the way it does, or it might not, but to understand it, it is difficult to truly follow in which direction to go to get a comprehensive overview of what you can trust the GC to do and not to do, so it's too easy simply distrust the language, because the purpose of a language is to have controlled behavior up to philosophical extent(it's easy for a programmer, especially novices to fall into existential crisis from certain system/language behaviors) you are capable of tolerating(and if you can't, you just won't use the language until you have to), and more things you can't control for no known reason why you can't control them is inherently harmful.


First, there is a difference between spec and reality. The spec says that System.gc() is a hint that GC should run and the VM is free to ignore it. The reality is, the VM will never ignore a call to System.gc().


Calling GC comes with a non-trivial overhead to the call and if you do this at some random point in time it's likely you'll see no reward for your efforts. On the other hand, a naturally triggered collection is very likely to recoup the costs of the call. If you have information that indicates that a GC should be run than you can make the call to System.gc() and you should see benefits. However, it's my experience that this happens only in a few edge cases as it's very unlikely that you'll have enough information to understand if and when System.gc() should be called.


One example listed here, hitting the garbage can in your IDE. If you're off to a meeting why not hit it. The overhead isn't going to affect you and heap might be cleaned up for when you get back. Do this in a production system and frequent calls to collect will bring it to a grinding halt! Even occasional calls such as those made by RMI can be disruptive to performance.


Sometimes (not often!) you do truly know more about past, current and future memory usage then the run time does.   This does not happen very often, and I would claim never in a web application while normal pages are being served.


Many year ago I work on a report generator, that


Firstly as it was not real time and the users expected to wait for a report, a delay while the GC run was not an issue, but we needed to produce reports at a rate that was faster than they were requested. 


Looking at the above outline of the process, it is clear that.


Therefore clearly it was well worth while doing a GC run whenever the request queue was empty; there was no downside to this.


It may be worth doing a GC run after each report is emailed, as we know this is a good time for a GC run.   However if the computer had enough ram, better results would be obtained by delaying the GC run.


This behaviour was configured on a per installation bases, for some customers enabling a forced GC after each report greatly speeded up the protection of reports.   (I expect this was due to low memory on their server and it running lots of other processes, so hence a well time forced GC reduced paging.)


We never detected an installation that did not benefit was a forced GC run every time the work queue was empty.


Yes, calling System.gc() doesn't guarantee that it will run, it's a request to the JVM that may be ignored. From the docs:


Calling the gc method suggests that the Java Virtual Machine expend effort toward recycling unused objects


It's almost always a bad idea to call it because the automatic memory management usually knows better than you when to gc. It will do so when its internal pool of free memory is low, or if the OS requests some memory be handed back. 


It might be acceptable to call System.gc() if you know that it helps. By that I mean you've thoroughly tested and measured the behaviour of both scenarios on the deployment platform, and you can show it helps. Be aware though that the gc isn't easily predictable - it may help on one run and hurt on another.


Maybe I write crappy code, but I've come to realize that clicking the trash-can icon on eclipse and netbeans IDEs is a 'good practice'.


In my experience, using System.gc() is effectively a platform-specific form of optimization (where "platform" is the combination of hardware architecture, OS, JVM version and possible more runtime parameters such as RAM available), because its behaviour, while roughly predictable on a specific platform, can (and will) vary considerably between platforms.


Yes, there are situations where System.gc() will improve (perceived) performance. On example is if delays are tolerable in some parts of your app, but not in others (the game example cited above, where you want GC to happen at the start of a level, not during the level).


However, whether it will help or hurt (or do nothing) is highly dependent on the platform (as defined above).


So I think it is valid as a last-resort platform-specific optimization (i.e. if other performance optimizations are not enough). But you should never call it just because you believe it might help(without specific benchmarks), because chances are it will not.


Since objects are dynamically allocated by using the new operator,
you might be wondering how such objects are destroyed and their
memory released for later reallocation.


In some languages, such as C++, dynamically allocated objects must
be manually released by use of a delete operator.


my 2 cents: I load some AnimationDrawables in an activity and play them. I load, play, then set the imageview background to null, one at the time. If I get out the activity and then come back again quickly, after 3 or 4 times the memory engaged grows too much until I get an out of memory exception. 


By calling garbage collector explicitly after setting imageview background to null, I see on Eclipse logcat that memory is kept free enough - and in my case gc is actually run - and I don't get the app stopped working anymore.


It's obvious that system may decide to postpone the execution of gc but if you know more or less how a gc works, you can trust in a case like mine it will be called as soon as possible, for the reason system notices memory used growing and app it's about to ask for more to the system. I think it works like c++ std library containers: you get some starting memory and each time it's not enough, it doubles.


Saying that if you need to call it it's due to broken or bad code is an unreasonable dogmatic way of answering to me: expecially if you can program in a language with total manual memory management like C++ and you have to face the limit of resources on mobile device with a language like java instead, with no chance to free memory manually, you quickly can think of many situations in which it's necessary to call gc explicitly, expecially where you have a tracing gc and not a reference counting one, thou the code is clean and well done.






What program can I use to decompile a class file? Will I actually get Java code, or is it just JVM assembly code?


On Java performance questions on this site I often see responses from people who have "decompiled" the Java class file to see how the compiler optimizes certain things.


Update February 2016:


www.javadecompilers.com lists JAD as being:


the most popular Java decompiler, but primarily of this age only. Written in C++, so very fast.
  Outdated, unsupported and does not decompile correctly Java 5 and later


So your mileage may vary with recent jdk (7, 8).


The same site list other tools.


And javadecompiler, as noted by Salvador Valencia in the comments (Sept 2017), offers a SaaS where you upload the .class file to the cloud and it returns you the decompiled code. 


Original answer: Oct. 2008


Java Decompiler (Yet another Fast Java decompiler) has:





It works with compilers from JDK 1.1.8 up to JDK 1.7.0, and others (Jikes, JRockit, etc.). 


It features an online live demo version that is actually fully functional! You can just drop a jar file on the page and see the decompiled source code without installing anything.


There are a few decompilers out there... A quick search yields:


And many more.


These produce Java code. Java comes with something that lets you see JVM byte code (javap).


To see Java source code check some decompiler. Go search for jad.


If you want to see bytecodes, just use javap which comes with the JDK.


I tried several, and Procyon seemed to work the best for me. It's under active development and supports many features of the latest versions of Java.


These are the others I tried:


I use JAD Decompiler.


There is an Eclipse plugin for it, jadeclipse. It is pretty nice.


Soot is an option for newer Java code. At least it has the advantage of still being recently maintained...


Also, Java Decompiler is a decompiler with both a stand-alone GUI and Eclipse integration.


Lastly, Jdec hasn't been mentioned, though it's not as polished as other options.


Procyon includes a decompiler. It is FOSS.


JD-GUI is really good. You could just open a JAR file and browse through the code as if
you are working on an IDE. Good stuff.


There are a few programs you can use. You will get the actual Java code, but sometimes the code will have been obfuscated so methods are named by one letter or number or a random mix of letters and numbers.


DJ Decompiler
Mocha


Most decompilers for Java are based on JAD.  It's a great tool, but unfortunately hasn't been updated for a while and does not handle Java 1.5+ classes very well.  I have not seen any tools that will properly handle 1.5+ classes.  


Here's a list of decompilers as of Feb 2015:


Procyon, open-source, https://bitbucket.org/mstrobel/procyon/wiki/Java%20Decompiler


CFR, free, no source-code available,  http://www.benf.org/other/cfr/
JD, free for non-commercial use only, http://jd.benow.ca/


Fernflower, open-source, https://github.com/fesh0r/fernflower, 


JAD – given here only for historical reason. Free, no source-code available, http://varaneckas.com/jad/
Outdated, unsupported and does not decompile correctly Java 5 and later.


You may test above-mentioned decompilers online, no installation required and make your own educated choice. 


Java decompilers in the cloud: http://www.javadecompilers.com/


Take a look at cavaj.


All of the JAD links listed so far far seem to be broken, so I found this site. Works great (for Linux, at least)! On Ubuntu 11.10 I had to download the static one for whatever reason.


http://www.varaneckas.com/jad


JAD is one that works and is simple.


Also, if you just want to see the methods, use javap.


If you want to see how the Java compiler does certain things, you don't want decompilation, you want disassembly. Decompilation involves transforming the bytecode into Java source, meaning that a lot of low level information is lost, and if you're wondering about compiler optimization, this is probably the very information you're interested in.


Anyway, I happen to have written an open source Java disassembler. Unlike Javap, this works even on highly pathological classes, so you can see what obfuscation tools are doing to your classes as well. It can also do decompilation, though I wouldn't recommend it.


JAD doesn't work for me (Ubuntu 11.10 issue) so I've moved forward and sopped on JODO. At least it has Open Java source code and been able to decompile my .class properly.    


I recommend to check out 'branches/generic' branch first. The trunks is not stable.  


On IntelliJ IDEA platform you can use Java Decompiler IntelliJ Plugin. It allows you to display all the Java sources during your debugging process, even if you do not have them all. It is based on the famous tools JD-GUI.





With AndroChef Java Decompiler you can decompile apk, dex, jar and java class-files. It's simple and easy. AndroChef JD is based on FernFlower. You can evaluate it in 10 free uses.


AndroChef supports Java language features like generics, enums and annotations. According to some studies, AndroChef Java Decompiler is able to decompile 98.04% of Java applications generated with traditional Java compilers - a very high recovery rate. It is simple but powerful tool that allows you to decompile Java and Dalvik bytecode (DEX, APK) into readable Java source.


For OSX I recommend: jarzilla or JD-GUI


They both allow you to view jar,war,etc. file content and decompiles any class files inside of them.


Jarzilla: https://code.google.com/p/jarzilla/
JD-GUI: http://jd.benow.ca/






An 64-bit double can represent integer +/- 253 exactly


Given this fact I choose to use a double type as a single type for all my types, since my largest integer is unsigned 32-bit.


But now I have to print these pseudo integers, but the problem is they are also mixed in with actual doubles.


So how do I print these doubles nicely in Java?


I have tried String.format("%f", value), which is close, except I get a lot of trailing zeros for small values.


Here's an example output of of %f


What I want is:


Sure I can write a function to trim those zeros, but that's lot of performance loss due to String manipulation.  Can I do better with another format code?


EDIT


The answers by Tom E. and Jeremy S. are unacceptable as they both arbitrarily rounds to 2 decimal places.  Please understand the problem before answering.


EDIT 2


Please note that String.format(format, args...) is locale-dependent (see answers below).


If the idea is to print integers stored as doubles as if they are integers, and otherwise print the doubles with the minimum necessary precision:


Produces:


And does not rely on string manipulation.


As pointed in the comments, this is not the right answer to the original question.
That said, it is a very useful way to format numbers without unnecessary trailing zeros.


In short:


If you want to get rid of trailing zeros and Locale problems, then you should use :


Explanation:


Why other answers did not suit me :


Double.toString() or System.out.println or FloatingDecimal.toJavaFormatString uses scientific notations if double is less than 10^-3 or greater than or equal to 10^7


by using %f, the default decimal precision is 6, otherwise you can hardcode it but it results in extra zeros added if you have less decimals. Example :


by using setMaximumFractionDigits(0); or %.0f you remove any decimal precision, which is fine for integers/longs but not for double


by using DecimalFormat, you are local dependent. In French locale, the decimal separator is a comma, not a point :


Using the ENGLISH locale makes sure you get a point for decimal separator, wherever your program will run


Why using 340 then for setMaximumFractionDigits ?


Two reasons :


On my machine, the following function is roughly 7 times faster than the function provided by JasonD's answer, since it avoids String.format:


Why not:


This should work with the extreme values supported by Double. Yields:


My 2 cents:


Naw, never mind.


Performance loss due to String manipulation is zero.


And here's the code to trim the end after %f


I made a DoubleFormatter to efficiently convert a great numbers of double values to a nice/presentable String:


Here the code:


Note: I used 2 functions from GUAVA library. If you don't use GUAVA, code it yourself: 


Please note that String.format(format, args...) is locale-dependent because it formats using the user's default locale, that is, probably with commas and even spaces inside like 123 456,789 or 123,456.789, which may be not exactly what you expect.


You may prefer to use String.format((Locale)null, format, args...).


For example,


prints


and this is what will String.format(format, args...) do in different countries.


EDIT Ok, since there has been a discussion about formalities:


This one will get the job done nicely, I know the topic is old, but I was struggling with the same issue till I came to this. I hope someone find it useful.


Late answer but...


You said you choose to store your numbers with the double type. I think this could be the root of the problem because it forces you to store integers into doubles (and therefore losing the initial information about the value's nature). What about storing your numbers in instances of the Number class (superclass of both Double and Integer) and rely on polymorphism to determine the correct format of each number ?


I know it may not be acceptable to refactor a whole part of your code due to that but it could produce the desired output without extra code/casting/parsing.


Example:


Will produce the following output:


Here is an answer that actually works (combination of different answers here)


Here are two ways to achieve it. First, the shorter (and probably better) way:


And here's the longer and probably worse way:


I had to use this cause d == (long)d was giving me violation in sonar report


Use a DecimalFormat and setMinimumFractionDigits(0)


I know this is a really old thread.. But I think the best way to do this is as below:


Output:


The only issue is the last one where .0 doesn't get removed. But if you are able to live with that then this works best. %.2f will round it to the last 2 decimal digits. So will DecimalFormat. If you need all the decimal places but not the trailing zeros then this works best.


This will make the string to drop the tailing 0-s.






I went to the Environment Variables in 'System' in the control panel and made two new variables, one for user variables and one for system variables. Both were named JAVA_HOME and both pointing to


C:\Sun\SDK\jdk\bin


But for some reason, I still get the below error when running a Java command...


How can I fix this problem?


Find JDK Installation Directory


First you need to know the installation path for the Java Development Kit.


Open the default installation path for the JDK:


There should be a subdirectory like:


Note: one has only to put the path to the jdk without /bin in the end (as suggested on a lot of places). e.g. C:\Java\jdk1.6.0_31 and NOT C:\Java\jdk1.6.0_31\bin !


Set the JAVA_HOME Variable


Once you have the JDK installation path:


Note: You might need to restart Windows


The complete article is here, on my blog: Setting JAVA_HOME Variable in Windows.


Get Video Solution.


What worked for me was adding the %JAVA_HOME%\bin to the Path environment variable with the JAVA_HOME environment variable pointing to the jdk folder.


You have to first Install JDK in your system. 


Set Java Home


JAVA_HOME = C:\Program Files\Java\jdk1.7.0 [Location of your JDK Installation Directory]


Once you have the JDK installation path: 


 


Set JAVA Path under system variable


PATH= C:\Program Files\Java\jdk1.7.0; [Append Value with semi-colon]





http://javahowto.blogspot.com/2006/05/javahome-vs-javahome.html


Control Panel > Java, Java tab, click the View button. In Runtime Parameters, put:


Or when you execute Java you can add that command line switch to the command:


In cmd (temporarily for that cmd window):


You need to set it to C:\Sun\SDK\jdk (Assuming that is where the JDK is installed - It is not the default) - Do not put the \bin in C:\Sun\SDK\jdk\bin.


If your app only runs when you are logged in as the current user then put it in the user variables - If it needs to run for all users on your system then put it in System variables.


You might also need to add %JAVA_HOME%\bin to the path also (Also it depends on whether you run it from just the user or from all users, including System)


This is the official solution for setting the Java environment from www.java.com - here.


There are solutions for Windows 7, Windows Vista, Windows XP, Linux/Solaris and other shells.


For those who are still stumped with this problem (I tried all the above suggestions) --


If you're on a 64-bit version of Windows and you've installed the 32-bit JDK, besides adjusting PATH variables, you may need to adjust registry variables, too.


I was pulling my hair out, having correctly set my PATH variables -- still to no avail -- and then only finding "vacated" Java entries in my registry, seemingly a deadend of fixing the "misfiring" Java Runtime Environment. 


By using Process Monitor to watch the program I was trying to get started, in order to sniff out where it was looking in the registry for Java (Runtime Environment), I triumphantly discovered that it's looking in the 32-bit version of registry entries, found in HKEY_LOCAL_MACHINE\SOFTWARE\**Wow6432Node**\JavaSoft\Java Runtime Environment. 


Within that key, you should find subkeys of different Java versions installed (past and/or present). Click on the subkey of the latest version (my subkey is currently 1.7.0_25, for example). After clicking on that subkey, you'll see registry string values listed on the right, and particularly, JavaHome and RuntimeLib. You need to modify the values of those two values to reflect the both the current folder and jvm.dll file, respectively.


For example, in my case, the values were (previously) respectively set at C:\Program Files (x86)\Java\jre7 and C:\Program Files (x86)\Java\jre7\bin\client\jvm.dll which are nonexistent on my machine. I had to update these to the current folder and file of C:\Program Files (x86)\Java\jdk1.7.0_25\jre and C:\Program Files (x86)\Java\jdk1.7.0_25\jre\bin\client\jvm.dll.


Again, this will depend entirely on both what version of Java (JDK and/or JRE) you have installed -- 32 or 64-bit -- and what type of operating system you're on -- 32 or 64-bit. Just know that they're reflected in different locations within the registry (like the Wow6432Node for 32 bit applications, in my case with the 32-bit JDK installed on a 64-bit machine).


Now that I've updated those two registry values, my program runs flawlessly, with no more hiccups or complaints about a missing Java Runtime Environment (stemming from the registry).


Go to Control Panel\All Control Panel Items\User Accounts using Explorer (not Internet Explorer!)


or 


click on the Start button





click on your picture





Change my environment variables





New...





(if you don't have enough permissions to add it in the System variables section, add it to the User variables section)


Add JAVA_HOME as Variable name and the JDK location as Variable value > OK





Test:


One Image can fix this issue.



For More


In Eclipse: Window->Preferences->Java->Installed JREs


Use the search feature to make sure your latest Java installation is listed; then make sure it is the one that is checked. This should be a JDK not a JRE.


While adding your Java directory to your PATH variable, you might want to put it right at the beginning of it. I've had the problem, that putting the Java directory at the end of the PATH would not work. After checking, I've found java.exe in my Windows\System32 directory and it looks like the first one wins, when there are several files with the same name in your PATH...


We need to make a distinction between the two environment variables that are discussed here interchangeably. One is the JAVA_HOME variable. The other is the Path variable. Any process that references the JAVA_HOME variable is looking for the search path to the JDK, not the JRE. The use of JAVA_HOME variable is not meant for the Java compiler itself. The compiler is aware of its own location. The variable is meant for other software to more easily locate the compiler. This variable is typically used by IDE software in order to compile and build applications from Java source code. By contrast, the Windows CMD interpreter, and many other first and third party software references the Path variable, not the JAVA_HOME variable.


Use case 1: Compiling from CMD


So for instance, if you are not using any IDE software, and you just want to be able to compile from the CMD, independent of your current working directory, then what you want is to set the Path variable correctly. In your case, you don't even need the JAVA_HOME variable. Because CMD is using Path, not JAVA_HOME to locate the Java compiler.


Use case 2: Compiling from IDE


However, if you are using some IDE software, then you have to look at the documentation first of all. It may require JAVA_HOME to be set, but it may also use another variable name for the same purpose. The de-facto standard over the years has been JAVA_HOME, but this may not always be the case.


Use case 3: Compiling from IDE and CMD


If in addition to the IDE software you also want to be able to compile from the CMD, independent of your current working directory, then in addition to the JAVA_HOME variable you may also need to append the JDK search path to the Path variable.


JAVA_HOME vs. Path


If your problem relates to compiling Java, then you want to check the JAVA_HOME variable, and Path (where applicable). If your problem relates to running Java applications, then you want to check your Path variable.


Path variable is used universally across all operating systems. Because it is defined by the system, and because it's the default variable that's used for locating the JRE, there is almost never any problem running Java applications. Especially not on Windows where the software installers usually set everything up for you. But if you are installing manually, the safest thing to do is perhaps to skip the JAVA_HOME variable altogether and just use the Path variable for everything, for both JDK and the JRE. Any recent version of an IDE software should be able to pick that up and use it.


Symlinks


Symbolic links may provide yet another way to reference the JDK search path by piggybacking one of the existing environment variables.


I am not sure about previous versions of Oracle/Sun JDK/JRE releases, but at least the installer for jdk1.8.0_74 appends the search path C:\ProgramData\Oracle\Java\javapath to the Path variable, and it puts it at the beginning of the string value. This directory contains symbolic links to the java.exe, javaw.exe and javaws.exe in the JRE directory.


So at least with the Java 8 JDK, and presumably the Java 8 JRE standalone, no environment variable configuration needs to be done for the JRE. As long as you use the installer package to set it up. There may be differences on your Windows installation however. Note that the Oracle JRE comes bundled with the JDK.


If you ever find that your Java JDK configuration is using the wrong version of the compiler, or it appears to be working by magic, without being explicitly defined so (without casting the spell), then you may have a symlink somewhere in your environment variables. So you may want to check for symlink.


Run Eclipse as Administrator.


That solved my problem. I'm still digging for the logic behind it.


if you have not restarted your computer after installing jdk just restart your computer.


if you want to make a portable java and set path before using java, just make a batch file i explained below.


if you want to run this batch file when your computer start just put your batch file shortcut in startup folder. In windows 7 startup folder is "C:\Users\user\AppData\Roaming\Microsoft\Windows\Start Menu\Programs\Startup"


make a batch file like this:


note:
java_home and path are variables. you can make any variable as you wish.
for example set amir=good_boy and you can see amir by %amir% or you can see java_home by %java_home%


After hours of work around most of the solutions here, the problem was solved for me just by installing 32-bit JDK.






Searching the web, it is not clear if Java 8 is supported for Android development or not.


Before I download/setup Java 8, can some one point me at any "official" documentation that says Java 8 is or is not supported for Android development.


Android supports all Java 7 language features and a subset of Java 8 language features that vary by platform version.


To check which features of java 8 are supported 


Use Java 8 language features


We've decided to add support for Java 8 language features directly into the current javac and dx set of tools, and deprecate the Jack toolchain. With this new direction, existing tools and plugins dependent on the Java class file format should continue to work. Moving forward, Java 8 language features will be natively supported by the Android build system. We're aiming to launch this as part of Android Studio in the coming weeks, and we wanted to share this decision early with you. 


Future of Java 8 Language Feature Support on Android


For old developers who prefer Eclipse, google stops support Eclipse Android Developer tools


if you installed Java 8 JDK, then give it a try, if any problems appears try to set the compiler as 1.6 in Eclipse from window menu → Preferences → Java → Compiler.
Java 7 will works too:





Java 7 or higher is required if you are targeting Android 5.0 and
  higher.


install multiple JDK and try.


Android does not support Java 8. It only supports up to Java 7 (if you have kitkat) and still it doesn't have invokedynamic, only the new syntax sugar.


If you want to use lambdas, one of the major features of Java 8 in Android, you can use gradle-retrolamba. It's a gradle build dependency that integrates retrolambda, a tool that converts Java 8 bytecode back to Java 6/7. Basically, if you set the compiler in Android Studio to compile Java 8 bytecode, thus allowing lambdas, it'll convert it back to Java 6/7 bytecode which then in turn gets converted to dalvik bytecode. It's a hack for if you want to try out some JDK 8 features in Android in lieu of official support.


You can indeed use gradle-retrolamba gradle build dependency to use Java 8 for Android Development.


Below is the complete guide that I have recently followed to run lambda expressions for Android development. The original source of this guide is mentioned at the end.


In this guide, a method for bringing some Java 8 features into
  Android Development Tools will be demonstrated, specifically aiming at
  Eclipse IDE. However, steps which will be described throughout this guide might also be adapted to Google’s new uprising development
  environment, Android Studio. It is based on the community edition of
  popular IntelliJ Idea IDE by JetBrains and it has recently been
  upgraded to its ‘beta’ version by Google in early July 2014, slightly
  before this guide was written. Eclipse will remain as the prominent
  development environment, at least for a while, and considering the
  fact that most Android projects have been developed using Eclipse, a
  method for bringing new Java 8 features like lambda expressions into
  ADT seems to be quite useful for developers.


Android Development is based on a custom Java implementation called
  Apache Harmony Project which was terminated back in 2011. The most
  commonly used Java syntax in Android Development is Java 6 (v1.6) and
  Java 7 (v1.7) is also partially supported on the KitKat edition
  (Android 4.4.+). Therefore, Java 8 features like lambda expressions
  cannot be used directly in the Android App Development without
  applying some tweaks into the development tools. Luckily, these
  constructs are basically some ‘syntactic sugar’ enhancements which
  give developers the shortcomings of things like ‘anonymous classes’
  and they can be translated into Java 6 or Java 7 classes.


A recent approach for translating a Java 8 source code into lower Java
  versions is called RetroLambda. This library makes developers run
  Java 8 code with lambda expressions on Java 7 or even lower.
  Unfortunately, Java 8 features other than lambda expressions are not
  supported by RetroLambda for now but the concept of lambda expressions
  is the biggest leap on Java 8 platform and it’s a great tool for
  Android developers anyway. 


Details about this library can be found on its GitHub page:


https://github.com/orfjackal/retrolambda#getting-started


Also, a Gradle plugin for RetroLambda created by another developer
  allows Gradle-based builds to be implemented in Java or Android
  Projects. However, the developer only mentions about integrating this
  plugin into Android Studio environment. Details can be found on its
  GitHub page:


https://github.com/evant/gradle-retrolambda


Using these infrastructures within an Eclipse-based development
  environment cannot be approached directly but it’s doable and will be
  demonstrated throughout this guide.


This guide assumes that the reader has a basic understanding of Android Development and it is based on ADT version 22.6.2 because recent ADT version 23.0.2 seems to have problems like layout folder creation. Details about this issue can be found under the following link:


http://code.google.com/p/android/issues/detail?id=72591


Steps in this guide will be given for a Windows 8.1, 64-bit development machine but they can easily be adapted to other platforms. The new build system Gradle will be used for build/clean processes and its installation procedure will also be provided. Also, both JDK 8 and JDK 7 must coexist on the development machine. Steps given below must be followed to install them:


Now, ADT-22.6.2 must be downloaded from the following link:


http://dl.google.com/android/adt/22.6.2/adt-bundle-windows-x86_64-20140321.zip


If everything goes well, ADT will be up and running.


The installation of the following tools is also highly recommended:


Eclipse Kepler Java 8 Support: It makes Eclipse recognize new Java 8 syntax extensions and makes you get rid of annoying red dots in your Java code editor. It might be installed through Help -> Install New Software in Eclipse. Enter http://download.eclipse.org/eclipse/updates/4.3-P-builds/ into the Work with field and continue to install it.


Nodeclipse/Enide Gradle: It is mainly used to highlight Groovy language keywords. Groovy is used as the DSL for Gradle build scripts. This plugin can be installed through Eclipse Marketplace. However, Eclipse within ADT-22.6.2 does not come along with Eclipse Marketplace Client. Therefore, you will first need to install Eclipse Marketplace Client by means of Install New Software tool in Eclipse. Enter http//:download.eclipse.org/mpc/kepler/ into the Work with field and continue to install it. After installing Eclipse Marketplace Client, you may search for Nodeclipse/Enide Gradle in the Eclipse Marketplace Client and install it.


Genymotion Virtual Device: It is a great replacement of the default Android Virtual Device which comes along with ADT. AVD is annoyingly cumbersome and it keeps on crashing for no reason. Genymotion makes you prepare Android VD's using CyanogenMod images which are executed by Oracle VirtualBox. Its single user license is for free and it can be downloaded from http://www.genymotion.com. Only a login is required and it can also be integrated into Eclipse. Details can be found under:


https://cloud.genymotion.com/page/doc/#collapse8


Below is a screenshot of an Android 4.3 based CyanogenMod virtual device,





It might be considered as a fully-fledge Android device running on a x86 or x64 based personal computer. In order to use Google services like Google PlayStore on this virtual device, a gapps image for the Android version that it uses must be flashed onto the device. A proper gapps image for the device might be downloaded from CyanogenMod website:


http://wiki.cyanogenmod.org/w/Google_Apps


Gradle installation is optional since it is also provided by Android SDK itself but its separate installation is highly recommended. Installation of it might be conducted by following these steps:


Go to Gradle web site: http://www.gradle.org/


Click Downloads


A simple app will be created to demonstrate the usage of the tools which were described in the previous section. 
You may simply follow the steps given below to get an insight on using lambda expressions in Android Developer Tools:





Create following batch files under the builders folder:


Fill in these batch files as follows:


gradle_build.cmd:





gradle_post_build.cmd:





gradle_clean.cmd:





Main Tab of the new Builder Configuration





Refresh Tab of the new Builder Configuration





Environment Tab of the new Builder Configuration





Build Options Tab of the new Builder Configuration





New Builders of the HelloLambda Project





Clean Project Window











Build Process



Right-click on the project and go to Properties -> Java Build Path. Add the following folders to the build path (also shown in below image):





Eclipse will now be able to recognize R.java and buildConfig.java files and it will not display any red dots which denote errors related to the resource files of the project.





You may observe in the LogCat window that the code snippet with a simple lambda expression works properly





Source: Using Java 8 Lambda Expressions in Android Developer Tools


Follow this link for new updates. Use Java 8 language features


Old Answer


As of Android N preview release Android support limited features of Java 8 see Java 8 Language Features


To start using these features, you need to download and set up Android
  Studio 2.1  and the Android N Preview SDK, which includes the
  required Jack toolchain and updated Android Plugin for Gradle. If you
  haven't yet installed the Android N Preview SDK, see Set Up to Develop
  for Android N.


Supported Java 8 Language Features and APIs


Android does not currently support all Java 8 language features.
  However, the following features are now available when developing apps
  targeting the Android N Preview:


Default and static interface methods


Lambda expressions (also available on API level 23 and lower)


Repeatable annotations


Method References (also available on API level 23 and lower)


There are some additional Java 8 features which Android support, you can see complete detail from Java 8 Language Features


Update


Note: The Android N bases its implementation of lambda expressions on
  anonymous classes. This approach allows them to be backwards
  compatible and executable on earlier versions of Android. To test
  lambda expressions on earlier versions, remember to go to your
  build.gradle file, and set compileSdkVersion and targetSdkVersion to
  23 or lower.


Update 2


Now Android studio 3.0 stable release support Java 8 libraries and Java 8 language features (without the Jack compiler).


Android uses a Java that branches off of Java 6.


As of Android SDK version 19, you can use Java 7 features by doing this.  No full support for Java 8 (yet).


Android OFFICIALLY supports Java 8 as of Android N. 


Feature announcements are here, the Java 8 language announcement is:


Improved Java 8 language support - We’re excited to bring Java 8 language features to Android. With Android's Jack compiler, you can
  now use many popular Java 8 language features, including lambdas and
  more, on Android versions as far back as Gingerbread. The new features
  help reduce boilerplate code. For example, lambdas can replace
  anonymous inner classes when providing event listeners. Some Java 8
  language features --like default and static methods, streams, and
  functional interfaces -- are also now available on N and above. With
  Jack, we’re looking forward to tracking the Java language more closely
  while maintaining backward compatibility.


Now it is possible 


But you will need to have your device rom run on java 1.8  and enable "jackOptions" to run it. 
Jack is the name for the new Android compiler that runs Java 8


https://developer.android.com/guide/platform/j8-jack.html


add these lines to build_gradle 


Java 8 seem to be the running java engine of Android studio 2.0, 
But it still does not accept the syntax of java 8 after I checked, and you cannot chose a compiler from android studio now. However, you can use the scala plugin if you need functional programming mechanism in your android client. 





We Can Use Java 8 using:


In build.gradle (Project: myProject) add following


In build.gradle (Module: myModule) add following


Native Java 8 arrives on android! Finally!


remove the Retrolambda plugin and retrolambda block from each module's
  build.gradle file:


To disable Jack and switch to the default toolchain, simply remove the
  jackOptions block from your module’s build.gradle file


To start using supported Java 8 language features, update the Android plugin to 3.0.0 (or higher)


Starting with Android Studio 3.0 , Java 8 language features are now natively supported by android:


Also from min API level 24 the following Java 8 API are available:


Add these lines to your application module’s build.gradle to inform the project of the language level:


Disable Support for Java 8 Language Features by adding the following to your gradle.properties file:


You’re done! You can now use native java8!


Android Studio 3.0 started to provide built-in support for some of Java 8 language features, which are:


Also starting from API level 24 the following Java 8 API are available:


Besides that, the try-with-resources support was extended to all Android API levels.


More Java 8 features are promised to be added in the future.


To start using supported Java 8 language features, update the Android
  plugin to 3.0.0-alpha1 (or higher) and add the following to your
  module’s build.gradle file:


For more details visit:
https://developer.android.com/studio/write/java8-support.html


When I asked this question almost 2 years ago the answer really was “officially” no,  but as pointed out by ekcr1's answer you can get one of the most highly anticipated features (lambdas) to work if you  use retrolamba.  At the time I was still using eclipse, as Android Studio was in “preview” mode,  so I never did pursue this path.


Today, I think the “official” answer is still no,  and while retrolamba still seems like a good way to go, there is another option for those willing to go down a somewhat “unofficial”  route can take, namely Kotlin.


Today Kotlin reached 1.0.0.  For those not familiar with Kotlin,  more info can be found at their website found here:


https://kotlinlang.org


or watch this utube video of a talk given by Jake Wharton


https://www.youtube.com/watch?v=A2LukgT2mKc


Latest news:


Google announce that with Android N and Android Studio 2.1+, platform will support Java 8. Also stable version of studio 2.1 was released. 


At last we can use lambda expressions. No more list filter in for loop. Horeeey.


Add this config build.gradle and sync gradle:


Google just announced that Java 8 will be natively support by Android and that the Jack toolchain will deprecate:


We've decided to add support for Java 8 language features directly into the current javac and dx set of tools, and deprecate the Jack toolchain. With this new direction, existing tools and plugins dependent on the Java class file format should continue to work. Moving forward, Java 8 language features will be natively supported by the Android build system. We're aiming to launch this as part of Android Studio in the coming weeks, and we wanted to share this decision early with you. 


More Info here:
https://android-developers.googleblog.com/2017/03/future-of-java-8-language-feature.html


Yes. We will use Java 8 soon!


We've decided to add support for Java 8 language features directly into the current javac and dx set of tools, and deprecate the Jack toolchain. With this new direction, existing tools and plugins dependent on the Java class file format should continue to work. Moving forward, Java 8 language features will be natively supported by the Android build system. We're aiming to launch this as part of Android Studio in the coming weeks, and we wanted to share this decision early with you. 


https://android-developers.googleblog.com/2017/03/future-of-java-8-language-feature.html


I wrote a similar answer to a similar question on Stack Overflow, but here is part of that answer.


The new version of Android Studio (2.1) has support for Java 8 features. Here is an extract from the Android Developers blogspot post:


... Android Studio 2.1 release includes support for the new Jack compiler and support for Java 8. 


...


To use Java 8 language features when developing with the N Developer Preview, you need to use the Jack compiler. The New Project Wizard [File→ New→ Project] generates the correct configurations for projects targeting the N.


Android does not support Java 1.8 yet (it only supports up to 1.7), so you cannot use Java 8 features like lambdas.


This answer gives more detail on Android Studio's compatibility; it states:


If you want to use lambdas, one of the major features of Java 8 in Android, you can use gradle-retrolamba


If you want to know more about using gradle-retrolambda, this answer gives a lot of detail on doing that.


I figured I would post an updated answer for those looking at for something a little more current. 


Currently Android and Android Studio are supporting a subset of Java 8 features. According to the Android documentation located on their website, Google says: 


Support for Java 8 language features requires a new compiler called Jack. Jack is supported only on Android Studio 2.1 and higher. So if you want to use Java 8 language features, you need to use Android Studio 2.1 to build your app.


If you already have Android Studio installed, make sure you update to the latest version by clicking Help > Check for Update (on Mac, Android Studio > Check for Updates). If you don't already have the IDE installed on your workstation, download Android Studio here.


Supported Java 8 Language Features and APIs


Android does not support all Java 8 language features. However, the following features are available when developing apps targeting Android 7.0 (API level 24):


Additionally, the following Java 8 language APIs are also available:


Reflection and language-related APIs:


Utility APIs:


In order to use the new Java 8 language features, you need to also use the Jack toolchain. This new Android toolchain compiles Java language sources into Android-readable DEX bytecode, has its own .jack library format, and provides most toolchain features as part of a single tool: repackaging, shrinking, obfuscation and multidex.


Here is a comparison of the two toolchains used to build Android DEX files:


I asked this question over 3 years ago and obviously the answers have changed over the years.  As many above have already answered, as of sometime back, the answer became Yes.   I have never updated the accepted answer because it was the correct answer at the time. (I am not sure what the Stack Overflow policy is on that)


I just wanted to add another answer for those who still search for this topic. As of  5/17/2017 Google also announced that Kotlin is also an official language for Android development.


I have not found an official press release, but I did watch some of the Google I/O videos where it was announced.  Here is a link to a blog post by the Kotlin team on the announcement. 


Adding the following fixed the problem for me (Android studio 2.3.2):


build.gradle (Project)


build.gradle (Module: app)






How do you left pad an int with zeros in java when converting to a string?


I'm basically looking to pad out integers up to 9999 with the leading zeros (e.g. 1 = "0001").


Use java.lang.String.format(String,Object...) like this:


for zero-padding with a length of 5. For hexadecimal output replace the d with an x as in "%05x".


The full formatting options are documented as part of java.util.Formatter.


If you for any reason use pre 1.5 Java then may try with Apache Commons Lang method


Let's say you want to print 11 as 011


You could use a formatter: "%03d".





You can use this formatter like this:


Alternatively, some java methods directly support these formatters:


Found this example... Will test...


Tested this and:


Both work, for  my purposes I think String.Format is better and more succinct.


If performance is important in your case you could do it yourself with less overhead compared to the String.format function:


Performance


Result


Own function: 1697ms


String.format: 38134ms


You can use Google Guava:


Maven:


Sample code:


Note:


Guava is very useful library, it also provides lots of features which related to Collections, Caches, Functional idioms, Concurrency, Strings, Primitives, Ranges, IO, Hashing, EventBus, etc


Ref: GuavaExplained 


Although many of the above approaches are good, but sometimes we need to format integers as well as floats. We can use this, particularly when we need to pad particular number of zeroes on left as well as right of decimal numbers.


if you want to print the formatted text directly onto the screen.


Check my code that will work for integer and String.


Assume our first number is 2. And we want to add zeros to that so the the length of final string will be 4. For that you can use following code


The only problem with this approach is that it makes you put on your thinking hat to figure out how it works.


No packages needed:


This will pad the string to three characters, and it is easy to add a part more for four or five. I know this is not the perfect solution in any way (especially if you want a large padded string), but I like it.






What are the reasons behind the decision to not have a fully generic get method 
in the interface of java.util.Map<K, V>.


To clarify the question, the signature of the method is 


V get(Object key)


instead of 


V get(K key)


and I'm wondering why (same thing for remove, containsKey, containsValue).


As mentioned by others, the reason why get(), etc. is not generic because the key of the entry you are retrieving does not have to be the same type as the object that you pass in to get(); the specification of the method only requires that they be equal. This follows from how the equals() method takes in an Object as parameter, not just the same type as the object.


Although it may be commonly true that many classes have equals() defined so that its objects can only be equal to objects of its own class, there are many places in Java where this is not the case. For example, the specification for List.equals() says that two List objects are equal if they are both Lists and have the same contents, even if they are different implementations of List. So coming back to the example in this question, according to the specification of the method is possible to have a Map<ArrayList, Something> and for me to call get() with a LinkedList as argument, and it should retrieve the key which is a list with the same contents. This would not be possible if get() were generic and restricted its argument type.


An awesome Java coder at Google, Kevin Bourrillion, wrote about exactly this issue in a blog post a while ago (admittedly in the context of Set instead of Map). The most relevant sentence:


Uniformly, methods of the Java
  Collections Framework (and the Google
  Collections Library too) never
  restrict the types of their parameters
  except when it's necessary to prevent
  the collection from getting broken.


I'm not entirely sure I agree with it as a principle - .NET seems to be fine requiring the right key type, for example - but it's worth following the reasoning in the blog post. (Having mentioned .NET, it's worth explaining that part of the reason why it's not a problem in .NET is that there's the bigger problem in .NET of more limited variance...)


The contract is expressed thus:


More formally, if this map contains a
  mapping from a key k to a value v such
  that (key==null ? k==null :
  key.equals(k)), then this method
  returns v; otherwise it returns null.
  (There can be at most one such
  mapping.)


(my emphasis)


and as such, a successful key lookup depends on the input key's implementation of the equality method. That is not necessarily dependent on the class of k.


It's an application of Postel's Law, "be  conservative in what you do, be liberal in what you accept from others."


Equality checks can be performed regardless of type; the equals method is defined on the Object class and accepts any Object as a parameter. So, it makes sense for key equivalence, and operations based on key equivalence, to accept any Object type.


When a map returns key values, it conserves as much type information as it can, by using the type parameter.


I think this section of Generics Tutorial explains the situation (my emphasis):


"You need to make certain that the generic API is not unduly restrictive; it must
continue to support the original contract of the API. Consider again some examples
from java.util.Collection. The pre-generic API looks like:


A naive attempt to generify it is:


While this is certainly type safe, it doesn’t live up to the API’s original contract.
The containsAll() method works with any kind of incoming collection. It will only
succeed if the incoming collection really contains only instances of E, but:


The reason is that containment is determined by equals and hashCode which are methods on Object and both take an Object parameter. This was an early design flaw in Java's standard libraries. Coupled with limitations in Java's type system, it forces anything that relies on equals and hashCode to take Object.


The only way to have type-safe hash tables and equality in Java is to eschew Object.equals and Object.hashCode and use a generic substitute. Functional Java comes with type classes for just this purpose: Hash<A> and Equal<A>. A wrapper for HashMap<K, V> is provided that takes Hash<K> and Equal<K> in its constructor. This class's get and contains methods therefore take a generic argument of type K.


Example:


There is one more weighty reason, it can not be done technically, because it brokes Map.


Java has polymorphic generic construction like <? extends SomeClass>. Marked such reference can point to type signed with <AnySubclassOfSomeClass>. But polymorphic generic makes that reference readonly. The compiler allows you to use generic types only as returning type of method (like simple getters), but blocks using of methods where generic type is argument (like ordinary setters).
It means if you write Map<? extends KeyType, ValueType>, the compiler does not allow you to call method get(<? extends KeyType>), and the map will be useless. The only solution is to make this method not generic: get(Object).


Compatibility.


Before generics were available, there was just get(Object o).


Had they changed this method to get(<K> o) it would have potentially forced massive code maintenance onto java users just to make working code compile again.


They could have introduced an additional method, say get_checked(<K> o) and deprecate the old get() method so there was a gentler transition path.  But for some reason, this was not done.  (The situation we are in now is that you need to install tools like findBugs to check for type compatibility between the get() argument and the declared key type <K> of the map.)


The arguments relating to the semantics of .equals() are bogus, I think.  (Technically they're correct, but I still think they're bogus.  No designer in his right mind is ever going to make o1.equals(o2) true if o1 and o2 do not have any common superclass.)


Backwards compatibility, I guess. Map (or HashMap) still needs to support get(Object).


I was looking at this and thinking why they did it this way. I don't think any of the existing answers explains why they couldn't just make the new generic interface accept only the proper type for the key. The actual reason is that even though they introduced generics they did NOT create a new interface. The Map interface is the same old non-generic Map it just serves as both generic and non-generic version. This way if you have a method that accepts non-generic Map you can pass it a Map<String, Customer> and it would still work. At the same time the contract for get accepts Object so the new interface should support this contract too.


In my opinion they should have added a new interface and implemented both on existing collection but they decided in favor of compatible interfaces even if it means worse design for the get method. Note that the collections themselves would be compatible with existing methods only the interfaces wouldn't.


We are doing big refactoring just now and we were missing this strongly typed get() to check that we did not missed some get() with old type.


But I found workaround/ugly trick for compilation time check: create Map interface with strongly typed get, containsKey, remove... and put it to java.util package of your project.


You will get compilation errors just for calling get(), ... with wrong types,  everything others seems ok for compiler (at least inside eclipse kepler).


Do not forget to delete this interface after check of your build as this is not what you want in runtime.






What is the main difference between StringBuffer and StringBuilder?
Is there any performance issues when deciding on any one of these?


StringBuffer is synchronized, StringBuilder is not. 


StringBuilder is faster than StringBuffer because it's not synchronized.


Here's a simple benchmark test:


A test run gives the numbers of 2241 ms for StringBuffer vs 753 ms for StringBuilder.


Basically, StringBuffer methods are synchronized while StringBuilder are not.


The operations are "almost" the same, but using synchronized methods in a single thread is overkill.


That's pretty much about it.


Quote from StringBuilder API:


This class [StringBuilder] provides an API compatible with StringBuffer, but with no guarantee of synchronization. This class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread (as is generally the case). Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations.


So it was made to substitute it.


The same happened with Vector and ArrayList.


But needed to get the clear difference with the help of an example?


StringBuffer or StringBuilder


Simply use StringBuilder unless you really are trying to share a buffer between threads. StringBuilder is the unsynchronized (less overhead = more efficient) younger brother of the original synchronized StringBuffer class.


First lets see the similarities:
Both StringBuilder and StringBuffer are mutable. That means you can change the content of them, with in the same location.


Differences:
StringBuffer is mutable and synchronized as well. Where as StringBuilder is mutable but not synchronized by default.


Meaning of synchronized (synchronization):
When some thing is synchronized, then multiple threads can access, and modify it with out any problem or side effect.
StringBuffer is synchronized, so you can use it with multiple threads with out any problem.


Which one to use when?
StringBuilder : When you need a string, which can be modifiable, and only one thread is accessing and modifying it.
StringBuffer : When you need a string, which can be modifiable, and multiple threads are accessing and modifying it.


Note : Don't use StringBuffer unnecessarily, i.e., don't use it if only one thread is modifying and accessing it because it has lot of locking and unlocking code for synchronization which will unnecessarily take up CPU time. Don't use locks unless it is required. 


In single threads, StringBuffer is not significantly slower than StringBuilder, thanks to JVM optimisations. And in multithreading, you can't use safely a StringBuilder.


Here is my test : 


Results :
strings: 319740
Buffers : 23
Builder : 7 !


So Builders are faster than Buffers, and WAY faster than strings concatenation.
Now let's use an Executor for multiple threads :


Now StringBuffers take 157 ms for 100000 appends. It's not the same test, but compared to the previous 37 ms, you can safely assume that StringBuffers appends are slower with multithreading use. The reason is that the JIT/hotspot/compiler/something makes optimizations when it detects that there is no need for checking locks.


But with StringBuilder, you have java.lang.ArrayIndexOutOfBoundsException, because a concurrent thread tries to add something where it should not. 


Conclusion is that you don't have to chase StringBuffers. And where you have threads, think about what they are doing, before trying to gain a few nanoseconds.


StringBuilder was introduced in Java 1.5 so it won't work with earlier JVMs.


From the Javadocs:


StringBuilder class provides an API compatible with StringBuffer, but with no guarantee of synchronization. This class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread (as is generally the case). Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations. 


Pretty Good Question


Here are the differences, i have noticed :


StringBuffer :-


StringBuilder:-


Common thing :-


Both have same methods with same signatures. Both are mutable.


StringBuilder is not thread safe. String Buffer is. More info here.


EDIT: As for performance , after hotspot kicks in , StringBuilder is the winner. However , for small iterations , the performance difference is negligible.


StringBuilder and StringBuffer are almost the same. The difference is that StringBuffer is synchronized and StringBuilder is not. Although, StringBuilder is faster than StringBuffer, the difference in performance is very little. StringBuilder is a SUN's replacement of StringBuffer. It just avoids synchronization from all the public methods. Rather than that, their functionality is the same.


Example of good usage:


If your text is going to change and is used by multiple threads, then it is better to use StringBuffer. If your text is going to change but is used by a single thread, then use StringBuilder.


StringBuffer


StringBuffer is mutable means one can change the value of the object . The object created through StringBuffer is stored in the heap .  StringBuffer  has the same methods as the StringBuilder , but each method in StringBuffer is synchronized that is StringBuffer is thread safe .


because of this it does not allow  two threads to simultaneously access the same method . Each method can be accessed by one thread at a time .


But being thread safe has disadvantages too as the performance of the StringBuffer hits due to thread safe property . Thus  StringBuilder is faster than the StringBuffer when calling the same methods of each class.


StringBuffer value can be changed , it means it can be assigned to the new value . Nowadays its a most common interview question ,the differences between the above classes .
String Buffer can be converted to the string by using
toString() method.


StringBuilder


StringBuilder  is same as the StringBuffer , that is it stores the object in heap and it can also be modified . The main difference between the StringBuffer and StringBuilder is that StringBuilder is also not thread safe. 
StringBuilder is fast as it is not thread safe .





Resource: String Vs StringBuffer Vs StringBuilder


StringBuffer
 - Synchronized hence threadsafe
 - thread safe hence slow
 - 


StringBuilder
 - Introduced in java 5.0
 - Asynchronous hence fast & efficient
 - User explicitly need to synchronized it, if he wants
 - You can replace it will StringBuilder without a any other change 


The javadoc explains the difference:


This class provides an API compatible with StringBuffer, but with no guarantee of synchronization. This class is designed for use as a drop-in replacement for StringBuffer in places where the string buffer was being used by a single thread (as is generally the case). Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations.


String is an immutable.


StringBuffer is a mutable and synchronized. 


StringBuilder is also mutable but its not synchronized.


StringBuilder (introduced in Java 5) is identical to StringBuffer, except its methods are not synchronized.  This means it has better performance than the latter, but the drawback is that it is not thread-safe.


Read tutorial for more details.


StringBuilder is  much faster than StringBuffer because It's non synchronized.


Here you got more idea about the cost of synchronize 


Let take programmatically look how much StringBuilder faster than StringBuffer


OutPut


Time taken by StringBuffer: 16ms


Time taken by StringBuilder: 0ms


A simple program illustrating the difference between StringBuffer and StringBuilder:


StringBuffer is synchronized, but StringBuilder is not. As a result, StringBuilder is faster than StringBuffer.


StringBuffer
is mutable. It can change in terms of length and content. StringBuffers are thread-safe, meaning that they have synchronized methods to control access so that only one thread can access a StringBuffer object's synchronized code at a time. Thus, StringBuffer objects are generally safe to use in a multi-threaded environment where multiple threads may be trying to access the same StringBuffer object at the same time.


StringBuilder
The StringBuilder class is very similar to StringBuffer, except that its access is not synchronized so that it is not thread-safe. By not being synchronized, the performance of StringBuilder can be better than StringBuffer. Thus, if you are working in a single-threaded environment, using StringBuilder instead of StringBuffer may result in increased performance. This is also true of other situations such as a StringBuilder local variable (ie, a variable within a method) where only one thread will be accessing a StringBuilder object.


StringBuffer


StringBuffer is mutable means one can change the value of the object . The object created through StringBuffer is stored in the heap . StringBuffer  has the same methods as the StringBuilder , but each method in StringBuffer is synchronized that is StringBuffer is thread safe . 


StringBuilder


StringBuilder  is same as the StringBuffer , that is it stores the object in heap and it can also be modified . The main difference between the StringBuffer and StringBuilder is that StringBuilder is not thread safe. 
StringBuilder is fast as it is not thread safe .  


StringBuffer is used to store character strings that will be changed (String objects cannot be changed). It automatically expands as needed. Related classes: String, CharSequence.


StringBuilder was added in Java 5. It is identical in all respects to StringBuffer except that it is not synchronized, which means that if multiple threads are accessing it at the same time, there could be trouble. For single-threaded programs, the most common case, avoiding the overhead of synchronization makes the StringBuilder very slightly faster.


Better use StringBuilder since it is not synchronized and therefor better performance. StringBuilder is a drop-in replacement of the older StringBuffer.


StringBuffer:


StringBuilder


This link will make you understand the concepts of not only StringBuilder and StringBuffer but also their association and difference with String class. This will make you understand when to use which class.
http://www.acquireandinspire.org/2013/01/string-string-builder-string-buffer.html


There are no basic differences between StringBuilder and StringBuffer, only a few differences exist between them. In StringBuffer the methods are synchronized. This means that at a time only one thread can operate on them. If there are more than one thread then the second thread will have to wait for the first one to finish and the third one will have to wait for the first and second one to finish and so on. This makes the process very slow and hence the performance in case of StringBuffer is low.


On the other hand StringBuilder is non synchronized. This means that at a time multiple threads can operate on the same StrinBuilder object at the same time. This makes the process very fast and hence performance of StringBuilder is high.


Check the internals of synchronized append method of StringBuffer and non-synchronized append method of StringBuilder.


StringBuffer:


StringBuilder:


Since append is synchronized, StringBuffer has performance overhead compared to StrinbBuilder in multi-threading scenario. As long as you are not sharing buffer among multiple threads, use StringBuilder, which is fast due to absence of synchronized in append methods.


Since StringBuffer is synchronized, it needs some extra effort, hence based on perforamance, its a bit slow than StringBuilder.


String-Builder :


String-Buffer


It is recommended to use StringBuilder whenever possible because it is faster than StringBuffer. However, if the thread safety is necessary, the best option is StringBuffer objects.


String is an immutable object which means the value cannot be changed where as StringBuffer is mutable.


The StringBuffer is Synchronized hence thread safe where as StringBuilder is not and suitable for only single threaded instances.


Every method present in StringBuffer is Synchronized.
hence at a time only one thread is allowed to operate StringBuffer object.
It Increases waiting time of a Thread and Creates Performance problems
to overcome this problem SUN People intoduced StringBuilder in 1.5 version.






Assuming String a and b:


Under the hood, are they the same thing?


Here is concat decompiled as reference. I'd like to be able to decompile the + operator as well to see what that does.


No, not quite.


Firstly, there's a slight difference in semantics. If a is null, then a.concat(b) throws a NullPointerException but a+=b will treat the original value of a as if it were null. Furthermore, the concat() method only accepts String values while the + operator will silently convert the argument to a String (using the toString() method for objects). So the concat() method is more strict in what it accepts.


To look under the hood, write a simple class with a += b;


Now disassemble with javap -c (included in the Sun JDK). You should see a listing including:


So, a += b is the equivalent of


The concat method should be faster. However, with more strings the StringBuilder method wins, at least in terms of performance.


The source code of String and StringBuilder (and its package-private base class) is available in src.zip of the Sun JDK. You can see that you are building up a char array (resizing as necessary) and then throwing it away when you create the final String. In practice memory allocation is surprisingly fast.


Update: As Pawel Adamski notes, performance has changed in more recent HotSpot. javac still produces exactly the same code, but the bytecode compiler cheats. Simple testing entirely fails because the entire body of code is thrown away. Summing System.identityHashCode (not String.hashCode) shows the StringBuffer code has a slight advantage. Subject to change when the next update is released, or if you use a different JVM. From @lukaseder, a list of HotSpot JVM intrinsics.


Niyaz is correct, but it's also worth noting that the special + operator can be converted into something more efficient by the Java compiler.  Java has a StringBuilder class which represents a non-thread-safe, mutable String.  When performing a bunch of String concatenations, the Java compiler silently converts


into


which for large strings is significantly more efficient.  As far as I know, this does not happen when you use the concat method.


However, the concat method is more efficient when concatenating an empty String onto an existing String.  In this case, the JVM does not need to create a new String object and can simply return the existing one.  See the concat documentation to confirm this.


So if you're super-concerned about efficiency then you should use the concat method when concatenating possibly-empty Strings, and use + otherwise.  However, the performance difference should be negligible and you probably shouldn't ever worry about this.


I ran a similar test as @marcio but with the following loop instead:


Just for good measure, I threw in StringBuilder.append() as well.  Each test was run 10 times, with 100k reps for each run.  Here are the results:


I haven't decompiled the class to see the internals or run it through profiler yet, but I suspect a += b spends much of the time creating new objects of StringBuilder and then converting them back to String.


Tom is correct in describing exactly what the + operator does.  It creates a temporary StringBuilder, appends the parts, and finishes with toString().


However, all of the answers so far are ignoring the effects of HotSpot runtime optimizations.  Specifically, these temporary operations are recognized as a common pattern and are replaced with more efficient machine code at run-time.


@marcio: You've created a micro-benchmark; with modern JVM's this is not a valid way to profile code.


The reason run-time optimization matters is that many of these differences in code -- even including object-creation -- are completely different once HotSpot gets going.  The only way to know for sure is profiling your code in situ.


Finally, all of these methods are in fact incredibly fast.  This might be a case of premature optimization.  If you have code that concatenates strings a lot, the way to get maximum speed probably has nothing to do with which operators you choose and instead the algorithm you're using!


How about some simple testing? Used the code below:


Tested several times. The concat() version execution took half of the time on average.


This result surprised me because the concat() method always creates a new string (it returns a "new String(result)". It's well known that:


Why wasn't the compiler capable of optimize the string creation in "a + b" code, knowing the it always resulted in the same string? It could avoid a new string creation.
If you don't believe the statement above, test for your self. 


I don't think so. a.concat(b) is implemented in String and I think the implementation didn't change much since early java machines. The + operation implementation depends on java version and compiler. Currently + is implemented using StringBuffer to make the operation as fast as possible. Maybe in future this will change. In earlier versions of java + operation on Strings was much slower as it produced intermediate results. I guess that += is implemented using + and similarly optimized.


Basically, there are two important differences between + and the concat method.


If you are using the concat method then you would only be able to concatenate strings while in case of the + operator, you can also concatenate the string with any data type.


For Example:


In this case, the output should be 10Hello.


In the above case you have to provide two strings mandatory.


The second and main difference between + and concat is that:


Case 1:
Suppose I concat the same strings with concat operator in this way


In this case total number of objects created in the pool are 7 like this:


Case 2:


Now I am going to concatinate the same strings via + operator


In the above case total number of objects created are only 5.


Actually when we concatinate the strings via + operator then it maintains a StringBuffer class to perform the same task as follows:-


In this way it will create only five objects.


So guys these are the basic differences between + and the concat method.
Enjoy :)


Most answers here are from 2008. It looks that things have changed over the time.  My latest benchmarks made with JMH shows that on Java 8 + is around two times faster than concat. 


My benchmark:


Results:


The + operator can work between a string and a string, char, integer, double or float data type value. It just converts the value to its string representation before concatenation.


The concat operator can only be done on and with strings. It checks for data type compatibility and throws an error, if they don't match.


Except this, the code you provided does the same stuff.


For the sake of completeness, I wanted to add that the definition of the '+' operator can be found in the JLS SE8 15.18.1:


If only one operand expression is of type String, then string
  conversion (§5.1.11) is performed on the other operand to produce a
  string at run time.


The result of string concatenation is a reference to a String object
  that is the concatenation of the two operand strings. The characters
  of the left-hand operand precede the characters of the right-hand
  operand in the newly created string.


The String object is newly created (§12.5) unless the expression is a
  constant expression (§15.28).


About the implementation the JLS says the following:


An implementation may choose to perform conversion and concatenation
  in one step to avoid creating and then discarding an intermediate
  String object. To increase the performance of repeated string
  concatenation, a Java compiler may use the StringBuffer class or a
  similar technique to reduce the number of intermediate String objects
  that are created by evaluation of an expression.


For primitive types, an implementation may also optimize away the
  creation of a wrapper object by converting directly from a primitive
  type to a string.


So judging from the 'a Java compiler may use the StringBuffer class or a similar technique to reduce', different compilers could produce different byte-code. 


When using +, the speed decreases as the string's length increases, but when using concat, the speed is more stable, and the best option is using the StringBuilder class which has stable speed in order to do that.


I guess you can understand why. But the totally best way for creating long strings is using StringBuilder() and append(), either speed will be unacceptable.






It has always bothered me that the only way to copy a file in Java involves opening streams, declaring a buffer, reading in one file, looping through it, and writing it out to the other steam.  The web is littered with similar, yet still slightly different implementations of this type of solution.


Is there a better way that stays within the bounds of the Java language (meaning does not involve exec-ing OS specific commands)?  Perhaps in some reliable open source utility package, that would at least obscure this underlying implementation and provide a one line solution?


As toolkit mentions above, Apache Commons IO is the way to go, specifically FileUtils.copyFile(); it handles all the heavy lifting for you.


And as a postscript, note that recent versions of FileUtils (such as the 2.0.1 release) have added the use of NIO for copying files; NIO can significantly increase file-copying performance, in a large part because the NIO routines defer copying directly to the OS/filesystem rather than handle it by reading and writing bytes through the Java layer.  So if you're looking for performance, it might be worth checking that you are using a recent version of FileUtils.


I would avoid the use of a mega api like apache commons. This is a simplistic operation and its built into the JDK in the new NIO package. It was kind of already linked to in a previous answer, but the key method in the NIO api are the new functions "transferTo" and "transferFrom".


http://java.sun.com/javase/6/docs/api/java/nio/channels/FileChannel.html#transferTo(long,%20long,%20java.nio.channels.WritableByteChannel)


One of the linked articles shows a great way on how to integrate this function into your code, using the transferFrom:


Learning NIO can be a little tricky, so you might want to just trust in this mechanic before going off and trying to learn NIO overnight. From personal experience it can be a very hard thing to learn if you don't have the experience and were introduced to IO via the java.io streams.


Now with Java 7, you can use the following try-with-resource syntax:


Or, better yet, this can also be accomplished using the new Files class introduced in Java 7:


Pretty snazzy, eh?


In Java 7 it is easy...


Note that all of these mechanisms only copy the contents of the file, not the metadata such as permissions. So if you were to copy or move an executable .sh file on linux the new file would not be executable. 


In order to truly a copy or move a file, ie to get the same result as copying from a command line, you actually need to use a native tool. Either a shell script or JNI. 


Apparently, this might be fixed in java 7 - http://today.java.net/pub/a/today/2008/07/03/jsr-203-new-file-apis.html. Fingers crossed!


To copy a file and save it to your destination path you can use the method below.


Google's Guava library also has a copy method:



public static void copy(File from,
                        File to)
                 throws IOException

Copies all the bytes from one file to another.


Warning: If to represents an existing file, that file
 will be overwritten with the contents of from. If to and
 from refer to the same file, the contents of that file
 will be deleted.


Parameters:from - the source fileto - the destination file
Throws:
IOException - if an I/O error occurs
IllegalArgumentException - if from.equals(to)



Warning: If to represents an existing file, that file
 will be overwritten with the contents of from. If to and
 from refer to the same file, the contents of that file
 will be deleted.


Parameters:from - the source fileto - the destination file
Throws:
IOException - if an I/O error occurs
IllegalArgumentException - if from.equals(to)





Parameters:from - the source fileto - the destination file
Throws:
IOException - if an I/O error occurs
IllegalArgumentException - if from.equals(to)



Parameters:from - the source fileto - the destination file


Throws:
IOException - if an I/O error occurs
IllegalArgumentException - if from.equals(to)


Available as standard in Java 7, path.copyTo:
http://openjdk.java.net/projects/nio/javadoc/java/nio/file/Path.html
http://java.sun.com/docs/books/tutorial/essential/io/copy.html


I can't believe it took them so long to standardise something so common and simple as file  copying :(


Here is three ways that you can easily copy files with single line of code!


Java7:


java.nio.file.Files#copy


Appache Commons IO:


FileUtils#copyFile


Guava :


Files#copy


Three possible problems with the above code: 


This is why org.apache.tools.ant.util.ResourceUtils.copyResource is so complicated. Also note that while transferFrom is OK, transferTo breaks on JDK 1.4 on Linux (see Bug ID:5056395) – Jesse Glick Jan 


If you are in a web application which already uses Spring and if you do not want to include Apache Commons IO for simple file copying, you can use FileCopyUtils of the Spring framework.


Fast and work with all the versions of Java also Android:


NIO copy with a buffer is the fastest according to my test. See the working code below from a test project of mine at https://github.com/mhisoft/fastcopy


}






How can I clone an ArrayList and also clone its items in Java?


For example I have:


And I would expect that objects in clonedList are not the same as in dogs list.


You will need to iterate on the items, and clone them one by one, putting the clones in your result array as you go.


For that to work, obviously, you will have to get your Dog object to implement the Cloneable interface, and the clone() method.


I, personally, would add a constructor to Dog:


Then just iterate (as shown in Varkhan's answer):


I find the advantage of this is you don't need to screw around with the broken Cloneable stuff in Java.  It also matches the way that you copy Java collections.


Another option could be to write your own ICloneable interface and use that.  That way you could write a generic method for cloning.


All standard collections have copy constructors. Use them.


clone() was designed with several mistakes (see this question), so it's best to avoid it.


From Effective Java 2nd Edition, Item 11: Override clone judiciously


Given all of the problems associated with Cloneable, it’s safe to say 
  that other interfaces should not extend it, and that classes
  designed for inheritance (Item 17) should not implement it. Because of
  its many shortcomings, some expert programmers simply choose never to
  override the clone method and never to invoke it except, perhaps, to
  copy arrays. If you design a class for inheritance, be aware that if
  you choose not to provide a well-behaved protected clone method, it
  will be impossible for subclasses to implement Cloneable.


This book also describes the many advantages copy constructors have over Cloneable/clone.


Consider another benefit of using copy constructors: Suppose you have a HashSet s, and you want to copy it as a TreeSet. The clone method can’t offer this functionality, but it’s easy with a conversion constructor: new TreeSet(s).


Basically there are three ways without iterating manually, 


1  Using constructor


2 Using addAll(Collection<? extends E> c)


3 Using addAll(int index, Collection<? extends E> c) method with int parameter


NB : The behavior of these operations will be undefined if the specified collection is modified while the operation is in progress.


Java 8 provides a new way to call the copy constructor or clone method on the element dogs elegantly and compactly: Streams, lambdas and collectors.


Copy constructor:


The expression Dog::new is called a method references. It references a constructor on Dog which takes another dog as argument.


Clone method:


Or, if you have to get an ArrayList back (in case you want to modify it later):


If you don't need to keep the original content of the dogs list you can use the replaceAll method and update the list in place instead:


All examples assume import static java.util.stream.Collectors.*;.


The collector from the last example can be made into a util method. Since this is such a common thing to do I personally like it to be short and pretty. Like this:


For this solution to work the clone method of Dog must not declare that it throws CloneNotSupportedException. The reason is that the argument to map is not allowed to throw any checked exceptions.


Like this:


This should not be a big problem however, since that is the best practice anyway. (Effectice Java for example gives this advice.)


Thanks to Gustavo for noting this.


If you find it prettier you can instead use the method reference syntax to do exactly the same thing:


I think the current green answer is bad , why you might ask?


The way serialization is also bad imo, you might have to add Serializable all over the place.


So what is the solution:


Java Deep-Cloning library
The cloning library is a small, open source (apache licence) java library which deep-clones objects. The objects don't have to implement the Cloneable interface. Effectivelly, this library can clone ANY java objects. It can be used i.e. in cache implementations if you don't want the cached object to be modified or whenever you want to create a deep copy of objects. 


Check it out at https://github.com/kostaskougios/cloning


A nasty way is to do it with reflection. Something like this worked for me.


You will need to clone the ArrayList by hand (by iterating over it and copying each element to a new ArrayList), because clone() will not do it for you. Reason for this is that the objects contained in the ArrayList may not implement Clonable themselves.


Edit: ... and that is exactly what Varkhan's code does.


Here's yet another approach, presumably a fast approach: http://javatechniques.com/blog/faster-deep-copies-of-java-objects/


The other posters are correct: you need to iterate the list and copy into a new list.


However...
If the objects in the list are immutable - you don't need to clone them. If your object has a complex object graph - they will need to be immutable as well. 


The other benefit of immutability is that they are threadsafe as well.


Here is a solution using a generic template type:


for you objects override clone() method


and call .clone() for Vector obj or ArraiList obj....


Easy way by using commons-lang-2.3.jar that library of java to clone list


link download commons-lang-2.3.jar


How to use


I hope this one can helpful.


:D


The package import org.apache.commons.lang.SerializationUtils;


There is a method SerializationUtils.clone(Object);


Example


I think I found a really easy way to make a deep copy ArrayList.  Assuming you want to copy a String ArrayList arrayA.


Let me know if it doesn't work for you.


I have found a way, you can use json to serialize/unserialize the list. The serialized list holds no reference to the original object when unserialized.


Using gson:


You can do that using jackson and any other json library too.


I have just developed a lib that is able to clone an entity object and a java.util.List object. Just download the jar in https://drive.google.com/open?id=0B69Sui5ah93EUTloSktFUkctN0U and use the static method cloneListObject(List list). This method not only clones the List but also all entity elements.






How do I add local jar files (not yet part of the Maven repository) directly in my project's library sources?


Install the JAR into your local Maven repository as follows:


Reference


You can add local dependencies directly (as mentioned in build maven project with propriatery libraries included) like this:


Firstly I would like to give credit for this answer to anonymous stackoverflow user - I am pretty sure I've seen similar answer here before - but now I cannot find it. 


The best option for having local jar files as a dependency is to create local maven repository. Such repo is nothing else than proper directory structure with pom files in it. 


On my example:
I have master project on ${master_project} location and subroject1 is on ${master_project}/${subproject1}


then I am creating mvn repository in:
${master_project}/local-maven-repo


In pom file in subproject1 located ${master_project}/${subproject1}/pom.xml repository needs to be specified which would take file path as an url parameter:


Dependency can be specified as for any other repository. This makes your pom repository independent. For instance once desired jar is available in maven central you just need to delete it from your local repo and it will be pulled from default repo. 


The last but not least thing to do is to add jar file to local repository using -DlocalRepositoryPath switch like here:


Onece jar file is installed such mvn repo can be committed to code repository and whole set up is system independent. (working example in github)


I agree that having JARs committed to source code repo is not a good practice but in real life quick and dirty solution sometimes is better than full blown nexus repo to host one jar that you cannot publish. 


Create a new folder, let's say local-maven-repo at the root of your Maven project.


Just add a local repo inside your <project> of your pom.xml:


Then for each external jar you want to install, go at the root of your project and execute:


I'd like such solution - use maven-install-plugin in pom file:


In this case you can perform mvn initialize and jar will be installed in local maven repo. Now this jar is available during any maven step on this machine (do not forget to include this dependency as any other maven dependency in pom with <dependency></dependency> tag). It is also possible to bind jar install not to initialize step, but any other step you like.


Yes , you can have but its not good idea.


Instead install all these jars to maven repos


Also See


One way is to upload it to your own Maven repository manager (such as Nexus). It's good practice to have an own repository manager anyway.


Another nice way I've recently seen is to include the Maven Install Plugin in your build lifecycle: You declare in the POM to install the files to the local repository. It's a little but small overhead and no manual step involved.


http://maven.apache.org/plugins/maven-install-plugin/install-file-mojo.html


Of course you can add jars to that folder. But maybe it does not what you want to achieve...


If you need these jars for compilation, check this related question: Can I add jars to maven 2 build classpath without installing them?


Also, before anyone suggests it, do NOT use the system scope.


The preferred way would be to create your own remote repository.


See here for details on how to do it.
Have a look at the 'Uploading to a Remote Repository' section.


Add your own local JAR in POM file and use that in maven build.


For example:


Then add it to the POM like this:





Also take a look at...


Maven Dependencies.  This is the default but I've found in some cases explicitly setting that scope also Maven to find local libraries in the local repository.


I want to share a code where you can upload a folder full of jars. It's useful when a provider doesn't have a public repository and you need to add lots of libraries  manually. I've decided to build a .bat instead of call directly to maven because It could be Out of Memory errors. It was prepared for a windows environment but is easy to adapt it to linux OS:


After run this main from any IDE, run the update_repo_maven.bat.


Another interesting case is when you want to have in your project private maven jars. You may want to keep the capabilities of Maven to resolve transitive dependencies. The solution is fairly easy.


Add the following lines in your pom.xml file


Open the .m2/repository folder and copy the directory structure of the project you want to import into the libs folder. 


E.g. suppose you want to import the dependency


Just go on .m2/repository and you will see the following folder


com/mycompany/myproject/1.2.3


Copy everything in your libs folder (again, including the folders under .m2/repository) and you are done.


Note that it is NOT necessarily a good idea to use a local repo.
If this project is shared with others then everyone else will have problems and questions when it doesn't work, and the jar won't be available even in your source control system!


Although the shared repo is the best answer, if you cannot do this for some reason then embedding the jar is better than a local repo. Local-only repo contents can cause lots of problems, especially over time.


THIS ANSWER IS ONLY FOR ECLIPSE USERS:


If you are using Eclipse, place the jar in lib/, right click on the jar name and click "add to build path". 
Eclipse will create a "referenced libraries" and place the jar for you


It resolved the import of the jar right away in the program for me 


This is a short syntax for newer versions:


It works when the JAR was built by Apache Maven - the most common case. Then it'll contain a pom.xml in a subfolder of the META-INF directory, which will be read by default.


Source: http://maven.apache.org/guides/mini/guide-3rd-party-jars-local.html


On your local repository you can install your jar by issuing the commands


Follow this useful  link to do the same from mkyoung's website. You can also check maven guide for the same


To install third party jar, Please call the command like below


Using maven-install-plugin in the parent pom or a synthetic parent pom works for me. Say we put the jar file in lib directory of parent module, we just need then to create a property as lib-path :


Then follows as @sphinks describes it above using maven-install-plugin. There will be no manual step and the artifact can be added as any other dependencies to the sub module.


NB. You can use also some plugins to fix the lib folder. Some suggest using Maven Directory Plugin


For some reason, in the web application I'm giving maintenance to, neither Alireza Fattahi's solution nor JJ Roman's solution worked correctly. In both cases, the compilation goes okay (it sees the jar), but the packaging fails to include the jar inside the war.


The only way I managed to make it work was by putting the jar on /src/main/webapp/WEB-INF/lib/ and then combining it with either Fattahis's or Roman's solution.






Say I have an enum which is just


and I would like to find the enum value of a string, for example "A" which would be Blah.A. How would it be possible to do this?


Is the Enum.valueOf() the method I need? If so, how would I use this?


Yes, Blah.valueOf("A") will give you Blah.A.


Note that the name must be an exact match, including case: Blah.valueOf("a") and Blah.valueOf("A ") both throw an IllegalArgumentException.


The static methods valueOf() and values() are created at compile time and do not appear in source code. They do appear in Javadoc, though; for example, Dialog.ModalityType shows both methods.


Another solution if the text is not the same to the enumeration value:


Here's a nifty utility I use:


Then in my enum class I usually have this to save some typing:


If your enums are not all caps, just change the Enum.valueOf line.


Too bad I can't use T.class for Enum.valueOf as T is erased.


You should also be careful with your case. Let me explain: doing Blah.valueOf("A") works, but Blah.valueOf("a") will not work. Then again Blah.valueOf("a".toUpperCase(Locale.ENGLISH)) would work.


edit
Changed toUpperCase to toUpperCase(Locale.ENGLISH) based on tc. comment and the java docs


edit2
On android you should use Locale.US, as sulai points out.


Here's a method that can do it for any Enum, and is case insensitive.


Using Blah.valueOf(string) is best but you can use Enum.valueOf(Blah.class, string) as well.


Use the pattern from Joshua Bloch, Effective Java:


(simplified for brevity)


Also see:


Oracle Java Example using Enum and Map of instances


Execution order of of static blocks in an Enum type


How can I lookup a Java enum from its String value


If you don't want to write your own utility use Google's guava library:


Unlike the built in java function it let's you check if A is present in Blah and doesn't throw an exception.


You may need to this :


One More Addition :


This will return you the Value by a Stringified Enum Name For e.g. if you provide "PERSON" in the fromEnumName it'll return you the Value of Enum i.e. "Person"


Another way of doing this by using implicit static method name() of Enum. name will return the exact string used to create that enum which can be used to check against provided string:


Testing:


System.out.println(Blah.getEnum("B").name()); 


inspiration: 10 Examples of Enum in Java


Solution using Guava libraries. Method getPlanet () is case insensitive, so
getPlanet ("MerCUrY") will return Planet.MERCURY.


To add to the previous answers, and address some of the discussions around nulls and NPE I'm using Guava Optionals to handle absent/invalid cases.  This works great for URI/parameter parsing.


For those not aware, here's some more info on avoiding null with Optional: https://code.google.com/p/guava-libraries/wiki/UsingAndAvoidingNullExplained#Optional


java.lang.Enum defines several useful methods, which is available to all enumeration type in Java:


In this code snippet, valueOf() method returns an Enum constant Gender.MALE, calling name on that returns "MALE".


O(1) method inspired from thrift generated code which utilize a hashmap.


In Java 8 the static Map pattern is even easier and is my preffered method. If you want to use the Enum with Jackson you can override toString and use that instead of name, then annotate with @JsonValue


My 2 cents here: using Java8 Streams + checking an exact string:


Apache's commons-lang library has a static function org.apache.commons.lang3.EnumUtils.getEnum which will map a String to your Enum type. Same answer essentially as Geoffreys but why roll your own when it's out there in the wild already. 


Another utility capturing in reverse way. Using a value which identify that Enum, not from its name.


Example:


EnumUtil.from(Foo.class, "drei") returns Foo.THREE, because it will use getValue to match "drei", which is unique public, not final and not static method in Foo.
In case Foo has more than on public, not final and not static method, for example, getTranslate which returns "drei", the other method can be used: EnumUtil.from(Foo.class, "drei", "getTranslate").


Adding on to the top rated answer, with a helpful utility...


valueOf() throws two different Exceptions in cases where it doesn't like its input.


If your requirements are such that you don't have any guarantee that your String will definitely match an enum value, for example if the String data comes from a database and could contain old version of the enum, then you'll need to handle these often...


So here's a reusable method I wrote which allows us to define a default Enum to be returned if the String we pass doesn't match.


Use it like this:


In Java 8:


I like to use this sort of process to parse commands as strings into enumerations.  I normally have one of the enumerations as "unknown" so it helps to have that returned when the others are not found (even on a case insensitive basis) rather than null (that meaning there is no value).  Hence I use this approach.






When I create a new Date object, it is initialized to the current time but in the local timezone. How can I get the current date and time in GMT?


java.util.Date has no specific time zone, although its value is most commonly thought of in relation to UTC. What makes you think it's in local time?


To be precise: the value within a java.util.Date is the number of milliseconds since the Unix epoch, which occurred at midnight January 1st 1970, UTC. The same epoch could also be described in other time zones, but the traditional description is in terms of UTC. As it's a number of milliseconds since a fixed epoch, the value within java.util.Date is the same around the world at any particular instant, regardless of local time zone.


I suspect the problem is that you're displaying it via an instance of Calendar which uses the local timezone, or possibly using Date.toString() which also uses the local timezone, or a SimpleDateFormat instance, which, by default, also uses local timezone.


If this isn't the problem, please post some sample code.


I would, however, recommend that you use Joda-Time anyway, which offers a much clearer API.


Generate a String to represent that value:


2016-09-13T23:30:52.123Z


As the correct answer by Jon Skeet stated, a java.util.Date object has no time zone†. But its toString implementation applies the JVM’s default time zone when generating the String representation of that date-time value. Confusingly to the naïve programmer, a Date seems to have a time zone but does not.


The java.util.Date, j.u.Calendar, and java.text.SimpleDateFormat classes bundled with Java are notoriously troublesome. Avoid them. Instead, use either of these competent date-time libraries: 


Java 8 brings an excellent new java.time.* package to supplant the old java.util.Date/Calendar classes. 


Getting current time in UTC/GMT is a simple one-liner…


That Instant class is the basic building block in java.time, representing a moment on the timeline in UTC with a resolution of nanoseconds. 


In Java 8, the current moment is captured with only up to milliseconds resolution. Java 9 brings a fresh implementation of Clock captures the current moment in up to the full nanosecond capability of this class, depending on the ability of your host computer’s clock hardware.


It’s toString method generates a String representation of its value using one specific ISO 8601 format. That format outputs zero, three, six or nine digits digits (milliseconds, microseconds, or nanoseconds) as necessary to represent the fraction-of-second.


If you want more flexible formatting, adjustments in or out of various time zones, or other additional features, then apply a time zone (ZoneId object) to get a ZonedDateTime. The time zone can be for UTC or any other time zone. The subclass of ZoneId, ZoneOffset holds a constant for UTC.


Dump to console…


When run…


The java.time classes are defined by JSR 310. They were inspired by Joda-Time but are entirely re-architected.


UPDATE: The Joda-Time project, now in maintenance mode, advises migration to the java.time classes.


Using the Joda-Time 3rd-party open-source free-of-cost library, you can get the current date-time in just one line of code.


Joda-Time inspired the new java.time.* classes in Java 8, but has a different architecture. You may use Joda-Time in older versions of Java. Joda-Time continues to work in Java 8 and continues to be actively maintained (as of 2014). However, the Joda-Time team does advise migration to java.time.


More detailed example code (Joda-Time 2.3)…


Dump to console…


When run…


For more example code doing time zone work, see my answer to a similar question.


I recommend you always specify a time zone rather than relying implicitly on the JVM’s current default time zone (which can change at any moment!). Such reliance seems to be a common cause of confusion and bugs in date-time work.


When calling now() pass the desired/expected time zone to be assigned. Use the DateTimeZone class.


That class holds a constant for UTC time zone.


If you truly want to use the JVM’s current default time zone, make an explicit call so your code is self-documenting.


Read about ISO 8601 formats. Both java.time and Joda-Time use that standard’s sensible formats as their defaults for both parsing and generating strings.


† Actually, java.util.Date does have a time zone, buried deep under layers of source code. For most practical purposes, that time zone is ignored. So, as shorthand, we say java.util.Date has no time zone. Furthermore, that buried time zone is not the one used by Date’s toString method; that method uses the JVM’s current default time zone. All the more reason to avoid this confusing class and stick with Joda-Time and java.time.


This definitely returns UTC time: as String and Date objects !


Actually not time, but it's representation could be changed.


Time is the same in any point of the Earth, but our perception of time could be different depending on location.


Calendar aGMTCalendar = Calendar.getInstance(TimeZone.getTimeZone("GMT"));
  Then all operations performed using the aGMTCalendar object will be done with the GMT time zone and will not have the daylight savings time or fixed offsets applied


Wrong!


and 


will return the same time. Idem for 


This works for getting UTC milliseconds in Android.


This code prints the current time UTC.


Result


Jon Skeet asks: 


@Downvoter: Care to comment? What exactly is incorrect in my answer? –
  Jon Skeet Oct 26 '09 at 21:09


I am not the Downvoter, but here is what seems to be incorrect in that answer. You said:


java.util.Date is always in UTC. What makes you think it's in local
  time? I suspect the problem is that you're displaying it via an
  instance of Calendar which uses the local timezone, or possibly using
  Date.toString() which also uses the local timezone.


However, the code:


gives the local hours, not GMT (UTC hours), using no Calendar and no SimpleDateFormat at all.


That is why is seems something is incorrect.


Putting together the responses, the code: 


shows the GMT hours instead of the local hours -- note that getTime.getHours() is missing because that would create a Date() object, which theoretically stores the date in GMT, but gives back the hours in the local time zone.


If you want a Date object with fields adjusted for UTC you can do it like this with Joda Time:


You can use:


Then all operations performed using the aGMTCalendar object will be done with the GMT time zone and will not have the daylight savings time or fixed offsets applied. I think the previous poster is correct that the Date() object always returns a GMT it's not until you go to do something with the date object that it gets converted to the local time zone.


With:


Then cal have the current date and time.
You also could get the current Date and Time for timezone with:


You could ask cal.get(Calendar.DATE); or other Calendar constant about others details.
Date and Timestamp are deprecated in Java. Calendar class it isn't.


Here an other suggestion to get a GMT Timestamp object:


Here is another way to get GMT time in String format


You can directly use this


Sample code to render system time in a specific time zone and a specific format.


Output


Just to make this simpler, to create a Date in UTC you can use Calendar :


Which will construct a new instance for Calendar using the "UTC" TimeZone.


If you need a Date object from that calendar you could just use getTime().


Converting Current DateTime in UTC:


This worked for me, returns the timestamp in GMT!


To put it simple. A calendar object stores information about time zone but when you perform cal.getTime() then the timezone information will be lost. So for Timezone conversions I will advice to use DateFormat classes...


Use this Class to get ever the right UTC Time from a Online NTP Server: 


And use it with:


If you need UTC Time "now" as DateTimeString use function:


and use it with:


Here is my implementation of toUTC:


There's probably several ways to improve it, but it works for me.


this is my implementation:


If you're using joda time and want the current time in milliseconds without your local offset you can use this:


If you want to avoid parsing the date and just want a timestamp in GMT, you could use:






Can anybody explain to me the concept of the toString() method, defined in the Object class? How is it used, and what is its purpose?


From the Object.toString() docs:


Returns a string representation of the
  object. In general, the toString
  method returns a string that
  "textually represents" this object.
  The result should be a concise but
  informative representation that is
  easy for a person to read. It is
  recommended that all subclasses
  override this method. 


The toString method for class Object
  returns a string consisting of the
  name of the class of which the object
  is an instance, the at-sign character
  `@', and the unsigned hexadecimal
  representation of the hash code of the
  object. In other words, this method
  returns a string equal to the value
  of:


Example:


Use of the String toString:
whenever you require to explore the constructor called value in the String form, you can simply use String toString...
for an example...


... copy this program into your eclipse, and run it... you will get the ideas about String toString...


The toString() method returns a textual representation of an object. A basic implementation is already included in java.lang.Object and so because all objects inherit from java.lang.Object it is guaranteed that every object in Java has this method.


Overriding the method is always a good idea, especially when it comes to debugging, because debuggers often show objects by the result of the toString() method. So use a meaningful implementation but use it for technical purposes. The application logic should use getters:


It may optionally have uses within the context of an application but far more often it is used for debugging purposes. For example, when you hit a breakpoint in an IDE, it's far easier to read a meaningful toString() of objects than it is to inspect their members.


There is no set requirement for what a toString() method should do. By convention, most often it will tell you the name of the class and the value of pertinent data members. More often than not, toString() methods are auto-generated in IDEs.


Relying on particular output from a toString() method or parsing it within a program is a bad idea. Whatever you do, don't go down that route.


toString() returns a string/textual representation of the object.
Commonly used for diagnostic purposes like debugging, logging etc., the toString() method is used to read meaningful details about the object.


It is automatically invoked when the object is passed to println, print, printf, String.format(), assert or the string concatenation operator.


The default implementation of toString() in class Object returns a string consisting of the class name of this object followed by @ sign and the unsigned hexadecimal representation of the hash code of this object using the following logic,


For example, the following


prints


Now, overriding toString() in the Coordinates class as below,


results in


The usefulness of overriding toString() becomes even more when the method is invoked on collections containing references to these objects. For example, the following


prints


instead of this,


Few implementation pointers,


Provide accessors/getters for all of the instance fields that are contained in the string returned. For example, in the Coordinates class,


A comprehensive coverage of the toString() method is in Item 10 of the book, Effective Java™, Second Edition, By Josh Bloch.


Whenever you access an Object (not being a String) in a String context then the toString() is called under the covers by the compiler.


This is why


works, and by overriding the standard toString() from Object in your own classes, you can make your objects useful in String contexts too.


(and consider it a black box!  Never, ever use the contents for anything else than presenting to a human)


Coding: 


Student.java:


Output:


[Steve 12 Daniel, Sachin 10 Tendulkar]


[Steve 12 Daniel, Sachin 10 Tendulkar, Yuvi 12 Bhajji]


If you are not used toString() in Pojo(Student.java) class,you will get an output like [com.steve.test.Student@6e1408, com.steve.test.Student@e53108].To avoid these kind of issue we are using toString() method.


Correctly overridden toString method can help in logging and debugging of Java.


Apart from what cletus answered with regards to debugging, it is used whenever you output an object, like when you use


or


The main purpose of toString is to generate a String representation of an object, means the return value is always a String. In most cases this simply is the object's class and package name, but on some cases like StringBuilder you will got actually a String-text.


the toString() converts the specified object to a string value.


If you learn Python first and then Java. I think it plays the same role as __str__() method in Python, it is a magic method like __dict__() and __init__() but to refer to a string representing the the object. 


JVM uses a string representation of an object when it is being contactenated using plus sign (+) or when it being used in System.out.println() method. You can get more details from my blog






I need to find the caller of a method. Is it possible using stacktrace or reflection?


According to the Javadocs:


The last element of the array represents the bottom of the stack, which is the least recent method invocation in the sequence. 


A StackTraceElement has getClassName(), getFileName(), getLineNumber() and getMethodName().


You will have to experiment to determine which index you want
(probably stackTraceElements[1] or [2]).


An alternative solution can be found in a comment to this request for enhancement.
It uses the getClassContext() method of a custom SecurityManager and seems to be faster than the stack trace method.


The following program tests the speed of the different suggested methods (the most interesting bit is in the inner class SecurityManagerMethod):


An example of the output from my 2.4 GHz Intel Core 2 Duo MacBook running Java 1.6.0_17:


The internal Reflection method is much faster than the others. Getting a stack trace from a newly created Throwable is faster than getting it from the current Thread. And among the non-internal ways of finding the caller class the custom SecurityManager seems to be the fastest.


As lyomi points out in this comment the sun.reflect.Reflection.getCallerClass() method has been disabled by default in Java 7 update 40 and removed completely in Java 8. Read more about this in this issue in the Java bug database. 


As zammbi has found, Oracle was forced to back out of the change that removed the sun.reflect.Reflection.getCallerClass(). It is still available in Java 8 (but it is deprecated).


3 years after: Update on timing with current JVM.


Sounds like you're trying to avoid passing a reference to this into the method.  Passing this is way better than finding the caller through the current stack trace.  Refactoring to a more OO design is even better.  You shouldn't need to know the caller.  Pass a callback object if necessary.


This method does the same thing but a little more simply and possibly a little more performant and in the event you are using reflection, it skips those frames automatically. The only issue is it may not be present in non-Sun JVMs, although it is included in the runtime classes of JRockit 1.4-->1.6. (Point is, it is not a public class).


As far as what the realFramesToSkip value should be, the Sun 1.5 and 1.6 VM versions of java.lang.System, there is a package protected method called getCallerClass() which calls sun.reflect.Reflection.getCallerClass(3), but in my helper utility class I used 4 since there is the added frame of the helper class invocation.


For example, if you try to get the calling method line for debug purpose, you need to get past the Utility class  in which you code those static methods:
(old java1.4 code, just to illustrate a potential StackTraceElement usage)


I've done this before.  You can just create a new exception and grab the stack trace on it without throwing it, then examine the stack trace.  As the other answer says though, it's extremely costly--don't do it in a tight loop.


I've done it before for a logging utility on an app where performance didn't matter much (Performance rarely matters much at all, actually--as long as you display the result to an action such as a button click quickly).  


It was before you could get the stack trace, exceptions just had .printStackTrace() so I had to redirect System.out to a stream of my own creation, then (new Exception()).printStackTrace(); Redirect System.out back and parse the stream.  Fun stuff.


Oneliner: 


Note that you might need to replace the 2 with 1.


Here is a part of the code that I made based in the hints showed in this topic.
Hope it helps.


(Feel free to make any suggestions to improve this code, please tell me)


The counter:


And the object:


use this method:-


Caller of method example Code is here:-


JEP 259 provides an efficient standard API for stack walking that allows easy filtering of, and lazy access to, the information in stack traces. Before Stack-Walking API, common ways of accessing stack frames were:


Throwable::getStackTrace and Thread::getStackTrace return an array of
  StackTraceElement objects, which contain the class name and method
  name of each stack-trace element.


SecurityManager::getClassContext is a protected method, which allows a
  SecurityManager subclass to access the class context.


JDK-internal sun.reflect.Reflection::getCallerClass method which you shouldn't use anyway


Using these APIs are usually inefficient:


These APIs require the VM to eagerly capture a snapshot of the entire
  stack, and they return information representing the entire stack.
  There is no way to avoid the cost of examining all the frames if the
  caller is only interested in the top few frames on the stack.


In order to find the immediate caller's class, first obtain a StackWalker:


Then either call the getCallerClass():


or walk the StackFrames and get the first preceding StackFrame:






I have an ArrayList of Strings, and I want to remove repeated strings from it. How can I do this?


If you don't want duplicates in a Collection, you should consider why you're using a Collection that allows duplicates. The easiest way to remove repeated elements is to add the contents to a Set (which will not allow duplicates) and then add the Set back to the ArrayList:


Of course, this destroys the ordering of the elements in the ArrayList.


Although converting the ArrayList to a HashSet effectively removes duplicates, if you need to preserve insertion order, I'd rather suggest you to use this variant


Then, if you need to get back a List reference, you can use again the conversion constructor.


In Java 8:


Please note that the hashCode-equals contract for list members should be respected for the filtering to work properly.


If you don't want duplicates, use a Set instead of a List. To convert a List to a Set you can use the following code:


If really necessary you can use the same construction to convert a Set back into a List.


Here's a way that doesn't affect your list ordering:


l1 is the original list, and l2 is the list whithout repeated items
(Make sure YourClass has the equals method acording to what you want to stand for equality)


There is also ImmutableSet from Guava as an option (here is the documentation):


Java 8 streams provide a very simple way to remove duplicate elements from a list. Using the distinct method.
If we have a list of cities and we want to remove duplicates from that list it can be done in a single line - 


How to remove duplicate elements from an arraylist


It is possible to remove duplicates from arraylist without using HashSet or one more arraylist. 


Try this code..


Output is


Suppose we have a list of String like:


Then we can remove duplicate elements in in multiple ways.


Note: If we want to maintain the insertion order then we need to use LinkedHashSet in place of HashSet.


Probably a bit overkill, but I enjoy this kind of isolated problem. :)


This code uses a temporary Set (for the uniqueness check) but removes elements directly inside the original list. Since element removal inside an ArrayList can induce a huge amount of array copying, the remove(int)-method is avoided.


While we're at it, here's a version for LinkedList (a lot nicer!):


Use the marker interface to present a unified solution for List:


EDIT: I guess the generics-stuff doesn't really add any value here.. Oh well. :)


this can solve the problem:


You can also do it this way, and preserve order:


If you're willing to use a third-party library, you can use the method distinct() in Eclipse Collections (formerly GS Collections).


The advantage of using distinct() instead of converting to a Set and then back to a List is that distinct() preserves the order of the original List, retaining the first occurrence of each element. It's implemented by using both a Set and a List.


If you cannot convert your original List into an Eclipse Collections type, you can use ListAdapter to get the same API.


Note: I am a committer for Eclipse Collections.


This three lines of code can remove the duplicated element from ArrayList or any collection.


When you are filling the ArrayList, use a condition for each element. For example:


We will get an array {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10}


If you want to preserve your Order then it is best to use LinkedHashSet.
Because if you want to pass this List to an Insert Query by Iterating it, the order would be preserved.


Try this


This conversion will be very helpful when you want to return a List but not a Set.


Code:


Note: Definitely, there will be memory overhead.


As said before, you should use a class implementing Set interface instead of List to be sure of unicity of elements. If you have to keep the order of elements, the SortedSet interface can then be used ; the TreeSet class implements that interface.


LinkedHashSet will do the trick.


//output: 5,1,2,3,4


If you want to remove duplicates from ArrayList means find the below logic,


The @jonathan-stafford solution is OK. But this don't preserve the list order.


If you want preserve the list order you have to use this:


It's only to complete the answer. Very good!


Here is my answer without using any other data structure like set or hashmap etc.


Would something like this work better ? 


}


That should maintain the order and also not be quadratic in run time.






Is there any method to generate MD5 hash of a string in Java?


java.security.MessageDigest is your friend. Call getInstance("MD5") to get an MD5 message digest you can use.


The MessageDigest class can provide you with an instance of the MD5 digest.


When working with strings and the crypto classes be sure to always specify the encoding you want the byte representation in. If you just use string.getBytes() it will use the platform default. (Not all platforms use the same defaults)


If you have a lot of data take a look at the .update(byte[]) method which can be called repeatedly. Then call .digest() to obtain the resulting hash.


You might also want to look at the DigestUtils class of the apache commons codec project, which provides very convenient methods to create MD5 or SHA digests.


If you actually want the answer back as a string as opposed to a byte array, you could always do something like this:


Found this:


on the site below, I take no credit for it, but its a solution that works!
For me lots of other code didnt work properly, I ended up missing 0s in the hash.
This one seems to be the same as PHP has.
source: http://m2tec.be/blog/2010/02/03/java-md5-hex-0093


Here is how I use it:


where Hex is: org.apache.commons.codec.binary.Hex from the Apache Commons project.


I just downloaded commons-codec.jar and got perfect php like md5. Here is manual.


Just import it to your project and use


and there you have it.


I've found this to be the most clear and concise way to do it:


Found this solution which is much cleaner in terms of getting a String representation back from an MD5 hash.


The code was extracted from here.


Another option is to use the Guava Hashing methods:


Handy if you are already using Guava (which if you're not, you probably should be).


Another implementation:


I have a Class (Hash) to convert plain text in hash in formats: md5 or sha1, simillar that php functions (md5, sha1):


https://github.com/fitorec/java-hashes


My not very revealing answer:


Bombe's answer is correct, however note that unless you absolutely must use MD5 (e.g. forced on you for interoperability), a better choice is SHA1 as MD5 has weaknesses for long term use.


I should add that SHA1 also has theoretical vulnerabilities, but not as severe. The current state of the art in hashing is that there are a number of candidate replacement hash functions but none have yet emerged as the standard best practice to replace SHA1. So, depending on your needs you would be well advised to make your hash algorithm configurable so it can be replaced in future.


No need to make it too complicated. DigestUtils works fine and make you comfortable while working with md5 hashes.


or


Either you can use any other encryption methods such as sha or md.


There is a DigestUtils class in Spring also:


http://static.springsource.org/spring/docs/3.0.x/javadoc-api/org/springframework/util/DigestUtils.html


This class contains the method md5DigestAsHex() that does the job. 


You can try following. See details and download codes here: http://www.luyue.org/java-hashgenerator-md5-sha-1/


Another implementation: Fast MD5 Implementation in Java


I do not know if this is relevant for anyone reading this, but I just had the problem that I wanted to


I wanted to do it with JRE classes only (no Apache Commons or similar). A quick web search did not show me sample code snippets doing both at the same time, only each task separately. Because this requires to read the same file twice, I figured it might be worth the while to write some code which unifies both tasks, calculating the checksum on the fly while downloading the file. This is my result (sorry if it is not perfect Java, but I guess you get the idea anyway):


MD5 is perfectly fine if you don't need the best security, and if you're doing something like checking file integrity then security is not a consideration.  In such as case you might want to consider something simpler and faster, such as Adler32, which is also supported by the Java libraries.


For what it's worth, I stumbled upon this because I want to synthesize GUIDs from a natural key for a program that will install COM components; I want to syhthesize so as not to manage GUID lifecycle. I'll use MD5 and then use the UUID class to get a string out of it. (http://stackoverflow.com/questions/2190890/how-can-i-generate-guid-for-a-string-values/12867439 raises this issue).


In any case, java.util.UUID can get you a nice String from the MD5 bytes.


Take a look at the following link, the Example gets an MD5 Hash of a supplied image:
MD5 Hash of an Image


this one gives the exact md5 as you get from mysql's md5 function or php's md5 functions etc. This is the one I use (you can change according to your needs)


Unlike PHP where you can do an md5 encryption of your text by just calling md5 function ie md5($text), in java it was made little bit complicated. I usually implemented it by calling an function which return the md5 hash text. 
Here is how I implemented it , First create a function named md5encryption inside your main class as given below . 


Now call the function when ever you needed as given below.


Here you can see that hashtext is appended with a zero to make it match with md5 encryption in PHP. 


try this:


This is what I came here for- a handy scala function that returns string of MD5 hash: 


There is an article on Codingkit about that. Check out: http://codingkit.com/a/JAVA/2013/1020/2216.html


I did this... Seems to work ok - I'm sure somebody will point out mistakes though...






I understand that with (1), implementations of the List interface can be swapped.  It seems that (1) is typically used in an application regardless of need (myself I always use this).  


I am wondering if anyone uses (2)?  


Also, how often (and can I please get an example) does the situation actually require using (1) over (2) (i.e. where (2) wouldn't suffice..aside coding to interfaces and best practices etc.)


Almost always the first one is preferred over the second one. The first has the advantage that the implementation of the List can change (to a LinkedList for example), without affecting the rest of the code. This will be a difficult task to do with an ArrayList, not only because you will need to change ArrayList to LinkedList everywhere, but also because you may have used ArrayList specific methods.


You can read about List implementations here. You may start with an ArrayList, but soon afterwards discover that another implementation is more appropriate.


I am wondering if anyone uses (2)? 


Yes.  But rarely for a good reason.


And sometimes people get burned because they used ArrayList when they should have used List:


Utility methods like Collections.singletonList(...) or Arrays.asList(...) don't return an ArrayList.


Methods in the List API don't guarantee to return a list of the same type.  


For example, in https://stackoverflow.com/a/1481123/139985 the poster had problems with "slicing" because ArrayList.sublist(...) doesn't return an ArrayList ... and he had designed his code to use ArrayList as the type of all of his list variables.  He ended up "solving" the problem by copying the sublist into a new ArrayList.


The argument that you need to know how the List behaves is largely addressed by using the RandomAccess marker interface.  Yes, it is a bit clunky, but the alternative is worse.


Also, how often does the situation actually require using (1) over (2) (i.e. where (2) wouldn't suffice..aside 'coding to interfaces' and best practices etc.)


The "how often" part of the question is objectively unanswerable.  


(and can I please get an example) 


Occasionally, the application may require that you use methods in the ArrayList API that are not in the List API.  For example, ensureCapacity(int), trimToSize() or removeRange(int, int).  (And the last one will only arise if you have created a subtype of ArrayList that declares the method to be public.)


That is the only sound reason for coding to the class rather than the interface, IMO.  


(It is theoretically possible that you will get a slight improvement in performance ... under certain circumstances ... on some platforms ... but unless you really need that last 0.05%, it is not worth doing this.  This is not a sound reason, IMO.)


You can’t write efficient code if you don’t know whether random access is efficient or not.


That is a valid point.  However, Java provides better ways to deal with that; e.g.


If you call that with a list that does not implement RandomAccess you will get a compilation error.


You could also test dynamically ... using instanceof ... if static typing is too awkward.  And you could even write your code to use different algorithms (dynamically) depending on whether or not a list supported random access.


Note that ArrayList is not the only list class that implements RandomAccess.  Others include CopyOnWriteList, Stack and Vector.


For example you might decide a LinkedList is the best choice for your application, but then later decide ArrayList might be a better choice for performance reason.


Use:


Instead of:


For reference:





(posted mostly for Collection diagram)


It is considered good style to store a reference to a HashSet or TreeSet in a variable of type Set.


Set<String> names = new HashSet<String>();


This way, you have to change only one line if you decide to use a TreeSet instead.


Also, methods that operate on sets should specify parameters of type Set:


public static void print(Set<String> s)


Then the method can be used for all set implementations.


In theory, we should make the same recommendation for linked lists, namely to save
LinkedList references in variables of type List. However, in the Java library, the List interface is common to both the ArrayList and the LinkedList class. In particular, it has get and set methods for random access, even though these methods are very inefficient for linked lists.


You can’t write efficient code if you don’t know whether random access is efficient or not.


This is plainly a serious design error in the standard library, and I cannot recommend using
the List interface for that reason. 


To see just how embarrassing that error is, have a look at
the source code for the binarySearch method of the Collections class. That method takes a
List parameter, but binary search makes no sense for a linked list. The code then clumsily
tries to discover whether the list is a linked list, and then switches to a linear search!


The Set interface and the Map interface, are well designed, and you should use them.


I use (2) if code is the "owner" of the list. This is for example true for local-only variables. There is no reason to use the abstract type List instead of ArrayList.
Another example to demonstrate ownership:


I think the people who use (2) don't know the Liskov substitution principle or the Dependency inversion principle. Or they really have to use ArrayList.


(3) Collection myCollection = new ArrayList();


I am using this typically. And only if I need List methods, I will use List. Same with ArrayList. You always can switch to more "narrow" interface, but you can't switch to more "wide".


When you write List, you actually tell, that your object implements List interface only, but you don't specify what class your object belongs to. 


When you write ArrayList, you specify that your object class is a resizable-array.


So, the first version makes your code more flexible in future.


Look at Java docs: 


Class ArrayList - Resizable-array implementation of the List interface.


Interface List - An ordered collection (also known as a sequence). The user of this interface has precise control over where in the list each element is inserted.


Array - container object that holds a fixed number of values of a single type.


Actually there are occasions where (2) is not only preferred but mandatory and I am very surprised, that nobody mentions this here.


Serialization!


If you have a serializable class and you want it to contain a list, then you must declare the field to be of a concrete and serializable type like ArrayList because the List interface does not extend java.io.Serializable


Obviously most people do not need serialization and forget about this.


An example:


Out of the following two:


First is generally preferred. As you will be using methods from List interface only, it provides you the freedom to use some other implementation of List e.g. LinkedList in future. So it decouples you from specific implementation. Now there are two points worth mentioning:


I am wondering if anyone uses (2)


Yes sometimes (read rarely). When we need methods that are part of implementation of ArrayList but not part of the interface List. For example ensureCapacity.


Also, how often (and can I please get an example) does the situation
  actually require using (1) over (2)


Almost always you prefer option (1). This is a classical design pattern in OOP where you always try to decouple your code from specific implementation and program to the interface.


List is an interface.It doesn't have methods. When you call method on a List reference. It in fact calls the method of ArrayList in both cases.


And for future you can change List obj = new ArrayList<> to  List obj = new LinkList<> or other type which implements List interface.


The only case that I am aware of where (2) can be better is when using GWT, because it reduces application footprint (not my idea, but the google web toolkit team says so). But for regular java running inside the JVM (1) is probably always better.


Somebody asked this again (duplicate) which made me go a little deeper on this issue. 


If we use a bytecode viewer (I used http://asm.ow2.org/eclipse/index.html) weĺl see the following (only list initialization and assignment) for our list snippet:


and for alist:


The difference is list ends up calling INVOKEINTERFACE whereas aList calls INVOKEVIRTUAL. Accoding to the Bycode Outline Plugin reference, 


invokeinterface is used to invoke a method declared within a Java
  interface


while invokevirtual 


invokes all methods except interface methods (which use
  invokeinterface), static methods (which use invokestatic), and the few
  special cases handled by invokespecial.


In summary, invokevirtual pops objectref off the stack while for invokeinterface 


the interpreter pops 'n' items off the operand stack, where 'n' is an 8-bit unsigned
  integer parameter taken from the bytecode. The first of these items is
  objectref, a reference to the object whose method is being called.


If I understand this correctly, the difference is basically how each way retrieves objectref.


I would say that 1 is preferred, unless 


My guess is that in 99% of the cases you can get by with List, which is preferred.






Can someone explain me in simple terms, why does this code throw an exception, "Comparison method violates its general contract!", and how do I fix it?


Your comparator is not transitive.


Let A be the parent of B, and B be the parent of C. Since A > B and B > C, then it must be the case that A > C. However, if your comparator is invoked on A and C, it would return zero, meaning A == C. This violates the contract and hence throws the exception.


It's rather nice of the library to detect this and let you know, rather than behave erratically.


One way to satisfy the transitivity requirement in compareParents() is to traverse the getParent() chain instead of only looking at the immediate ancestor.


Just because this is what I got when I Googled this error, my problem was that I had 


the value >= other.value should (obviously) actually be value > other.value so that you can actually return 0 with equal objects. 


The violation of the contract often means that the comparator is not providing the correct or consistent value when comparing objects. For example, you might want to perform a string compare and force empty strings to sort to the end with:


But this overlooks the case where BOTH one and two are empty - and in that case, the wrong value is returned (1 instead of 0 to show a match), and the comparator reports that as a violation. It should have been written as:


In our case were were getting this error because we had accidentally flipped the order of comparison of s1 and s2.  So watch out for that.  It was obviously way more complicated than the following but this is an illustration:


Even if your compareTo is holds transitivity in theory, sometimes subtle bugs mess things up... such as floating point arithmetic error. It happened to me. this was my code:


The transitive property clearly holds, but for some reason I was getting the IllegalArgumentException. And it turns out that due to tiny errors in floating point arithmetic, the round-off errors where causing the transitive property to break where they shouldn't! So I rewrote the code to consider really tiny differences 0, and it worked:


Java does not check consistency in a strict sense, only notifies you if it runs into serious trouble. Also it does not give you much information from the error.


I was puzzled with what's happening in my sorter and made a strict consistencyChecker, maybe this will help you:


I've seen this happen in a piece of code where the often recurring check for null values was performed:


You can't compare object data like this:s1.getParent() == s2 - this will compare the object references. You should override equals function for Foo class and then compare them like this s1.getParent().equals(s2)


In my case I was doing something like the following:


What I forgot to check was when both a.someField and b.someField are null.






I've a problem trying to making my page printing out the JSONObject in the order i want. In my code, I entered this:


However, when I see the display on my page, it gives:


JSON formatted string: [{"success":"NO","userid":"User 1","bid":24.23}


I need it in the order of userid, amount, then success. Already tried re-ordering in the code, but to no avail. I've also tried .append....need some help here thanks!!


You cannot and should not rely on the ordering of elements within a JSON object.


From the JSON specification at http://www.json.org/


An object is an unordered set of
  name/value pairs


As a consequence,
JSON libraries are free to rearrange the order of the elements as they see fit.
This is not a bug.


I agree with the other answers. You cannot rely on the ordering of JSON elements.


However if we need to have an ordered JSON, one solution might be to prepare a LinkedHashMap object with elements and convert it to JSONObject.


Normally the order is not preserved as below.


You may check my post too: http://www.flyingtomoon.com/2011/04/preserving-order-in-json.html


from lemiorhan example
i can solve with just change some line of lemiorhan's code
use:


instead of this:


so in my test code is :


Real answer can be found in specification, json is unordered.
However as a human reader I ordered my elements in order of importance. Not only is it a more logic way, it happened to be easier to read. Maybe the author of the specification never had to read JSON, I do.. So, Here comes a fix:


JavaScript objects, and JSON, have no way to set the order for the keys. You might get it right in Java (I don't know how Java objects work, really) but if it's going to a web client or another consumer of the JSON, there is no guarantee as to the order of keys. 


Download "json simple 1.1 jar" from this https://code.google.com/p/json-simple/downloads/detail?name=json_simple-1.1.jar&can=2&q=


And add the jar file to your lib folder


using JSONValue you can convert LinkedHashMap to json string


for more reference click here http://androiddhina.blogspot.in/2015/09/ordered-json-string-in-android.html


As all are telling you, JSON does not maintain "sequence" but array does, maybe this could convince you:
Ordered JSONObject


u can retain the order, if u use JsonObject that belongs to com.google.gson :D


Usage of this JsonObject doesn't even bother using Map<>


CHEERS!!!


For those who're using maven, please try com.github.tsohr/json


It's forked from JSON-java but switch its map implementation with LinkedHashMap which @lemiorhan noted above. 


For Java code, Create a POJO class for your object instead of a JSONObject.
and use JSONEncapsulator for your POJO class.
that way order of elements depends on the order of getter setters in your POJO class.
for eg. POJO class will be like


and where you need to send your json object in response


The response of this line will be


{myObject : {//attributes order same as getter setter order.}}






I'm creating a regexp for password validation to be used in a Java application as a configuration parameter.


The regexp is:


The password policy is:


At least 8 chars


Contains at least one digit


Contains at least one lower alpha char and one upper alpha char


Contains at least one char within a set of special chars (@#%$^ etc.)


Does not contain space, tab, etc.


I’m missing just point 5. I'm not able to have the regexp check for space, tab, carriage return, etc.


Could anyone help me?


Try this:


Explanation:


It's easy to add, modify or remove individual rules, since every rule is an independent "module".


The (?=.*[xyz]) construct eats the entire string (.*) and backtracks to the first occurrence where [xyz] can match. It succeeds if [xyz] is found, it fails otherwise. 


The alternative would be using a reluctant qualifier: (?=.*?[xyz]). For a password check, this will hardly make any difference, for much longer strings it could be the more efficient variant.


The most efficient variant (but hardest to read and maintain, therefore the most error-prone) would be (?=[^xyz]*[xyz]), of course. For a regex of this length and for this purpose, I would dis-recommend doing it that way, as it has no real benefits.


simple example using regex


Explanations:


All the previously given answers use the same (correct) technique to use a separate lookahead for each requirement.  But they contain a couple of inefficiencies and a potentially massive bug, depending on the back end that will actually use the password.


I'll start with the regex from the accepted answer:


First of all, since Java supports \A and \z I prefer to use those to make sure the entire string is validated, independently of Pattern.MULTILINE.  This doesn't affect performance, but avoids mistakes when regexes are recycled.


Checking that the password does not contain whitespace and checking its minimum length can be done in a single pass by using the all at once by putting variable quantifier {8,} on the shorthand \S that limits the allowed characters:


If the provided password does contain a space, all the checks will be done, only to have the final check fail on the space.  This can be avoided by replacing all the dots with \S:


The dot should only be used if you really want to allow any character.  Otherwise, use a (negated) character class to limit your regex to only those characters that are really permitted.  Though it makes little difference in this case, not using the dot when something else is more appropriate is a very good habit.  I see far too many cases of catastrophic backtracking because the developer was too lazy to use something more appropriate than the dot.


Since there's a good chance the initial tests will find an appropriate character in the first half of the password, a lazy quantifier can be more efficient:


But now for the really important issue: none of the answers mentions the fact that the original question seems to be written by somebody who thinks in ASCII.  But in Java strings are Unicode.  Are non-ASCII characters allowed in passwords?  If they are, are only ASCII spaces disallowed, or should all Unicode whitespace be excluded.


By default \s matches only ASCII whitespace, so its inverse \S matches all Unicode characters (whitespace or not) and all non-whitespace ASCII characters.  If Unicode characters are allowed but Unicode spaces are not, the UNICODE_CHARACTER_CLASS flag can be specified to make \S exclude Unicode whitespace.  If Unicode characters are not allowed, then [\x21-\x7E] can be used instead of \S to match all ASCII characters that are not a space or a control character.


Which brings us to the next potential issue: do we want to allow control characters?  The first step in writing a proper regex is to exactly specify what you want to match and what you don't.  The only 100% technically correct answer is that the password specification in the question is ambiguous because it does not state whether certain ranges of characters like control characters or non-ASCII characters are permitted or not.


You should not use overly complex Regex (if you can avoid them) because they are


Although there might be a small performance overhead in using many small regular expressions, the points above outweight it easily.


I would implement like this:


Password Requirement :


Passwords must include characters from at least two (2) of these groupings: alpha, numeric, and special characters.


I tested it and it works


I think this can do it also (as a simpler mode):


[Regex Demo]


For anyone interested in minimum requirements for each type of character, I would suggest making the following extension over Tomalak's accepted answer:


Notice that this is a formatting string and not the final regex pattern. Just substitute %d with the minimum required occurrences for: digits, lowercase, uppercase, non-digit/character, and entire password (respectively). Maximum occurrences are unlikely (unless you want a max of 0, effectively rejecting any such characters) but those could be easily added as well. Notice the extra grouping around each type so that the min/max constraints allow for non-consecutive matches. This worked wonders for a system where we could centrally configure how many of each type of character we required and then have the website as well as two different mobile platforms fetch that information in order to construct the regex pattern based on the above formatting string.






I'm trying to put some anti sql injection in place in java and am finding it very difficult to work with the the "replaceAll" string function. Ultimately I need a function that will convert any existing \ to \\, any " to \", any ' to \', and any \n to \\n so that when the string is evaluated by MySQL SQL injections will be blocked. 


I've jacked up some code I was working with and all the \\\\\\\\\\\ in the function are making my eyes go nuts. If anyone happens to have an example of this I would greatly appreciate it.


PreparedStatements are the way to go, because they make SQL injection impossible.  Here's a simple example taking the user's input as the parameters:


No matter what characters are in name and email, those characters will be placed directly in the database.  They won't affect the INSERT statement in any way.


There are different set methods for different data types -- which one you use depends on what your database fields are.  For example, if you have an INTEGER column in the database, you should use a setInt method.  The PreparedStatement documentation lists all the different methods available for setting and getting data.


The only way to prevent SQL injection is with parameterized SQL. It simply isn't possible to build a filter that's smarter than the people who hack SQL for a living.


So use parameters for all input, updates, and where clauses. Dynamic SQL is simply an open door for hackers, and that includes dynamic SQL in stored procedures. Parameterize, parameterize, parameterize.


If really you can't use Defense Option 1: Prepared Statements (Parameterized Queries) or Defense Option 2: Stored Procedures, don't build your own tool, use the OWASP Enterprise Security API. From the OWASP ESAPI hosted on Google Code:


Don’t write your own security controls! Reinventing the wheel when it comes to developing security controls for every web application or web service leads to wasted time and massive security holes. The OWASP Enterprise Security API (ESAPI) Toolkits help software developers guard against security‐related design and implementation flaws.


For more details, see Preventing SQL Injection in Java and SQL Injection Prevention Cheat Sheet. 


Pay a special attention to Defense Option 3: Escaping All User Supplied Input that introduces the OWASP ESAPI project).


(This is in answer to the OP's comment under the original question; I agree completely that PreparedStatement is the tool for this job, not regexes.)


When you say \n, do you mean the sequence \+n or an actual linefeed character?  If it's \+n, the task is pretty straightforward:


To match one backslash in the input, you put four of them in the regex string. To put one backslash in the output, you put four of them in the replacement string.  This is assuming you're creating the regexes and replacements in the form of Java String literals.  If you create them any other way (e.g., by reading them from a file), you don't have to do all that double-escaping.


If you have a linefeed character in the input and you want to replace it with an escape sequence, you can make a second pass over the input with this:


Or maybe you want two backslashes (I'm not too clear on that):


PreparedStatements are the way to go in most, but not all cases. Sometimes you will find yourself in a situation where a query, or a part of it, has to be built and stored as a string for later use. Check out the SQL Injection Prevention Cheat Sheet on the OWASP Site for more details and APIs in different programming languages.


Using a regular expression to remove text which could cause a SQL injection sounds like the SQL statement is being sent to the database via a Statement rather than a PreparedStatement.


One of the easiest ways to prevent an SQL injection in the first place is to use a PreparedStatement, which accepts data to substitute into a SQL statement using placeholders, which does not rely on string concatenations to create an SQL statement to send to the database.


For more information, Using Prepared Statements from The Java Tutorials would be a good place to start.


In case you are dealing with a legacy system, or you have too many places to switch to PreparedStatements in too little time - i.e. if there is an obstacle to using the best practice suggested by other answers, you can try AntiSQLFilter


You need the following code below. At a glance, this may look like any old code that I made up. However, what I did was look at the source code for http://grepcode.com/file/repo1.maven.org/maven2/mysql/mysql-connector-java/5.1.31/com/mysql/jdbc/PreparedStatement.java. Then after that, I carefully looked through the code of setString(int parameterIndex, String x) to find the characters which it escapes and customised this to my own class so that it can be used for the purposes that you need. After all, if this is the list of characters that Oracle escapes, then knowing this is really comforting security-wise. Maybe Oracle need a nudge to add a method similar to this one for the next major Java release.


Prepared Statements are the best solution, but if you really need to do it manually you could also use the StringEscapeUtils class from the Apache Commons-Lang library. It has an escapeSql(String) method, which you can use:


import org.apache.commons.lang.StringEscapeUtils;
…
String escapedSQL = StringEscapeUtils.escapeSql(unescapedSQL);



After searching an testing alot of solution for prevent sqlmap from sql injection, in case of legacy system which cant apply prepared statments every where.


java-security-cross-site-scripting-xss-and-sql-injection topic
WAS THE SOLUTION


i tried @Richard s solution but did not work in my case.
i used a filter


The goal of this filter is to wrapper the request into an own-coded
  wrapper MyHttpRequestWrapper which transforms:


the HTTP parameters with special characters (<, >, ‘, …) into HTML
  codes via the org.springframework.web.util.HtmlUtils.htmlEscape(…)
  method. Note: There is similar classe in Apache Commons :
  org.apache.commons.lang.StringEscapeUtils.escapeHtml(…) the SQL
  injection characters (‘, “, …) via the Apache Commons classe
  org.apache.commons.lang.StringEscapeUtils.escapeSql(…)


From:[Source]


}






I'm new to using Java, but I have some previous experience with C#. The issue I'm having comes with reading user input from console.


I'm running into the "java.util.NoSuchElementException" error with this portion of code:


I have two functions that get user input:


If I don't call PromptCustomerQty then I don't get this error, which leads me to believe I am doing something wrong with scanner. Below is my full code sample. I appreciate any help. 


This has really puzzled me for a while but this is what I found in the end.


When you call, sc.close() in first method, it not only closes your scanner but closes your System.in input stream as well. You can verify it by printing its status at very top of the second method as :


So, now when you re-instantiate, Scanner in second method, it doesn't find any open System.in stream and hence the exception.


I doubt if there is any way out to reopen System.in because:


public void close() throws IOException --> Closes this input stream and releases any system resources associated with this stream. The general contract of close is that it closes the input stream. A closed stream cannot perform input operations and **cannot be reopened.**


The only good solution for your problem is to initiate the Scanner in your main method, pass that as argument in your two methods, and close it again in your main method e.g.:


main method related code block:


Your Methods:


Hope this gives you some insight about the failure and possible resolution.


The problem is


When a Scanner is closed, it will close its input source if the source implements the Closeable interface.


http://docs.oracle.com/javase/1.5.0/docs/api/java/util/Scanner.html


Thus scan.close() closes System.in.


To fix it you can make


Scanner scan static
and do not close it in PromptCustomerQty.  Code below works.


On a side note, you shouldn't use == for String comparision, use .equals instead.


After this line:


Always add one more line to clear the scanner:


Also, use 


instead of 






I am trying to understand the difference between matches() and find().


According to the Javadoc, (from what I understand), matches() will search the entire string even if it finds what it is looking for, and find() will stop when it finds what it is looking for.


If that assumption is correct, I cannot see whenever you would want to use matches() instead of find(), unless you want to count the number of matches it finds.


In my opinion the String class should then have find() instead of matches() as an inbuilt method.


So to summarize:


matches tries to match the expression against the entire string and implicitly add a ^ at the start and $ at the end of your pattern, meaning it will not look for a substring. Hence the output of this code:


123 is a substring of a123b so the find() method outputs true. matches() only 'sees' a123b which is not the same as 123 and thus outputs false.


matches return true if the whole string matches the given pattern. find tries to find a substring that matches the pattern.


matches() will only return true if the full string is matched.
find() will try to find the next occurrence within the substring that matches the regex. Note the emphasis on "the next". That means, the result of calling find() multiple times might not be the same. In addition, by using find() you can call start() to return the position the substring was matched. 


Will output:


So, be careful when calling find() multiple times if the Matcher object was not reset, even when the regex is surrounded with ^ and $ to match the full string.


matches(); does not buffer, but find() buffers. find() searches to the end of the string first, indexes the result, and return the boolean value and corresponding index. 


That is why when you have a code like 


At 4: The regex engine using the pattern structure will read through the whole of your code (index to index as specified by the regex[single character] to find at least one match. If such match is found, it will be indexed then the loop will execute based on the indexed result else if it didn't do ahead calculation like which matches(); does not. The while statement would never execute since the first character of the matched string is not an alphabet. 


find() will consider the sub-string against the regular expression where as matches() will consider complete expression. 


find() will returns true only if the sub-string of the expression matches the pattern.






As of Java 1.5, you can pretty much interchange Integer with int in many situations.


However, I found a potential defect in my code that surprised me a bit.


The following code:


appeared to be incorrectly setting mismatch when the values were equal, although I can't determine under what circumstances. I set a breakpoint in Eclipse and saw that the Integer values were both 137, and I inspected the boolean expression and it said it was false, but when I stepped over it, it was setting mismatch to true.


Changing the conditional to:


fixed the problem.


Can anyone shed some light on why this happened? So far, I have only seen the behavior on my localhost on my own PC. In this particular case, the code successfully made it past about 20 comparisons, but failed on 2. The problem was consistently reproducible.


If it is a prevalent problem, it should be causing errors on our other environments (dev and test), but so far, no one has reported the problem after hundreds of tests executing this code snippet.


Is it still not legitimate to use == to compare two Integer values?


In addition to all the fine answers below, the following stackoverflow link has quite a bit of additional information. It actually would have answered my original question, but because I didn't mention autoboxing in my question, it didn't show up in the selected suggestions:


Why can't the compiler/JVM just make autoboxing “just work”?


The JVM is caching Integer values. == only works for numbers between -128 and 127
http://www.owasp.org/index.php/Java_gotchas#Immutable_Objects_.2F_Wrapper_Class_Caching


You can't compare two Integer with a simple == they're objects so most of the time references won't be the same.


There is a trick, with Integer between -128 and 127, references will be the same as autoboxing uses Integer.valueOf() which caches small integers.


If the value p being boxed is true, false, a byte, a char in the range \u0000 to \u007f, or an int or short number between -128 and 127, then let r1 and r2 be the results of any two boxing conversions of p. It is always the case that r1 == r2.


Resources :


On the same topic :


The issue is that your two Integer objects are just that, objects. They do not match because you are comparing your two object references, not the values within. Obviously .equals is overridden to provide a value comparison as opposed to an object reference comparison.


Integer refers to the reference, that is, when comparing references you're comparing if they point to the same object, not value.  Hence, the issue you're seeing.  The reason it works so well with plain int types is that it unboxes the value contained by the Integer.


May I add that if you're doing what you're doing, why have the if statement to begin with?


"==" always compare the memory location or object references of the values. equals method always compare the values. But equals also indirectly uses the "==" operator to compare the values.


Integer uses Integer cache to store the values from -128 to +127. If == operator is used to check for any values between -128 to 127 then it returns true. for other than these values it returns false .


Refer the  link  for some additional info






Can any body please tell me what code is used for clear screen in Java? For example in C++ 


What code is used in Java for clear screen?


Thanks!


Since there are several answers here showing non-working code for Windows, here is a clarification:


This command does not work, for two reasons:


There is no executable named cls.exe or cls.com in a standard Windows installation that could be invoked via Runtime.exec, as the well-known command cls is builtin to Windows’ command line interpreter.


When launching a new process via Runtime.exec, the standard output gets redirected to a pipe which the initiating Java process can read. But when the output of the cls command gets redirected, it doesn’t clear the console.


To solve this problem, we have to invoke the command line interpreter (cmd) and tell it to execute a command (/c cls) which allows invoking builtin commands. Further we have to directly connect its output channel to the Java process’ output channel, which works starting with Java 7, using inheritIO():


Now when the Java process is connected to a console, i.e. has been started from a command line without output redirection, it will clear the console.


You can use following code to clear command line console:


for reference ,refer this link http://techno-terminal.blogspot.in/2014/12/clear-command-line-console-and-bold.html


This is how I would handle it. This method will work for the Windows OS case and the Linux/Unix OS case (which means it also works for Mac OS X).


A way to get this can be print multiple end of lines ("\n") and simulate the clear screen. At the end clear, at most in the unix shell, not removes the previous content, only moves it up and if you make scroll down can see the previous content.


Here is a sample code:


If you want a more system independent way of doing this, you can use the JLine library and ConsoleReader.clearScreen().  Prudent checking of whether JLine and ANSI is supported in the current environment is probably worth doing too.


Something like the following code worked for me:


When running this, if you type 'clear' at the prompt it will clear the screen.  Make sure you run it from a proper terminal/console and not in Eclipse.


Runtime.getRuntime().exec(cls) did NOT work on my XP laptop.  This did -


Hope this is useful


Create a method in your class like this: [as @Holger said here.]


This works for windows at least, I have not checked for Linux so far. If anyone checks it for Linux please let me know if it works (or not).


As an alternate method is to write this code in clrscr():


I will not recommend you to use this method.


You can use an emulation of cls with 
    for (int i = 0; i < 50; ++i) System.out.println();


This will work if you are doing this in Bluej or any other similar software.


Try the following :


This will work fine in Linux environment


You need to use JNI. 


First of all use create a .dll using visual studio, that call system("cls"). 
After that use JNI to use this DDL. 


I found this article that is nice: 


http://www.planet-source-code.com/vb/scripts/ShowCode.asp?txtCodeId=5170&lngWId=2






I am trying to split the Value using a separator.
But I am finding the surprising results


I am expecting to get 8 values. [5,6,7,EMPTY,8,9,EMPTY,EMPTY]
But I am getting only 6 values.


Any idea and how to fix. No matter EMPTY value comes at anyplace, it should be in array.


split(delimiter) by default removes trailing empty strings from result array. To turn this mechanism off we need to use overloaded version of split(delimiter, limit) with limit set to negative value like


Little more details:
split(regex) internally returns result of split(regex, 0) and in documentation of this method you can find (emphasis mine)


The limit parameter controls the number of times the pattern is applied and therefore affects the length of the resulting array. 


If the limit n is greater than zero then the pattern will be applied at most n - 1 times, the array's length will be no greater than n, and the array's last entry will contain all input beyond the last matched delimiter. 


If n is non-positive then the pattern will be applied as many times as possible and the array can have any length. 


If n is zero then the pattern will be applied as many times as possible, the array can have any length, and trailing empty strings will be discarded.


Exception:


It is worth mentioning that removing trailing empty string makes sense only if such empty strings ware created by split mechanism. So for "".split(anything) since we can't split "" farther we will get as result [""] array.
It happens because split didn't happen here, so "" despite being empty and trailing represents original string, not empty string which was created by splitting process.


From the documentation of String.split(String regex):


This method works as if by invoking the two-argument split method with the given expression and a limit argument of zero. Trailing empty strings are therefore not included in the resulting array. 


So you will have to use the two argument version String.split(String regex, int limit) with a negative value:


Doc:


If the limit n is greater than zero then the pattern will be applied at most n - 1 times, the array's length will be no greater than n, and the array's last entry will contain all input beyond the last matched delimiter. If n is non-positive then the pattern will be applied as many times as possible and the array can have any length. If n is zero then the pattern will be applied as many times as possible, the array can have any length, and trailing empty strings will be discarded.


This will not leave out any empty elements, including the trailing ones.


From String.split() API Doc:


Splits this string around matches of the given regular expression.
  This method works as if by invoking the two-argument split method with
  the given expression and a limit argument of zero. Trailing empty
  strings are therefore not included in the resulting array.


Overloaded String.split(regex, int) is more appropriate for your case.


Another option is to use Guava's Splitter. It not does have the overhead of a regular expression (which you don't need in this case) and by default does not discard empty trailing strings. 


For example:


For further information, see wiki:
https://github.com/google/guava/wiki/StringsExplained






I am doing a https post and I'm getting an exception of ssl exception Not trusted server certificate. If i do normal http it is working perfectly fine. Do I have to accept the server certificate somehow?


I'm making a guess, but if you want an actual handshake to occur, you have to let android know of your certificate.  If you want to just accept no matter what, then use this pseudo-code to get what you need with the Apache HTTP Client:


CustomSSLSocketFactory:


FullX509TrustManager is a class that implements javax.net.ssl.X509TrustManager, yet none of the methods actually perform any work, get a sample here.


Good Luck!


This is what I am doing. It simply doesn't check the certificate anymore.


and


While trying to answer this question I found a better tutorial.  With it you don't have to compromise the certificate check.


http://blog.crazybob.org/2010/02/android-trusting-ssl-certificates.html


*I did not write this but thanks to Bob Lee for the work


You can also look at my blog article, very similar to crazybobs.


This solution also doesn't compromise certificate checking and explains how to add the trusted certs in your own keystore.


http://blog.antoine.li/index.php/2010/10/android-trusting-ssl-certificates/


http://madurangasblogs.blogspot.in/2013/08/avoiding-javaxnetsslsslpeerunverifiedex.html


Courtesy Maduranga 


When developing an application that uses https, your test server doesn't have a valid SSL certificate. Or sometimes the web site is using a self-signed certificate or the web site is using free SSL certificate. So if you try to connect to the server using Apache HttpClient, you will get a exception telling that the "peer not authenticated". Though it is not a good practice to trust all the certificates in a production software, you may have to do so according to the situation.
This solution resolves the exception caused by "peer not authenticated".


But before we go to the solution, I must warn you that this is not a good idea for a production application. This will violate the purpose of using a security certificate. So unless you have a good reason or if you are sure that this will not cause any problem, don't use this solution.


Normally you create a HttpClient like this.


HttpClient httpclient = new DefaultHttpClient();


But you have to change the way you create the HttpClient.


First you have to create a class extending org.apache.http.conn.ssl.SSLSocketFactory.


Then create a method like this.


Then you can create the HttpClient.


HttpClient httpclient = getNewHttpClient();


If you are trying to send a post request to a login page the rest of the code would be like this.


You get the html page to the InputStream. Then you can do whatever you want with the returned html page.


But here you will face a problem. If you want to manage a session using cookies, you will not be able to do it with this method. If you want to get the cookies, you will have to do it via a browser. Then only you will receive cookies.


If you are using a StartSSL or Thawte certificate, it will fail for Froyo and older versions. You can use a newer version's CAcert repository instead of trusting every certificate.


None of these worked for me (aggravated by the Thawte bug as well). Eventually I got it fixed with Self-signed SSL acceptance on Android and Custom SSL handling stopped working on Android 2.2 FroYo


Any of this answers didn't work for me so here is code which trust any certificates.


I don't know about the Android specifics for ssl certificates, but it would make sense that Android won't accept a self signed ssl certificate off the bat. I found this post from android forums which seems to be addressing the same issue:
http://androidforums.com/android-applications/950-imap-self-signed-ssl-certificates.html


This is a known problem with Android 2.x. I was struggling with this problem for a week until I came across the following question, which not only gives a good background of the problem but also provides a working and effective solution devoid of any security holes.


'No peer certificate' error in Android 2.3 but NOT in 4


For some reason the solution mentioned for httpClient above didn't worked for me. At the end I was able to make it work by correctly overriding the method when implementing the custom SSLSocketFactory class.


This is how it worked perfectly for me. You can see the full custom class and implementing on the following thread:
http://blog.syedgakbar.com/2012/07/21/android-https-and-not-trusted-server-certificate-error/


I make this class and found


in you code white this


Sources that helped me get to work with my self signed certificate on my AWS Apache server and connect with HttpsURLConnection from android device:
SSL on aws instance - amazon tutorial on ssl
Android Security with HTTPS and SSL - creating your own trust manager on client for accepting your certificate
Creating self signed certificate - easy script for creating your certificates


Then I did the following:


Place the certificates in their proper place on the server (you can find configuration in /etc/httpd/conf.d/ssl.conf). All these should be set:
SSLCertificateFile
SSLCertificateKeyFile
SSLCertificateChainFile
SSLCACertificateFile


Restart httpd using sudo service httpd restart and make sure httpd started:
Stopping httpd: [  OK  ]
Starting httpd: [  OK  ]


Copy my-private-root-ca.cert to your android project assets folder


Create your trust manager:


SSLContext SSLContext;


CertificateFactory cf = CertificateFactory.getInstance("X.509");
          InputStream caInput = context.getAssets().open("my-private-root-ca.cert.pem");
          Certificate ca;
          try {
            ca = cf.generateCertificate(caInput);
          } finally {
            caInput.close();
          }


And make the connection using HttpsURLConnection:


HttpsURLConnection connection = (HttpsURLConnection) url.openConnection();
connection.setSSLSocketFactory(SSLContext.getSocketFactory());


Thats it, try your https connection.


Just use this method as your HTTPClient:






Why do Generics in Java work with objects but not with primitive types?


For example  


Generics in Java are an entirely compile-time construct - the compiler turns all generic uses into casts to the right type. This is to maintain backwards compatibility with previous JVM runtimes.


This:


gets turned into (roughly):


So, anything that is used as generics has to be convertable to Object (in this example get(0) returns an Object), and the primitive types aren't. So they can't be used in generics.


C# is a separate matter - generics are implemented directly as part of the runtime, so primitive types can be used - the CLR generates new versions of generic classes for primitives and structs as they are used. The only disadvantage is (until .NET 4) no generic covariance or contravariance was allowed, unlike Java (see the super and extends keywords in generic definitions)


In Java, generics work the way that they do ... at least in part ... because they were added to the language a number of years after the language was designed1.  The language designers were constrained in their options for generics by having to come up with a design that was backwards compatible with the existing language and the Java class library.


Other programming languages (e.g. C++, C#, Ada) do allow primitive types to be used as parameter types for generics.  But the flip side of doing this is that such languages' implementations of generics (or template types) typically entail generation of a distinct copy of the generic type for each type parameterization.


1 - The reason generics were not included in Java 1.0 was because of time pressure.  They felt that they had to get the Java language released quickly to fill the new market opportunity presented by web browsers.  James Gosling has stated that he would have liked to include generics if they had had the time.  What the Java language would have looked like if this had happened is anyone's guess.


The collections are defined to require a type which derives from java.lang.Object. The basetypes simply don't do that.






Can anybody tell me what daemon threads are in Java?


A daemon thread is a thread that does not prevent the JVM from exiting when the program finishes but the thread is still running. An example for a daemon thread is the garbage collection.


You can use the setDaemon(boolean) method to change the Thread daemon properties before the thread starts.


A few more points (Reference: Java Concurrency in Practice)  


Normal thread and daemon threads differ in what happens when
they exit. When the JVM halts any remaining daemon threads are
abandoned: 


Due to this reason daemon threads
should be used sparingly and it is dangerous to use them for tasks
that might perform any sort of I/O.


All the above answers are good. Here's a simple little code snippet, to illustrate the difference. Try it with each of the values of true and false in setDaemon.


Traditionally daemon processes in UNIX were those that were constantly running in background, much like services in Windows.


A daemon thread in Java is one that doesn't prevent the JVM from exiting. Specifically the JVM will exit when only daemon threads remain. You create one by calling the setDaemon() method on Thread.


Have a read of Daemon threads.


Daemon threads are like a service providers for other threads or objects running in the same process as the daemon thread. Daemon threads are used for background supporting tasks and are only needed while normal threads are executing. If normal threads are not running and remaining threads are daemon threads then the interpreter exits.


For example, the HotJava browser uses up to four daemon threads named "Image Fetcher" to fetch images from the file system or network for any thread that needs one.


Daemon threads are typically used to perform services for your application/applet (such as loading the "fiddley bits"). The core difference between user threads and daemon threads is that the JVM will only shut down a program when all user threads have terminated. Daemon threads are terminated by the JVM when there are no longer any user threads running, including the main thread of execution.


setDaemon(true/false) ? This method is used to specify that a thread is daemon thread.


public boolean isDaemon() ? This method is used to determine the thread is daemon thread or not. 


Eg:


OutPut:


A daemon thread is a thread that is considered doing some tasks in the background like handling requests or various chronjobs that can exist in an application.


When your program only have damon threads remaining it will exit. That's because usually these threads work together with normal threads and provide background handling of events.


You can specify that a Thread is a demon one by using setDaemon method, they usually don't exit, neither they are interrupted.. they just stop when application stops.


Java has a special kind of thread called daemon thread. 


What are daemon threads used for?  


Normally used as service providers for normal threads.
Usually have an infinite loop that waits for the service request or performs the tasks of the thread.
They can’t do important jobs. (Because we don't know when they are going to have CPU time and they can finish any time if there aren't any other threads running. )


A typical example of these kind of threads is the Java garbage collector.


There's more...  


What is Daemon thread in java? 


One misconception I would like to clarify:


Daemon Thread and User Threads. Generally all threads created by programmer are user thread (unless you specify it to be daemon or your parent thread is a daemon thread). User thread are generally meant to run our programm code. JVM doesn't terminates unless all the user thread terminate. 


Daemon thread is just like a normal thread except that the JVM will only shut down when the other non daemon threads are not existing. Daemon threads are typically used to perform services for your application.


Daemon threads are as everybody explained, will not constrain JVM to exit, so basically its a happy thread for Application from exit point of view.


Want to add that daemon threads can be used when say I'm providing an API like pushing data to a 3rd party server / or JMS, I might need to aggregate data at the client JVM level and then send to JMS in a separate thread. I can make this thread as daemon thread, if this is not a mandatory data to be pushed to server.
This kind of data is like log push / aggregation. 


Regards,
Manish


Daemon thread in Java are those thread which runs in background and mostly created by JVM for performing background task like Garbage collection and other house keeping tasks.


Points to Note : 


Any thread created by main thread, which runs main method in Java is by default non daemon because Thread inherits its daemon nature from the Thread which creates it i.e. parent Thread and since main thread is a non daemon thread, any other thread created from it will remain non-daemon until explicitly made daemon by calling setDaemon(true).


Thread.setDaemon(true) makes a Thread daemon but it can only be called before starting Thread in Java. It will throw IllegalThreadStateException if corresponding Thread is already started and running.


Difference between Daemon and Non Daemon thread in Java :


1) JVM doesn't wait for any daemon thread to finish before existing.


2) Daemon Thread are treated differently than User Thread when JVM terminates, finally blocks are not called, Stacks are not unwounded and JVM just exits.


Daemon thread is like daemon process which is responsible for managing resources,a daemon thread is created by the Java VM to serve the user threads.
example updating system for unix,unix is daemon process.
child of daemon thread is always daemon thread,so by default daemon is false.you can check thread as daemon or user by using "isDaemon()" method.
so daemon thread or daemon process are basically responsible for managing resources.
for example when you starting jvm there is garbage collector running that is daemon thread whose priority is 1 that is lowest,which is managing memory.
jvm is alive as long as user thread is alive,u can not kill daemon thread.jvm is responsible to kill daemon threads.


Daemon threads are generally known as "Service Provider" thread. These threads should not be used to execute program code but system code. These threads run parallel to your code but JVM can kill them anytime. When JVM finds no user threads, it stops it and all daemon threads terminate instantly. We can set non-daemon thread to daemon using : 


Daemon threads are like assistants. Non-Daemon threads are like front performers. Assistants help performers to complete a job. When the job is completed, no help is needed by performers to  perform anymore. As no help is needed the assistants leave the place. So when the jobs of Non-Daemon threads is over, Daemon threads march away.


Any Java thread can be a daemon thread.
Daemon threads are service providers for other threads running in the same process as the daemon thread. For example, the HotJava browser uses up to four daemon threads named "Image Fetcher" to fetch images from the file system or network for any thread that needs one. The run() method for a daemon thread is typically an infinite loop that waits for a service request.
When the only remaining threads in a process are daemon threads, the interpreter exits. This makes sense because when only daemon threads remain, there is no other thread for which a daemon thread can provide a service.


To specify that a thread is a daemon thread, call the setDaemon method with the argument true. To determine if a thread is a daemon thread, use the accessor method isDaemon.


Hope this may help!!!!!!


For me, daemon thread it's like house keeper for user threads.
If all user threads finished , the daemon thread has no job and 
killed by JVM.
I explained it in the YouTube video.


Daemon threads are threads that run in background as long as other non-daemon threads of the process are still running. Thus, when all of the non-daemon threads complete, the daemon threads are terminated. An example for non-daemon thread is the thread running the Main.
A thread is made daemon by calling the setDaemon() method before the thread is started


For More Reference : Daemon thread in Java


Let's talk only in code with working examples. I like russ's answer above but to remove any doubt I had, I enhanced it a little bit. I ran it twice, once with the worker thread set to deamon true  (deamon thread) and another time set it to false (user thread). It confirms that the deamon thread ends when the main thread terminates.


Daemon threads die when the creator thread exits.


Non-daemon threads (default) can even live longer than the main thread.


In Java, Daemon Threads are one of the types of thread which does not prevent Java Virtual Machine (JVM) from exiting.
The main purpose of daemon thread is to execute background task especially in case of some routine periodic task or work. With JVM exits, daemon thread also dies.


By setting a thread.setDaemon(true), a thread becomes a daemon thread. However, you can only set this value before the thread start.






How does one go about and try to find all subclasses of a given class (or all implementors of a given interface) in Java?
As of now, I have a method to do this, but I find it quite inefficient (to say the least).
The method is: 


In Eclipse, there is a nice feature called the Type Hierarchy that manages to show this quite efficiently.
How does one go about and do it programmatically?


There is no other way to do it other than what you described. Think about it - how can anyone know what classes extend ClassX without scanning each class on the classpath?


Eclipse can only tell you about the super and subclasses in what seems to be an "efficient" amount of time because it already has all of the type data loaded at the point where you press the "Display in Type Hierarchy" button (since it is constantly compiling your classes, knows about everything on the classpath, etc).


Scanning for classes is not easy with pure Java. 


The spring framework offers a class called ClassPathScanningCandidateComponentProvider that can do what you need. The following example would find all subclasses of MyClass in the package org.example.package


This method has the additional benefit of using a bytecode analyzer to find the candidates which means it will not load all classes it scans.


This is not possible to do using only the built-in Java Reflections API.


A project exists that does the necessary scanning and indexing of your classpath so you can get access this information...


A Java runtime metadata analysis, in the spirit of Scannotations



Using Reflections you can query your metadata for:



(disclaimer: I have not used it, but the project's description seems to be an exact fit for your needs.)


Don't forget that the generated Javadoc for a class will include a list of known subclasses (and for interfaces, known implementing classes).


I know I'm a few years late to this party, but I came across this question trying to solve the same problem.  You can use Eclipse's internal searching programatically, if you're writing an Eclipse Plugin (and thus take advantage of their caching, etc), to find classes which implement an interface.  Here's my (very rough) first cut:


The first problem I see so far is that I'm only catching classes which directly implement the interface, not all their subclasses - but a little recursion never hurt anyone.


I did this several years ago.  The most reliable way to do this (i.e. with official Java APIs and no external dependencies) is to write a custom doclet to produce a list that can be read at runtime.


You can run it from the command line like this:


or run it from ant like this:


Here's the basic code:


For simplicity, I've removed command line argument parsing and I'm writing to System.out rather than a file.


Keeping in mind the limitations mentioned in the other answers, you can also use openpojo's PojoClassFactory (available on Maven) in the following manner:


Where packageRoot is the root String of the packages you wish to search in (e.g. "com.mycompany" or even just "com"), and Superclass is your supertype (this works on interfaces as well).


It should be noted as well that this will of course only find all those subclasses that exist on your current classpath.  Presumably this is OK for what you are currently looking at, and chances are you did consider this, but if you have at any point released a non-final class into the wild (for varying levels of "wild") then it is entirely feasible that someone else has written their own subclass that you will not know about.


Thus if you happened to be wanting to see all subclasses because you want to make a change and are going to see how it affects subclasses' behaviour - then bear in mind the subclasses that you can't see.  Ideally all of your non-private methods, and the class itself should be well-documented; make changes according to this documentation without changing the semantics of methods/non-private fields and your changes should be backwards-compatible, for any subclass that followed your definition of the superclass at least.


The reason you see a difference between your implementation and Eclipse is because you scan each time, while Eclipse (and other tools) scan only once (during project load most of the times) and create an index. Next time you ask for the data it doesn't scan again, but look at the index.


You could try my library FastClasspathScanner -- it can find all subclasses of a given class on the classpath (as well as all subinterfaces of a given interface, all classes that implement a given interface, all classes annotated with a given annotation, and more). It's a small dependency, and it is extremely fast compared to other classpath scanning options.


BTW, scanning the classpath is not as simple as checking the java.class.path property, because there are many ways that the classpath can be specified (e.g. you can add Class-Path entries to a jarfile's manifest). FastClasspathScanner handles these complexities for you.


I just write a simple demo to use the org.reflections.Reflections to get subclasses of abstract class:


https://github.com/xmeng1/ReflectionsDemo


Add them to a static map inside (this.getClass().getName()) the parent classes constructor (or create a default one) but this will get updated in runtime. If lazy initialization is an option you can try this approach.


I'm using a reflection lib, which scans your classpath for all subclasses: https://github.com/ronmamo/reflections


This is how it would be done:


Depending on your particular requirements, in some cases Java's service loader mechanism might achieve what you're after.


In short, it allows developers to explicitly declare that a class subclasses some other class (or implements some interface) by listing it in a file in the JAR/WAR file's META-INF/services directory. It can then be discovered using the java.util.ServiceLoader class which, when given a Class object, will generate instances of all the declared subclasses of that class (or, if the Class represents an interface, all the classes implementing that interface).


The main advantage of this approach is that there is no need to manually scan the entire classpath for subclasses - all the discovery logic is contained within the ServiceLoader class, and it only loads the classes explicitly declared in the META-INF/services directory (not every class on the classpath).


There are, however, some disadvantages:


Apparently Java 9 will be addressing some of these shortcomings (in particular, the ones regarding instantiation of subclasses).


Suppose you're interested in finding classes that implement an interface com.example.Example:


The class com.example.ExampleImpl implements that interface:


You would declare the class ExampleImpl is an implementation of Example by creating a file META-INF/services/com.example.Example containing the text com.example.ExampleImpl.


Then, you could obtain an instance of each implementation of Example (including an instance of ExampleImpl) as follows:






One of the first things I've learned about Java EE development is that I shouldn't spawn my own threads inside a Java EE container. But when I come to think about it, I don't know the reason.


Can you clearly explain why it is discouraged? 


I am sure most enterprise applications need some kind of asynchronous jobs like mail daemons, idle sessions, cleanup jobs etc.


So, if indeed one shouldn't spawn threads, what is the correct way to do it when needed?


It is discouraged because all resources within the environment are meant to be managed, and potentially monitored, by the server.  Also, much of the context in which a thread is being used is typically attached to the thread of execution itself.  If you simply start your own thread (which I believe some servers will not even allow), it cannot access other resources.  What this means, is that you cannot get an InitialContext and do JNDI lookups to access other system resources such as JMS Connection Factories and Datasources.


There are ways to do this "correctly", but it is dependent on the platform being used.  


The commonj WorkManager is common for WebSphere and WebLogic as well as others


More info here


And here


Also somewhat duplicates this one  from this morning


UPDATE: Please note that this question and answer relate to the state of Java EE in 2009, things have improved since then!


For EJBs, it's not only discouraged, it's expressly forbidden by the specification:


An enterprise bean must not use thread
  synchronization primitives to
  synchronize execution of multiple
  instances.


and


The enterprise bean must not attempt
  to manage threads.  The enterprise
  bean must not attempt to start, stop,
  suspend, or resume a thread, or to
  change a thread’s priority or name.
  The enterprise bean must not attempt
  to manage thread groups.


The reason is that EJBs are meant to operate in a distributed environment.  An EJB might be moved from one machine in a cluster to another.  Threads (and sockets and other restricted facilities) are a significant barrier to this portability.


The reason that you shouldn't spawn your own threads is that these won't be managed by the container. The container takes care of a lot of things that a novice developer can find hard to imagine. For example things like thread pooling, clustering, crash recoveries are performed by the container. When you start a thread you may lose some of those. Also the container lets you restart your application without affecting the JVM it runs on. How this would be possible if there are threads out of the container's control?


This the reason that from J2EE 1.4 timer services were introduced. See this article for details.


There is now a standard, and correct way to create threads with the core Java EE API:


By using Concurrency Utils, you ensure that your new thread is created, and managed by the container, guaranteeing that all EE services are available.


Examples here


You can always tell the container to start stuff as part of your deployment descriptors.  These can then do whatever maintainance tasks you need to do.


Follow the rules.  You will be glad some day you did :)


Threads are prohibited in Java EE containers according to the blueprints. Please refer to the blueprints  for more information.


There is no real reason not to do so. I used Quarz with Spring in a webapp without problems. Also the concurrency framework java.util.concurrent may be used. If you implement your own thread handling, set the theads to deamon or use a own deamon thread group for them so the container may unload your webapp any time.


But be careful, the bean scopes session and request do not work in threads spawned! Also other code beased on ThreadLocal does not work out of the box, you need to transfer the values to the spawned threads by yourself.


I've never read that it's discouraged, except from the fact that it's not easy to do correctly.


It is fairly low-level programming, and like other low-level techniques you ought to have a good reason. Most concurrency problems can be resolved far more effectively using built-in constructs like thread pools.


One reason I have found if you spawn some threads in you EJB and then you try to have the container unload or update your EJB you are going to run into problems. There is almost always another way to do something where you don't need a Thread so just say NO.






I am trying to use a java.util.Date as input and then creating a query with it - so I need a java.sql.Date.  


I was surprised to find that it couldn't do the conversion implicitly or explicitly - but I don't even know how I would do this, as the Java API is still fairly new to me.


If you are trying to work with date-only values (no time-of-day, no time zone), use the LocalDate class rather than java.util.Date.


In Java 8 and later, the troublesome old date-time classes bundled with early versions of Java have been supplanted by the new java.time package. See Oracle Tutorial. Much of the functionality has been back-ported to Java 6 & 7 in ThreeTen-Backport and further adapted to Android in ThreeTenABP.


A SQL data type DATE is meant to be date-only, with no time-of-day and no time zone. Java never had precisely such a class† until java.time.LocalDate in Java 8. Let's create such a value by getting today's date according to a particular time zone (time zone is important in determining a date as a new day dawns earlier in Paris than in Montréal, for example).


At this point, we may be done. If your JDBC driver complies with JDBC 4.2 spec, you should be able to pass a LocalDate via setObject on a PreparedStatement to store into a SQL DATE field. 


Likewise, use ResultSet::getObject to fetch from a SQL DATE column to a Java LocalDate object. Specifying the class in the second argument makes your code type-safe.


In other words, this entire Question is irrelevant under JDBC 4.2 or later.


If your JDBC driver does not perform in this manner, you need to fall back to converting to the java.sql types.


To convert, use new methods added to the old date-time classes. We can call java.sql.Date.valueOf(…) to convert a LocalDate.


And going the other direction.


While you should avoid using the old date-time classes, you may be forced to when working with existing code. If so, you can convert to/from java.time. 


Go through the Instant class, which represents a moment on the timeline in UTC. An Instant is similar in idea to a java.util.Date. But note that Instant has a resolution up to nanoseconds while java.util.Date has only milliseconds resolution.


To convert, use new methods added to the old classes. For example, java.util.Date.from( Instant ) and java.util.Date::toInstant.


To determine a date, we need the context of a time zone. For any given moment, the date varies around the globe by time zone. Apply a ZoneId to get a ZonedDateTime.


† The java.sql.Date class pretends to be date-only without a time-of-day but actually does a time-of-day, adjusted to a midnight time. Confusing? Yes, the old date-time classes are a mess.


Nevermind....


explains it.  The link is http://www.java2s.com/Tutorial/Java/0040__Data-Type/ConvertfromajavautilDateObjecttoajavasqlDateObject.htm


With the other answer you may have troubles with the time info (compare the dates with unexpected results!)


I suggest:


This function will return a converted SQL date from java date object.


Converting java.util.Data to java.sql.Data will lost the hour,minute and second. So if it is possible, I suggest you use java.sql.Timestamp like this:


For more info, you can check this question.


In my case of picking date from JXDatePicker (java calender) and getting it stored in database as SQL Date type, below works fine ..


java.sql.Date date = new java.sql.Date(pickedDate.getDate().getTime());


where pickedDate is object of JXDatePicker


This function will return a converted SQL date from java date object.


Here the example of converting Util Date to Sql date and ya this is one example what i am using in my project might be helpful to you too.


Format your java.util.Date first. Then use the formatted date to get the date in java.sql.Date


Method for comparing 2 dates (util.date or sql.date)  


try with this 


I think the best way to convert is:


If you want to insert the dt variable into an SQL table you can do:


I am a novice: after much running around this worked.  Thought might be useful


You can use this method to convert util date to sql date,


i am using the following code please try it out


specify the format of the date you want
for example "DD-MM_YYYY" or 'YYYY-mm-dd'  then use the java Date datatype as


then it will parse your date


I was trying the following coding that worked fine.


java.util.Date utilDate = new java.util.Date(); java.sql.Date
  sqlDate = new java.sql.Date(utilDate);


If you are usgin Mysql a date column can be passed a String representation of this date


so i using the DateFormatter Class to format it and then set it as a String in the sql statement or prepared statement


here is the code illustration:


String date = converUtilDateToSqlDate(otherTransaction.getTransDate());


//then pass this date in you sql statement






From my understanding, garbage collection in Java cleans up some object if nothing else is 'pointing' to that object.


My question is, what happens if we have something like this:


a, b, and c should be garbage collected, but they are all being referenced by other objects.


How does the Java garbage collection deal with this? (or is it simply a memory drain?)


Java's GC considers objects "garbage" if they aren't reachable through a chain starting at a garbage collection root, so these objects will be collected.  Even though objects may point to each other to form a cycle, they're still garbage if they're cut off from the root.


See the section on unreachable objects in Appendix A: The Truth About Garbage Collection in Java Platform Performance: Strategies and Tactics for the gory details.


yes Java Garbage collector handles circular-reference!


There are special objects called called garbage-collection roots (GC roots). These are always reachable and so is any object that has them at its own root.


A simple Java application has the following GC roots:





To determine which objects are no longer in use, the JVM intermittently runs what is very aptly called a mark-and-sweep algorithm. It works as follows


So if any object is not reachable from the GC roots(even if it is self-referenced or cyclic-referenced) it will be subjected to garbage collection.


Ofcourse sometimes this may led to memory leak if programmer forgets to dereference an object.





Source : Java Memory Management


A garbage collector starts from some "root" set of places that are always considered "reachable", such as the CPU registers, stack, and global variables. It works by finding any pointers in those areas, and recursively finding everything they point at. Once it's found all that, everything else is garbage.


There are, of course, quite a few variations, mostly for the sake of speed. For example, most modern garbage collectors are "generational", meaning that they divide objects into generations, and as an object gets older, the garbage collector goes longer and longer between times that it tries to figure out whether that object is still valid or not -- it just starts to assume that if it has lived a long time, chances are pretty good that it'll continue to live even longer.


Nonetheless, the basic idea remains the same: it's all based on starting from some root set of things that it takes for granted could still be used, and then chasing all the pointers to find what else could be in use.


Interesting aside: may people are often surprised by the degree of similarity between this part of a garbage collector and code for marshaling objects for things like remote procedure calls. In each case, you're starting from some root set of objects, and chasing pointers to find all the other objects those refer to...


You are correct. The specific form of garbage collection you describe is called "reference counting". The way it works (conceptually, at least, most modern implementations of reference counting are actually implemented quite differently) in the simplest case, looks like this:


And this simple strategy has exactly the problem you decribe: if A references B and B references A, then both of their reference counts can never be less than 1, which means they will never get collected.


There are four ways to deal with this problem:


By the way, the other major way to implement a garbage collector (and I have already hinted at that a couple of times above), is tracing. A tracing collector is based on the concept of reachability. You start out with some root set that you know is always reachable (global constants, for example, or the Object class, the current lexical scope, the current stack frame) and from there you trace all objects that are reachable from the root set, then all objects that are reachable from the objects reachable from the root set and so on, until you have the transitive closure. Everything that is not in that closure is garbage.


Since a cycle is only reachable within itself, but not reachable from the root set, it will be collected.


The Java GCs don't actually behave as you describe.  It's more accurate to say that they start from a base set of objects, frequently called "GC roots", and will collect any object that can not be reached from a root.
GC roots include things like:


So, in your case, once the local variables a, b, and c go out of scope at the end of your method, there are no more GC roots that contain, directly or indirectly, a reference to any of your three nodes, and they'll be eligible for garbage collection.


TofuBeer's link has more detail if you want it.


This article goes into depth about the garbage collector (conceptually... there are several implementations).  The relevant part to your post is "A.3.4 Unreachable".


Garbage collection doesn't usually mean "clean some object iff nothing else is 'pointing' to that object" (that's reference counting). Garbage collection roughly means finding objects that can't be reached from the program.


So in your example, after a,b, and c go out of scope, they can be collected by the GC, since you can't access these objects anymore.


Bill answered your question directly. As Amnon said, your definition of garbage collection is just reference counting. I just wanted to add that even very simple algorithms like mark and sweep and copy collection easily handle circular references. So, nothing magic about it!






Before Java 8 when we split on empty string like 


split mechanism would split in places marked with |


because empty space "" exists before and after each character. So as result it would generate at first this array


and later will remove trailing empty strings (because we didn't explicitly provide negative value to limit argument) so it will finally return 


In Java 8 split mechanism seems to have changed. Now when we use 


we will get ["a", "b", "c"] array instead of ["", "a", "b", "c"] so it looks like empty strings at start are also removed. But this theory fails because for instance


is returning array with empty string at start ["", "bc"]. 


Can someone explain what is going on here and how rules of split for this cases have changed in Java 8?


The behavior of String.split (which calls Pattern.split) changes between Java 7 and Java 8.


Comparing between the documentation of Pattern.split in Java 7 and Java 8, we observe the following clause being added:


When there is a positive-width match at the beginning of the input sequence then an empty leading substring is included at the beginning of the resulting array. A zero-width match at the beginning however never produces such empty leading substring.


The same clause is also added to String.split in Java 8, compared to Java 7.


Let us compare the code of Pattern.split of the reference implemetation in Java 7 and Java 8. The code is retrieved from grepcode, for version 7u40-b43 and 8-b132.


The addition of the following code in Java 8 excludes the zero-length match at the beginning of the input string, which explains the behavior above.


To make split behaves consistently across versions and compatible with the behavior in Java 8:


(?!\A) checks that the string does not end at the beginning of the string, which implies that the match is an empty match at the beginning of the string.


There is no general solution to make split backward-compatible with Java 7 and prior, short of replacing all instance of split to point to your own custom implementation.


This has been specified in the documentation of split(String regex, limit).


When there is a positive-width match at the beginning of this string
  then an empty leading substring is included at the beginning of the
  resulting array. A zero-width match at the beginning however never
  produces such empty leading substring.


In "abc".split("") you  got a zero-width match at the beginning so the leading empty substring is not included in the resulting array. 


However in your second snippet when you split on "a" you got a positive width match (1 in this case), so the empty leading substring is included as expected.


(Removed irrelevant source code)


There was a slight change in the docs for split() from Java 7 to Java 8. Specifically, the following statement was added:


When there is a positive-width match at the beginning of this string then an empty leading substring is included at the beginning of the resulting array. A zero-width match at the beginning however never produces such empty leading substring.


(emphasis mine)


The empty string split generates a zero-width match at the beginning, so an empty string is not included at the start of the resulting array in accordance with what is specified above. By contrast, your second example which splits on "a" generates a positive-width match at the start of the string, so an empty string is in fact included at the start of the resulting array.






I need to know when the finalize() method is called in the JVM. I created a test class which writes into a file when the finalize() method is called by overriding it. It is not executed. Can anybody tell me the reason why it is not executing?


In general it's best not to rely on finalize() to do any cleaning up etc.


According to the Javadoc (which it would be worth reading), it is:


Called by the garbage collector on an object when garbage collection determines that there are no more references to the object.


As Joachim pointed out, this may never happen in the life of a program if the object is always accessible.


Also, the garbage collector is not guaranteed to run at any specific time. In general, what I'm trying to say is finalize() is probably not the best method to use in general unless there's something specific you need it for.


The finalize method is called when an object is about to get garbage collected. That can be at any time after it has become eligible for garbage collection.


Note that it's entirely possible that an object never gets garbage collected (and thus finalize is never called). This can happen when the object never becomes eligible for gc (because it's reachable through the entire lifetime of the JVM) or when no garbage collection actually runs between the time the object become eligible and the time the JVM stops running (this often occurs with simple test programs).


There are ways to tell the JVM to run finalize on objects that it wasn't called on yet, but using them isn't a good idea either (the guarantees of that method aren't very strong either).


If you rely on finalize for the correct operation of your application, then you're doing something wrong. finalize should only be used for cleanup of (usually non-Java) resources. And that's exactly because the JVM doesn't guarantee that finalize is ever called on any object.


if overridding finalize() it is good programming practice to use a
  try-catch-finally statement and to
  always call super.finalize(). This
  is a safety measure to ensure you do
  not inadvertently miss closing a
  resource used by the objects calling
  class 


any exception thrown by finalize() during garbage collection halts the
  finalization but is otherwise ignored


quoted from: http://www.janeg.ca/scjp/gc/finalize.html


You could also check this article:


The Java finalize() method is not a destructor and should not be used to handle logic that your application depends on. The Java spec states there is no guarantee that the finalize method is called at all during the livetime of the application.


What you problably want is a combination of finally and a cleanup method, as in:


Check out Effective Java, 2nd edition page 27.
Item 7: Avoid finalizers


Finalizers are unpredictable, often dangerous, and generally unnecessary. never do anything time-critical in a finalizer. never
  depend on a finalizer to update critical persistent state.


To terminate a resource, use try-finally instead:


When is the finalize() method called in Java?


The finalize method will be called after the GC detects that the object is no longer reachable, and before it actually reclaims the memory used by the object.


If an object never becomes unreachable, finalize() will never be called on it.


If the GC doesn't run then finalize() may never be called.  (Normally, the GC only runs when the JVM decides that there is likely to enough garbage to make it worthwhile.)


It may take more than one GC cycle before the GC determines that a specific object is unreachable.  (Java GCs are typically "generational" collectors ...)


Once the GC detects an object is unreachable and finalizable, it is places on a finalization queue.  Finalization typically occurs asynchronously with the normal GC.


(The JVM spec actually allows a JVM to never run finalizers ... provided that it doesn't reclaim the space used by the objects.  A JVM that was implemented this way would be crippled / useless, but it this behavior is "allowed".)


The upshot is that it is unwise to rely on finalization to do things that have to be done in a definite time-frame.  It is "best practice" not to use them at all.  There should be a better (i.e. more reliable) way to do whatever it is you are trying to do in the finalize() method.  


The only legitimate use for finalization is to clean up resources associated with objects that have been lost by application code.  Even then, you should try to write the application code so that it doesn't lose the objects in the first place.  (For example, use Java 7+ try-with-resources to ensure that close() is always called ...)


I created a test class which writes into a file when the finalize() method is called by overriding it.  It is not executed. Can anybody tell me the reason why it is not executing?


It is hard to say, but there are a few possibilities:


Since there is an uncertainity in calling of finalize() method by JVM (not sure whether finalize() which is overridden would be executed or not), for study purposes the better way to observe what happens when finalize() is called, is to force the JVM to call garbage collection by command System.gc().


Specifically, finalize() is called when an object is no longer in use. But when we try to call it by creating new objects there is no certainty of its call. So for certainty we create a null object c which obviously  has no future use, hence we see the object c's finalize call.


Example


Output


Note - Even after printing upto 70 and after which object b is not being used in the program, there is  uncertainty that b is cleared or not by JVM since "Called finalize method in class Bike..." is not printed.


finalize will print out the count for class creation. 


main


As you can see. The following out put show the gc got executed first time when the class count is 36.


Having wrestled with finalizer methods lately (in order to dispose connection pools during testing), I have to say that finalizer lacks many things. Using VisualVM to observe as well as using weak references to track the actual interaction I found that following things are true in a Java 8 environment (Oracle JDK, Ubuntu 15):


Final Thought


Finalize method is unreliable but can be used for one thing only. You can ensure that an object was closed or disposed before it was garbage collected making it possible to implement a fail safe if objects with a more complex life-cylce involving a end-of-life action are handled correctly. That is the one reason I can think of that makes it worth in order to override it.


finalize method is not guaranteed.This method is called when the object becomes eligible for GC. There are many situations where the objects may not be garbage collected.


An Object becomes eligible for Garbage collection or GC if its not reachable from any live threads or any static refrences in other words you can say that an object becomes eligible for garbage collection if its all references are null. Cyclic dependencies are not counted as reference so if Object A has reference of object B and object B has reference of Object A and they don't have any other live reference then both Objects A and B will be eligible for Garbage collection. 
Generally an object becomes eligible for garbage collection in Java on following cases:


Class where we override finalize method


The chances of finalize method being called


when the memory is overloaded with dump objects the gc will call finalize method


run and see the console, where you dont find the finalize method being called frequently, when the memory is getting overloaded then the finalize method will be called. 


Java allows objects to implement a method called finalize()
  that might get called.


finalize() method gets called if the garbage collector tries to
  collect the object.


If the garbage collector doesn't run, the method doesn't get called.


If the garbage collector fails to collect the object and tries to run
it again, the method doesn't get called in the second time.


In practice, you are highly unlikely to use it in real projects.


Just keep in mind that it might not get called and that it definitely
  won't be called twice. The finalize() method could run zero or one
  time.


In the following code, finalize() method produces no output when we
  run it since the program exits before there is any need to run the
  garbage collector.


Source


Sometimes when it is destroyed, an object must make an action. For example, if an object has a non-java resource such as a file handle or a font, you can verify that these resources are released before destroying an object. To manage such situations, java offers a mechanism called "finalizing". By finalizing it, you can define specific actions that occur when an object is about to be removed from the garbage collector.
To add a finalizer to a class simply define the finalize() method. Java execution time calls this method whenever it is about to delete an object of that class. Within the finalize method() you specify actions to be performed before destroying an object.
The garbage collector is periodically searched for objects that no longer refer to any running state or indirectly any other object with reference. Before an asset is released, the Java runtime calls the finalize() method on the object. The finalize() method has the following general form:


With the protected keyword, access to finalize() by code outside its class is prevented.
It is important to understand that finalize() is called just just before the garbage collection. It is not called when an object leaves the scope, for example. It means you can not know when, or if, finalize() will be executed. As a result, the program must provide other means to free system resources or other resources used by the object. You should not rely on finalize() for normal running of the program.


Try runiing this Program for better understanding






This could be the dumbest question ever asked but I think it is a total confusion for a newbie. 


A nice example (in Java) will be really appreciated.


Immutable means that once the constructor for an object has completed execution that instance can't be altered.


This is useful as it means you can pass references to the object around, without worrying that someone else is going to change its contents. Especially when dealing with concurrency, there are no locking issues with objects that never change


e.g.


Foo doesn't have to worry that the caller to getValue() might change the text in the string.


If you imagine a similar class to Foo, but with a StringBuilder rather than a String as a member, you can see that a caller to getValue() would be able to alter the StringBuilder attribute of a Foo instance.


Also beware of the different kinds of immutability you might find: Eric Lippert wrote a blog article about this. Basically you can have objects whose interface is immutable but behind the scenes actual mutables private state (and therefore can't be shared safely between threads).


An immutable object is an object where the internal fields (or at least, all the internal fields that affect its external behavior) cannot be changed.


There are a lot of advantages to immutable strings:


Performance: Take the following operation:


The underlying C for the substring() method is probably something like this:


Note that none of the characters have to be copied!  If the String object were mutable (the characters could change later) then you would have to copy all the characters, otherwise changes to characters in the substring would be reflected in the other string later.


Concurrency: If the internal structure of an immutable object is valid, it will always be valid.  There's no chance that different threads can create an invalid state within that object. Hence, immutable objects are Thread Safe.


Garbage collection: It's much easier for the garbage collector to make logical decisions about immutable objects.


However, there are also downsides to immutability:


Performance: Wait, I thought you said performance was an upside of immutability!  Well, it is sometimes, but not always.  Take the following code:


The two lines both replace the fourth character with the letter "a".  Not only is the second piece of code more readable, it's faster.  Look at how you would have to do the underlying code for foo.  The substrings are easy, but now because there's already a character at space five and something else might be referencing foo, you can't just change it; you have to copy the whole string (of course some of this functionality is abstracted into functions in the real underlying C, but the point here is to show the code that gets executed all in one place).


Note that concatenate gets called twice meaning that the entire string has to be looped through!  Compare this to the C code for the bar operation:


The mutable string operation is obviously much faster.


In Conclusion: In most cases, you want an immutable string.  But if you need to do a lot of appending and inserting into a string, you need the mutability for speed.  If you want the concurrency safety and garbage collection benefits with it the key is to keep your mutable objects local to a method:


Since the mutable object is a local reference, you don't have to worry about concurrency safety (only one thread ever touches it).  And since it isn't referenced anywhere else, it is only allocated on the stack, so it is deallocated as soon as the function call is finished (you don't have to worry about garbage collection).  And you get all the performance benefits of both mutability and immutability.


Actually String is not immutable if you use the wikipedia definition suggested above. 


String's state does change post construction. Take a look at the hashcode() method.  String caches the hashcode value in a local field but does not calculate it until the first call of hashcode().  This lazy evaluation of hashcode places String in an interesting position as an immutable object whose state changes, but it cannot be observed to have changed without using reflection. 


So maybe the definition of immutable should be an object that cannot be observed to have changed. 


If the state changes in an immutable object after it has been created but no-one can see it (without reflection) is the object still immutable?


Immutable objects are objects that can't be changed programmatically. They're especially good for multi-threaded environments or other environments where more than one process is able to alter (mutate) the values in an object.


Just to clarify, however, StringBuilder is actually a mutable object, not an immutable one. A regular java String is immutable (meaning that once it's been created you cannot change the underlying string without changing the object).


For example, let's say that I have a class called ColoredString that has a String value and a String color:


In this example, the ColoredString is said to be mutable because you can change (mutate) one of its key properties without creating a new ColoredString class. The reason why this may be bad is, for example, let's say you have a GUI application which has multiple threads and you are using ColoredStrings to print data to the window. If you have an instance of ColoredString which was created as


Then you would expect the string to always be "Blue". If another thread, however, got ahold of this instance and called


You would suddenly, and probably unexpectedly, now have a "Red" string when you wanted a "Blue" one. Because of this, immutable objects are almost always preferred when passing instances of objects around. When you have a case where mutable objects are really necessary, then you would typically guard the objet by only passing copies out from your specific field of control.


To recap, in Java, java.lang.String is an immutable object (it cannot be changed once it's created) and java.lang.StringBuilder is a mutable object because it can be changed without creating a new instance.


"immutable" means you cannot change value. If you have an instance of String class, any method you call which seems to modify the value, will actually create another String.


To preserve changes you should do something like this
    foo = foo.sustring(3);


Immutable vs mutable can be funny when you work with collections. Think about what will happen if you use mutable object as a key for map and then change the value (tip: think about equals and hashCode).


String s1 = "Old string"; 


String s2 = s1; 


s1 = "New String";


The original string 'in memory' didn't change, but the
  reference variable was changed so that it refers to the new string.
  And if we didn't have s2, "Old String" would still be in the memory but
  we'll not be able to access it...


I really like the explaination from SCJP Sun Certified Programmer for Java 5 Study Guide.


To make Java more memory efficient, the JVM sets aside a special area of  memory called the "String constant pool." When the compiler encounters a String literal, it checks the pool to see if  an identical String already exists. If  a match is found, the reference to the new literal is directed to the existing String, and no new String literal object is created. 


Objects which are immutable can not have their state changed after they have been created.


There are three main reasons to use immutable objects whenever you can, all of which will help to reduce the number of bugs you introduce in your code:


There are also some other optimisations you might be able to make in code when you know that the state of an object is immutable - caching the calculated hash, for example - but these are optimisations and therefore not nearly so interesting.


It might be a bit late but in order to understand what an immutable object is, consider the following example from the new Java 8 Date and Time API (java.time). As you probably know all date objects from Java 8 are immutable so in the following example


Output:


2014-03-18


This prints the same year as the initial date because the plusYears(2) returns a new object so the old date is still unchanged because it's an immutable object. Once created you cannot further modify it and the date variable still points to it.


So, that code example should capture and use the new object instantiated and returned by that call to plusYears.


date.toString()… 2014-03-18


dateAfterTwoYears.toString()… 2016-03-18


One meaning has to do with how the value is stored in the computer,  For a .Net string for example, it means that the string in memory cannot be changed,   When you think you're changing it, you are in fact creating a new string in memory and pointing the existing variable (which is just a pointer to the actual collection of characters somewhere else) to the new string. 


Once instanciated, cannot be altered. Consider a class that an instance of might be used as the key for a hashtable or similar. Check out Java best practices.


Immutable means that once the object is created, non of its members will change. String is immutable since you can not change its content.
For example:


In the code above, the string s1 did not change, another object (s2) was created using s1.


s1="Hi" : an object s1 was created with "Hi" value in it.


s2=s1   : an object s2 is created with reference to s1 object.


s1="Bye" : the previous s1 object's value doesn't change because s1 has String type and String type is an immutable type, instead compiler create a new String object with "Bye" value and s1 referenced to it. here when we print s2 value, the result will be "Hi" not "Bye" because s2 referenced to previous s1 object which had "Hi" value.


Immutable Objects


An object is considered immutable if its state cannot change after it is constructed. Maximum reliance on immutable objects is widely accepted as a sound strategy for creating simple, reliable code.


Immutable objects are particularly useful in concurrent applications. Since they cannot change state, they cannot be corrupted by thread interference or observed in an inconsistent state.


Programmers are often reluctant to employ immutable objects, because they worry about the cost of creating a new object as opposed to updating an object in place. The impact of object creation is often overestimated, and can be offset by some of the efficiencies associated with immutable objects. These include decreased overhead due to garbage collection, and the elimination of code needed to protect mutable objects from corruption.


The following subsections take a class whose instances are mutable and derives a class with immutable instances from it. In so doing, they give general rules for this kind of conversion and demonstrate some of the advantages of immutable objects.


Source


What is an Immutable Object ?


As per the Java Reference Documentation,
"An object is considered immutable if its state cannot change after it is constructed"
Simply an immutable class is a class whose properties can not be modified after creation. That means at creation, all of the instance data is provided and remain unchanged till the destruction of the objects.


Why Immutable Objects ?


Immutable classes are great for concurrent applications. As per their immutable nature, they help to maintain the application in non-corrupted and consistent behavior as the state of the instances can not be changed.


Concerns


Immutable classes are easy to design, develop and use as they are more error resistant and secure due to the immutability. However programmers reluctant to use them due to the re -usability limitation. Also it may have an performance impact on object creation than reusing. However with the latest sophisticated compilers, the cost of creation is a minimal. Also the provided capabilities and the advantage of immutability can be adopted beyond the re-usability as per the need. 


How does this String append is working ?


New String object is created with the given value and the reference is updated to the new instance isolating the old object.


Reference : http://www.devdummy.com/2017/09/immutable-objects-in-java.html


An immutable object is the one you cannot modify after you create it. A typical example are string literals.


A D programming language, which becomes increasingly popular, has a notion of "immutability" through "invariant" keyword. Check this Dr.Dobb's article about it - http://dobbscodetalk.com/index.php?option=com_myblog&show=Invariant-Strings.html&Itemid=29 . It explains the problem perfectly.






How do I set environment variables from Java?  I see that I can do this for subprocesses using ProcessBuilder.  I have several subprocesses to start, though, so I'd rather modify the current process's environment and let the subprocesses inherit it.


There's a System.getenv(String) for getting a single environment variable.  I can also get a Map of the complete set of environment variables with System.getenv().  But calling put() on that Map throws an UnsupportedOperationException -- apparently they mean for the environment to be read only.  And there's no System.setenv().


So, is there any way to set environment variables in the currently running process?  If so, how?  If not, what's the rationale?  (Is it because this is Java and therefore I shouldn't be doing evil nonportable obsolete things like touching my environment?)  And if not, any good suggestions for managing the environment variable changes that I'm going to need to be feeding to several subprocesses?


(Is it because this is Java and therefore I shouldn't be doing evil nonportable obsolete things like touching my environment?)


I think you've hit the nail on the head.


A possible way to ease the burden would be to factor out a method


and pass any ProcessBuilders through it before starting them.


Also, you probably already know this, but you can start more than one process with the same ProcessBuilder. So if your subprocesses are the same, you don't need to do this setup over and over.


For use in scenarios where you need to set specific environment values for unit tests, you might find the following hack useful. It will change the environment variables throughout the JVM (so make sure you reset any changes after your test), but will not alter your system environment.


I found that a combination of the two dirty hacks by Edward Campbell and anonymous works best, as one of the does not work under linux, one does not work under windows 7. So to get a multiplatform evil hack I combined them:


This Works like a charm. Full credits to the two authors of these hacks.


on Android the interface is exposed via Libcore.os as a kind of hidden API.


The Libcore class as well as the interface OS is public. Just the class declaration is missing and need to be shown to the linker. No need to add the classes to the application, but it also does not hurt if it is included.


It turns out that the solution from @pushy/@anonymous/@Edward Campbell does not work on Android because Android is not really Java.  Specifically, Android does not have java.lang.ProcessEnvironment at all.  But it turns out to be easier in Android, you just need to do a JNI call to POSIX setenv():


In C/JNI:



And in Java:


Poking around online, it looks like it might be possible to do this with JNI.  You'd then have to make a call to putenv() from C, and you'd (presumably) have to do it in a way that worked on both Windows and UNIX.


If all that can be done, it surely wouldn't be too hard for Java itself to support this instead of putting me in a straight jacket.


A Perl-speaking friend elsewhere suggests that this is because environment variables are process global and Java is striving for good isolation for good design.


This is a combination of @paul-blair 's answer converted to Java which includes some cleanups pointed out by paul blair and some mistakes that seem to have been inside @pushy 's code which is made up of @Edward Campbell and anonymous.


I cannot emphasize how much this code should ONLY be used in testing and is extremely hacky. But for cases where you need the environment setup in tests it is exactly what I needed.


This also includes some minor touches of mine that allow the code to work on both Windows running on 


as well as Centos running on


The implementation:


Tried pushy's answer above and it worked for the most part. However, in certain circumstances, I would see this exception:


This turns out to happen when the method was called more than once, owing to the implementation of certain inner classes of ProcessEnvironment. If the setEnv(..) method is called more than once, when the keys are retrieved from the theEnvironment map, they are now strings (having been put in as strings by the first invocation of setEnv(...) ) and cannot be cast to the map's generic type, Variable, which is a private inner class of ProcessEnvironment.


A fixed version (in Scala), is below. Hopefully it isn't too difficult to carry over into Java.


Setting single environment variables (based on answer by Edward Campbell):


Usage:


First, put the method in any class you want, e.g. SystemUtil.


If you call System.getenv("SHELL") after this, you'll get "/bin/bash" back.


Like most people who have found this thread, I was writing some unit tests and needed to modify the environment variables to set the correct conditions for the test to run.  However, I found the most upvoted answers had some issues and/or were very cryptic or overly complicated.  Hopefully this will help others to sort out the solution more quickly.


First off, I finally found @Hubert Grzeskowiak's solution to be the simplest and it worked for me.  I wish I would have come to that one first.  It's based on @Edward Campbell's answer, but without the complicating for loop search.


However, I started with @pushy's solution, which got the most upvotes. It is a combo of @anonymous and @Edward Campbell's.  @pushy claims both approaches are needed to cover both Linux and Windows environments.  I'm running under OS X and find that both work (once an issue with @anonymous approach is fixed).  As others have noted, this solution works most of the time, but not all.


I think the source of most of the confusion comes from @anonymous's solution operating on the 'theEnvironment' field.  Looking at the definition of the ProcessEnvironment structure, 'theEnvironment' is not a Map< String, String > but rather it is a Map< Variable, Value >.  Clearing the map works fine, but the putAll operation rebuilds the map a Map< String, String >, which potentially causes problems when subsequent operations operate on the data structure using the normal API that expects Map< Variable, Value >.  Also, accessing/removing individual elements is a problem.  The solution is to access 'theEnvironment' indirectly through 'theUnmodifiableEnvironment'.  But since this is a type UnmodifiableMap the access must be done through the private variable 'm' of the UnmodifiableMap type.  See getModifiableEnvironmentMap2 in code below.


In my case I needed to remove some of the environment variables for my test (the others should be unchanged).  Then I wanted to restore the environment variables to their prior state after the test.  The routines below make that straight forward to do.  I tested both versions of getModifiableEnvironmentMap on OS X, and both work equivalently.  Though based on comments in this thread, one may be a better choice than the other depending on the environment.


Note: I did not include access to the 'theCaseInsensitiveEnvironmentField' since that seems to be Windows specific and I had no way to test it, but adding it should be straight forward.


You can pass parameters into your initial java process with -D:






Possible Duplicate:
How do I iterate over each Entry in a Collection Map? 


What's the best way to iterate over the items in a HashMap?


Iterate through the entrySet like so:


Read more on Map


If you're only interested in the keys, you can iterate through the keySet() of the map:


If you only need the values, use values():


Finally, if you want both the key and value, use entrySet():


One caveat: if you want to remove items mid-iteration, you'll need to do so via an Iterator (see karim79's answer). However, changing item values is OK (see Map.Entry).


Extracted from the reference How to Iterate Over a Map in Java:


There are several ways of iterating over a Map in Java. Let's go over the most common methods and review their advantages and disadvantages. Since all maps in Java implement the Map interface, the following techniques will work for any map implementation (HashMap, TreeMap, LinkedHashMap, Hashtable, etc.)


Method #1: Iterating over entries using a For-Each loop.


This is the most common method and is preferable in most cases. It should be used if you need both map keys and values in the loop.


Note that the For-Each loop was introduced in Java 5, so this method is working only in newer versions of the language. Also a For-Each loop will throw NullPointerException if you try to iterate over a map that is null, so before iterating you should always check for null references.


Method #2: Iterating over keys or values using a For-Each loop.


If you need only keys or values from the map, you can iterate over keySet or values instead of entrySet.


This method gives a slight performance advantage over entrySet iteration (about 10% faster) and is more clean.


Method #3: Iterating using Iterator.


Using Generics:


Without Generics:


You can also use same technique to iterate over keySet or values.


This method might look redundant, but it has its own advantages. First of all, it is the only way to iterate over a map in older versions of Java. The other important feature is that it is the only method that allows you to remove entries from the map during iteration by calling iterator.remove(). If you try to do this during For-Each iteration you will get "unpredictable results" according to Javadoc.


From a performance point of view this method is equal to a For-Each iteration.


Method #4: Iterating over keys and searching for values (inefficient).


This might look like a cleaner alternative for method #1, but in practice it is pretty slow and inefficient as getting values by a key might be time-consuming (this method in different Map implementations is 20%-200% slower than method #1). If you have FindBugs installed, it will detect this and warn you about inefficient iteration. This method should be avoided.


Conclusion:


If you need only keys or values from the map, use method #2. If you are stuck with older version of Java (less than 5) or planning to remove entries during iteration, you have to use method #3. Otherwise use method #1.


You can iterate through the entries in a Map in several ways. Getting each key and value like this:    


Or you can get the list of keys with


If you just want to get all of the values, and aren't concerned with the keys, you can use:


Smarter:


Depends. If you know you're going to need both the key and the value of every entry, then go through the entrySet. If you just need the values, then there's the values() method. And if you just need the keys, then use keyset().


A bad practice would be to iterate through all of the keys, and then within the loop, always do map.get(key) to get the value. If you're doing that, then the first option I wrote is for you.






How do I get a platform-dependent newline in Java? I can’t use "\n" everywhere.


In addition to the line.separator property, if you are using java 1.5 or later and the String.format (or other formatting methods) you can use %n as in


See the Java 1.8 API for Formatter for more details.


You can use


to get the line separator


Java 7 now has a System.lineSeparator() method.


If you're trying to write a newline to a file, you could simply use BufferedWriter's newLine() method. 


This is also possible: String.format("%n").


Or String.format("%n").intern() to save some bytes.


The commons-lang library has a constant field available called SystemUtils.LINE_SEPARATOR 


Use the method newLine() of class  BufferedWriter  which provides platform independent way to write  the new line in file


The above snippet will have two strings separated by a new line irrespective of platforms.


Avoid appending strings using String + String etc, use StringBuilder instead.






I have a custom list adapter:


in the overridden 'getView' method I do a print to check what position is and whether it is a convertView or not:


The output of this (when the list is first displayed, no user input as yet)


AFAIK, though I couldn't find it stated explicitly, getView() is only called for visible rows. Since my app starts with four visible rows at least the position numbers cycling from 0-3 makes sense. But the rest is a mess:


I did a bit of reseach, and without getting a good answer, I did notice that people were associating this issue with layout issues. So in case, here's the layout that contains the list:


and the layout of each individual row:


Thank you for your time


This is not an issue, there is absolutely no guarantee on the order in which getView() will be called nor how many times. In your particular case you are doing the worst thing possible with a ListView by giving it a height=wrap_content. This forces ListView to measure a few children out of the adapter at layout time, to know how big it should be. This is what provides ListView with the convertViews you see passed to getView() even before you scroll.


Try with match_parent on the layout_height property of the list view. It will prevent getView() to be called so often.


I got rid of this issue when I changed both layout_width and layout_height to match_parent (changing only layout_height didn't help).


Helpful note watch out if you have nested items. You've got to change the "highest" one to match_parent.  Hope it helps someone.


I am not able to answer your "Why" question but i definitely have a solution to the problem of the irritating "ListView items repeating" problem(if you have items in ur collection which are more than the screen height).


As many people above have mentioned, keep the android:layout_height property of the ListVew tag as fill_parent.


And about the getView() function, the solution is to use a static class called ViewHolder. Check out this example. It successfully does the task of adding all the items in ur Array or ArrayCollection.


Hope this helps friends!!


Best Regards,
Siddhant


Ques: Why Adapter calls getView() manytimes?
Ans: As Listview renders on scrolling is refreshes it's view with next upcoming views, for
     which adapter needs to get views by calling getView().


Ques: Why it's calls lesser if listview width and height set to fill_parent?
Ans: Because as inflator has the fixed size for the screen area for list it calculates once for
     rendering the views onto the screen.


Hope it will resolve your query.


I was having the same problem with the dropdown in an AutoCompleteTextView. I was fighting with the problem for two days until I arrive here and you show me the solution.


If I write dropDownHeight="match_parent" the problem is fixed. Now the problem is related to UI (when you have one item the dropdown is too large) but the problem of multiple calls (much more important) is fixed.


Thank you!!


"Why is getview called for each row three times?"
 Because getView is called when you scroll on listview and to say better then that it is called when the position of an view of your list  is changed!


I am having the same issue. If I have height set to fill_parent, then I get "usually" 2 calls per row. But, if I set height of my ListView to exact value, let's say to 300dp, then I get exactly one GetView call per row. 


So, it seems to me that the only way is to first determine height of the screen, then programmatically set height of listvilew to that value. I don't like it. I hope there is a better way.


For all of you who still (After setting the height of the ListView to match_parent) are stuck (like I was):


You also have to set the height of the parent layout to match_parent.


See example below. The LinearLayout is the parent here:






Can anybody provide examples or links on how to establish a JDBC connection pool?


From searching google I see many different ways of doing this and it is rather confusing.


Ultimately I need the code to return a java.sql.Connection object, but I am having trouble getting started..any suggestions welcome.


Update:  Doesn't javax.sql or java.sql have pooled connection implementations? Why wouldn't it be best to use these?


If you need a standalone connection pool, my preference goes to C3P0 over DBCP (that I've mentioned in this previous answer), I just had too much problems with DBCP under heavy load. Using C3P0 is dead simple. From the documentation:


But if you are running inside an application server, I would recommend to use the built-in connection pool it provides. In that case, you'll need to configure it (refer to the documentation of your application server) and to retrieve a DataSource via JNDI:


Usually if you need a connection pool you are writing an application that runs in some managed environment, that is you are running inside an application server. If this is the case be sure to check what connection pooling facilities your application server providesbefore trying any other options. 


The out-of-the box solution will be the best integrated with the rest of the application servers facilities. If however you are not running inside an application server I would recommend the Apache Commons DBCP Component. It is widely used and provides all the basic pooling functionality most applications require.


I would recommend using the commons-dbcp library.  There are numerous examples listed on how to use it, here is the link to the move simple one.  The usage is very simple:


You only need to create the data source once, so make sure you read the documentation if you do not know how to do that.  If you are not aware of how to properly write JDBC statements so you do not leak resources, you also might want to read this Wikipedia page.


Don't reinvent the wheel.


Try one of the readily available 3rd party components:


Apache DBCP comes with different example on how to setup a pooling javax.sql.DataSource.  Here is one sample that can help you get started.


In the app server we use where I work (Oracle Application Server 10g, as I recall), pooling is handled by the app server.  We retrieve a javax.sql.DataSource using a JNDI lookup with a javax.sql.InitialContext.


it's done something like this


(We didn't write this code, it's copied from this documentation.)


As answered by others, you will probably be happy with Apache Dbcp or c3p0. Both are popular, and work fine.


Regarding your doubt


Doesn't javax.sql or java.sql have
  pooled connection implementations? Why
  wouldn't it be best to use these?


They don't provide implementations, rather interfaces and some support classes, only revelant to the programmers that implement third party libraries (pools or drivers). Normally you don't even look at that. Your code should deal with the connections from your pool just as they were "plain" connections, in a transparent way.


It's modern, it's fast, it's simple. I use it for every new project.
I prefer it a lot over C3P0, don't know the other pools too well.


Vibur DBCP is another library for that purpose. Several examples showing how to configure it for use with Hibernate, Spring+Hibernate, or programatically, can be found on its website: http://www.vibur.org/


Also, see the disclaimer here.


Pool


« Pooling [ Object pool, String Constant Pool, Thread Pool, Connection pool]


String Constant pool


Example: String to verify Unique Object from pool.


Connection pool using Type-4 Driver using 3rd party libraries[ DBCP2, c3p0, Tomcat JDBC]


Type 4 - The Thin driver converts JDBC calls directly into the vendor-specific database protocol Ex[Oracle - Thick, MySQL - Quora]. wiki


In Connection pool mechanism, when the class is loaded it get's the physical JDBC connection objects and provides a wrapped physical connection object to user. PoolableConnection is a wrapper around the actual connection. 


Example: Using ~ DBCP2 Connection Pool with Java 7[try-with-resources]


jdbc:<DB>:<drivertype>:<HOST>:<TCP/IP PORT>:<dataBaseName>
jdbc:oracle:thin:@localhost:1521:myDBName
jdbc:mysql://localhost:3306/myDBName


connectionpool.properties


Web Application: To avoid connection problem when all the connection's are closed[MySQL "wait_timeout" default 8 hours] in-order to reopen the connection with underlying DB.


You can do this to Test Every Connection by setting testOnBorrow = true and validationQuery= "SELECT 1" and donot use autoReconnect for MySQL server as it is deprecated. issue


See these also:


Apache Commons has a library for that purpose: DBCP. Unless you have strange requirements around your pools, I'd use a library as it's bound to be trickier and more subtle than you would hope.


You should consider using UCP. 
Universal Connection Pool (UCP) is a Java connection pool.  It is a features rich connection pool and tightly integrated with Oracle's Real Application Clusters (RAC), ADG, DG databases.  


Refer to this page for more details about UCP. 


MiniConnectionPoolManager is a one-java-file implementation, if you're looking for an embeddable solution and are not too concerned about performances (though I haven't tested it in that regard).


It is multi-licensed EPL, LGPL and MPL.


Its documentation also gives alternatives worth checking (on top of DBCP and C3P0):






As far I know, the two most common methods of reading character-based data from a file in Java is using Scanner or BufferedReader. I also know that the BufferedReader read files efficiently  by using a buffer to avoid physical disk operations. My questions are:


Scanner is used for parsing tokens from the contents of the stream while BufferedReader just reads the stream and does not do any special parsing.


In fact you can pass a BufferedReader to a scanner as the source of characters to parse.


In currently latest JDK6 release/build (b27), the Scanner has a smaller buffer (1024 chars) as opposed to the BufferedReader (8192 chars), but it's more than sufficient.


As to the choice, use the Scanner if you want to parse the file, use the BufferedReader if you want to read the file line by line. Also see the introductory text of their aforelinked API documentations.


See this link, following is quoted from there:


A BufferedReader is a simple class meant to efficiently read from the 
  underling stream. Generally, each read request made of a Reader like a
  FileReader causes a corresponding read request to be made to
  underlying stream.  Each invocation of read() or readLine() could
  cause bytes to be read  from the file, converted into characters, and
  then returned, which can be very  inefficient. Efficiency is improved
  appreciably if a Reader is warped in a  BufferedReader.


BufferedReader is synchronized, so read operations on a BufferedReader
  can safely be done from multiple threads.


A scanner on the other hand has a lot more cheese built into it;  it
  can do all that a BufferedReader can do and at the same level of 
  efficiency as well. However, in addition a Scanner can parse  the
  underlying stream for primitive types and strings using regular
  expressions.  It can also tokenize the underlying stream with the
  delimiter of your choice.  It can also do forward scanning of the
  underlying stream disregarding  the delimiter!


A scanner however is not thread safe, it has to be externally
  synchronized.


The choice of using a BufferedReader or a Scanner depends on the code 
  you are writing, if you are writing a simple log reader Buffered
  reader  is adequate. However if you are writing an XML parser Scanner
  is  the more natural choice.


Even while reading the input, if want to accept user input line by
  line and  say just add it to a file, a BufferedReader is good enough. 
  On the other hand if you want to accept user input as a command with 
  multiple options, and then intend to perform different operations
  based  on the command and options specified, a Scanner will suit
  better.


BufferedReader has significantly larger buffer memory than Scanner. Use BufferedReader if you want to get long strings from a stream, and use Scanner if you want to parse specific type of token from a stream.


Scanner can use tokenize using custom delimiter and parse the stream into primitive types of data, while BufferedReader can only read and store String.


BufferedReader is synchronous while Scanner is not. Use BufferedReader if you're working with multiple threads.


Scanner hides IOException while BufferedReader throws it immediately.


I suggest to use BufferedReader for reading text. Scanner hides IOException while BufferedReader throws it immediately.


The Scanner class is the complement of Formater class (used to convert binary data into formatted text). Scanner reads formatted input and converts it into its binary form. Although it has always been possible to read formatted input, it required more effort than most programmers would prefer. Because of the addition of Scanner, it is now easy to read all types of numeric values, strings and other types of data, whether it comes from a disk file, the keyboard, or another source. Scanner can be used to read input from the console, a file, a string, or any other source that implements the Readable interface or ReadableByteChannel. For example, you can use Scanner to read a number from the keyboard and assign its value to a variable.


BufferedReader, on the other hand, is a character stream I/O class. Character streams provide a convenient way for input and output in terms of characters (Unicode). BufferedReader is mostly used for taking input from the console, System.in. It takes an InputStreamReader object as an argument.


The Main Differences:


Example


prints the following output:


The same output can be generated with this code, which uses a regular expression to parse all four tokens at once:


BufferedReader:


Reads text from a character-input stream, buffering characters so as to provide for the efficient reading of characters, arrays, and lines.


The buffer size may be specified, or the default size may be used. The default is large enough for most purposes.


In general, each read request made of a Reader causes a corresponding read request to be made of the underlying character or byte stream. It is therefore advisable to wrap a BufferedReader around any Reader whose read() operations may be costly, such as FileReaders and InputStreamReaders. For example,


will buffer the input from the specified file. Without buffering, each invocation of read() or readLine() could cause bytes to be read from the file, converted into characters, and then returned, which can be very inefficient.
Programs that use DataInputStreams for textual input can be localized by replacing each DataInputStream with an appropriate BufferedReader.


Source:Link


========================================================================


There are different ways of taking input in java like:


1) BufferedReader 2) Scanner 3) Command Line Arguments


BufferedReader Read text from a character-input stream, buffering characters so as to provide for the efficient reading of characters, arrays, and lines.


Where Scanner is a simple text scanner which can parse primitive types and strings using regular expressions.


if you are writing a simple log reader Buffered reader is adequate. if you are writing an XML parser Scanner is the more natural choice.


For more information please refer:


http://java.meritcampus.com/t/240/Bufferedreader?tc=mm69



Following are the differences between BufferedReader and Scanner


Thanks


The answer below is taken from Reading from Console: JAVA Scanner vs BufferedReader


When read an input from console, there are two options exists to achieve that. First using Scanner, another using BufferedReader. Both of them have different characteristics. It means differences how to use it.


Scanner treated given input as token. BufferedReader just read line by line given input as string. Scanner it self provide parsing capabilities just like nextInt(), nextFloat().


But, what is others differences between?


Scanner come with since JDK version 1.5 higher.


When should use Scanner, or Buffered Reader?


Look at the main differences between both of them, one using tokenized, others using stream line. When you need parsing capabilities, use Scanner instead. But, i am more comfortable with BufferedReader. When you need to read from a File, use BufferedReader, because it’s use buffer when read a file. Or you can use BufferedReader as input to Scanner.


Listing few...


java.util.Scanner class is a simple text scanner which can parse primitive types and strings. It internally uses regular expressions to read different types.


Java.io.BufferedReader class reads text from a character-input stream, buffering characters so as to provide for the efficient reading of sequence of characters


1) BufferedReader is synchronous while Scanner is not. BufferedReader should be used if we are working with multiple threads.


2)BufferedReader has significantly larger buffer memory than Scanner.
The Scanner has a little buffer (1KB char buffer) as opposed to the BufferedReader (8KB byte buffer), but it’s more than enough.


3)BufferedReader is a bit faster as compared to Scanner because Scanner does parsing of input data and BufferedReader simply reads sequence of characters.


I prefer Scanner because it doesn't throw checked exceptions and therefore it's usage results in a more streamlined code.


Difference between BufferedReader and Scanner are following:


Code to read a line from console:


BufferedReader:


Scanner:






I'm trying to understand how threads works in java. This is a simple database request that returns a ResultSet. I'm using JavaFx.


This returns an exception: 


Exception in thread "Thread A" java.lang.IllegalStateException: Not on FX application thread; currentThread = Thread A


How do I correctly implement threading so that every database request is executed in a second thread instead of the main thread?


I've heard of implementing Runnable but then how do I invoke different methods in run method? 


Never worked with threading before but I thought it's time for it.


Threading Rules for JavaFX


There are two basic rules for threads and JavaFX:


The reason for the first rule is that, like most UI toolkits, the framework is written without any synchronization on the state of elements of the scene graph. Adding synchronization incurs a performance cost, and this turns out to be a prohibitive cost for UI toolkits. Thus only one thread can safely access this state. Since the UI thread (FX Application Thread for JavaFX) needs to access this state to render the scene, the FX Application Thread is the only thread on which you can access "live" scene graph state. In JavaFX 8 and later, most methods subject to this rule perform checks and throw runtime exceptions if the rule is violated. (This is in contrast to Swing, where you can write "illegal" code and it may appear to run fine, but is in fact prone to random and unpredictable failure at arbitrary time.) This is the cause of the IllegalStateException you are seeing: you are calling courseCodeLbl.setText(...) from a thread other than the FX Application Thread.


The reason for the second rule is that the FX Application Thread, as well as being responsible for processing user events, is also responsible for rendering the scene. Thus if you perform a long-running operation on that thread, the UI will not be rendered until that operation is complete, and will become unresponsive to user events. While this won't generate exceptions or cause corrupt object state (as violating rule 1 will), it (at best) creates a poor user experience.


Thus if you have a long-running operation (such as accessing a database) that needs to update the UI on completion, the basic plan is to perform the long-running operation in a background thread, returning the results of the operation when it is complete, and then schedule an update to the UI on the UI (FX Application) thread. All single-threaded UI toolkits have a mechanism to do this: in JavaFX you can do so by calling Platform.runLater(Runnable r) to execute r.run() on the FX Application Thread. (In Swing, you can call SwingUtilities.invokeLater(Runnable r) to execute r.run() on the AWT event dispatch thread.) JavaFX (see later in this answer) also provides some higher-level API for managing the communication back to the FX Application Thread.


General Good Practices for Multithreading


The best practice for working with multiple threads is to structure code that is to be executed on a "user-defined" thread as an object that is initialized with some fixed state, has a method to perform the operation, and on completion returns an object representing the result. Using immutable objects for the initialized state and computation result is highly desirable. The idea here is to eliminate the possibility of any mutable state being visible from multiple threads as far as possible. Accessing data from a database fits this idiom nicely: you can initialize your "worker" object with the parameters for the database access (search terms, etc). Perform the database query and get a result set, use the result set to populate a collection of domain objects, and return the collection at the end.


In some cases it will be necessary to share mutable state between multiple threads. When this absolutely has to be done, you need to carefully synchronize access to that state to avoid observing the state in an inconsistent state (there are other more subtle issues that need to be addressed, such as liveness of the state, etc). The strong recommendation when this is needed is to use a high-level library to manage these complexities for you.


Using the javafx.concurrent API


JavaFX provides a concurrency API that is designed for executing code in a background thread, with API specifically designed for updating the JavaFX UI on completion of (or during) the execution of that code. This API is designed to interact with the java.util.concurrent API, which provides general facilities for writing multithreaded code (but with no UI hooks). The key class in javafx.concurrent is Task, which represents a single, one-off, unit of work intended to be performed on a background thread. This class defines a single abstract method, call(), which takes no parameters, returns a result, and may throw checked exceptions. Task implements Runnable with its run() method simply invoking call(). Task also has a collection of methods which are guaranteed to update state on the FX Application Thread, such as updateProgress(...), updateMessage(...), etc. It defines some observable properties (e.g. state and value): listeners to these properties will be notified of changes on the FX Application Thread. Finally, there are some convenience methods to register handlers (setOnSucceeded(...), setOnFailed(...), etc); any handlers registered via these methods will also be invoked on the FX Application Thread.


So the general formula for retrieving data from a database is:


For database access, I strongly recommend encapsulating the actual database code in a separate class that knows nothing about the UI (Data Access Object design pattern). Then just have the task invoke the methods on the data access object.


So you might have a DAO class like this (note there is no UI code here):


Retrieving a bunch of widgets might take a long time, so any calls from a UI class (e.g a controller class) should schedule this on a background thread. A controller class might look like this:


Notice how the call to the (potentially) long-running DAO method is wrapped in a Task which is run on a background thread (via the accessor) to prevent blocking the UI (rule 2 above). The update to the UI (widgetTable.setItems(...)) is actually executed back on the FX Application Thread, using the Task's convenience callback method setOnSucceeded(...) (satisfying rule 1). 


In your case, the database access you are performing returns a single result, so you might have a method like


And then your controller code would look like


The API docs for Task have many more examples, including updating the progress property of the task (useful for progress bars..., etc.


Exception in thread "Thread A" java.lang.IllegalStateException: Not on FX application thread; currentThread = Thread A


The exception is trying to tell you that you are trying to access JavaFX scene graph outside the JavaFX application thread. But where ??


If I can't do this how do I use a background thread?


The are different approaches which leads to similar solutions.


There easier and most simple way is to wrap the above line in Plaform.runLater, such that it gets executed on JavaFX Application thread.


The better approach to go with these scenarios is to use Task, which has specialized methods to send back updates. In the following example, I am using updateMessage to update the message. This property is bind to courseCodeLbl textProperty.


This has nothing to do with database. JavaFx, like pretty much all GUI libraries, requires that you only use the main UI thread to modify the GUI.


You need to pass the data from the database back to the main UI thread. Use Platform.runLater() to schedule a Runnable to be run in the main UI thread.


Alternatively, you can use Task.






Specifically, the problem is to write a method like this:


where the return value is the same as in.read() if data is available within 'timeout' milliseconds, and -2 otherwise.  Before the method returns, any spawned threads must exit.


To avoid arguments, the subject here java.io.InputStream, as documented by Sun (any Java version).  Please note this is not as simple as it looks.  Below are some facts which are supported directly by Sun's documentation.


The in.read() method may be non-interruptible.


Wrapping the InputStream in a Reader or InterruptibleChannel doesn't help, because all those classes can do is call methods of the InputStream.  If it were possible to use those classes, it would be possible to write a solution that just executes the same logic directly on the InputStream.


It is always acceptable for in.available() to return 0.


The in.close() method may block or do nothing.


There is no general way to kill another thread.


Using inputStream.available()


It is always acceptable for System.in.available() to return 0.


I've found the opposite - it always returns the best value for the number of bytes available.  Javadoc for InputStream.available():


An estimate is unavoidable due to timing/staleness.  The figure can be a one-off underestimate because new data are constantly arriving.  However it always "catches up" on the next call - it should account for all arrived data, bar that arriving just at the moment of the new call.  Permanently returning 0 when there are data fails the condition above.


First Caveat: Concrete subclasses of InputStream are responsible for available()


InputStream is an abstract class.  It has no data source.  It's meaningless for it to have available data.  Hence, javadoc for available() also states:


And indeed, the concrete input stream classes do override available(), providing meaningful values, not constant 0s.


Second Caveat: Ensure you use carriage-return when typing input in Windows.


If using System.in, your program only receives input when your command shell hands it over.  If you're using file redirection/pipes (e.g. somefile > java myJavaApp or somecommand | java myJavaApp ), then input data are usually handed over immediately.  However, if you manually type input, then data handover can be delayed.  E.g. With windows cmd.exe shell, the data are buffered within cmd.exe shell.  Data are only passed to the executing java program following carriage-return (control-m or <enter>).  That's a limitation of the execution environment.  Of course, InputStream.available() will return 0 for as long as the shell buffers the data - that's correct behaviour; there are no available data at that point.  As soon as the data are available from the shell, the method returns a value > 0.  NB: Cygwin uses cmd.exe too.


Just use this:


OR equivalently,


Declare this:


Then use this:


Assuming your stream is not backed by a socket (so you can't use Socket.setSoTimeout()), I think the standard way of solving this type of problem is to use a Future.


Suppose I have the following executor and streams:


I have writer that writes some data then waits for 5 seconds before writing the last piece of data and closing the stream:


The normal way of reading this is as follows. The read will block indefinitely for data and so this completes in 5s:


which outputs:


If there was a more fundamental problem, like the writer not responding, the reader would block for ever. 
If I wrap the read in a future, I can then control the timeout as follows:


which outputs:


I can catch the TimeoutException and do whatever cleanup I want.


I would question the problem statement rather than just accept it blindly. You only need timeouts from the console or over the network. If the latter you have Socket.setSoTimeout() and HttpURLConnection.setReadTimeout() which both do exactly what is required, as long as you set them up correctly when you construct/acquire them. Leaving it to an arbitrary point later in the application when all you have is the InputStream is poor design leading to a very awkward implementation.


If your InputStream is backed by a Socket, you can set a Socket timeout (in milliseconds) using setSoTimeout.  If the read() call doesn't unblock within the timeout specified, it will throw a SocketTimeoutException.


Just make sure that you call setSoTimeout on the Socket before making the read() call.


I have not used the classes from the Java NIO package, but it seems they might be of some help here. Specifically, java.nio.channels.Channels and java.nio.channels.InterruptibleChannel.


Here is a way to get a NIO FileChannel from System.in and check for availability of data using a timeout, which is a special case of the problem described in the question.  Run it at the console, don't type any input, and wait for the results.  It was tested successfully under Java 6 on Windows and Linux.


Interestingly, when running the program inside NetBeans 6.5 rather than at the console, the timeout doesn't work at all, and the call to System.exit() is actually necessary to kill the zombie threads.  What happens is that the interruptor thread blocks (!) on the call to reader.interrupt().  Another test program (not shown here) additionally tries to close the channel, but that doesn't work either.


As jt said, NIO is the best (and correct) solution. If you really are stuck with an InputStream though, you could either


Spawn a thread who's exclusive job is to read from the InputStream and put the result into a buffer which can be read from your original thread without blocking. This should work well if you only ever have one instance of the stream. Otherwise you may be able to kill the thread using the deprecated methods in the Thread class, though this may cause resource leaks.


Rely on isAvailable to indicate data that can be read without blocking. However in some cases (such as with Sockets) it can take a potentially blocking read for isAvailable to report something other than 0.






This question already has an answer here:


I wrote the following code on immutable Strings.


Output:


Here the value of variable a has been changed (while many say that contents of the immutable objects cannot be changed). But what exactly does one mean by saying String is immutable? Could you please clarify this topic for me?


source : https://docs.oracle.com/javase/tutorial/java/nutsandbolts/datatypes.html


Before proceeding further with the fuss of immutability, let's just take a look into the String class and its functionality a little before coming to conclusions about its immutability.


This is how String works:


This, as usual, creates a string containing "knowledge" and assigns it a reference str. Simple enough? Lets perform some more functions:


Lets see how the below statement works:


This appends a string " base" to str. But wait, how is this possible, since String objects are immutable? Well to your surprise, it is.


When the above statement is executed, the VM takes the value of String str, i.e. "knowledge" and appends " base", giving us the value "knowledge base". Now, since Strings are immutable, the VM can't assign this value to str, so it creates a new String object, gives it a value "knowledge base", and gives it a reference str.


An important point to note here is that, while the String object is immutable, its reference variable is not. So that's why, in the above example, the reference was made to refer to a newly formed String object.


At this point in the example above, we have two String objects: the first one we created with value "knowledge", pointed to by s, and the second one "knowledge base", pointed to by str. But, technically, we have three String objects, the third one being the literal "base" in the concat statement.


What if we didn't have another reference s to "knowledge"? We would have lost that String. However, it still would have existed, but would be considered lost due to having no references.
Look at one more example below


What's happening: 


The reference variable s1 still refers to the original String "java".


Almost every method, applied to a String object in order to modify it, creates new String object. So, where do these String objects go? Well, these exist in memory, and one of the key goals of any programming language is to make efficient use of memory.


As applications grow, it's very common for String literals to occupy large area of memory, which can even cause redundancy. So, in order to make Java more efficient, the JVM sets aside a special area of memory called the "String constant pool".


When the compiler sees a String literal, it looks for the String in the pool. If a match is found, the reference to the new literal is directed to the existing String and no new String object is created. The existing String simply has one more reference. Here comes the point of making String objects immutable:


In the String constant pool, a String object is likely to have one or many references. If several references point to same String without even knowing it, it would be bad if one of the references modified that String value. That's why String objects are immutable.


Well, now you could say, what if someone overrides the functionality of String class? That's the reason that the String class is marked final so that nobody can override the behavior of its methods.


String is immutable means that you cannot change the object itself, but you can change the reference to the object. When you called a = "ty", you are actually changing the reference of a to a new object created by the String literal "ty". Changing an object means to use its methods to change one of its fields (or the fields are public and not final, so that they can be updated from outside without accessing them via methods), for example:


While in an immutable class (declared as final, to prevent modification via inheritance)(its methods cannot modify its fields, and also the fields are always private and recommended to be final), for example String, you cannot change the current String but you can return a new String, i.e:


You're changing what a refers to. Try this:


You will see that the object to which a and then b refers has not changed.


If you want to prevent your code from changing which object a refers to, try:


A string is a char[] containing a series of UTF-16 code units, an int offset into that array, and an int length.


For example.


It creates space for a string reference.  Assigning copies references around but does not modify the objects to which those references refer.


You should also be aware that


doesn't really do anything useful.  It merely creates another instance backed by the same array, offset, and length as s.  There is very rarely a reason to do this so it is considered bad practice by most Java programmers.


Java double quoted strings like "my string" are really references to interned String instances so "bar" is a reference to the same String instance regardless of how many times it appears in your code.


The "hello" creates one instance that is pooled, and the new String(...) creates a non-pooled instance. Try System.out.println(("hello" == "hello") + "," + (new String("hello") == "hello") + "," + (new String("hello") == new String("hello"))); and you should see true,false,false


immutable means you can't not change the value of the same referance.every time you required to create new referance means new memory location.
ex:


here, in the above code ,in the memory there are 2 blocks for storing the value.the first for value "abc" and second for "bcd".the second value is not replace to first value.


this is call the immutable.


In your example, the variable a is just a reference to an instance of a string object.  When you say a = "ty", you are not actually changing the string object, but rather pointing the reference at an entirely different instance of the string class.


You are not changing the object in the assignment statement, you replace one immutable object with another one. Object String("a") does not change to String("ty"), it gets discarded, and a reference to ty gets written into a in its stead.


In contrast, StringBuffer represents a mutable object. You can do this:


Here, you did not re-assign b: it still points to the same object, but the content of that object has changed.


You are actually getting a reference to a new string, the string itself is not being changed as it is immutable.  This is relevant.


See


Immutable objects on Wikipedia


An immutable object is an object whose state cannot be modified after it is created. 


So a = "ABC" <-- immutable object. "a" holds reference to the object.
And, a = "DEF" <-- another immutable object, "a" holds reference to it now.


Once you assign a string object, that object can not be changed in memory.


In summary, what you did is to change the reference of "a" to a new string object. 


This shows that once a string object is create it cannot be changed. EveryTime you need to create new and put in another String. S


I think the following code clears the difference:


Java String is immutable, String will Store the value in the form of object. so if u assign the value String a="a"; it will create an object and the value is stored in that and again if you are assigning value a="ty" means it will create an another object store the value in that, if you want to understand clearly, check the has code for the String.


see here 


output:


This indicates that whenever you are modifying the content of immutable string object a a new object will be created. i.e you are not allowed to change the content of immutable object. that's why the address are different for both the object.


Only the reference is changing. First a was referencing to the string "a", and later you changed it to "ty". The string "a" remains the same.


In your example, a refers first to "a", and then to "ty". You're not mutating any String instance; you're just changing which String instance a refers to. For example, this:


prints "a", because we never mutate the String instance that b points to.


If some object bar holds a reference to a mutable object foo and encapsulates some of its state in mutable aspects of foo's state, that will allow code which can change those aspects of foo to change the corresponding aspects of bar's state without actually touching bar or even knowing of its existence.  Generally, this means that objects which encapsulate their own state using mutable objects must ensure that no references to those objects are exposed to any code which might unexpectedly mutate them.  By contrast, if bar holds a reference to an object moo and only uses immutable aspects of moo other than identity to encapsulate its state, then bar can freely expose moo to outside code without worrying about anything the outside code might do to it.


Hope the below code would clarify your doubts :


Before String Concat: Hello
After  String Concat: Hello
Before StringBuffer Append: Hello
After StringBuffer Append: HelloWorld


String  is immutable meant  that the content of the String Object can't be changeable


if you want to modify the content use StringBuffer instead of String which is mutable


Probably every answer provided above is right, but my answer is specific to use of hashCode() method, to prove the points like, String... once created can't be modified and modifications will results in new value at different memory location.






Is there any real practical difference between "java -server" and "java -client"?  All I can find on Sun's site is a vague "-server starts slower but should run faster".  What are the real differences?  (Using JDK 1.6.0_07 currently.)


This is really linked to HotSpot and the default option values (Java HotSpot VM Options) which differ between client and server configuration.


From Chapter 2 of the whitepaper (The Java HotSpot Performance Engine Architecture):


The JDK includes two flavors of the VM -- a client-side offering, and a VM tuned for server applications. These two solutions share the Java HotSpot runtime environment code base, but use different compilers that are suited to the distinctly unique performance characteristics of clients and servers. These differences include the compilation inlining policy and heap defaults. 


Although the Server and the Client VMs are similar, the Server VM has been specially tuned to maximize peak operating speed. It is intended for executing long-running server applications, which need the fastest possible operating speed more than a fast start-up time or smaller runtime memory footprint.


The Client VM compiler serves as an upgrade for both the Classic VM and the just-in-time (JIT) compilers used by previous versions of the JDK. The Client VM offers improved run time performance for applications and applets. The Java HotSpot Client VM has been specially tuned to reduce application start-up time and memory footprint, making it particularly well suited for client environments. In general, the client system is better for GUIs. 


So the real difference is also on the compiler level:


The Client VM compiler does not try to execute many of the more complex optimizations performed by the compiler in the Server VM, but in exchange, it requires less time to analyze and compile a piece of code. This means the Client VM can start up faster and requires a smaller memory footprint.


The Server VM contains an advanced adaptive compiler that supports many of the same types of optimizations performed by optimizing C++ compilers, as well as some optimizations that cannot be done by traditional compilers, such as aggressive inlining across virtual method invocations. This is a competitive and performance advantage over static compilers. Adaptive optimization technology is very flexible in its approach, and typically outperforms even advanced static analysis and compilation techniques. 


Note: The release of jdk6 update 10 (see Update Release Notes:Changes in 1.6.0_10) tried to improve startup time, but for a different reason than the hotspot options, being packaged differently with a much smaller kernel.


G. Demecki points out in the comments that in 64-bit versions of JDK, the -client option is ignored for many years.
See Windows java command:


Selects the Java HotSpot Client VM.
A 64-bit capable JDK currently ignores this option and instead uses the Java Hotspot Server VM.


The most visible immediate difference in older versions of Java would be the memory allocated to a -client as opposed to a -server application. For instance, on my Linux system, I get:


as it defaults to -server, but with the -client option I get:


so with -server most of the memory limits and initial allocations are much higher for this java version.


These values can change for different combinations of architecture, operating system and jvm version however. Recent versions of the jvm have removed flags and re-moved many of the distinctions between server and client.


Remember too that you can see all the details of a running jvm using jvisualvm. This is useful if you have users who or modules which set JAVA_OPTS or use scripts which change command line options. This will also let you monitor, in real time, heap and permgen space usage along with lots of other stats.


One difference I've just noticed is that in "client" mode, it seems the JVM actually gives some unused memory back to the operating system - whereas with "server" mode, once the JVM grabs the memory, it won't give it back. Thats how it appears on Solaris with Java6 anyway (using prstat -Z to see the amount of memory allocated to a process).


Oracle’s online documentation provides some information for Java SE 7.


On the java – the Java application launcher page for Windows, the -client option is ignored in a 64-bit JDK:


Select the Java HotSpot Client VM. A 64-bit capable jdk currently ignores this option and instead uses the Java HotSpot Server VM. 


However (to make things interesting), under -server it states:


Select the Java HotSpot Server VM. On a 64-bit capable jdk only the Java HotSpot Server VM is supported so the -server option is implicit. This is subject to change in a future release. 


The Server-Class Machine Detection page gives information on which VM is selected by OS and architecture.


I don’t know how much of this applies to JDK 6.


the -client and -server systems are different binaries. They are essentially two different compilers (JITs) interfacing to the same runtime system. The client system is optimal for applications which need fast startup times or small footprints, the server system is optimal for applications where the overall performance is most important. In general the client system is better suited for interactive applications such as GUIs  





We run the following code with both switches:


Note: The code is been compiled only once! The classes are the same in both runs!


With -client:
 java.exe -client -classpath C:\mywork\classes com.blogspot.sdoulger.LoopTest
 Time spent: 766  


With -server:
 java.exe -server -classpath C:\mywork\classes com.blogspot.sdoulger.LoopTest
 Time spent: 0  


It seems that the more aggressive optimazation of the server system, remove the loop as it understands that it does not perform any action!


Reference


IIRC the server VM does more hotspot optimizations at startup so it runs faster but takes a little longer to start and uses more memory. The client VM defers most of the optimization to allow faster startup.


Edit to add: Here's some info from Sun, it's not very specific but will give you some ideas.


From Goetz - Java Concurrency in Practice:


Listing 3.4. Counting sheep.



  volatile boolean asleep;
  ...
  while (!asleep)
     countSomeSheep();


My emphasis. YMMV


IIRC, it involves garbage collection strategies.  The theory is that a client and server will be different in terms of short-lived objects, which is important for modern GC algorithms.


Here is a link on server mode.  Alas, they don't mention client mode.


Here is a very thorough link on GC in general; this is a more basic article. Not sure if either address -server vs -client but this is relevant material.


At No Fluff Just Stuff, both Ken Sipe and Glenn Vandenburg do great talks on this kind of thing.


I've not noticed any difference in startup time between the 2, but clocked a very minimal improvement in application performance with "-server" (Solaris server, everyone using SunRays to run the app).  That was under 1.5.


Last time I had a look at this, (and admittedly it was a while back) the biggest difference I noticed was in the garbage collection. 


IIRC:


If you can compare two java VMs, one client, one server using the jvisualvm tool, you should see a difference in the frequency and effect of the garbage collection, as well as in the number of generations. 


I had a pair of screenshots that showed the difference really well, but I can't reproduce as I have a 64 bit JVM which only implements the server VM. (And I can't be bothered to download and wrangle the 32 bit version on my system as well.)


When doing a migration from 1.4 to 1.7("1.7.0_55")version.The thing that we observed here is, there is no such differences in default values assigned to heapsize|permsize|ThreadStackSize parameters in client & server mode. 


By the way, (http://www.oracle.com/technetwork/java/ergo5-140223.html). This is the snippet taken from above link.


ThreadStackSize is higher in 1.7, while going through Open JDK forum,there are discussions which stated frame size is somewhat higher in 1.7 version.
It is believed real difference could be possible to measure at run time based on your behavior of your application






What is String Interning in Java, when I should use it, and why?


http://docs.oracle.com/javase/7/docs/api/java/lang/String.html#intern()


Basically doing String.intern() on a series of strings will ensure that all strings having same contents share same memory. So if you have list of names where 'john' appears 1000 times, by interning you ensure only one 'john' is actually allocated memory.


This can be useful to reduce memory requirements of your program. But be aware that the cache is maintained by JVM in permanent memory pool which is usually limited in size compared to heap so you should not use intern if you don't have too many duplicate values.


More on memory constraints of using intern()


On one hand, it is true that you can remove String duplicates by
  internalizing them. The problem is that the internalized strings go to
  the Permanent Generation, which is an area of the JVM that is reserved
  for non-user objects, like Classes, Methods and other internal JVM
  objects. The size of this area is limited, and is usually much smaller
  than the heap. Calling intern() on a String has the effect of moving
  it out from the heap into the permanent generation, and you risk
  running out of PermGen space.


-- 
From: http://www.codeinstructions.com/2009/01/busting-javalangstringintern-myths.html


From JDK 7 (I mean in HotSpot),  something has changed.


In JDK 7, interned strings are no longer allocated in the permanent generation of the Java heap, but are instead allocated in the main part of the Java heap (known as the young and old generations), along with the other objects created by the application. This change will result in more data residing in the main Java heap, and less data in the permanent generation, and thus may require heap sizes to be adjusted. Most applications will see only relatively small differences in heap usage due to this change, but larger applications that load many classes or make heavy use of the String.intern() method will see more significant differences.


-- From Java SE 7 Features and Enhancements


Update: Interned strings are stored in main heap from Java 7 onwards. http://www.oracle.com/technetwork/java/javase/jdk7-relnotes-418459.html#jdk7changes


There are some "catchy interview" questions why You get


If You should compare the Strings You should use equals(). The above will print equals, because the testString is allready interned for You by the compiler. You can intern the strings yourself using intern method as is shown in previous answers....


JLS 7 3.10.5 defines it and gives a practical example:


Moreover, a string literal always refers to the same instance of class String. This is because string literals - or, more generally, strings that are the values of constant expressions (§15.28) - are "interned" so as to share unique instances, using the method String.intern.


Example 3.10.5-1. String Literals


The program consisting of the compilation unit (§7.3): 


and the compilation unit:


produces the output:


JVMS 7 5.1 says says that interning is implemented magically and efficiently with a dedicated CONSTANT_String_info struct (unlike most other objects which have more generic representations):


A string literal is a reference to an instance of class String, and is derived from a CONSTANT_String_info structure (§4.4.3) in the binary representation of a class or interface. The CONSTANT_String_info structure gives the sequence of Unicode code points constituting the string literal.


The Java programming language requires that identical string literals (that is, literals that contain the same sequence of code points) must refer to the same instance of class String (JLS §3.10.5). In addition, if the method String.intern is called on any string, the result is a reference to the same class instance that would be returned if that string appeared as a literal. Thus, the following expression must have the value true:


To derive a string literal, the Java Virtual Machine examines the sequence of code points given by the CONSTANT_String_info structure.


If the method String.intern has previously been called on an instance of class String containing a sequence of Unicode code points identical to that given by the CONSTANT_String_info structure, then the result of string literal derivation is a reference to that same instance of class String.


Otherwise, a new instance of class String is created containing the sequence of Unicode code points given by the CONSTANT_String_info structure; a reference to that class instance is the result of string literal derivation. Finally, the intern method of the new String instance is invoked.


Let's decompile some OpenJDK 7 bytecode to see interning in action.


If we decompile:


we have on the constant pool:


and main:


Note how:


The representation of constant strings is quite magic on the bytecode:


and the JVMS quote above seems to say that whenever the Utf8 pointed to is the same, then identical instances are loaded by ldc.


I have done similar tests for fields, and:


Conclusion: there is direct bytecode support for the string pool, and the memory representation is efficient.


Bonus: compare that to the Integer pool, which does not have direct bytecode support (i.e. no CONSTANT_String_info analogue).


What is String intern() ?


String Interning is a method of storing only one copy of each distinct String Value, which must be immutable.
It can be used to return string from pool memory, if it is created by new keyword.


In Java, String class has a public method intern() that returns a canonical representation for the string object. Java’s String class privately maintains a pool of strings, where String literals are automatically interned.


When the intern() method is invoked on a String object it looks the string contained by this String object in the pool, if the string is found there then the string from the pool is returned. Otherwise, this String object is added to the pool and a reference to this String object is returned.


The intern() method helps in comparing two String objects with == operator by looking into the pre-existing pool of string literals, it is faster than equals() method.
The pool of strings in Java is maintained for saving space and for faster comparisons.I recommonds to use equals(), not ==, to compare two strings. This is because == operator compares memory locations, while equals() method compares the content stored in two objects.


Why and When to use Intern ?


Though Java automatically interns all Strings by default, remember that we only need to intern strings when they are not constants, and we want to be able to quickly compare them to other interned strings. The intern() method should be used on strings constructed with new String() in order to compare them by == operator.


Let’s take a look at the following  program to understand the intern() behavior


Sources = https://en.wikipedia.org/wiki/String_interning


String interning is an optimization technique by the compiler. If you have two identical string literals in one compilation unit then the code generated ensures that there is only one string object created for all the instance of that literal(characters enclosed in double quotes) within the assembly.


I am from C# background, so i can explain by giving a example from that:


output of the following comparisons:


Note1:Objects are compared by reference.


Note2:typeof(int).Name is evaluated by reflection method so it does not gets evaluated at compile time. Here these comparisons are made at compile time.


Analysis of the Results:
1) true because they both contain same literal and so the code generated will have only one object referencing "Int32". See Note 1.


2) true because the content of both the value is checked which is same.


3) FALSE because str2 and obj does not have the same literal. See Note 2. 






Edit :- Tried to format the question and accepted answer in more presentable way at mine Blog 


Here  is the original issue:-


I am getting this error


detailed message sun.security.validator.ValidatorException: PKIX path
  building failed:
  sun.security.provider.certpath.SunCertPathBuilderException: unable to
  find valid certification path  to requested target


cause javax.net.ssl.SSLHandshakeException:
  sun.security.validator.ValidatorException: PKIX path   building
  failed: sun.security.provider.certpath.SunCertPathBuilderException:
  unable to find valid certification path to requested target


i am using tomcat 6 as webserver. i have two https webbapplication installed on different tomcat on differte port but on same machine. Say App1(port 8443) and 
 App2(port 443). App1 connects to App2 .When App1 connects to App2 i get above error. I know this is very common error so came across many solutions on different
 forums and sites. I have below entry in server.xml of both tomcat i.e


Every site says the same reason that certificate given by app2 is not in the trusted store of app1 jvm. This seems to be true also when i tired to hit the same
URL in IE browser, it works(with warming, There is a problem with this web site's security certificate. here i say continue to this website) But when same url
is hit by java client(in my case). So i get the above error. So to put it in trustore i tried  these tree options i.e


Option1


Option2
Setting below in environment variable


Option3
Setting below in environment variable


But nothing worked .


What at last worked   is executing the java approach suggested in How to handle invalid SSL certificates with Apache HttpClient? by Pascal Thivent i.e 
executing the program InstallCert. 


But this approach is fine for devbox setup but i can not use it at production environment. 


I am wondering
why three approaches mentioned above did not work when  i have mentioned same values in server.xml of app2 server and same values in truststore by setting


System.setProperty("javax.net.ssl.trustStore", "C:/.keystore") and System.setProperty("javax.net.ssl.trustStorePassword", "changeit");


in app1 program.


For more information this is how i am making the connection


You need to add the certificate for App2 to the truststore file of the used JVM located at %JAVA_HOME%\lib\security\cacerts.


First you can check if your certificate is already in the truststore by running the following command:
keytool -list -keystore "%JAVA_HOME%/jre/lib/security/cacerts" (you don't need to provide a password)


If your certificate is missing, you can get it by downloading it with your browser and add it to the truststore with the following command:


keytool -import -noprompt -trustcacerts -alias <AliasName> -file   <certificate> -keystore <KeystoreFile> -storepass <Password>


Afer import you can run the first command again to check if your certificate was added.


Sun/Oracle information can be found here.


javax.net.ssl.SSLHandshakeException: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target


• When I got the error, I tried to Google out the meaning of the expression and I found, this issue occurs when a server changes their HTTPS SSL certificate, and our older version of java doesn’t recognize the root certificate authority (CA).


• If you can access the HTTPS URL in your browser then it is possible to update Java to recognize the root CA.


• In your browser, go to the HTTPS URL that Java could not access. Click on the HTTPS certificate chain (there is lock icon in the Internet Explorer), click on the lock to view the certificate.


• Go to “Details” of the certificate and “Copy to file”. Copy it in Base64 (.cer) format. It will be saved on your Desktop.


• Install the certificate ignoring all the alerts.


• This is how I gathered the certificate information of the URL that I was trying to access.


Now I had to make my java version to know about the certificate so that further it doesn’t refuse to recognize the URL. In this respect I must mention that I googled out that root certificate information stays by default in JDK’s  \jre\lib\security location, and the default password to access is: changeit.


To view the cacerts information the following are the procedures to follow:


• Click on Start Button-->Run


• Type cmd. The command prompt opens (you may need to open it as administrator).


• Go to your Java/jreX/bin directory


• Type the following


keytool -list -keystore D:\Java\jdk1.5.0_12\jre\lib\security\cacerts


It gives the list of the current certificates contained within the keystore. It looks something like this:


C:\Documents and Settings\NeelanjanaG>keytool -list -keystore D:\Java\jdk1.5.0_12\jre\lib\security\cacerts


Enter keystore password:  changeit


Keystore type: jks


Keystore provider: SUN


Your keystore contains 44 entries


verisignclass3g2ca, Mar 26, 2004, trustedCertEntry,


Certificate fingerprint (MD5): A2:33:9B:4C:74:78:73:D4:6C:E7:C1:F3:8D:CB:5C:E9


entrustclientca, Jan 9, 2003, trustedCertEntry,


Certificate fingerprint (MD5): 0C:41:2F:13:5B:A0:54:F5:96:66:2D:7E:CD:0E:03:F4


thawtepersonalbasicca, Feb 13, 1999, trustedCertEntry,


Certificate fingerprint (MD5): E6:0B:D2:C9:CA:2D:88:DB:1A:71:0E:4B:78:EB:02:41


addtrustclass1ca, May 1, 2006, trustedCertEntry,


Certificate fingerprint (MD5): 1E:42:95:02:33:92:6B:B9:5F:C0:7F:DA:D6:B2:4B:FC


verisignclass2g3ca, Mar 26, 2004, trustedCertEntry,


Certificate fingerprint (MD5): F8:BE:C4:63:22:C9:A8:46:74:8B:B8:1D:1E:4A:2B:F6


• Now I had to include the previously installed certificate into the cacerts.


• For this the following is the procedure:


keytool –import –noprompt –trustcacerts –alias ALIASNAME -file FILENAME_OF_THE_INSTALLED_CERTIFICATE -keystore PATH_TO_CACERTS_FILE -storepass PASSWORD


If you are using Java 7:


keytool –importcert –trustcacerts –alias ALIASNAME -file PATH_TO_FILENAME_OF_THE_INSTALLED_CERTIFICATE -keystore PATH_TO_CACERTS_FILE -storepass changeit


• It will then add the certificate information into the cacert file.


It is the solution I found for the Exception mentioned above!!


I wanted to support a self signed certificate in a Tomcat App but the following snippet failed to work


this is what solved my issue:


Even though iv'e installed my certificate in Java's default certificate stores, Tomcat ignores that (seems like it's not configured to use Java's default certificate stores). 


To hack this, add the following somewhere in your code:


My cacerts file was totally empty.  I solved this by copying the cacerts file off my windows machine (that's using Oracle Java 7) and scp'd it to my Linux box (OpenJDK).  


and then on the linux machine


It's worked great so far.


Using Tomcat 7 under Linux, this did the trick.


Under Linux, $JAVA_HOME is not always setup, but usually /etc/alternatives/jre points to $JAVA_HOME/jre


i wrote a small win32 (WinXP 32bit testet) stupid cmd (commandline) script which looks for all java versions in program files and adds a cert to them. 
The Password needs to be the default "changeit" or change it yourself in the script :-)


For Tomcat running on Ubuntu server, to find out which Java is being used, use "ps -ef | grep tomcat" command:


Sample:


Then, we can go in to: cd /usr/local/java/jdk1.7.0_15/jre/lib/security


Default cacerts file is located in here. Insert the untrusted certificate into it.


I have this problem too.


I tried almost everything by adding the SSL cert to .keystore, but, it was not working with Java1_6_x.
For me it helped if we start using newer version of Java, Java1_8_x as JVM.


For me, this error appeared too while trying to connect to a process behind an NGINX reverse proxy which was handling the SSL. 


It turned out the problem was a certificate without the entire certificate chain concatenated. 
When I added intermediate certs, the problem was solved.


Hope this helps.


Its a flaw of Java not using the standard Operating system keystore like in MacOS X. I filed a change request today see http://bugs.java.com/bugdatabase/view_bug.do?bug_id=JDK-8185892






How can I resolve this error?


Caused by: java.lang.illegalargumentexception
  11-01 11:08:12.845: E/AndroidRuntime(28885): Caused by: java.lang.IllegalStateException: The meta-data tag in your app's AndroidManifest.xml does not have the right value.  Expected 4030500 but found 0.  You must have the following declaration within the  element:     



google-play-services_lib Manifest:






Full error log:


You need to add the following in your manifest:


EDIT:


This information can be found in the logcat error msg as well as on Setting Up Google Play Services (Thanks Brais Gabin)


@Benoit'a answer has exact solution i am answering with additional knowledge:


1. one way as Benoit answered is add following inside application tag of AndroidManifest.xml


2.  we can directly add the version code like 


4030500 is version code which is stored inside 


google-play-services_lib>res>values>version.xml


Like


Conclusion: Latest google play services requires a version name, which is to be mentioned using <meta-data .. /> inside AndroidManifest.xml


Note: I would strongly recommend to use 1st way


A few things changed since you asked that question. If you're using Google Play services 7.0 or newer, Gradle will automatically merge manifests and include the required meta-data for you.


Citing Ian Lake:


(...) Google Play services
  7.0 also has one other time saving feature if you're using Gradle: it automatically includes the 


entry in your AndroidManifest.xml for you - no need to manually add
  it! Perfect example of simple Manifest merging where libraries can
  add required meta-data, receivers, permissions, and anything else they
  made need - one less thing to forget!


Note: this does not apply to the full play-services or
  play-services-all-wear AARs - only the granular AARs have this built
  in.


Just make sure to add the below two meta-data tags to 'your' application's AndroidManifest.xml 


This solution worked for me.


I imported my existing project from Eclipse to Android Studio, In Eclipse project Integers.xml was containing hardcoded value as following 


causing version conflict with latest version of Play Services being built by Android Studio. after removing this line from Integers.xml it started working for me.


I did create a file "version.xml" in the res/values folder of the included copy of google services and pasted the code:


the original copy missed the file and it did solve my problem


Add <meta-data>after closing <application> tag. This solved my problem






Upcasting is allowed in Java, however downcasting gives a compile error. 


The compile error can be removed by adding a cast but would anyway break at the runtime. 


In this case why Java allows downcasting if it cannot be executed at the runtime?
Is there any practical use for this concept? 


Downcasting is allowed when there is a possibility that it suceeds at run time:


In some cases this will not succeed:


In others it will work:


Note that some casts will be disallowed at compile time, because they will never succeed at all:


Using your example, you could do:


I believe this applies to all statically typed languages:


The typecast effectively says: assume this is a reference to the cast class and use it as such.  Now, lets say o is really an Integer, assuming this is a String makes no sense and will give unexpected results, thus there needs to be a runtime check and an exception to notify the runtime environment that something is wrong.


In practical use, you can write code working on a more general class, but cast it to a subclass if you know what subclass it is and need to treat it as such.  A typical example is overriding Object.equals().  Assume we have a class for Car:


We can all see that the code you provided won't work at run time. That's because we know that the expression new A() can never be an object of type B.


But that's not how the compiler sees it. By the time the compiler is checking whether the cast is allowed, it just sees this:


And as others have demonstrated, that sort of cast is perfectly legal. The expression on the right could very well evaluate to an object of type B. The compiler sees that A and B have a subtype relation, so with the "expression" view of the code, the cast might work.


The compiler does not consider the special case when it knows exactly what object type expression_of_type_A will really have. It just sees the static type as A and considers the dynamic type could be A or any descendant of A, including B.


In this case why Java allows downcasting if it cannot be executed at the runtime?


I believe this is because there is no way for the compiler to know at compile-time if the cast will succeed or not. For your example, it's simple to see that the cast will fail, but there are other times where it is not so clear. 


For instance, imagine that types B, C, and D all extend type A, and then a method public A getSomeA() returns an instance of either B, C or D depending on a randomly generated number. The compiler cannot know which exact run-time type will be returned by this method, so if you later cast the results to B, there is no way to know if the cast will succeed (or fail). Therefore the compiler has to assume casts will succeed.


@ Original Poster - see inline comments.


Downcast works in the case when we are dealing with an upcasted object.
Upcasting:


So now this objValue variable can always be downcasted to int because the object which was cast is an Integer,


but because objValue is an Object it cannot be cast to String because int cannot be cast to String.


Downcasting is very useful in the following code snippet I use this all the time. Thus proving that downcasting is useful. 


I store String in the Linked List. 
When I retrieve the elements of Linked List, Objects are returned. To access the elements as Strings(or any other Class Objects), downcasting helps me. 


Java allows us to compile downcast code trusting us that we are doing the wrong thing. 
Still if humans make a mistake, it is caught at runtime.


Consider the below example


here we create the object of subclass Bone and assigned it to super class AOne reference and now superclass reference does not know 
about the method method2 in the subclass i.e Bone  during compile time.therefore we need to downcast this reference of superclass to subclass reference so as the resultant reference can know about the presence of methods in the subclass i.e Bone






I understood, I think, that a "Bean" is a Java class with properties and getters/setters. As much as I understand, it is the equivalent of a C struct. Is that true?


Also, is there a real syntactic difference between a bean and a regular class? Is there any special definition or an interface?


Basically, why is there a term for this?


Edit: If you can be so kind and add information regarding the Serializable interface, and what it means, to your answer, I'd be very grateful.


A JavaBean is just a standard


That's it. It's just a convention.  Lots of libraries depend on it though....


With respect to Serializable, from the API documentation:


Serializability of a class is enabled by the class implementing the
  java.io.Serializable interface. Classes that do not implement this
  interface will not have any of their state serialized or deserialized.
  All subtypes of a serializable class are themselves serializable. The
  serialization interface has no methods or fields and serves only to
  identify the semantics of being serializable.


In other words, serializable objects can be written to streams, and hence files, object databases, anything really.  


Also, there is no syntactic difference between a JavaBean and another class -- a class defines a JavaBean if it follows the standards.


There is a term for it because the standard allows libraries to programmatically do things with class instances you define in a predefined way. For example, if a library wants to stream any object you pass into it, it knows it can because your object is serializable (assuming the lib requires your objects be proper JavaBeans). 


There's a term for it to make it sound special.  The reality is nowhere near so mysterious.


Basically, a "Bean":


Update:


As for Serializable:  That is nothing but a "marker interface" (an interface that doesn't declare any functions) that tells Java that the implementing class consents to (and implies that it is capable of) "serialization" -- a process that converts an instance into a stream of bytes.  Those bytes can be stored in files, sent over a network connection, etc, and have enough info to allow a JVM (at least, one that knows about the object's type) to reconstruct the object later -- possibly in a different instance of the application, or even on a whole other machine!


Of course, in order to do that, the class has to abide by certain limitations.  Chief among them is that all instance fields must be either primitive types (int, bool, etc), instances of some class that is also serializable, or marked as transient so that Java won't try to include them.  (This of course means that transient fields will not survive the trip over a stream.  A class that has transient fields should be prepared to reinitialize them if necessary.)


A class that can not abide by those limitations should not implement Serializable (and, IIRC, the Java compiler won't even let it do so.)


JavaBeans are Java classes which adhere to an extremely simple coding convention.
All you have to do is to 


Properties of JavaBeans


A JavaBean is a Java object that satisfies certain programming conventions: 


The JavaBean class must implement either Serializable or
Externalizable 


The JavaBean class must have a no-arg constructor


All JavaBean properties must have public setter and getter methods


All JavaBean instance variables should be private


Example of JavaBeans


Java Beans are using for less code and more work approach... 
Java Beans are used throughout Java EE as a universal contract for runtime discovery and access. For example, JavaServer Pages (JSP) uses Java Beans as data transfer objects between pages or between servlets and JSPs. Java EE's JavaBeans Activation Framework uses Java Beans for integrating support for MIME data types into Java EE. The Java EE Management API uses JavaBeans as the foundation for the instrumentation of resources to be managed in a Java EE environment. 


About Serialization:


In object serialization an object can be represented as a sequence of bytes that includes the object's data as well as information about the object's type and the types of data stored in the object.


After a serialized object has been written into a file, it can be read from the file and deserialized that is, the type information and bytes that represent the object and its data can be used to recreate the object in memory.


You will find Serialization useful when deploying your project across multiple servers since beans will be persisted and transferred across them.


As per the Wikipedia:


The class must have a public default constructor (with no arguments). This allows easy instantiation within editing and activation frameworks.


The class properties must be accessible using get, set, is (can be used for boolean properties instead of get), and other methods (so-called accessor methods and mutator methods) according to a standard naming convention. This allows easy automated inspection and updating of bean state within frameworks, many of which include custom editors for various types of properties. Setters can have one or more than one argument.


The class should be serializable. [This allows applications and frameworks to reliably save, store, and restore the bean's state in a manner independent of the VM and of the platform.]


For more information follow this link.


Explanation with an example.


1. import java.io.Serializable


As for the Serialization, see the documentation.


2. private fields


Fields should be private for prevent outer classes to easily modify those fields.
Instead of directly accesing to those fields, usuagly getter/setter methods are used.


3. Constructor


A public constructor without any argument.


4. getter/setter


Getter and setter methods for accesing private fields.


Regarding the second part of your question, Serialization is a persistence mechanism used to store objects as a sequence of signed bytes. Put less formally, it stores the state of an object so you can retrieve it later, by de-serialization.


Java Beans is a standard, and its basic syntax requirements have been clearly explained by the other answers.


However, IMO, it is more than a simple syntax standard. The real meaning or intended usage of Java Beans is, together with various tool supports around the standard,  to facilitate code reuse and component-based software engineering, i.e. enable developers to build applications by assembling existing components (classes) and without having to write any code (or only have to write a little glue code). Unfortunately this technology is way under-estimated and under-utilized by the industry, which can be told from the answers in this thread.


If you read Oracle's tutorial on Java Beans, you can get a better understanding in that.


They are serializable, have a zero-argument constructor, and allow access to properties using getter and setter methods. The name "Bean" was given to encompass this standard, which aims to create reusable software components for Java.according to wiki


The objects that form the backbone of your application and that are managed by the Spring IoC container are called beans. A bean is an object that is instantiated, assembled, and otherwise managed by a Spring IoC container. Otherwise, a bean is simply one of many objects in your application. 
according to spring io.


A Java Bean is a java class [conceptual] that should follow following conventions:


It is a reusable software component. It can encapsulate many object into one object so that same object can be accessed from multiples places and is a step towards easy maintenance of code.


To understand JavaBean you need to notice the followings:
JavaBean is a conceptual stuff and can not represent a class of specific things


JavaBean is a development tool can be visualized in the operation of reusable software components


JavaBean is based on the Sun JavaBeans specification and can be  reusable components. Its biggest feature is the re-usability.


Java Beans are just ordinary Java classes that follow certain conventions - you don't need special tools to create them.


There are two primary conventions that must be followed in creating Java Bean classes:






I'm new to regular expressions and would appreciate your help.  I'm trying to put together an expression that will split the example string using all spaces that are not surrounded by single or double quotes. My last attempt looks like this: (?!") and isn't quite working. It's splitting on the space before the quote.


Example input: 


Desired output:


Note that "will be" and 'regular expression' retain the space between the words.


I don't understand why all the others are proposing such complex regular expressions or such long code.  Essentially, you want to grab two kinds of things from your string: sequences of characters that aren't spaces or quotes, and sequences of characters that begin and end with a quote, with no quotes in between, for two kinds of quotes.  You can easily match those things with this regular expression:


I added the capturing groups because you don't want the quotes in the list.


This Java code builds the list, adding the capturing group if it matched to exclude the quotes, and adding the overall regex match if the capturing group didn't match (an unquoted word was matched).


If you don't mind having the quotes in the returned list, you can use much simpler code:


There are several questions on StackOverflow that cover this same question in various contexts using regular expressions. For instance: 


UPDATE: Sample regex to handle single and double quoted strings. Ref: How can I split on a string except when inside quotes?


Tested this with a quick Perl snippet and the output was as reproduced below. Also works for empty strings or whitespace-only strings if they are between quotes (not sure if that's desired or not). 


Note that this does include the quote characters themselves in the matched values, though you can remove that with a string replace, or modify the regex to not include them. I'll leave that as an exercise for the reader or another poster for now, as 2am is way too late to be messing with regular expressions anymore ;)


If you want to allow escaped quotes inside the string, you can use something like this:


Quoted strings will be group 2, single unquoted words will be group 3.


You can try it on various strings here: http://www.fileformat.info/tool/regex.htm or http://gskinner.com/RegExr/


The regex from Jan Goyvaerts is the best solution I found so far, but creates also empty (null) matches, which he excludes in his program. These empty matches also appear from regex testers (e.g. rubular.com).
If you turn the searches arround (first look for the quoted parts and than the space separed words) then you might do it in once with:


This will match the spaces not surrounded by double quotes.
I have to use min,max {0,99999} because Java doesn't support * and + in lookbehind.


It'll probably be easier to search the string, grabbing each part, vs. split it.


Reason being, you can have it split at the spaces before and after "will be". But, I can't think of any way to specify ignoring the space between inside a split.


(not actual Java)


Also, capturing single quotes could lead to issues:


String.split() is not helpful here because there is no way to distinguish between spaces within quotes (don't split) and those outside (split). Matcher.lookingAt() is probably what you need:


which produces the following output:


I liked Marcus's approach, however, I modified it so that I could allow text near the quotes, and support both " and ' quote characters. For example, I needed a="some value" to not split it into [a=, "some value"].


A couple hopefully helpful tweaks on Jan's accepted answer:


Jan's approach is great but here's another one for the record. 


If you actually wanted to split as mentioned in the title, keeping the quotes in "will be" and 'regular expression', then you could use this method which is straight out of Match (or replace) a pattern except in situations s1, s2, s3 etc


The regex: 


The two left alternations match complete 'quoted strings' and "double-quoted strings". We will ignore these matches. The right side matches and captures spaces to Group 1, and we know they are the right spaces because they were not matched by the expressions on the left. We replace those with SplitHere then split on SplitHere. Again, this is for a true split case where you want "will be", not will be.


Here is a full working implementation (see the results on the online demo).


I'm reasonably certain this is not possible using regular expressions alone.  Checking whether something is contained inside some other tag is a parsing operation.  This seems like the same problem as trying to parse XML with a regex -- it can't be done correctly.  You may be able to get your desired outcome by repeatedly applying a non-greedy, non-global regex that matches the quoted strings, then once you can't find anything else, split it at the spaces... that has a number of problems, including keeping track of the original order of all the substrings.  Your best bet is to just write a really simple function that iterates over the string and pulls out the tokens you want.


You can also try this:






I want to write an comparator that will let me sort TreeMap by value instead of the default natural sorting. i tried something like this, but can't find out what went wrong:


I guess what am i asking is what controls what gets passed to comparator function, can i get an Map.Entry passed to comparator?


You can't have the TreeMap itself sort on the values, since that defies the SortedMap specification:


A Map that further provides a total ordering on its keys. 


However, using an external collection, you can always sort Map.entrySet() however you wish, either by keys, values, or even a combination(!!) of the two.


Here's a generic method that returns a SortedSet of Map.Entry, given a Map whose values are Comparable:


Now you can do the following:


Note that funky stuff will happen if you try to modify either the SortedSet itself, or the Map.Entry within, because this is no longer a "view" of the original map like entrySet() is.


Generally speaking, the need to sort a map's entries by its values is atypical.


Your original comparator compares Integer using ==. This is almost always wrong, since == with Integer operands is a reference equality, not value equality.


polygenelubricants answer is almost perfect. It has one important bug though. It will not handle map entries where the values are the same.


This code:...


Would output:


Note how our cow dissapeared  as it shared the value "1" with our ape :O!


This modification of the code solves that issue:


In Java 8:


A TreeMap is always sorted by the keys, anything else is impossible. A Comparator merely allows you to control  how the keys are sorted.


If you want the sorted values, you have to extract them into a List and sort that.


This can't be done by using a Comparator, as it will always get the key of the map to compare. TreeMap can only sort by the key.


Olof's answer is good, but it needs one more thing before it's perfect. In the comments below his answer, dacwe (correctly) points out that his implementation violates the Compare/Equals contract for Sets. If you try to call contains or remove on an entry that's clearly in the set, the set won't recognize it because of the code that allows entries with equal values to be placed in the set. So, in order to fix this, we need to test for equality between the keys:


"Note that the ordering maintained by a sorted set (whether or not an explicit comparator is provided) must be consistent with equals if the sorted set is to correctly implement the Set interface... the Set interface is defined in terms of the equals operation, but a sorted set performs all element comparisons using its compareTo (or compare) method, so two elements that are deemed equal by this method are, from the standpoint of the sorted set, equal."
(http://docs.oracle.com/javase/6/docs/api/java/util/SortedSet.html)


Since we originally overlooked equality in order to force the set to add equal valued entries, now we have to test for equality in the keys in order for the set to actually return the entry you're looking for. This is kinda messy and definitely not how sets were intended to be used - but it works.


A lot of people hear adviced to use List and i prefer to use it as well


here are two methods you need to sort the entries of the Map according to their values.


I know this post specifically asks for sorting a TreeMap by values, but for those of us that don't really care about implementation but do want a solution that keeps the collection sorted as elements are added, I would appreciate feedback on this TreeSet-based solution. For one, elements are not easily retrieved by key, but for the use case I had at hand (finding the n keys with the lowest values), this was not a requirement.






I am getting this message when I run my web application. It runs fine but I get this message during shutdown.


SEVERE: A web application registered the JBDC driver [oracle.jdbc.driver.OracleDriver] but failed to unregister it when the web application was stopped. To prevent a memory leak, the JDBC Driver has been forcibly unregistered.


Any help appreciated.


Since version 6.0.24, Tomcat ships with a memory leak detection feature, which in turn can lead to this kind of warning messages when there's a JDBC 4.0 compatible driver in the webapp's /WEB-INF/lib which auto-registers itself during webapp's startup using the ServiceLoader API, but which did not auto-deregister itself during webapp's shutdown. This message is purely informal, Tomcat has already taken the memory leak prevention action accordingly.


What can you do?


Ignore those warnings. Tomcat is doing its job right. The actual bug is in someone else's code (the JDBC driver in question), not in yours. Be happy that Tomcat did its job properly and wait until the JDBC driver vendor get it fixed so that you can upgrade the driver. On the other hand, you aren't supposed to drop a JDBC driver in webapp's /WEB-INF/lib, but only in server's /lib. If you still keep it in webapp's /WEB-INF/lib, then you should manually register and deregister it using a ServletContextListener.


Downgrade to Tomcat 6.0.23 or older so that you will not be bothered with those warnings. But it will silently keep leaking memory. Not sure if that's good to know after all. Those kind of memory leaks are one of the major causes behind OutOfMemoryError issues during Tomcat hotdeployments.


Move the JDBC driver to Tomcat's /lib folder and have a connection pooled datasource to manage the driver. Note that Tomcat's builtin DBCP does not deregister drivers properly on close. See also bug DBCP-322 which is closed as WONTFIX. You would rather like to replace DBCP by another connection pool which is doing its job better then DBCP. For example HikariCP, BoneCP, or perhaps Tomcat JDBC Pool. 


In your servlet context listener contextDestroyed() method, manually deregister the drivers:


Although Tomcat does forcibly deregister the JDBC driver for you, it is nonetheless good practice to clean up all resources created by your webapp on context destruction in case you move to another servlet container which doesn't do the memory leak prevention checks that Tomcat does.


However, the methodology of blanket driver deregistration is dangerous.  Some drivers returned by the DriverManager.getDrivers() method may have been loaded by the parent ClassLoader (i.e., the servlet container's classloader) not the webapp context's ClassLoader (e.g., they may be in the container's lib folder, not the webapp's, and therefore shared across the whole container).  Deregistering these will affect any other webapps which may be using them (or even the container itself).


Therefore, one should check that the ClassLoader for each driver is the webapp's ClassLoader before deregistering it.  So, in your ContextListener's contextDestroyed() method:


I see this issue come up a lot. Yes, Tomcat 7 does automatically deregister it, but it that REALLY taking control of your code and a good coding practice? Surely YOU want to know that you have all the correct code in place to close all your objects, shut down database connection pool threads, and get rid of all warnings. I certainly do.


This is how I do it.


Step 1: Register a Listener


web.xml


Step 2: Implement the Listener


com.mysite.MySpecialListener.java


Please feel free to comment and/or add...


This is purely driver registration/deregistration issue in mysql`s driver or tomcats webapp-classloader. Copy mysql driver into tomcats lib folder (so its loaded by jvm directly, not by tomcat), and message will be gone. That makes mysql jdbc driver to be unloaded only at JVM shutdown, and noone cares about memory leaks then.


This is a listener I wrote to solve the problem: it autodetects if the driver has registered itself and acts accordingly.it 


Important: it is meant to be used ONLY when the driver jar is deployed in WEB-INF/lib, not in the Tomcat /lib, as many suggest, so that each application can take care of its own driver and run on a untouched Tomcat. That is the way it should be IMHO.


Just configure the listener in your web.xml before any other and enjoy.


add near the top of web.xml:


save as utils/db/OjdbcDriverRegistrationListener.java:


If you are getting this message from a Maven built war change the scope of the JDBC driver to provided, and put a copy of it in the lib directory. Like this: 


I will add to this something I found on the Spring forums. If you move your JDBC driver jar to the tomcat lib folder, instead of deploying it with your webapp, the warning seems to disappear. I can confirm that this worked for me


http://forum.springsource.org/showthread.php?87335-Failure-to-unregister-the-MySQL-JDBC-Driver&p=334883#post334883


I found that implementing a simple destroy() method to de-register any JDBC drivers works nicely.


I was having a similar problem, but additionally I was getting a Java Heap Space error anytime I modified/saved JSP pages with Tomcat server running, therefore the context were not fully recharged. 


My versions were Apache Tomcat 6.0.29 and JDK 6u12.


Upgrading JDK to 6u21 as suggested in References section of URL http://wiki.apache.org/tomcat/MemoryLeakProtection solved the Java Heap Space problem (context now reloads OK) although JDBC Driver error still appears.


I found the same issue with Tomcat version 6.026.


I used the Mysql JDBC.jar in WebAPP Library as well as in TOMCAT Lib.


To fix the above by removing the Jar from the TOMCAT lib folder.


So what I understand is that TOMCAT is handling the JDBC memory leak properly. But if the MYSQL Jdbc jar is duplicated in WebApp and Tomcat Lib, Tomcat will only be able to handle the jar present in the Tomcat Lib folder.


I have faced this problem when I was deploying my Grails application on AWS. This is matter of JDBC default driver org.h2 driver . 
As you can see this in the Datasource.groovy inside your configuration folder . As you can see below :        


Comment those lines wherever there is mentioned org.h2.Driver in the datasource.groovy file , if you are not using that database .
Otherwise you have to download that database jar file .


Thanks .


Removing the app (tomcat6) solves it. The conf files are preserved. 
It breaks itself somehow. I am not really sure how it does it.






I have an array A which is constantly being updated. Lets say A = [1,2,3,4,5]. I need to make an exact duplicate copy of A and call it B. If A were to change to [6,7,8,9,10], B should still be [1,2,3,4,5]. What is the best way to do this? I tried a for loop like:


but that doesn't seem to work correctly. Please don't use advanced terms like deep copy etc because I do not know what that means.


You can try using System.arraycopy()


you can use


as well.


If you want to make a copy of:


This is the way to go:


Arrays.copyOf may be faster than a.clone() on small arrays. Both copy elements equally fast but clone() returns Object so the compiler has to insert an implicit cast to int[]. You can see it in the bytecode, something like this:


I have a feeling that all of these "better ways to copy an array" are not really going to solve your problem.


You say


I tried a for loop like [...] but that doesn't seem to be working correctly?


Looking at that loop, there's no obvious reason for it not to work ... unless:


In either case, alternative ways of doing the copying won't solve the underlying problem.


The fix for the first scenario is obvious.  For the second scenario you will have to figure out some way of synchronizing the threads.  Atomic array classes don't help because they have no atomic copy constructors or clone methods, but synchronizing using a primitive mutex will do the trick.


(There are hints in your question that lead me to think that this is indeed thread related; e.g. your statement that a is constantly changing.)


Nice explanation from http://www.journaldev.com/753/how-to-copy-arrays-in-java


Java Array Copy Methods


Object.clone(): Object class provides clone() method and since array
  in java is also an Object, you can use this method to achieve full
  array copy. This method will not suit you if you want partial copy of
  the array.


System.arraycopy(): System class arraycopy() is the best way to do
  partial copy of an array. It provides you an easy way to specify the
  total number of elements to copy and the source and destination array
  index positions. For example System.arraycopy(source, 3, destination,
  2, 5) will copy 5 elements from source to destination, beginning from
  3rd index of source to 2nd index of destination.


Arrays.copyOf(): If you want to copy first few elements of an array or
  full copy of array, you can use this method. Obviously it’s not
  versatile like System.arraycopy() but it’s also not confusing and easy
  to use.


Arrays.copyOfRange(): If you want few elements of an array to be
  copied, where starting index is not 0, you can use this method to copy
  partial array.


All solution that call length from array, add your code redundant null checkersconsider example:


I recommend you not inventing the wheel and use utility class where all necessary checks have already performed. Consider ArrayUtils from apache commons. You code become shorter:


Apache commons you can find there


You can also use Arrays.copyOfRange.


Example:


This method is similar to Arrays.copyOf, but it's more flexible. Both of them use System.arraycopy under the hood. 


See:


You can try using Arrays.copyOf() in Java


For a null-safe copy of an array, you can also use an optional with the Object.clone() method provided in this answer.


If you must work with raw arrays and not ArrayList then Arrays has what you need. If you look at the source code, these are the absolutely best ways to get a copy of an array. They do have a good bit of defensive programming because the System.arraycopy() method throws lots of unchecked exceptions if you feed it illogical parameters.


You can use either Arrays.copyOf() which will copy from the first to Nth element to the new shorter array.


Copies the specified array, truncating or padding with nulls (if
  necessary) so the copy has the specified length. For all indices that
  are valid in both the original array and the copy, the two arrays will
  contain identical values. For any indices that are valid in the copy
  but not the original, the copy will contain null. Such indices will
  exist if and only if the specified length is greater than that of the
  original array. The resulting array is of exactly the same class as
  the original array.


or Arrays.copyOfRange() will also do the trick:


Copies the specified range of the specified array into a new array.
  The initial index of the range (from) must lie between zero and
  original.length, inclusive. The value at original[from] is placed into
  the initial element of the copy (unless from == original.length or
  from == to). Values from subsequent elements in the original array are
  placed into subsequent elements in the copy. The final index of the
  range (to), which must be greater than or equal to from, may be
  greater than original.length, in which case null is placed in all
  elements of the copy whose index is greater than or equal to
  original.length - from. The length of the returned array will be to -
  from. The resulting array is of exactly the same class as the original
  array.


As you can see, both of these are just wrapper functions over System.arraycopy with defensive logic that what you are trying to do is valid.


System.arraycopy is the absolute fastest way to copy arrays.






Is the memory space consumed by one object with 100 attributes the same as that of 100 objects, with one attribute each?


How much memory is allocated for an object?
How much additional space is used when adding an attribute?


Mindprod points out that this is not a straightforward question to answer:


A JVM is free to store data any way it pleases internally, big or little endian, with any amount of padding or overhead, though primitives must behave as if they had the official sizes.
  For example, the JVM or native compiler might decide to store a boolean[] in 64-bit long chunks like a BitSet. It does not have to tell you, so long as the program gives the same answers.


Then of course the hardware and OS have multilayer caches, on chip-cache, SRAM cache, DRAM cache, ordinary RAM working set and backing store on disk. Your data may be duplicated at every cache level. All this complexity means you can only very roughly predict RAM consumption. 


You can use Instrumentation.getObjectSize() to obtain an estimate of the storage consumed by an object.


To visualize the actual object layout, footprint, and references, you can use the JOL (Java Object Layout) tool.


In a modern 64-bit JDK, an object has a 12-byte header, padded to a multiple of 8 bytes, so the minimum object size is 16 bytes.  For 32-bit JVMs, the overhead is 8 bytes, padded to a multiple of 4 bytes.  (From Dmitry Spikhalskiy's answer, Jayen's answer, and JavaWorld.)


Typically, references are 4 bytes on 32bit platforms or on 64bit platforms up to -Xmx32G; and 8 bytes above 32Gb (-Xmx32G).  (See compressed object references.)


As a result, a 64-bit JVM would typically require 30-50% more heap space. (Should I use a 32- or a 64-bit JVM?, 2012, JDK 1.7)


Boxed wrappers have overhead compared to primitive types (from JavaWorld):


Integer: The 16-byte result is a little worse than I expected because an int value can fit into just 4 extra bytes. Using an Integer costs me a 300 percent memory overhead compared to when I can store the value as a primitive type


Long: 16 bytes also: Clearly, actual object size on the heap is subject to low-level memory alignment done by a particular JVM implementation for a particular CPU type. It looks like a Long is 8 bytes of Object overhead, plus 8 bytes more for the actual long value. In contrast, Integer had an unused 4-byte hole, most likely because the JVM I use forces object alignment on an 8-byte word boundary. 


Other containers are costly too:


Multidimensional arrays: it offers another surprise.
  Developers commonly employ constructs like int[dim1][dim2] in numerical and scientific computing.


In an int[dim1][dim2] array instance, every nested int[dim2] array is an Object in its own right. Each adds the usual 16-byte array overhead. When I don't need a triangular or ragged array, that represents pure overhead. The impact grows when array dimensions greatly differ.


For example, a int[128][2] instance takes 3,600 bytes. Compared to the 1,040 bytes an int[256] instance uses (which has the same capacity), 3,600 bytes represent a 246 percent overhead. In the extreme case of byte[256][1], the overhead factor is almost 19! Compare that to the C/C++ situation in which the same syntax does not add any storage overhead. 


String: a String's memory growth tracks its internal char array's growth. However, the String class adds another 24 bytes of overhead.


For a nonempty String of size 10 characters or less, the added overhead cost relative to useful payload (2 bytes for each char plus 4 bytes for the length), ranges from 100 to 400 percent. 


Consider this example object:


A naïve sum would suggest that an instance of X would use 17 bytes.  However, due to alignment (also called padding), the JVM allocates the memory in multiples of 8 bytes, so instead of 17 bytes it would allocate 24 bytes.


Each object has a certain overhead for its associated monitor and type information, as well as the fields themselves. Beyond that, fields can be laid out pretty much however the JVM sees fit (I believe) - but as shown in another answer, at least some JVMs will pack fairly tightly. Consider a class like this:


vs


On a 32-bit JVM, I'd expect 100 instances of SingleByte to take 1200 bytes (8 bytes of overhead + 4 bytes for the field due to padding/alignment). I'd expect one instance of OneHundredBytes to take 108 bytes - the overhead, and then 100 bytes, packed. It can certainly vary by JVM though - one implementation may decide not to pack the fields in OneHundredBytes, leading to it taking 408 bytes (= 8 bytes overhead + 4 * 100 aligned/padded bytes). On a 64 bit JVM the overhead may well be bigger too (not sure).


EDIT: See the comment below; apparently HotSpot pads to 8 byte boundaries instead of 32, so each instance of SingleByte would take 16 bytes.


Either way, the "single large object" will be at least as efficient as multiple small objects - for simple cases like this.


It depends on architecture/jdk. For modern JDK and 64bit architecture object has 12-bytes header and padding by 8 bytes - so minimum object size is 16 bytes. You can use tool called Java Object Layout to determine size and get details about object layout and internal structure of any entity or guess this information by class reference. Output, for example, for Integer on my environment:


So, for Integer, instance size is 16 bytes, because 4-bytes int compacted in place right after header and before padding boundary.


Code sample:


If you use maven, to get JOL:


Is the memory space consumed by one object with 100 attributes the same as that of 100 objects, with one attribute each?


No.


How much memory is allocated for an object?


How much additional space is used when adding an attribute?


No, registering an object takes a bit of memory too. 100 objects with 1 attribute will take up more memory.


I've gotten very good results from the java.lang.instrument.Instrumentation approach mentioned in another answer.  For good examples of its use, see the entry, Instrumentation Memory Counter from the JavaSpecialists' Newsletter and the java.sizeOf library on SourceForge.


The total used / free memory of an program can be obtained in the program via 


The runtime has several method which relates to the memory. The following coding example demonstrate its usage.


The question will be a very broad one.


It depends on the class variable or you may call as states memory usage in java.


It also has some additional memory requirement for headers and referencing.


The heap memory used by a Java object includes


memory for primitive fields, according to their size (see below for Sizes of primitive types); 


memory for reference fields (4 bytes each); 


an object header, consisting of a few bytes of "housekeeping" information; 


Objects in java also requires some "housekeeping" information, such as recording an object's class, ID and status flags such as whether the object is currently reachable, currently synchronization-locked etc. 


Java object header size varies on 32 and 64 bit jvm.


Although these are the main memory consumers jvm also requires additional fields sometimes like for alignment of the code e.t.c.


Sizes of primitive types


boolean   & byte -- 1


char & short -- 2


int & float -- 4


long & double -- 8  


It appears that every object has an overhead of 16 bytes on 32-bit systems (and 24-byte on 64-bit systems).


http://algs4.cs.princeton.edu/14analysis/ is a good source of information. One example among many good ones is the following.





http://www.cs.virginia.edu/kim/publicity/pldi09tutorials/memory-efficient-java-tutorial.pdf is also very informative, for example:





no, 100 small objects needs more information (memory) than one big.


In case it's useful to anyone, you can download from my web site a small Java agent for querying the memory usage of an object. It'll let you query "deep" memory usage as well.


The rules about how much memory is consumed depend on the JVM implementation and the CPU architecture (32 bit versus 64 bit for example). 


For the detailed rules for the SUN JVM check my old blog


Regards,
Markus






I find that my constructors are starting to look like this:


with ever increasing parameter list. Since "Container" is my dependency injection container, why can't I just do this:


for every class? What are the downsides? If I do this, it feels like I'm using a glorified static. Please share your thoughts on IoC and Dependency Injection madness.


You are right that if you use the container as a Service Locator, it's more or less a glorified static factory. For lots of reasons I consider this an anti-pattern.


One of the wonderful benefits of Constructor Injection is that it makes violations of the Single Responsibility Principle glaringly obvious.


When that happens, it's time to refactor to Facade Services. In short, create a new, more coarse-grained interface that hides the interaction between some or all of the fine-grained dependencies you currently require.


I don't think your class constructors should have a reference to your IOC container period. This represents an unnecessary dependency between your class and the container (the type of dependency IOC is trying to avoid!). 


The difficulty of passing in the parameters is not the problem.  The problem is that your class is doing too much, and should be broken down more.


Dependency Injection can act as an early warning for classes getting too big, specifically because of the increasing pain of passing in all of the dependencies.


I came across a similar question about constructor based dependency Injection and how complex it was getting to pass in all the dependencies.


One of the approach, I have used in past is to use the application facade pattern using a service layer. This would have a coarse API. If this service depends on repositories, It would use a setter injection of the private properties. This requires creating an abstract factory and moving the logic of creating the repositories into a factory.


Detailed code with explanation can be found here


Best practices for IoC in complex service layer


This is the approach I use


Here is a crude approach how to perform the injections and run constructor after injecting values. This is fully functional program.


I am currently working on a hobby project which works like this
https://github.com/Jokine/ToolProject/tree/Core


Problem : 


1) Constructor with ever increasing parameter list.


2) If class is inherited (Ex: RepositoryBase) then changing constructor 
signature causes change in the derived classes.


Solution 1


Pass IoC Container to constructor 


Why


Why not


Solution 2


Create a class which groups all service and pass it to constructor


Derived class 


Why


Why not


Solution 2 is just a raw though, if there is solid argument against it, then descriptive comment would be appreciated


What dependency injection framework are you using?  Have you tried using setter based injection instead?


The benefit for constructor based injection is that it looks natural for Java programmers who don't use DI frameworks.  You need 5 things to initialize a class then you have 5 arguments for your constructor.  The downside is what you have noticed, it gets unwieldy when you have lots of dependencies.


With Spring you could pass the required values with setters instead and you could use @required annotations to enforce that they are injected.  The downside is that you need to move the initialization code from the constructor to another method and have Spring call that after all the dependencies are injected by marking it with @PostConstruct.  I'm not sure about other frameworks but I assume they do something similar.


Both ways work, its a matter of preference.






Is there a Java 8 stream operation that limits a (potentially infinite) Stream until the first element that fails to match a predicate? Something that looks like the (non-existent) takeWhile operation in the example below and would print all numbers less than 10?


If there is no such operation, what's the best way of implementing it in a general way? 


Such an operation ought to be possible with a Java 8 Stream, but it can't necessarily be done efficiently -- for example, you can't necessarily parallelize such an operation, as you have to look at elements in order.


The API doesn't provide an easy way to do it, but what's probably the simplest way is to take Stream.iterator(), wrap the Iterator to have a "take-while" implementation, and then go back to a Spliterator and then a Stream.  Or -- maybe -- wrap the Spliterator, though it can't really be split anymore in this implementation.


Here's an untested implementation of takeWhile on a Spliterator:


Operations takeWhile and dropWhile have been added to JDK 9. Your example code


will behave exactly as you expect it to when compiled and run under JDK 9.


JDK 9 has not yet been released as of this writing. All specifications are subject to change. Prerelease snapshot builds and documentation are available at https://jdk9.java.net/. Current direct link is here. 


allMatch() is a short-circuiting function, so you can use it to stop processing. The main disadvantage is that you have to do your test twice: once to see if you should process it, and again to see whether to keep going.


As a follow-up to @StuartMarks answer. My StreamEx library has the takeWhile operation which is compatible with current JDK-9 implementation. When running under JDK-9 it will just delegate to the JDK implementation (via MethodHandle.invokeExact which is really fast). When running under JDK-8, the "polyfill" implementation will be used. So using my library the problem can be solved like this:


takeWhile is one of the functions provided by the protonpack library.


I am sure this can be greatly improved upon: 
(someone could make it thread-safe maybe)


You can use java8 + rxjava.


Here is a version done on ints - as asked in the question.


Usage:


Here's code for StreamUtil:


This is the source copied from JDK 9 java.util.stream.Stream.takeWhile(Predicate).


Go to get library AbacusUtil. It provides the exact API you want and more:


Declaration： I'm the developer of AbacusUtil.


You can't abort a stream except by a short-circuiting terminal operation, which would leave some stream values unprocessed regardless of their value. But if you just want to avoid operations on a stream you can add a transform and filter to the stream:


That transforms the stream of things to nulls when the things meet some condition, then filters out nulls.  If you're willing to indulge in side effects, you could set the condition value to true once some thing is encountered, so all subsequent things are filtered out regardless of their value. But even if not you can save a lot of (if not quite all) processing by filtering values out of the stream that you don't want to process.


Actually there are 2 ways to do it in Java 8 without any extra libraries or using Java 9.


If you want to print numbers from 2 to 20 on the console you can do this:


or


The output is in both cases:


No one mentioned anyMatch yet. This is the reason for this post.


Even I was having a similar requirement -- invoke the web-service, if it fails, retry it 3 times. If it fails even after these many trials, send an email notification. After googling a lot, "anyMatch" came as a saviour. My sample code as follows. In the following example, if "webServiceCall" method returns true in the first iteration itself, stream does not iterate further as we have called "anyMatch". I believe, this is what you are looking for.


import java.util.stream.IntStream;


import io.netty.util.internal.ThreadLocalRandom;


class TrialStreamMatch {


}


I have another quick solution by implementing this (which is rly unclean in fact, but you get the idea):


Here is my attempt using just Java Stream library.


If you have different problem, different solution may be needed but for your current problem, I would simply go with:






What exactly is a default constructor — can you tell me which one of the following is a default constructor and what differentiates it from any other constructor?


Neither of them. If you define it, it's not the default.


The default constructor is the no-argument constructor automatically generated unless you define another constructor. It initialises any uninitialised fields to their default values. For your example, it would look like this assuming that the types are String, int and int:


This is exactly the same as


And exactly the same as having no constructors at all. However, if you define at least one constructor, the default constructor is not generated.


Reference: Java Language Specification


Technically it is not the constructor (default or otherwise) that default-initialises the fields. However, I am leaving this in the answer as 


A default constructor is created if you don't define any constructors in your class. It simply is a no argument constructor which does nothing. Edit: Except call super()


A default constructor is automatically generated by the compiler if you do not explicitly define at least one constructor in your class. You've defined two, so your class does not have a default constructor.


Per The Java Language Specification Third Edition:


8.8.9 Default Constructor


If a class contains no constructor
  declarations, then a default
  constructor that takes no parameters
  is automatically provided...


Hi. As per my knowledge let me clear the concept of default constructor:


The compiler automatically provides a no-argument, default constructor
  for any class without constructors. This default constructor will call
  the no-argument constructor of the superclass. In this situation, the
  compiler will complain if the superclass doesn't have a no-argument
  constructor so you must verify that it does. If your class has no
  explicit superclass, then it has an implicit superclass of Object,
  which does have a no-argument constructor.


I read this information from the Java Tutorials.


Java provides a default constructor which takes no arguments and performs no special actions or initializations, when no explicit constructors are provided.


The only action taken by the implicit default constructor is to call the superclass constructor using the super() call. Constructor arguments provide you with a way to provide parameters for the initialization of an object.


Below is an example of a cube class containing 2 constructors. (one default and one parameterized constructor).


General terminology is that if you don't provide any constructor in your object a no argument constructor is automatically placed which is called default constructor.


If you do define a constructor same as the one which would be placed if you don't provide any it is generally termed as no arguments constructor.Just a convention though as some programmer prefer to call this explicitly defined no arguments constructor as default constructor. But if we go by naming if we are explicitly defining one than it does not make it default.


As per the docs


If a class contains no constructor declarations, then a default constructor with no formal parameters and no throws clause is implicitly declared.


Example


will automatically be modified(by adding default constructor) as follows


and when you create it's object


this default constructor is invoked.


If a class doesn't have any constructor provided by programmer, then java compiler will add a default constructor with out parameters which will call super class constructor internally with super() call. This is called as default constructor.


In your case, there is no default constructor as you are adding them programmatically.
If there are no constructors added by you, then compiler generated default constructor will look like this.


Note: In side default constructor, it will add super() call also, to call super class constructor.


Purpose of adding default constructor:


Constructor's duty is to initialize instance variables, if there are no instance variables you could choose to remove constructor from your class. But when you are inheriting some class it is your class responsibility to call super class constructor to make sure that super class initializes all its instance variables properly. 


That's why if there are no constructors, java compiler will add a default constructor and calls super class constructor.


A default constructor does not take any arguments:


When we do not explicitly define a constructor for a class, then java creates a default constructor for the class. It is essentially a non-parameterized constructor, i.e. it doesn't accept any arguments.


The default constructor's job is to call the super class constructor and  initialize all instance variables. If the super class constructor is not present then it automatically initializes the instance variables to zero. So, that serves the purpose of using constructor, which is to initialize the internal state of an object so that the code creating an instance will have a fully initialized, usable object. 


Once we define our own constructor for the class, the default constructor is no longer used. So, neither of them is actually a default constructor.


default constructor refers to a constructor that is automatically generated by the compiler in the absence of any programmer-defined constructors.


If there's no constructor provided by programmer, the compiler implicitly declares a default constructor which calls super(), has no throws clause as well no formal parameters.


E.g.






Is there a good available (standard Java) data structure to represent a tree in Java?


Specifically I need to represent the following:


Is there an available structure for this or do I need to create my own (if so implementation suggestions would be great).


Here: 


That is a basic tree structure that can be used for String or any other object.  It is fairly easy to implement simple trees to do what you need.


All you need to add are methods for add to, removing from, traversing, and constructors.  The Node is the basic building block of the Tree.


Yet another tree structure:


Sample usage:


BONUS
See fully-fledged tree with:


https://github.com/gt4dev/yet-another-tree-structure


There is actually a pretty good tree structure implemented in the JDK.


Have a look at javax.swing.tree, TreeModel, and TreeNode. They are designed to be used with the JTreePanel but they are, in fact, a pretty good tree implementation and there is nothing stopping you from using it with out a swing interface.


What about this? (BTW, no matter what I seem to try, I cannot paste code that the site's code formatter will process properly. Sorry about that.)


I wrote a little library that handles generic trees. It's much more lightweight than the swing stuff. I also have a maven project for it.


Obviously you can add utility methods to add/remove children.


You should start by defining what a tree is (for the domain), this is best done by defining the interface first. Not all trees structures are modifyable, being able to add and remove nodes should be an optional feature, so we make an extra interface for that.


There's no need to create node objects which hold the values, in fact I see this as a major design flaw and overhead in most tree implementations. If you look at Swing, the TreeModel is free of node classes (only DefaultTreeModel makes use of TreeNode), as they are not really needed.


Given these interfaces, code that uses trees doesn't have to care much about how the tree is implemented. This allows you to use generic implementations as well as specialized ones, where you realize the tree by delegating functions to another API.
Example: File tree structure.


No answer mentions over-simplified but working code, so here it is:


Along the same lines as Gareth's answer, check out DefaultMutableTreeNode.  It's not generic, but otherwise seems to fit the bill.  Even though it's in the javax.swing package, it doesn't depend on any AWT or Swing classes.  In fact, the source code actually has the comment // ISSUE: this class depends on nothing in AWT -- move to java.util?


You can use any XML API of Java as Document and Node..as XML is a tree structure with Strings


There are a couple of tree data structures in Java, such as DefaultMutableTreeNode in JDK Swing, Tree in Stanford parser package, and other toy codes. But none of these are sufficient yet small enough for general purpose.


Java-tree project attempts to provide another general-purpose tree data structure in Java. The difference between this and others are


Since the question asks for an available data structure, a tree can be constructed from lists or arrays:


instanceof can be used to determine whether an element is a subtree or a terminal node.


As simple as it gets and very easy to use.  To use it, extend it:  


For example : 


Custom Tree implement of Tree without using the Collection framework. It contains different fundamental operation needed in Tree implementation.


If you're doing whiteboard coding, an interview, or even just planning to use a tree, the verbosity of these is all a little much.


It should further be said that the reason a tree is not in there like, say, a Pair (about which the same could be said), is because you should be encapsulating your data in the class using it, and the simplest implementation looks like:


That's really it for an arbitrary width tree.


If you wanted a binary tree it's often easier to use with named fields:


Or if you wanted a trie:


Now you said you want


to be able to get all the children (some sort of list or array of Strings) given an input string representing a given node


That sounds like your homework.
But since I'm reasonably sure any deadline has now passed…


This gets you use like:


You can use the HashTree class included in Apache JMeter that is part of the Jakarta Project.


HashTree class is included in the package org.apache.jorphan.collections. Although this package is not released outside the JMeter project, you can get it easily:


1) Download the JMeter sources.


2) Create a new package.


3) Copy on it /src/jorphan/org/apache/jorphan/collections/ . All files except Data.java


4) Copy also /src/jorphan/org/apache/jorphan/util/JOrphanUtils.java


5) HashTree is ready to use.


Please check the below code, where I have used Tree data structures, without using Collection classes. The code may have bugs/improvements but please use this just for reference  


There is no specific data structure in Java which suits to your requirements. Your requirements are quite specific and for that you need to design your own data structure. Looking at your requirements anyone can say that you need some kind of n-ary tree with some specific functionality. You can design your data structure in following way:


I would suggest, you write structure of the node in one class like Class Node { String  value; List children;} and all other methods like search, insert and getChildren in another NodeUtils class so that you can also pass the root of tree to perform operation on specific tree like:
class NodeUtils{ public static Node search(Node root, String value){// perform BFS and return Node}


In the past I have just used a nested map for this. This is what I use today, it is very simple but it fits my needs. Maybe this will help another one.


I wrote a tree library that plays nicely with Java8 and that has no other dependencies. It also provides a loose interpretation of some ideas from functional programming and lets you map/filter/prune/search the entire tree or subtrees.


https://github.com/RutledgePaulV/prune


The implementation doesn't do anything special with indexing and I didn't stray away from recursion, so it's possible that with large trees performance will degrade and you could blow the stack. But if all you need is a straightforward tree of small to moderate depth, I think it works well enough. It provides a sane (value based) definition of equality and it also has a toString implementation that lets you visualize the tree!


You can use TreeSet class in java.util.*. It is working like Binary search tree, so it is already sorted. TreeSet class implements Iterable, Collection and Set interfaces. You can traverse through the tree with iterator like a set. 


You can check, Java Doc and some other .






I read this question and thought that would easily be solved (not that it isn't solvable without) if one could write: 


I'm not sure if it is useful in many cases, but I wonder why it isn't and if something like this exists in other languages.


What do you guys think?


EDIT:
To clarify: yes I know, that's impossible in Java and I don't really miss it. This is nothing I expected to work and was surprised getting a compiler error. I just had the idea and like to discuss it.


It violates encapsulation. You shouldn't be able to bypass the parent class's behaviour. It makes sense to sometimes be able to bypass your own class's behaviour (particularly from within the same method) but not your parent's. For example, suppose we have a base "collection of items", a subclass representing "a collection of red items" and a subclass of that representing "a collection of big red items". It makes sense to have:


That's fine - RedItems can always be confident that the items it contains are all red. Now suppose we were able to call super.super.add():


Now we could add whatever we like, and the invariant in RedItems is broken.


Does that make sense?


I think Jon Skeet has the correct answer. I'd just like to add that you can access shadowed variables from superclasses of superclasses by casting this:


which produces the output:


(example from the JLS)


However, this doesn't work for method calls because method calls are determined based on the runtime type of the object.


I think the following code allow to use super.super...super.method() in most case.
(even if it's uggly to do that)


In short


Usage :


I don't have enough reputation to comment so I will add this to the other answers.


Jon Skeet answers excellently, with a beautiful example. Matt B has a point: not all superclasses have supers. Your code would break if you called a super of a super that had no super. 


Object oriented programming (which Java is) is all about objects, not functions. If you want task oriented programming, choose C++ or something else. If your object doesn't fit in it's super class, then you need to add it to the "grandparent class", create a new class, or find another super it does fit into. 


Personally, I have found this limitation to be one of Java's greatest strengths. Code is somewhat rigid compared to other languages I've used, but I always know what to expect. This helps with the "simple and familiar" goal of Java. In my mind, calling super.super is not simple or familiar. Perhaps the developers felt the same? 


In addition to the very good points that others have made, I think there's another reason: what if the superclass does not have a superclass?


Since every class naturally extends (at least) Object, super.whatever() will always refer to a method in the superclass. But what if your class only extends Object - what would super.super refer to then? How should that behavior be handled - a compiler error, a NullPointer, etc?


I think the primary reason why this is not allowed is that it violates encapsulation, but this might be a small reason too.


There's some good reasons to do this. You might have a subclass which has a method which is implemented incorrectly, but the parent method is implemented correctly. Because it belongs to a third party library, you might be unable/unwilling to change the source. In this case, you want to create a subclass but override one method to call the super.super method.


As shown by some other posters, it is possible to do this through reflection, but it should be possible to do something like


(SuperSuperClass this).theMethod();


I'm dealing with this problem right now - the quick fix is to copy and paste the superclass method into the subsubclass method :)


I think if you overwrite a method and want to all the super-class version of it (like, say for equals), then you virtually always want to call the direct superclass version first, which one will call its superclass version in turn if it wants. 


I think it only makes rarely sense (if at all. i can't think of a case where it does) to call some arbitrary superclass' version of a method. I don't know if that is possible at all in Java. It can be done in C++:


At a guess, because it's not used that often.  The only reason I could see using it is if your direct parent has overridden some functionality and you're trying to restore it back to the original.


Which seems to me to be against OO principles, since the class's direct parent should be more closely related to your class than the grandparent is.


I would put the super.super method body in another method, if possible


Or if you cannot change the super-super class, you can try this:


In both cases, the


results to "I am super super"


It would seem to be possible to at least get the class of the superclass's superclass, though not necessarily the instance of it, using reflection; if this might be useful, please consider the Javadoc at http://java.sun.com/j2se/1.5.0/docs/api/java/lang/Class.html#getSuperclass()


run:
A
BUILD SUCCESSFUL (total time: 0 seconds)


I have had situations like these when the architecture is to build common functionality in a common CustomBaseClass which implements on behalf of several derived classes.
However, we need to circumvent common logic for specific method for a specific derived class. In such cases, we must use a super.super.methodX implementation.


We achieve this by introducing a boolean member in the CustomBaseClass, which can be used to selectively defer custom implementation and yield to default framework implementation where desirable.


However, with good architecture principles followed in framework as well as app, we could avoid such situations easily, by using hasA approach, instead of isA approach. But at all times it is not very practical to expect well designed architecture in place, and hence the need to get away from solid design principles and introduce hacks like this.
Just my 2 cents...


@Jon Skeet Nice explanation. 
IMO if some one wants to call super.super method then one must be want to ignore the behavior of immediate parent, but want to access the grand parent behavior.
This can be achieved through instance Of. As below code


Here is driver class,


Output of this will be 


Class B printClass behavior will be ignored in this case.
I am not sure about is this a ideal or good practice to achieve super.super, but still it is working.


If you think you are going to be needing the superclass, you could reference it in a variable for that class. For example:


Should print out:


IMO, it's a clean way to achieve super.super.sayYourName() behavior in Java.


Output:


Request to lie: d.sayYourName(true) returns Grandma Fedora
Request not to lie: d.sayYourName(false) returns Little girl Masha


Calling of super.super.method() make sense when you can't change code of base class. This often happens when you are extending an existing library.


Ask yourself first, why are you extending that class? If answer is "because I can't change it" then you can create exact package and class in your application, and rewrite naughty method or create delegate:


For instance, you can create org.springframework.test.context.junit4.SpringJUnit4ClassRunner class in your application so this class should be loaded before the real one from jar. Then rewrite methods or constructors.


Attention: This is absolute hack, and it is highly NOT recommended to use but it's WORKING! Using of this approach is dangerous because of possible issues with class loaders. Also this may cause issues each time you will update library that contains overwritten class.


I think this is a problem that breaks the inheritance agreement. 
By extending a class  you obey / agree  its behavior, features 
Whilst when calling super.super.method(), you want to break your own obedience  agreement.


You just cannot cherry pick from the super class. 


However,  there  may happen situations when you feel the need to call super.super.method() -  usually a bad design sign,  in your code or in the code you inherit ! 
If the super and super super classes cannot be refactored (some legacy code), then opt for composition over inheritance.
Encapsulation breaking is when you @Override some methods by breaking the encapsulated code.
The methods  designed not to be overridden are marked
 final.


In C# you can call a method of any ancestor like this:


Also you can do this in Delphi: 


But in Java you can do such focus only by some gear. One possible way is:


objC.DoIt() result output:


It is simply easy to do. For instance:


C subclass of B and B subclass of A. Both of three have method methodName() for example.


public abstract class A {


}


public class B extends A {


}


public class C extends B {


}


Run class C Output will be:
Class A
Class C


Instead of output:
Class A
Class B
Class C


Output: Printed in the GrandDad






I have a string like this: 


I want to remove the whitespaces in the string. I tried trim() but this removes only whitespaces before and after the whole string. I also tried replaceAll("\\W", "") but then the = also gets removed.


How can I achieve a string with:


st.replaceAll("\\s+","") removes all whitespaces and non-visible characters (e.g., tab, \n).


st.replaceAll("\\s+","") and st.replaceAll("\\s","") produce the same result.


The second regex is 20% faster than the first one, but as the number consecutive spaces increases, the first one performs better than the second one.


Assign the value to a variable, if not used directly:


\w = Anything that is a word character


\W = Anything that isn't a word character (including punctuation etc)


\s = Anything that is a space character (including space, tab characters etc)


\S = Anything that isn't a space character (including both letters and numbers, as well as punctuation etc)


(Edit: As pointed out, you need to escape the backslash if you want \s to reach the regex engine, resulting in \\s.)


The most correct answer to the question is:


I just adapted this code from the other answers. I'm posting it because besides being exactly what the question requested, it also demonstrates that the result is returned as a new string, the original string is not modified as some of the answers sort of imply.


(Experienced Java developers might say "of course, you can't actually modify a String", but the target audience for this question may well not know this.)


How about replaceAll("\\s", ""). Refer here.


If you prefer utility classes to regexes, there is a method trimAllWhitespace(String) in StringUtils in the Spring Framework.


You've already got the correct answer from Gursel Koca but I believe that there's a good chance that this is not what you really want to do. How about parsing the key-values instead?


output:
  name = john
  age = 13
  year = 2001  


One way to handle String manipulations is StringUtils from Apache commons.


You can find it here.
commons-lang includes lots more and is well supported.


You should use


instead of:


This way, it will work with more than one spaces between each string. 
The + sign in the above regex means "one or more \s"


If you need to remove unbreakable spaces too, you can upgrade your code like this :


You can do it so simply by


//it work fine with any spaces 
*don't forget space in sting b


The easiest way to do this is by using the org.apache.commons.lang3.StringUtils class of commons-lang3 library such as "commons-lang3-3.1.jar" for example.


Use the static method "StringUtils.deleteWhitespace(String str)" on your input string & it will return you a string after removing all the white spaces from it. I tried your example string "name=john age=13 year=2001" & it returned me exactly the string that you wanted - "name=johnage=13year=2001". Hope this helps.


\W means "non word character". The pattern for whitespace characters is \s. This is well documented in the Pattern javadoc.


In java we can do following operation:


for this you need to import following packages to your program:


i hope it will help you.


there are many ways to solve this problem.
you can use split function or replace function of Strings.


for more info refer smilliar problem http://techno-terminal.blogspot.in/2015/10/how-to-remove-spaces-from-given-string.html


Using Pattern And Matcher it is more Dynamic.


First with space, second without space. 


Then it is done. 


This works for me and locates ll white spaces, not just spaces of a certain size.


To remove spaces in your example, this is another way to do it:


What this does is it converts it into an array with the spaces being the separators, and then it combines the items in the array together without the spaces.


It works pretty well and is easy to understand. 


You can achieve this without using replaceAll() or any Predefined Method in Java.
this way is preferred:-


Use apache string util class is better to avoid NullPointerException


Output will be:


TRY THIS 


Use mysz.replaceAll("\\s+","");


The code you want is


This will remove all the white spaces.






How to read all the files in a folder through Java?


Files.walk API is available from Java 8.


The example uses try-with-resources pattern recommended in API guide. It ensures that no matter circumstances the stream will be closed.


In Java 8 you can do this


which will print all files in a folder while excluding all directories. If you need a list, the following will do:


If you want to return List<File> instead of List<Path> just map it:


You also need to make sure to close the stream! Otherwise you might run into an exception telling you that too many files are open. Read here for more information.


All of the answers on this topic that make use of the new Java 8 functions are neglecting to close the stream. The example in the accepted answer should be:


From the javadoc of the Files.walk method:


The returned stream encapsulates one or more DirectoryStreams. If
  timely disposal of file system resources is required, the
  try-with-resources construct should be used to ensure that the
  stream's close method is invoked after the stream operations are completed.


In Java 7 you can now do it this way - http://docs.oracle.com/javase/tutorial/essential/io/dirs.html#listdir


You can also create a filter that can then be passed into the newDirectoryStream method above


Other filtering examples - http://docs.oracle.com/javase/tutorial/essential/io/dirs.html#glob


Just walk through all Files using Files.walkFileTree (Java 7)


If you want more options, you can use this function which aims to populate an arraylist of files present in a folder. Options are : recursivility and pattern to match.


Best, Adrien


nice usage of java.io.FileFilter as seen on https://stackoverflow.com/a/286001/146745


I think this is good way to read all the files in a folder and sub folder's


Simple example that works with Java 1.7 to recursively list files in directories specified on the command-line:


list down files from Test folder present inside class path


You can filter any textfiles or any other extension ..just replace it with .MP3


While I do agree with Rich, Orian and the rest for using:


for some reason all the examples here uses absolute path (i.e. all the way from root, or, say, drive letter (C:\) for windows..)


I'd like to add that it is possible to use relative path as-well.
So, if you're pwd (current directory/folder) is folder1 and you want to parse folder1/subfolder, you simply write (in the code above instead of ):


Java 8 Files.walk(..) is good when you are soore it will not throw Avoid Java 8 Files.walk(..) termination cause of ( java.nio.file.AccessDeniedException ) .


Here is a safe solution , not though so elegant as Java 8Files.walk(..) :


Just to expand on the accepted answer I store the filenames to an ArrayList (instead of just dumping them to System.out.println) I created a helper class "MyFileUtils" so it could be imported by other projects:


I added the full path to the file name. 
You would use it like this:


The ArrayList is passed by "value", but the value is used to point to the same ArrayList object living in the JVM Heap. In this way, each recursion call adds filenames to the same ArrayList (we are NOT creating a new ArrayList on each recursive call).


to prevent Nullpointerexceptions on the listFiles() function and recursivly get all files from subdirectories too..


Just pass your folder it will tell you main class about the method.






I have to keep thousands of strings in memory to be accessed serially in Java. Should I store them in an array or should I use some kind of List ?


Since arrays keep all the data in a contiguous chunk of memory (unlike Lists), would the use of an array to store thousands of strings cause problems ?


Answer: The common consensus is that the performance difference is minor. List interface provides more flexibility. 


I suggest that you use a profiler to test which is faster.


My personal opinion is that you should use Lists.


I work on a large codebase and a previous group of developers used arrays everywhere. It made the code very inflexible. After changing large chunks of it to Lists we noticed no difference in speed.


The Java way is that you should consider what data abstraction most suits your needs.  Remember that in Java a List is an abstract, not a concrete data type.  You should declare the strings as a List, and then initialize it using the ArrayList implementation.


This separation of Abstract Data Type and specific implementation is one the key aspects of object oriented programming.


An ArrayList implements the List Abstract Data Type using an array as its underlying implementation.  Access speed is virtually identical to an array, with the additional advantages of being able to add and subtract elements to a List (although this is an O(n) operation with an ArrayList) and that if you decide to change the underlying implementation later on you can.  For example, if you realize you need synchronized access, you can change the implementation to a Vector without rewriting all your code.


In fact, the ArrayList was specifically designed to replace the low-level array construct in most contexts.  If Java was being designed today, it's entirely possible that arrays would have been left out altogether in favor of the ArrayList construct.


Since arrays keep all the data in a contiguous chunk of memory (unlike Lists), would the use of an array to store thousands of strings cause problems ?


In Java, all collections store only references to objects, not the objects themselves.   Both arrays and ArrayList will store a few thousand references in a contiguous array, so they are essentially identical.  You can consider that a contiguous block of a few thousand 32-bit references will always be readily available on modern hardware.  This does not guarantee that you will not run out of memory altogether, of course, just that the contiguous block of memory requirement is not difficult to fufil.


You should prefer generic types over arrays. As mentioned by others, arrays are inflexible and do not have the expressive power of generic types. (They do however support runtime typechecking, but that mixes badly with generic types.)


But, as always, when optimizing you should always follow these steps:


Although the answers proposing to use ArrayList do make sense in most scenario, the actual question of relative performance has not really been answered.


There are a few things you can do with an array:


Although get and set operations are somewhat slower on an ArrayList (resp. 1 and 3 nanosecond per call on my machine), there is very little overhead of using an ArrayList vs. an array for any non-intensive use. There are however a few things to keep in mind:


Here are the results I measured for those three operations using the jmh benchmarking library (times in nanoseconds) with JDK 7 on a standard x86 desktop machine. Note that ArrayList are never resized in the tests to make sure results are comparable. Benchmark code available here.


I ran 4 tests, executing the following statements:


Results (in nanoseconds per call, 95% confidence):


Conclusion: no noticeable difference.


I ran 2 tests, executing the following statements:


Results (in nanoseconds per call, 95% confidence):


Conclusion: getting from an array is about 25% faster than getting from an ArrayList, although the difference is only on the order of one nanosecond.


I ran 2 tests, executing the following statements:


Results (in nanoseconds per call):


Conclusion: set operations on arrays are about 40% faster than on lists, but, as for get, each set operation takes a few nanoseconds - so for the difference to reach 1 second, one would need to set items in the list/array hundreds of millions of times!


ArrayList's copy constructor delegates to Arrays.copyOf so performance is identical to array copy (copying an array via clone, Arrays.copyOf or System.arrayCopy makes no material difference performance-wise).


I'm guessing the original poster is coming from a C++/STL background which is causing some confusion. In C++ std::list is a doubly linked list.


In Java [java.util.]List is an implementation-free interface (pure abstract class in C++ terms). List can be a doubly linked list - java.util.LinkedList is provided. However, 99 times out of 100 when you want a make a new List, you want to use java.util.ArrayList instead, which is the rough equivalent of C++ std::vector. There are other standard implementations, such as those returned by java.util.Collections.emptyList() and java.util.Arrays.asList().


From a performance standpoint there is a very small hit from having to go through an interface and an extra object, however runtime inlining means this rarely has any significance. Also remember that String are typically an object plus array. So for each entry, you probably have two other objects. In C++ std::vector<std::string>, although copying by value without a pointer as such, the character arrays will form an object for string (and these will not usually be shared).


If this particular code is really performance-sensitive, you could create a single char[] array (or even byte[]) for all the characters of all the strings, and then an array of offsets. IIRC, this is how javac is implemented.


I wrote a little benchmark to compare ArrayLists with Arrays. On my old-ish laptop, the time to traverse through a 5000-element arraylist, 1000 times, was about 10 milliseconds slower than the equivalent array code. 


So, if you're doing nothing but iterating the list, and you're doing it a lot, then maybe it's worth the optimisation. Otherwise I'd use the List, because it'll make it easier when you do need to optimise the code.


n.b. I did notice that using for String s: stringsList was about 50% slower than using an old-style for-loop to access the list. Go figure... Here's the two functions I timed; the array and list were filled with 5000 random (different) strings.


Well firstly it's worth clarifying do you mean "list" in the classical comp sci data structures sense (ie a linked list) or do you mean java.util.List? If you mean a java.util.List, it's an interface. If you want to use an array just use the ArrayList implementation and you'll get array-like behaviour and semantics. Problem solved.


If you mean an array vs a linked list, it's a slightly different argument for which we go back to Big O (here is a plain English explanation if this is an unfamiliar term.


Array;


Linked List:


So you choose whichever one best suits how you resize your array. If you resize, insert and delete a lot then maybe a linked list is a better choice. Same goes for if random access is rare. You mention serial access. If you're mainly doing serial access with very little modification then it probably doesn't matter which you choose.


Linked lists have a slightly higher overhead since, like you say, you're dealing with potentially non-contiguous blocks of memory and (effectively) pointers to the next element. That's probably not an important factor unless you're dealing with millions of entries however.


I agree that in most cases you should choose the flexibility and elegance of ArrayLists over arrays - and in most cases the impact to program performance will be negligible.


However, if you're doing constant, heavy iteration with little structural change (no adds and removes) for, say, software graphics rendering or a custom virtual machine, my sequential access benchmarking tests show that ArrayLists are 1.5x slower than arrays on my system (Java 1.6 on my one year-old iMac).


Some code:


No, because technically, the array only stores the reference to the strings. The strings themselves are allocated in a different location. For a thousand items, I would say a list would be better, it is slower, but it offers more flexibility and it's easier to use, especially if you are going to resize them.


If you have thousands, consider using a trie. A trie is a tree-like structure that merges the common prefixes of the stored string.


For example, if the strings were 


The trie would store:


The strings requires 57 characters (including the null terminator, '\0') for storage, plus whatever the size of the String object that holds them. (In truth, we should  probably round all sizes up to multiples of 16, but...) Call it 57 + 5 = 62 bytes, roughly.


The trie requires 29 (including the null terminator, '\0') for storage, plus sizeof the trie nodes, which are a ref to an array and a list of child trie nodes.


For this example, that probably comes out about the same; for thousands, it probably comes out less as long as you do have common prefixes.


Now, when using the trie in other code, you'll have to convert to String, probably using a StringBuffer as an intermediary. If many of the strings are in use at once as Strings, outside the trie, it's a loss.


But if you're only using a few at the time -- say, to look up things in a dictionary -- the trie can save you a lot of space. Definitely less space than storing them in a HashSet.


You say you're accessing them "serially" -- if that means sequentially an alphabetically, the trie also obviously gives you alphabetical order for free, if you iterate it depth-first.


UPDATE:


As Mark noted there is no significant difference after JVM warm up (several test passes). Checked with re-created array or even new pass starting with new row of matrix. With great probability this signs simple array with index access is not to be used in favor of collections.


Still first 1-2 passes simple array is 2-3 times faster.


ORIGINAL POST:


Too much words for the subject too simple to check. Without any question array is several times faster than any class container. I run on this question looking for alternatives for my performance critical section. Here is the prototype code I built to check real situation:


And here is the answer:


Based on array (line 16 is active):


Based on list (line 17 is active):


Any more comment on 'faster'? This is quite understood. The question is when about 3 time faster is better for you than flexibility of List. But this is another question.
By the way I checked this too based on manually constructed ArrayList. Almost the same result.


Since there are already a lot of good answers here, I would like to give you some other information of practical view, which is insertion and iteration performance comparison : primitive array vs Linked-list in Java.


This is actual simple performance check. So, the result will depend on the machine performance.


Source code used for this is below : 


Performance Result is below :





If you know in advance how large the data is then an array will be faster.


A List is more flexible.  You can use an ArrayList which is backed by an array.


list is slower than arrays.If you need efficiency use arrays.If you need flexibility use list.


Remember that an ArrayList encapsulates an array, so there is little difference compared to using a primitive array (except for the fact that a List is much easier to work with in java).


The pretty much the only time it makes sense to prefer an array to an ArrayList is when you are storing primitives, i.e. byte, int, etc and you need the particular space-efficiency you get by using primitive arrays.


Array vs. List choice is not so important (considering performance) in the case of storing string objects. Because both array and list will store string object references, not the actual objects.


It you can live with a fixed size, arrays will will be faster and need less memory.


If you need the flexibility of the List interface with adding and removing elements, the question remains which implementation you should choose. Often ArrayList is recommended and used for any case, but also ArrayList has its performance problems if elements at the beginning or in the middle of the list must be removed or inserted.


You therefore may want to have a look at http://java.dzone.com/articles/gaplist-%E2%80%93-lightning-fast-list which introduces GapList. This new list implementation combines the strengths of both ArrayList and LinkedList resulting in very good performance for nearly all operations.


Depending on the implementation. it's possible that an array of primitive types will be smaller and more efficient than ArrayList. This is because the array will store the values directly in a contiguous block of memory, while the simplest ArrayList implementation will store pointers to each value. On a 64-bit platform especially, this can make a huge difference.


Of course, it's possible for the jvm implementation to have a special case for this situation, in which case the performance will be the same. 


List is the preferred way in java 1.5 and beyond as it can use generics. Arrays cannot have generics. Also Arrays have a pre defined length, which cannot grow dynamically. Initializing an array with a large size is not a good idea.
ArrayList is the the way to declare an array with generics and it can dynamically grow.
But if delete and insert is used more frequently, then linked list is the fastest data structure to be used.


Arrays recommended everywhere you may use them instead of list, especially in case if you know items count and size would not be changing. 


See Oracle Java best practice: http://docs.oracle.com/cd/A97688_16/generic.903/bp/java.htm#1007056


Of course, if you need add and remove objects from collection many times easy use lists.


ArrayList stores its items in an Object[] array and use the untyped toArray method which is a lot faster (the blue bar) than the typed one. This is typesafe since the untyped array is wrapped in the generic type ArrayList<T> that is checked by the compiler.





This chart shows a benchmark with n = 5 on Java 7. However, the picture does not change much with more items or another VM. The CPU overhead might not seem drastic, but it adds up. Chances are that consumers of an array have to convert it into a collection in order to do anything with it, then convert the result back to an array to feed it into another interface method etc.
Using a simple ArrayList instead of an array improves performance, without adding much footprint. ArrayList adds a constant overhead of 32 bytes to the wrapped array. For example, an array with ten objects requires 104 bytes, an ArrayList 136 bytes.


This operation performs in constant time, so it’s much faster than any of the above (yellow bar). This is not the same as a defensive copy. An unmodifiable collection will change when your internal data changes. If this happens, clients can run into a ConcurrentModificationException while iterating over the items. It can be considered bad design that an interface provides methods that throw an UnsupportedOperationException at runtime. However, at least for internal use, this method can be a high-performance alternative to a defensive copy – something that is not possible with arrays.


None of the answers had information that I was interested in - repetitive scan of the same array many many times. Had to create a JMH test for this.


Results (Java 1.8.0_66 x32, iterating plain array is at least 5 times quicker than ArrayList):


Test


"Thousands" is not a large number. A few thousand paragraph-length strings are on the order of a couple of megabytes in size. If all you want to do is access these serially, use an immutable singly-linked List.


Don't get into the trap of optimizing without proper benchmarking. As others have suggested use a profiler before making any assumption.


The different data structures that you have enumerated have different purposes. A list is very efficient at inserting elements in the beginning and at the end but suffers a lot when accessing random elements. An array has fixed storage but provides fast random access. Finally an ArrayList improves the interface to an array by allowing it to grow. Normally the data structure to be used should be dictated by how the data stored will be access or added.


About memory consumption. You seem to be mixing some things. An array will only give you a continuous chunk of memory for the type of data that you have. Don't forget that java has a fixed data types: boolean, char, int, long, float and Object (this include all objects, even an array is an Object). It means that if you declare an array of String strings [1000] or MyObject myObjects [1000] you only get a 1000 memory boxes big enough to store the location (references or pointers) of the objects. You don't get a 1000 memory boxes big enough to fit the size of the objects. Don't forget that your objects are first created with "new". This is when the memory allocation is done and later a reference (their memory address) is stored in the array. The object doesn't get copied into the array only it's reference.


I don't think it makes a real difference for Strings. What is contiguous in an array of strings is the references to the strings, the strings themselves are stored at random places in memory.


Arrays vs. Lists can make a difference for primitive types, not for objects. IF you know in advance the number of elements, and don't need flexibility, an array of millions of integers or doubles will be more efficient in memory and marginally in speed than a list, because indeed they will be stored contiguously and accessed instantly. That's why Java still uses arrays of chars for strings, arrays of ints for image data, etc.


Array is faster - all memory is pre-allocated in advance.


A lot of microbenchmarks given here have found numbers of a few nanoseconds for things like array/ArrayList reads. This is quite reasonable if everything is in your L1 cache.


A higher level cache or main memory access can have order of magnitude times of something like 10nS-100nS, vs more like 1nS for L1 cache. Accessing an ArrayList has an extra memory indirection, and in a real application you could pay this cost anything from almost never to every time, depending on what your code is doing between accesses. And, of course, if you have a lot of small ArrayLists this might add to your memory use and make it more likely you'll have cache misses.


The original poster appears to be using just one and accessing a lot of contents in a short time, so it should be no great hardship. But it might be different for other people, and you should watch out when interpreting microbenchmarks.


Java Strings, however, are appallingly wasteful, especially if you store lots of small ones (just look at them with a memory analyzer, it seems to be > 60 bytes for a string of a few characters). An array of strings has an indirection to the String object, and another from the String object to a char[] which contains the string itself. If anything's going to blow your L1 cache it's this, combined with thousands or tens of thousands of Strings. So, if you're serious - really serious - about scraping out as much performance as possible then you could look at doing it differently. You could, say, hold two arrays, a char[] with all the strings in it, one after another, and an int[] with offsets to the starts. This will be a PITA to do anything with, and you almost certainly don't need it. And if you do, you've chosen the wrong language.


It depends on how you have to access it.


After storing, if you mainly want to do search operation, with little or no insert/delete, then go for Array (as search is done in O(1) in arrays, whereas add/delete may need re-ordering of the elements).


After storing, if your main purpose is to add/delete strings, with little or no search operation, then go for List. 


ArrayList internally uses  array  object to add(or store) the
  elements. In other words, ArrayList is backed by Array data
  -structure.The array of ArrayList is resizable (or dynamic).


Array is faster than Array because ArrayList internally use array. if we can directly add elements in Array and indirectly add element in 
Array through ArrayList always directly mechanism is faster than indirectly mechanism.


There are two overloaded add() methods in ArrayList class:
1.  add(Object)  : adds object to the end of the list.
2.  add(int index , Object )  : inserts the specified object at the specified position in the list.


How the size of ArrayList grows dynamically? 


Important point to note from above code is that we are checking the capacity of the ArrayList , before adding the element. ensureCapacity()  determines what is the current size of occupied elements and what is the maximum size of the array. If size of the  filled elements (including the new element to be added to the ArrayList class) is greater than the  maximum size of the array then increase the size of array. But the size of the array can not be increased dynamically. So what happens internally is new Array is created with capacity


Till Java 6


(Update) From Java 7


also, data from the old array is copied into the new array.


Having overhead methods in ArrayList that's why Array is faster than ArrayList.


Arrays - It would always be better when we have to achieve faster fetching of results


Lists- Performs results on insertion and deletion since they can be done in O(1) and this also provides methods to add, fetch and delete data easily. Much easier to use.


But always remember that the fetching of data would be fast when the index position in array where the data is stored - is known. 


This could be achieved well by sorting the array. Hence this increases the time to fetch the data (ie; storing the data + sorting the data + seek for the position where the data is found). Hence this increases additional latency to fetch the data from the array even they may be good at fetching the data sooner.


Hence this could be solved with trie data structure or ternary data structure. As discussed above the trie data structure would be very efficient in searching for the data the search for a particularly word can be done in O(1) magnitude. When time matters ie; if you have to search and retrieve data quickly you may go with trie data structure. 


If you want your memory space to be consumed less and you wish to have a better performance then go with ternary data structure. Both these are suitable for storing huge number of strings (eg; like words contained in dictionary).






I asked this question to get to know how to increase the runtime call stack size in the JVM. I've got an answer to this, and I've also got many useful answers and comments relevant to how Java handles the situation where a large runtime stack is needed. I've extended my question with the summary of the responses.


Originally I wanted to increase the JVM stack size so programs like runs without a StackOverflowError.


The corresponding configuration setting is the java -Xss... command-line flag with a large enough value. For the program TT above, it works like this with OpenJDK's JVM:


One of the answers has also pointed out that the -X... flags are implementation dependent. I was using


It is also possible to specify a large stack only for one thread (see in one of the answers how). This is recommended over java -Xss... to avoid wasting memory for threads that don't need it.


I was curious how large a stack the program above exactly needs, so I've run it n increased:


From the numbers above it seems that Java is using about 16 bytes per stack frame for the function above, which is reasonable.


The enumeration above contains can be enough instead of is enough, because the stack requirement is not deterministic: running it multiple times with the same source file and the same -Xss... sometimes succeeds and sometimes yields a StackOverflowError. E.g. for 1 << 20, -Xss18m was enough in 7 runs out of 10, and -Xss19m wasn't always enough either, but -Xss20m was enough (in all 100 runs out of 100). Does garbage collection, the JIT kicking in, or something else cause this nondeterministic behavior?


The stack trace printed at a StackOverflowError (and possibly at other exceptions as well) shows only the most recent 1024 elements of the runtime stack. An answer below demonstrates how to count the exact depth reached (which might be a lot larger than 1024).


Many people who responded has pointed out that it is a good and safe coding practice to consider alternative, less stack-hungry implementations of the same algorithm. In general, it is possible to convert to a set of recursive functions to iterative functions (using a e.g. Stack object, which gets populated on the heap instead of on the runtime stack). For this particular fact function, it is quite easy to convert it. My iterative version would look like:


FYI, as the iterative solution above shows it, the fact function cannot compute the exact factorial of numbers above 65 (actually, even above 20), because the Java built-in type long would overflow. Refactoring fact so it would return a BigInteger instead of long would yield exact results for large inputs as well.


Hmm... it works for me and with far less than 999MB of stack:


(Windows JDK 7, build 17.0-b05 client VM, and Linux JDK 6 - same version information as you posted)


I assume you calculated the "depth of 1024" by the recurring lines in the stack trace?
Obviously, the stack trace array length in Throwable seems to be limited to 1024,
try the following program:


If you want to play with the thread stack size, you'll want to look at the -Xss option on the Hotspot JVM.  It may be something different on non Hotspot VM's since the -X parameters to the JVM are distribution specific, IIRC.


On Hotspot, this looks like java -Xss16M if you want to make the size 16 megs.


Type java -X -help if you want to see all of the distribution specific JVM parameters you can pass in.  I am not sure if this works the same on other JVMs, but it prints all of Hotspot specific parameters.


For what it's worth - I would recommend limiting your use of recursive methods in Java.  It's not too great at optimizing them - for one the JVM doesn't support tail recursion (see Does the JVM prevent tail call optimizations?).  Try refactoring your factorial code above to use a while loop instead of recursive method calls. 


The only way to control the size of stack within process is start a new Thread. But you can also control by creating a self-calling sub java process with -Xss parameter.


Weird! You are saying that you want to generate a recursion of 1<<15 depth???!!!!


I'd suggest DON'T try it. The size of the stack will be 2^15 * sizeof(stack-frame). I don't know what stack-frame size is, but 2^15 is 32.768. Pretty much... Well, if it stops at 1024 (2^10) you'll have to make it 2^5 times bigger, it is, 32 times bigger than with your actual setting.


It is hard to give a sensible solution since you are keen to avoid all sane approaches. Refactoring one line of code is the senible solution.  


Note: Using -Xss sets the stack size of every thread and is a very bad idea.


Another approach is byte code manipulation to change the code as follows;


given every answer for n > 127 is 0. This avoid changing the source code.


Add this option 


--driver-java-options -Xss512m


to your spark-submit command will fix this issue.


Other posters have pointed out how to increase memory and that you could memoize calls. I'd suggest that for many applications, you can use Stirling's formula to approximate large n! very quickly with almost no memory footprint.


Take a gander at this post, which has some analysis of the function and code:


http://threebrothers.org/brendan/blog/stirlings-approximation-formula-clojure/


I did Anagram excersize, which is like Count Change problem but with 50 000 denominations (coins). I am not sure that it can be done iteratively, I do not care. I just know that the -xss option had no effect -- I always failed after 1024 stack frames (might be scala does bad job delivering to to java or printStackTrace limitation. I do not know). This is bad option, as explained anyway. You do not want all threads in to app to be monstrous. However, I did some experiments with new Thread (stack size). This works indeed, 


You see that stack can grow exponentially deeper with exponentially more stack alloted to the thread.


try jvm parameter:  -Xmx128m






So, I'm getting stuck with this piece of code:


and here is my output:


Insert a integer number:
   Invalid value!
  Insert a integer number:
   Invalid value!
  ...


As per the javadoc for Scanner:


When a scanner throws an
  InputMismatchException, the scanner
  will not pass the token that caused
  the exception, so that it may be
  retrieved or skipped via some other
  method.


That means that if the next token is not an int, it throws the InputMismatchException, but the token stays there. So on the next iteration of the loop, reader.nextInt() reads the same token again and throws the exception again. What you need is to use it up. Add a reader.next() inside your catch to consume the token, which is invalid and needs to be discarded.


What I would do is read in the whole line using Scanner.nextLine(). Then create another scanner that reads the returned string.


This would make your sample function something like this:


This way you have one scanner that gets the input and one that validates it so you don't have to worry about reader caring if they input the correct form of input. 


The guard of your while-do is 'loop' variable.


The exception itself thrown before your code reaches assignment loop = false;
To be precise, the exception is thrown in previous statement which is num = reader.nextInt();


When exception thrown, value of 'loop' variable is 'true' but your code jumps to catch block and then repeats the while-do. This while-do will never stop because next iteration will throw an exception again, jumps to catch block again and so on.


To terminate this while-do, you need to guard your while-do with another logical thing such as :


This can be done in catch block or some other lines. But precise solution depends on your specifications.


You may also try this:


Personally i use BufferedReader and InputStreamReader to read String and check if is a number or not, but with scanner is less code. The code is checked and run ok.






When comparing arrays in Java, are there any differences between the following 2 statements?


And if so what are they?


array1.equals(array2) is the same as array1 == array2, i.e. is it the same array. As @alf points out it's not what most people expect.


Arrays.equals(array1, array2) compares the contents of the arrays.


Similarly array.toString() may not be very useful and you need to use Arrays.toString(array).


It's an infamous problem: .equals() for arrays is badly broken, just don't use it, ever.


That said, it's not "broken" as in "someone has done it in a really wrong way" — it's just doing what's defined and not what's usually expected. So for purists: it's perfectly fine, and that also means, don't use it, ever.


Now the expected behaviour for equals is to compare data. The default behaviour is to compare the identity, as Object does not have any data (for purists: yes it has, but it's not the point); assumption is, if you need equals in subclasses, you'll implement it. In arrays, there's no implementation for you, so you're not supposed to use it.


So the difference is, Arrays.equals(array1, array2) works as you would expect (i.e. compares content), array1.equals(array2) falls back to Object.equals implementation, which in turn compares identity, and thus better replaced by == (for purists: yes I know about null).


Problem is, even Arrays.equals(array1, array2) will bite you hard if elements of array do not implement equals properly. It's a very naive statement, I know, but there's a very important less-than-obvious case: consider a 2D array. 


2D array in Java is an array of arrays, and arrays' equals is broken (or useless if you prefer), so Arrays.equals(array1, array2) will not work as you expect on 2D arrays.


Hope that helps.


Look inside the implementation of the two methods to understand them deeply:


while:


Sigh. Back in the 70s I was the "system programmer" (sysadmin) for an IBM 370 system, and my employer was a member of the IBM users group SHARE. It would sometimes happen thatsomebody submitted an APAR (bug report) on some unexpected behavior of some CMS command, and IBM would respond NOTABUG: the command does what it was designed to do (and what the documentation says).


SHARE came up with a counter to this: BAD -- Broken As Designed. I think this might apply to this implementation of equals for arrays.


There's nothing wrong with the implementation of Object.equals. Object has no data members, so there is nothing to compare. Two "Object"s are equal if and only if they are, in fact, the same Object (internally, the same address and length).


But that logic doesn't apply to arrays. Arrays have data, and you expect comparison (via equals) to compare the data. Ideally, the way Arrays.deepEquals does, but at least the way Arrays.equals does (shallow comparison of the elements).


So the problem is that array (as a built-in object) does not override Object.equals. String (as a named class) does override Object.equals and give the result you expect.


Other answers given are correct: [...].equals([....]) simply compares the pointers and not the contents. Maybe someday somebody will correct this. Or maybe not: how many existing programs would break if [...].equals actually compared the elements? Not many, I suspect, but more than zero.


Arrays inherit equals() from Object and hence compare only returns true if comparing an array against itself.


On the other hand, Arrays.equals compares the elements of the arrays.


This snippet elucidates the difference:


See also Arrays.equals(). Another static method there may also be of interest: Arrays.deepEquals().


The Arrays.equals(array1, array2) : 


check if both arrays contain the same number of elements, and all corresponding pairs of elements in the two arrays are equal.


The array1.equals(array2) :


compare the object to another object and return true only if the reference of the two object are equal as in the Object.equals()


The equals() of arrays is inherited from Object, so it does not look at the contents of the arrrays, it only considers each array equal to itself.


The Arrays.equals() methods do compare the arrays' contents. There's overloads for all primitive types, and the one for objects uses the objects' own equals() methods.






I'm creating an application using the NetBeans GUI Editor, in which I want to have a JSplitPane, the top component of which will be a Canvas within a JScrollPane and the bottom component will be a JTextArea, or something like that.


When I pull the divider downwards, and thus increasing the size of the top component everything seem to resize just fine.


The problem appears when I'm trying to push the divider upwards:
The divider seems to go beneath the Canvas (and maybe beneath the JScrollPane too).


I have tried various combinations of the preferred/minimum/maximum sizes of the JScrollPane and Canvas but nothing seems to work.


This is the part of the code that Netbeans generated that may have something to do with the problem at hand:


Since this is my first question, I'm not allowed to embed an image in the question, so I will just post the link:





The red arrows indicate the position of the divider.


Thanks in advance for your time.


Instead of setPreferredSize(), let your components calculate their own preferred size and pack() the enclosing Window to accommodate. The example below adds an instance of draw.GraphPanel to the top and a corresponding control panel to the bottom.





As I said in my comments, you should not mix AWT and Swing components. I think you are not using the components in the correct way. Take a look, it is a simple example of how to use a JSplitPane.


After reading the comment by davidbuzatto I googled about mixing AWT and Swing components and I was a little surprissed to find out that it is such a bad practice. 


I found the most accurate answer to my question here


Heavyweight components have their own Z-ordering. This is the reason why Swing and AWT cannot be combined in a single container. If they are, the AWT components will be drawn on TOP of Swing components.


For example: When AWT components are used with JtabbedPane, they do not disappear when the tabs are switched. 


Thanks davidbuzatto for showing me the way :-)






I know that if you compare a boxed primitive Integer with a constant such as:


a will automatically be unboxed and the comparison will work.


However, what happens when you are comparing two boxed Integers and want to compare either equality or less than/greater than?


Will above code result in checking to see if they are the same object, or will it auto-unbox in that case?


What about:


?


No, == between Integer, Long etc will check for reference equality - i.e.


this will check whether x and y refer to the same object rather than equal objects.


So


is guaranteed to print false. Interning of "small" autoboxed values can lead to tricky results:


This will print true, due to the rules of boxing (JLS section 5.1.7). It's still reference equality being used, but the references genuinely are equal.


Personally I'd use:


or


The latter is slightly less efficient - there isn't an overload for Integer.equals(Integer) so it will have to do execution time type checking, whereas the first uses the fact that we already know that both objects are Integers.


Fortunately, compareTo knows about the types, so:


should still be efficient. Of course, this is micro-optimisation territory and you should use the code you find clearest - after making sure it's correct :)


As you say, for any comparison between a wrapper type (Integer, Long etc) and a numeric type (int, long etc) the wrapper type value is unboxed and the test is applied to the primitive values involved.


This occurs as part of binary numeric promotion (JLS section 5.6.2). Look at each individual operator's documentation to see whether it's applied. For example, from the docs for == and != (JLS 15.21.1):


If the operands of an equality
  operator are both of numeric type, or
  one is of numeric type and the other
  is convertible (§5.1.8) to numeric
  type, binary numeric promotion is
  performed on the operands (§5.6.2).


and for <, <=, > and >= (JLS 15.20.1)


The type of each of the operands of a
  numerical comparison operator must be
  a type that is convertible (§5.1.8) to
  a primitive numeric type, or a
  compile-time error occurs. Binary
  numeric promotion is performed on the
  operands (§5.6.2). If the promoted
  type of the operands is int or long,
  then signed integer comparison is
  performed; if this promoted type is
  float or double, then floating-point
  comparison is performed.


Note how none of this is considered as part of the situation where neither type is a numeric type.


== will still test object equality.  It is easy to be fooled, however:


Your examples with inequalities will work since they are not defined on Objects.  However, with the == comparison, object equality will still be checked.  In this case, when you initialize the objects from a boxed primitive, the same object is used (for both a and b).  This is an okay optimization since the primitive box classes are immutable.


== checks for reference equality, however when writing code like:


Java is smart enough to reuse the same immutable for a and b, so this is true: a == b.  Curious, I wrote a small example to show where java stops optimizing in this way:


When I compile and run this (on my machine), I get:


tl;dr my opinion is to use a unary + to trigger the unboxing on one of the operands when checking for value equality, and simply use the maths operators otherwise. Rationale follows:


It has been mentioned already that == comparison for Integer is identity comparison, which is usually not what a programmer want, and that the aim is to do value comparison; still, I've done a little science about how to do that comparison most efficiently, both in term of code compactness, correctness and speed.


I used the usual bunch of methods:


and got this code after compilation and decompilation:


As you can easily see, method 1 calls Integer.equals() (obviously), methods 2-4 result in exactly the same code, unwrapping the values by means of .intValue() and then comparing them directly, and method 5 just triggers an identity comparison, being the incorrect way to compare values.


Since (as already mentioned by e.g. JS) equals() incurs an overhead (it has to do instanceof and an unchecked cast), methods 2-4 will work with exactly the same speed, noticingly better than method 1 when used in tight loops, since HotSpot is not likely to optimize out the casts & instanceof.


It's quite similar with other comparison operators (e.g. </>) - they will trigger unboxing, while using compareTo() won't - but this time, the operation is highly optimizable by HS since intValue() is just a getter method (prime candidate to being optimized out).


In my opinion, the seldom used version 4 is the most concise way - every seasoned C/Java developer knows that unary plus is in most cases equal to cast to int/.intValue() - while it may be a little WTF moment for some (mostly those who didn't use unary plus in their lifetime), it arguably shows the intent most clearly and most tersely - it shows that we want an int value of one of the operands, forcing the other value to unbox as well. It is also unarguably most similar to the regular i1 == i2 comparison used for primitive int values.


My vote goes for i1 == +i2 & i1 > i2 style for Integer objects, both for performance & consistency reasons. It also makes the code portable to primitives without changing anything other than the type declaration. Using named methods seems like introducing semantic noise to me, similar to the much-criticized bigInt.add(10).multiply(-3) style.


Calling


Will work most of the time, but it's not guaranteed to always work, so do not use it.


The most proper way to compare two Integer classes for equality, assuming they are named 'a' and 'b' is to call:


You can also use this way which is slightly faster.


On my machine 99 billion operations took 47 seconds using the first method, and 46 seconds using the second method. You would need to be comparing billions of values to see any difference.


Note that 'a' may be null since it's an Object. Comparing in this way will not cause a null pointer exception.


For comparing greater and less than, use


this method compares two Integer with null check, see tests






Is there a way in Java/J2ME to convert a string, such as:


to an internal Object representation of the same, in one line of code? 


Because the current method is too tedious:


Maybe a JSON library?


I used a few of them and my favorite is,


http://code.google.com/p/json-simple/


The library is very small so it's perfect for J2ME. 


You can parse JSON into Java object in one line like this,


The simplest option is Jackson:


There are other similarly simple to use libraries (Gson was already mentioned); but some choices are more laborious, like original org.json library, which requires you to create intermediate "JSONObject" even if you have no need for those.


GSON is a good option to convert java object to json object and vise versa.
It is a tool provided by google.


for converting json to java object use: fromJson(jsonObject,javaclassname.class)
for converting java object to json object use: toJson(javaObject)
and rest will be done automatically


For more information and for download


You can do this easily with Google GSON.


Let's say you have a class called User with the fields user, width, and height and you want to convert the following json string to the User object.


{"name":"MyNode", "width":200, "height":100}


You can easily do so, without having to cast (keeping nimcap's comment in mind ;) ), with the following code:


Where jsonString is the above JSON String.


For more information, please look into https://code.google.com/p/google-gson/


You have many JSON parsers for Java:


JSONObject.java
A JSONObject is an unordered collection of name/value pairs. Its external form is a string wrapped in curly braces with colons between the names and values, and commas between the values and names. The internal form is an object having get()  and opt() methods for accessing the values by name, and put() methods for adding or replacing values by name. The values can be any of these types: Boolean, JSONArray, JSONObject, Number, and String, or the JSONObject.NULL object.


JSONArray.java
A JSONArray is an ordered sequence of values. Its external form is a string wrapped in square brackets with commas between the values. The internal form is an object having get() and opt() methods for accessing the values by index, and put() methods for adding or replacing values. The values can be any of these types: Boolean, JSONArray, JSONObject, Number, and String, or the JSONObject.NULL object.


JSONStringer.java
A JSONStringer is a tool for rapidly producing JSON text.


JSONWriter.java
A JSONWriter is a tool for rapidly writing JSON text to streams.


JSONTokener.java
A JSONTokener takes a source string and extracts characters and tokens from it. It is used by the JSONObject and JSONArray constructors to parse JSON source strings.


JSONException.java
A JSONException is thrown when a syntax or procedural error is detected.


JSONString.java
The JSONString is an interface that allows classes to implement their JSON serialization.


JSON official site is where you should look at. It provides various libraries which can be used with Java, I've personally used this one, JSON-lib which is an implementation of the work in the site, so it has exactly the same class - methods etc in this page. 


If you click the html links there you can find anything you want. 


In short: 


to create a json object and a json array, the code is: 


o1, o2, can be primitive types (long, int, boolean), Strings or Arrays. 


The reverse process is fairly simple, I mean converting a string to json object/array. 


In order to be correctly parsed you just have to know if you are parsing an array or an object. 


Use google GSON library for this


http://iandjava.blogspot.in/2014/01/java-object-to-json-and-json-to-java.html


Like many stated already, A pretty simple way to do this using JSON.simple as below


And then use jsonObj to deal with JSON Object. e.g jsonObj.get("name");


As per the below link, JSON.simple is showing constant efficiency for both small and large JSON files


http://blog.takipi.com/the-ultimate-json-library-json-simple-vs-gson-vs-jackson-vs-json/


JSON IO is by far the easiest way to convert a JSON string or JSON input stream to a Java Object


String to Java Object
Object obj = JsonReader.jsonToJava("[\"Hello, World\"]");


https://code.google.com/p/json-io/


This is an old question and json-simple (https://code.google.com/p/json-simple/) could be a good solution at that time, but please consider that project seems not to be active for a while ! 


I suggest the Gson which is now hosted at: https://github.com/google/gson


If performance is your issue you can have a look at some benchmarks http://blog.takipi.com/the-ultimate-json-library-json-simple-vs-gson-vs-jackson-vs-json/ which compare.


Apart from www.json.org you can also implement your own parser using javacc and matching your personnal grammar/schema.
See this note on my blog : http://plindenbaum.blogspot.com/2008/07/parsing-json-with-javacc-my-notebook.html


I've written a library that uses json.org to parse JSON, but it will actually create a proxy of an interface for you. The code/JAR is on code.google.com.


http://fixjures.googlecode.com/


I don't know if it works on J2ME. Since it uses Java Reflection to create proxies, I'm thinking it won't work. Also, it's currently got a hard dependency on Google Collections which I want to remove and it's probably too heavyweight for your needs, but it allows you to interact with your JSON data in the way you're looking for:


Jackson for big files, GSON for small files, and JSON.simple for handling both.


Just make a Json object in java with the following Json String.In your case 


if the above is your Json string , just create a Json Object with it.






I have 2 matrices and I need to multiply them and then print the results of each cell. As soon as one cell is ready I need to print it, but for example I need to print the [0][0] cell before cell [2][0] even if the result of [2][0] is ready first. So I need to print it by order.
So my idea is to make the printer thread wait until the multiplyThread notifies it that the correct cell is ready to be printed and then the printerThread will print the cell and go back to waiting and so on..


So I have this thread that does the multiplication:


Thread that prints the result of each cell:


Now it throws me these exceptions:


line 49 in multiplyThread is the "notify()"..I think I need to use the synchronized differently but I am not sure how.


If anyone can help this code to work I will really appreciate it.


To be able to call notify() you need to synchronize on the same object.


While using the wait and notify or notifyAll methods in Java the following things must be remembered:


Do you need to thread this at all ? I'm wondering how big your matrices are, and whether there's any benefit in having one thread print whilst the other does the multiplication. 


Perhaps it would be worth measuring this time before doing the relatively complex threading work ?


If you do need to thread it, I would create 'n' threads to perform the multiplication of the cells (perhaps 'n' is the number of cores available to you), and then use the ExecutorService and Future mechanism to dispatch multiple multiplications simultaneously. 


That way you can optimise the work based on the number of cores, and you're using the higher level Java threading tools (which should make life easier). Write the results back into a receiving matrix, and then simply print this once all your Future tasks have completed.


Let's say you have 'black box' application with some class named BlackBoxClass that has method doSomething();.


Further, you have observer or listener named onResponse(String resp) that will be called by BlackBoxClass after unknown time.


The flow is simple: 


Lets say we don't know what is going on with BlackBoxClass and when we should  get answer but you don't want to continue your code till you get answer or in other word get onResponse call. Here enters 'Synchronize helper':


Now we can implement what we want:


You can only call notify on objects where you own their monitor. So you need something like


notify() needs to be synchronized as well


I'll right simple example show you the right way  to use wait and notify in Java.
So I'll create two class named ThreadA & ThreadB. ThreadA will call ThreadB. 


and for Class ThreadB:


we can call notify to resume the execution of waiting objects as


resume this by invoking notify on another object of same class


Simple use if you want How to execute threads alternatively :-


responce :-


For this particular problem, why not store up your various results in variables and then when the last of your thread is processed you can print in whatever format you want. This is especially useful if you are gonna be using your work history in other projects.


This looks like a situation for producer-consumer pattern. If you’re using java 5 or up, you may consider using blocking queue(java.util.concurrent.BlockingQueue) and leave the thread coordination work to the underlying framework/api implementation.
See the example from
java 5:
http://docs.oracle.com/javase/1.5.0/docs/api/java/util/concurrent/BlockingQueue.html
or java 7 (same example):
http://docs.oracle.com/javase/7/docs/api/java/util/concurrent/BlockingQueue.html


You have properly guarded your code block when you call wait() method by using synchronized(this). 


But you have not taken same precaution when you call notify() method without using guarded block : synchronized(this) or synchronized(someObject)


If you refer to oracle documentation page on Object class, which contains wait() ,notify(), notifyAll() methods, you can see below precaution in all these three methods


This method should only be called by a thread that is the owner of this object's monitor


Many things have been changed in last 7 years and let's have look into other alternatives to synchronized in below SE questions:


Why use a ReentrantLock if one can use synchronized(this)?


Synchronization vs Lock


Avoid synchronized(this) in Java?






In Maven, dependencies are usually set up like this:


Now, if you are working with libraries that have frequent releases, constantly updating the <version> tag can be somewhat annoying. Is there any way to tell Maven to always use the latest available version (from the repository)? 


NOTE: This answer applies to Maven 2 only! The mentioned LATEST and RELEASE metaversions have been dropped in Maven 3 "for the sake of reproducible builds", over 6 years ago.


If you  always want to use the newest version, Maven has two keywords you can use as an alternative to version ranges. You should use these options with care as you are no longer in control of the plugins/dependencies you are using.


When you depend on a plugin or a dependency, you can use the a version value of LATEST or RELEASE. LATEST refers to the latest released or snapshot version of a particular artifact, the most recently deployed artifact in a particular repository. RELEASE refers to the last non-snapshot release in the repository. In general, it is not a best practice to design software which depends on a non-specific version of an artifact. If you are developing software, you might want to use RELEASE or LATEST as a convenience so that you don't have to update version numbers when a new release of a third-party library is released. When you release software, you should always make sure that your project depends on specific versions to reduce the chances of your build or your project being affected by a software release not under your control. Use LATEST and RELEASE with caution, if at all.


See the POM Syntax section of the Maven book for more details. Or see this doc on Dependency Version Ranges, where: 


Here's an example illustrating the various options. In the Maven repository, com.foo:my-foo has the following metadata:


If a dependency on that artifact is required, you have the following options (other version ranges can be specified of course, just showing the relevant ones here):


Declare an exact version (will always resolve to 1.0.1):


Declare an explicit version (will always resolve to 1.0.1 unless a collision occurs, when Maven will select a matching version):


Declare a version range for all 1.x (will currently resolve to 1.1.1):


Declare an open-ended version range (will resolve to 2.0.0):


Declare the version as LATEST (will resolve to 2.0.0) (removed from maven 3.x)


Declare the version as RELEASE (will resolve to 1.1.1) (removed from maven 3.x):


Note that by default your own deployments will update the "latest" entry in the Maven metadata, but to update the "release" entry, you need to activate the "release-profile" from the Maven super POM. You can do this with either "-Prelease-profile" or "-DperformRelease=true"


It's worth emphasising that any approach that allows Maven to pick the dependency versions (LATEST, RELEASE, and version ranges) can leave you open to build time issues, as later versions can have different behaviour (for example the dependency plugin has previously switched a default value from true to false, with confusing results).


It is therefore generally a good idea to define exact versions in releases. As Tim's answer points out, the maven-versions-plugin is a handy tool for updating dependency versions, particularly the versions:use-latest-versions and versions:use-latest-releases goals.


Now I know this topic is old, but reading the question and the OP supplied answer it seems the Maven Versions Plugin might have actually been a better answer to his question:


In particular the following goals could be of use:


The following other goals are also provided:


Just thought I'd include it for any future reference.


Please take a look at this page (section "Dependency Version Ranges"). What you might want to do is something like 


These version ranges are implemented in Maven2.


Unlike others I think there are many reasons why you might always want the latest version. Particularly if you are doing continuous deployment (we sometimes have like 5 releases in a day) and don't want to do a multi-module project.


What I do is make Hudson/Jenkins do the following for every build:


That is I use the versions plugin and scm plugin to update the dependencies and then check it in to source control. Yes I let my CI do SCM checkins (which you have to do anyway for the maven release plugin).


You'll want to setup the versions plugin to only update what you want:


I use the release plugin to do the release which takes care of -SNAPSHOT and validates that there is a release version of -SNAPSHOT (which is important).


If you do what I do you will get the latest version for all snapshot builds and the latest release version for release builds. Your builds will also be reproducible.


Update


I noticed some comments asking some specifics of this workflow. I will say we don't use this method anymore and the big reason why is the maven versions plugin is buggy and in general is inherently flawed.


It is flawed because to run the versions plugin to adjust versions all the existing versions need to exist for the pom to run correctly. That is the versions plugin cannot update to the latest version of anything if it can't find the version referenced in the pom. This is actually rather annoying as we often cleanup old versions for disk space reasons.


Really you need a separate tool from maven to adjust the versions (so you don't depend on the pom file to run correctly). I have written such a tool in the the lowly language that is Bash. The script will update the versions like the version plugin and check the pom back into source control. It also runs like 100x faster than the mvn versions plugin. Unfortunately it isn't written in a manner for public usage but if people are interested I could make it so and put it in a gist or github.


Going back to workflow as some comments asked about that this is what we do:


At this point I'm of the opinion it is a good thing to have the release and auto version a separate tool from your general build anyway.


Now you might think maven sort of sucks because of the problems listed above but this actually would be fairly difficult with a build tool that does not have a declarative easy to parse extendable syntax (aka XML).


In fact we add custom XML attributes through namespaces to help hint bash/groovy scripts (e.g. don't update this version). 


The dependencies syntax is located at the Dependency Version Requirement Specification documentation. Here it is is for completeness:


Dependencies' version element define version requirements, used to compute effective dependency version. Version requirements have the following syntax:


In your case, you could do something like <version>[1.2.3,)</version>


Are you possibly depending on development versions that obviously change a lot during development? 


Instead of incrementing the version of development releases, you could just use a snapshot version that you overwrite when necessary, which means you wouldn't have to change the version tag on every minor change. Something like 1.0-SNAPSHOT...


But maybe you are trying to achieve something else ;)


Who ever is using LATEST, please make sure you have -U otherwise the latest snapshot won't be pulled.


By the time this question was posed there were some kinks with version ranges in maven, but these have been resolved in newer versions of maven.
This article captures very well how version ranges work and best practices to better understand how maven understands versions: https://docs.oracle.com/middleware/1212/core/MAVEN/maven_version.htm#MAVEN8855


The truth is even in 3.x it still works, surprisingly the projects builds and deploys. But the  LATEST/RELEASE keyword causing problems in m2e and eclipse all over the place, ALSO projects depends on the dependency which deployed through the  LATEST/RELEASE fail to recognize the version. 


It will also causing problem if you are try to define the version as property, and reference it else where.


So the conclusion is use the versions-maven-plugin if you can.


Sometimes you don't want to use version ranges, because it seems that they are "slow" to resolve your dependencies, especially when there is continuous delivery in place and there are tons of versions - mainly during heavy development.


One workaround would be to use the versions-maven-plugin. For example, you can declare a property:


and add the versions-maven-plugin to your pom file:


Then, in order to update the dependency, you have to execute the goals:


If there is a version newer than 1.1.1, it will tell you:






I am looking to implement a sort feature for my address book application.


I want to sort an ArrayList<Contact> contactArray. Contact is a class which contains four fields: name, home number, mobile number and address. I want to sort on name.


How can I write a custom sort function to do this?


Here's a tutorial about ordering objects:


Although I will give some examples, I would recommend to read it anyway.


There are various way to sort an ArrayList. If you want to define a natural (default) ordering, then you need to let Contact implement Comparable. Assuming that you want to sort by default on name, then do (nullchecks omitted for simplicity):


so that you can just do


If you want to define an external controllable ordering (which overrides the natural ordering), then you need to create a Comparator:


You can even define the Comparators in the Contact itself so that you can reuse them instead of recreating them everytime:


which can be used as follows:


And to cream the top off, you could consider to use a generic javabean comparator:


which you can use as follows:


(as you see in the code, possibly null fields are already covered to avoid NPE's during sort)


In addition to what was already posted you should know that since Java 8 we can shorten our code and write it like:


or since List now have sort method 


Since Java 8, functional interfaces (interfaces with only one abstract method - they can have more default or static methods) can be easily implemented using:


Since Comparator<T> has only one abstract method int compare(T o1, T o2) it is functional interface.


So instead of (example from @BalusC answer)


we can reduce this code to:


We can simplify this (or any) lambda by skipping 


So instead of  


we can write


Also now Comparator has static methods like comparing(FunctionToComparableValue) or comparing(FunctionToValue, ValueComparator) which we could use to easily create Comparators which should compare some specific values from objects. 


In other words we can rewrite above code as


This page tells you all you need to know about sorting collections, such as ArrayList.


Basically you need to


There's another way as well, involving creating a Comparator class, and you can read about that from the linked page as well.


Example:


BalusC and bguiz have already given very complete answers on how to use Java's built-in Comparators.


I just want to add that google-collections has an Ordering class which is more "powerful" than the standard Comparators.
It might be worth checking out. You can do cool things such as compounding Orderings, reversing them, ordering depending on a function's result for your objects...


Here is a blog post that mentions some of its benefits.


You need make your Contact classes implement Comparable, and then implement the compareTo(Contact) method.  That way, the Collections.sort will be able to sort them for you.  Per the page I linked to, compareTo 'returns a negative integer, zero, or a positive integer as this object is less than, equal to, or greater than the specified object.'


For example, if you wanted to sort by name (A to Z), your class would look like this:


By using lambdaj you can sort a collection of your contacts (for example by their name) as it follows


or by their address:


and so on. More in general, it offers a DSL to access and manipulate your collections in many ways, like filtering or grouping your contacts based on some conditions, aggregate some of their property values, etc.


The Collections.sort is a good sort implementation. If you don't have The comparable implemented for Contact, you will need to pass in a Comparator implementation


Of note:


The sorting algorithm is a modified mergesort (in which the merge is omitted if the highest element in the low sublist is less than the lowest element in the high sublist). This algorithm offers guaranteed n log(n) performance. The specified list must be modifiable, but need not be resizable. This implementation dumps the specified list into an array, sorts the array, and iterates over the list resetting each element from the corresponding position in the array. This avoids the n2 log(n) performance that would result from attempting to sort a linked list in place. 


The merge sort is probably better than most search algorithm you can do.


I did it by the following way.
number and name are two arraylist. I have to sort name .If any change happen to name arralist order then the number arraylist also change its order.


You shoud use the Arrays.sort function. The containing classes should implement Comparable.






It is quite simple to run a Unix command from Java. 


But is it possible to run a Unix shell script from Java code? If yes, would it be a good practice to run a shell script from within Java code?


You should really look at Process Builder.  It is really built for this kind of thing.


I would say that it is not in the spirit of Java to run a shell script from Java. Java is meant to be cross platform, and running a shell script would limit its use to just UNIX.


With that said, it's definitely possible to run a shell script from within Java. You'd use exactly the same syntax you listed (I haven't tried it myself, but try executing the shell script directly, and if that doesn't work, execute the shell itself, passing the script in as a command line parameter).


I think you have answered your own question with


As to whether it is good practice... what are you trying to do with a shell script that you cannot do with Java?


You can use Apache Commons exec library also.


Example :


For further reference, An example is given on Apache Doc also.


Yes it is possible to do so. This worked out for me.


As for me all things must be simple. 
For running script just need to execute


Here is my example. Hope it make sense.


To avoid having to hardcode an absolute path, you can use the following method that will find and execute your script if it is in your root directory.


It is possible, just exec it as any other program.  Just make sure your script has the proper #! (she-bang) line as the first line of the script, and make sure there are execute permissions on the file.


For example, if it is a bash script put #!/bin/bash at the top of the script, also chmod +x  .


Also as for if it's good practice, no it's not, especially for Java, but if it saves you a lot of time porting a large script over, and you're not getting paid extra to do it ;) save your time, exec the script, and put the porting to Java on your long-term todo list.


The ZT Process Executor library is an alternative to Apache Commons Exec. It has functionality to run commands, capturing their output, setting timeouts, etc.


I have not used it yet, but it looks reasonably well-documented.


An example from the documentation: Executing a command, pumping the stderr to a logger, returning the output as UTF8 string.


Its documentation lists the following advantages over Commons Exec:


Just the same thing that Solaris 5.10 it works like this ./batchstart.sh there is a trick I don´t know if your OS accept it use \\. batchstart.sh instead. This double slash may help.


I think with


Checking the operating system on can manage the shell/bash scrips  if such are supported.
if there is need to make the code portable.


Yes, it is possible and you have answered it ! About good practises, I think it is better to launch commands from files and not directely from your code. So you have to make Java execute the list of commands (or one command) in an existing .bat, .sh , .ksh ... files. 
Here is an example of executing a list of commands in a file "MyFile.sh":






When are static fields initialized? If I never instantiate a class, but I access a static field, are ALL the static blocks and private static methods used to instantiate private static fields called (in order) at that instant?


What if I call a static method? Does it also run all the static blocks? Before the method?


A class's static initialization normally happens immediately before the first time one of the following events occur:


See JLS 12.4.1.


It is also possible to force a class to initialize (if it hasn't already initialized) by using Class.forName(fqn, true, classLoader) or the short form Class.forName(fqn)


Static fields are initialized during the initialization "phase" of the class loading (loading, linking and initialization) that includes static initializers and initializations of its static fields. The static initializers are executed in a textual order as defined in the class.


Consider the example:


The Test.b prints null because when the sayHello was called in static scope, the static variable a was not initialized.


Yes, all static initializers are run before you access class first time. If it was any other way, I would call it a bug.






In java.util.Calendar, January is defined as month 0, not month 1. Is there any specific reason to that ?


I have seen many people getting confused about that...


It's just part of the horrendous mess which is the Java date/time API. Listing what's wrong with it would take a very long time (and I'm sure I don't know half of the problems). Admittedly working with dates and times is tricky, but aaargh anyway.


Do yourself a favour and use Joda Time instead, or possibly JSR-310.


EDIT: As for the reasons why - as noted in other answers, it could well be due to old C APIs, or just a general feeling of starting everything from 0... except that days start with 1, of course. I doubt whether anyone outside the original implementation team could really state reasons - but again, I'd urge readers not to worry so much about why bad decisions were taken, as to look at the whole gamut of nastiness in java.util.Calendar and find something better.


One point which is in favour of using 0-based indexes is that it makes things like "arrays of names" easier:


Of course, this fails as soon as you get a calendar with 13 months... but at least the size specified is the number of months you expect.


This isn't a good reason, but it's a reason...


EDIT: As a comment sort of requests some ideas about what I think is wrong with Date/Calendar:


C based languages copy C to some degree. The tm structure (defined in time.h) has an integer field tm_mon with the (commented) range of 0-11.


C based languages start arrays at index 0. So this was convenient for outputting a string in an array of month names, with tm_mon as the index.


Because doing math with months is much easier.


1 month after December is January, but to figure this out normally you would have to take the month number and do math


I know! I can fix this quickly by using a modulus of 12.


This works just fine for 11 months until November...


You can make all of this work again by subtracting 1 before you add the month, then do your modulus and finally add 1 back again... aka work around an underlying problem.


Now let's think about the problem with months 0 - 11.


All of the months work the same and a work around isn't necessary.


There has been alot of answers to this, but I will give my view on the subject anyway.
The reason behind this odd behavior, as stated previously, comes from the POSIX C time.h where the months where stored in an int with the range 0-11.
To explain why, look at it like this; years and days are considered numbers in spoken language, but months have their own names. So because January is the first month it will be stored as offset 0, the first array element. monthname[JANUARY] would be "January". The first month in the year is the first month array element.


The day numbers on the other hand, since they do not have names, storing them in an int as 0-30 would be confusing, add a lot of day+1 instructions for outputting and, of course, be prone to alot of bugs.


That being said, the inconsistency is confusing, especially in javascript (which also has inherited this "feature"), a scripting language where this should be abstracted far away from the langague.


TL;DR: Because months have names and days of the month do not.


Probably because C's "struct tm" does the same. 


In Java 8, there is a new Date/Time API JSR 310 that is more sane. The spec lead is the same as the primary author of JodaTime and they share many similar concepts and patterns.


I'd say laziness. Arrays start at 0 (everyone knows that); the months of the year are an array, which leads me to believe that some engineer at Sun just didn't bother to put this one little nicety into the Java code.


Personally, I took the strangeness of the Java calendar API as an indication that I needed to divorce myself from the Gregorian-centric mindset and try to program more agnostically in that respect.  Specifically, I learned once again to avoid hardcoded constants for things like months.


Which of the following is more likely to be correct?


This illustrates one thing that irks me a little about Joda Time - it may encourage programmers to think in terms of hardcoded constants.  (Only a little, though.  It's not as if Joda is forcing programmers to program badly.)


Because programmers are obsessed with 0-based indexes. OK, it's a bit more complicated than that: it makes more sense when you're working with lower-level logic to use 0-based indexing. But by and large, I'll still stick with my first sentence.


Java provides you another way to use 1 based indexes for months. Use the java.time.Month enum. One object is predefined for each of the twelve months. They have numbers assigned to each 1-12 for January-December; call getValue for the number.


Make use of Month.JULY (Gives you 7) 
instead of Calendar.JULY (Gives you 6).


For me, nobody explains it better than mindpro.com: 


Gotchas


java.util.GregorianCalendar has far fewer bugs and gotchas than the
  old java.util.Date class but it is still no picnic.


Had there been programmers when Daylight Saving Time was first
  proposed, they would have vetoed it as insane and intractable. With
  daylight saving, there is a fundamental ambiguity. In the fall when
  you set your clocks back one hour at 2 AM there are two different
  instants in time both called 1:30 AM local time. You can tell them
  apart only if you record whether you intended daylight saving or
  standard time with the reading. 


Unfortunately, there is no way to tell GregorianCalendar which you
  intended. You must resort to telling it the local time with the dummy
  UTC TimeZone to avoid the ambiguity. Programmers usually close their
  eyes to this problem and just hope nobody does anything during this
  hour.


Millennium bug. The bugs are still not out of the Calendar classes.
  Even in JDK (Java Development Kit) 1.3 there is a 2001 bug. Consider
  the following code:


The bug disappears at 7AM on 2001/01/01 for MST.


GregorianCalendar is controlled by a giant of pile of untyped int
  magic constants. This technique totally destroys any hope of
  compile-time error checking. For example to get the month you use
  GregorianCalendar. get(Calendar.MONTH));


GregorianCalendar has the raw
  GregorianCalendar.get(Calendar.ZONE_OFFSET) and the daylight savings
  GregorianCalendar. get( Calendar. DST_OFFSET), but no way to get the
  actual time zone offset being used. You must get these two separately
  and add them together.


GregorianCalendar.set( year, month, day, hour, minute) does not set
  the seconds to 0.


DateFormat and GregorianCalendar do not mesh properly. You must
  specify the Calendar twice, once indirectly as a Date.


If the user has not configured his time zone correctly it will default
  quietly to either PST or GMT.


In GregorianCalendar, Months are numbered starting at January=0,
  rather than 1 as everyone else on the planet does. Yet days start at 1
  as do days of the week with Sunday=1, Monday=2,… Saturday=7. Yet
  DateFormat. parse behaves in the traditional way with January=1.


In addition to DannySmurf's answer of laziness, I'll add that it's to encourage you to use the constants, such as Calendar.JANUARY.


It isn't exactly defined as zero per se, it's defined as Calendar.January. It is the problem of using ints as constants instead of enums. Calendar.January == 0.


The Answer by Jon Skeet is correct.


Now we have a modern replacement for those troublesome old legacy date-time classes: the java.time classes.


Among those classes is the Month enum, defining a dozen objects, one for each month in the year, January-December. Fortunately, they have sane numbering, 1-12 where 1 is January and 12 is December.


Get a Month object for a particular month number (1-12).


Going the other direction, ask a Month object for its month number.


Many other handy methods on this class, such as knowing the number of days in each month. The class can even generate a localized name of the month.


You can get the localized name of the month, in various lengths or abbreviations.


février


Also, you should pass objects of this enum around your code base rather than mere integer numbers. Doing so provides type-safety, ensures a valid range of values, and makes your code more self-documenting. See Oracle Tutorial if unfamiliar with the surprisingly powerful enum facility in Java.


You also may find useful the Year and YearMonth classes.


The java.time framework is built into Java 8 and later. These classes supplant the troublesome old legacy date-time classes such as java.util.Date, .Calendar, & java.text.SimpleDateFormat.


The Joda-Time project, now in maintenance mode, advises migration to java.time.


To learn more, see the Oracle Tutorial. And search Stack Overflow for many examples and explanations. Specification is JSR 310.


Where to obtain the java.time classes? 


The ThreeTen-Extra project extends java.time with additional classes. This project is a proving ground for possible future additions to java.time. You may find some useful classes here such as Interval, YearWeek, YearQuarter, and more.


Because everything starts with 0. This is a basic fact of programming in Java. If one thing were to deviate from that, then that would lead to a whole slue of confusion. Let's not argue the formation of them and code with them.






I want to print a double value in Java without exponential form.


It shows this E notation: 1.2345678E7.


I want it to print it like this: 12345678


What is the best way to prevent this?


You could use printf() with %f:


This will print dexp: 12345678.000000. If you don't want the fractional part, use


This uses the format specifier language explained in the documentation.


The default toString() format used in your original code is spelled out here.


Five different ways to convert a double to a normal number:


This program prints:


Which are all the same value.


Protip: If you are confused as to why those random digits appear beyond a certain threshold in the double value, this video explains: computerphile why does 0.1+0.2 equal 0.30000000000001?


http://youtube.com/watch?v=PZRI1IfStY0 


In short:


If you want to get rid of trailing zeros and Locale problems, then you should use :


Explanation:


Why other answers did not suit me :


by using %f, the default decimal precision is 6, otherwise you can hardcode it but it results in extra zeros added if you have less decimals. Example :


by using setMaximumFractionDigits(0); or %.0f you remove any decimal precision, which is fine for integers/longs but not for double


by using DecimalFormat, you are local dependent. In French locale, the decimal separator is a comma, not a point :


Using the ENGLISH locale makes sure you get a point for decimal separator, wherever your program will run


Why using 340 then for setMaximumFractionDigits ?


Two reasons :


You can try it with DecimalFormat. With this class you are very flexible in parsing your numbers.
You can exactly set the pattern you want to use.
In your case for example:


This will work as long as your number is a whole number:


If the double variable has precision after the decimal point it will truncate it.


I've got another solution involving BigDecimal's toPlainString(), but this time using the String-constructor, which is recommended in the javadoc:


this constructor is compatible with the values returned by Float.toString and Double.toString. This is generally the preferred way to convert a float or double into a BigDecimal, as it doesn't suffer from the unpredictability of the BigDecimal(double) constructor.


Looks like this in its shortest form:


Pre java 8 this results in "0.0" for any zero-valued Doubles, so you would need to add:


NaN and infinite values have to be checked extra.
Final result of all these considerations:


This can also be copied/pasted to work nicely with Float.


The following code detects if the provided number is presented in scientific notation. If so it is represented in normal presentation with a maximum of '25' digits.


I needed to convert some double to currency values, and fount that most to the solution are OK but not for me.


The DecimalFormat was eventually the way for me, so here is what I've done:


As you can see, if the number is natural I get - say - 20000000 instead of 2E7 (etc) - without any decimal point.


and if it's decimal, I get only 2 decimal digits.


Hope this will help.


I had this same problem in my production code when I was using it as a string input to a math.Eval() function which takes a string like  "x + 20 / 50"


I looked at hundreds of articles.. in the end I went with this because of the speed. and because the Eval function was going to convert it back into its own number format eventually and math.Eval() didn't support the trailing E-07 that other methods returned, and anything over 5dp was too much detail for my app anyways. 


This is now used in Production code for an app that has 1,000+ users...


I think everyone had the right idea, but all answers were not straightforward. 
I can see this being a very useful piece of code.  Here is a snippet of what will work:


the ".8" is where you set the number of decimal places you would like to show.


I am using Eclipse and it worked no problem.


Hope this was helpful. I would appreciate any feedback!






How would I go about doing calculations with extremely large numbers in Java? 


I have tried long but that maxes out at 9223372036854775807, and when using an integer it does not save enough digits and therefore is not accurate enough for what I need. 


Is there anyway around this?


You can use the BigInteger class for integers and BigDecimal for numbers with decimal digits. Both classes are defined in java.math package.


Example:


Use the BigInteger class that is a part of the Java library.


http://java.sun.com/j2se/1.5.0/docs/api/java/math/BigInteger.html


Here is an example which gets big numbers very quickly.


Checkout BigDecimal and BigInteger.


Depending on what you're doing you might like to take a look at GMP (gmplib.org) which is a high-performance multi-precision library. To use it in Java you need JNI wrappers around the binary library.


See some of the Alioth Shootout code for an example of using it instead of BigInteger to calculate Pi to an arbitrary number of digits.


http://shootout.alioth.debian.org/u32q/benchmark.php?test=pidigits&lang=java&id=3


using string datatype you easily solve this issue.






I'm working on a project where all conversions from int to String are done like this:


I'm not familiar with Java. Is this usual practice or is something wrong, as I suppose?


Normal ways would be Integer.toString(i) or String.valueOf(i).


The concatenation will work, but it is unconventional and could be a bad smell as it suggests the author doesn't know about the two methods above (what else might they not know?).


Java has special support for the + operator when used with strings (see the documentation) which translates the code you posted into:


at compile-time. It's slightly less efficient (sb.append() ends up calling Integer.getChars(), which is what Integer.toString() would've done anyway), but it works.


To answer Grodriguez's comment: ** No, the compiler doesn't optimise out the empty string in this case - look:


Initialise the StringBuilder:


Append the empty string:


Append the integer:


Extract the final string:


There's a proposal and ongoing work to change this behaviour, targetted for JDK 9.


It's acceptable, but I've never written anything like that.  I'd prefer this: 


It's not a good way.


When doing conversion from int to string, this should be used:


It's not only the optimization1. I don't like


because it does not express what I really want to do.


I don't want to append an integer to an (empty) string. I want to convert an integer to string:


Or, not my prefered, but still better than concatenation, get a string representation of an object (integer):


1. For code that is called very often, like in loops, optimization sure is also a point for not using concatenation.


A lot of introductory University courses seem to teach this style, for two reasons (in my experience):


It doesn’t require understanding of classes or methods. Usually, this is taught way before the word “class” is ever mentioned – nor even method calls. So using something like String.valueOf(…) would confuse students.


It is an illustration of “operator overloading” – in fact, this was sold to us as the idiomatic overloaded operator (small wonder here, since Java doesn’t allow custom operator overloading).


So it may either be born out of didactic necessity (although I’d argue that this is just bad teaching) or be used to illustrate a principle that’s otherwise quite hard to demonstrate in Java.


The expression 


leads to string conversion of i at runtime. The overall type of the expression is String. i is first converted to an Integer object (new Integer(i)), then String.valueOf(Object obj) is called. So it is equivalent to


Obviously, this is slightly less performant than just calling String.valueOf(new Integer(i)) which will produce the very same result.


The advantage of ""+i is that typing is easier/faster and some people might think, that it's easier to read. It is not a code smell as it does not indicate any deeper problem.


(Reference: JLS 15.8.1)


Personally, I don't see anything bad in this code.


It's pretty useful when you want to log an int value, and the logger just accepts a string. I would say such a conversion is convenient when you need to call a method accepting a String, but you have an int value.


As for the choice between Integer.toString or String.valueOf, it's all a matter of taste. String.valueOf calls the Integer.toString method by the way :)


The other way I am aware of is from the Integer class:


A concrete example (though I wouldn't think you need any):


It also works for other primitive types, for instance Double.toString.


See here for more details.


This technique was taught in an undergraduate level introduction-to-Java class I took over a decade ago. However, I should note that, IIRC, we hadn't yet gotten to the String and Integer class methods.


The technique is simple and quick to type. If all I'm doing is printing something, I'll use it (for example, System.out.println("" + i);. However, I think it's not the best way to do a conversion, as it takes a second of thought to realize what's going on when it's being used this way. Also, if performance is a concern, it seems slower (more below, as well as in other answers).


Personally, I prefer Integer.toString(), as it is obvious what's happening. String.valueOf() would be my second choice, as it seems to be confusing (witness the comments after darioo's answer).


Just for grins :) I wrote up classes to test the three techniques:  "" + i,  Integer.toString, and String.ValueOf. Each test just converted the ints from 1 to 10000 to Strings. I then ran each through the Linux time command five times. Integer.toString() was slightly faster than String.valueOf() once, they tied three times, and String.valueOf() was faster once; however, the difference was never more than a couple of milliseconds.


The "" + i technique was slower than both on every test except one, when it was 1 millisecond faster than Integer.toString() and 1 millisecond slower than String.valueOf() (obviously on the same test where String.valueOf() was faster than Integer.toString()). While it was usually only a couple milliseconds slower, there was one test where it was about 50 milliseconds slower. YMMV.


There are various ways of converting to Strings:


It depends on how you want to use your String. This can help:


Both of the ways are correct.


Mostly ditto on SimonJ. I really dislike the ""+i idiom. If you say String.valueOf(i), Java converts the integer to a string and returns the result. If you say ""+i, Java creates a StringBuilder object, appends an empty string to it, converts the integer to a string, appends this to the StringBuilder, then converts the StringBuilder to a String. That's a lot of extra steps. I suppose if you do it once in a big program, it's no big deal. But if you're doing this all the time, you're making the computer do a bunch of extra work and creating all these extra objects that then have to be cleaned up. I don't want to get fanatic about micro-optimization, but I don't want to be pointlessly wasteful either. 


Using "" + i is the shortest and simplest way to convert a number to a string.  It is not the most efficient, but it is the clearest IMHO and that is usually more important.  The simpler the code, the less likely you are to make a mistake.


There are many way to convert an integer to a string:


1)


2)


3)


4)


Personally I think that "" + i does look as the original question poster states "smelly". I have used a lot of OO languages besides Java. If that syntax was intended to be appropriate then Java would just interpret the i alone without needing the "" as desired to be converted to a string and do it since the destination type is unambiguous and only a single value would be being supplied on the right. The other seems like a 'trick" to fool the compiler, bad mojo when different versions of Javac made by other manufacturers or from other platforms are considered if the code ever needs to be ported. Heck for my money it should like many other OOL's just take a Typecast: (String) i. winks


Given my way of learning and for ease of understanding such a construct when reading others code quickly I vote for the Integer.toString(i) method. Forgetting a ns or two in how Java implements things in the background vs. String.valueOf(i) this method feels right to me and says exactly what is happening: I have and Integer and I wish it converted to a String.


A good point made a couple times is perhaps just using StringBuilder up front is a good answer to building Strings mixed of text and ints or other objects since thats what will be used in the background anyways right?


Just my two cents thrown into the already well paid kitty of the answers to the Mans question... smiles


EDIT TO MY OWN ANSWER AFTER SOME REFLECTION:


Ok, Ok, I was thinking on this some more and String.valueOf(i) is also perfectly good as well it says: I want a String that represents the value of an Integer. lol, English is by far more difficult to parse then Java! But, I leave the rest of my answer/comment... I was always taught to use the lowest level of a method/function chain if possible and still maintains readablity so if String.valueOf calls Integer.toString then Why use a whole orange if your just gonna peel it anyways, Hmmm?


To clarify my comment about StringBuilder, I build a lot of strings with combos of mostly literal text and int's and they wind up being long and ugly with calls to the above mentioned routines imbedded between the +'s, so seems to me if those become SB objects anyways and the append method has overloads it might be cleaner to just go ahead and use it... So I guess I am up to 5 cents on this one now, eh? lol...


There are three ways of converting to Strings


There are many different type of wat to convert Integer value to string 


Try simple typecasting






I'm using the runtime to run command prompt commands from my Java program.  However I'm not aware of how I can get the output the command returns.


Here is my code:


I tried doing System.out.print(proc); but that did not return anything.  The execution of that command should return two numbers separated by a semicolon, how could I get this in a variable to print out?


Here is the code I'm using now:


But I'm not getting anything as my output but when I run that command myself it works fine.


Here is the way to go:


Better read the Javadoc for more details here. ProcessBuilder would be good choice to use


A quicker way is this:


Which is basically a condensed version of this:


I know this question is old but I am posting this answer because I think this may be quicker.


Besides using ProcessBuilder as suggested Senthil, be sure to read and implement all the recommendations of When Runtime.exec() won't.


@Senthil and @Arend answer (https://stackoverflow.com/a/5711150/2268559) mentioned ProcessBuilder. Here is the example using ProcessBuilder with specifying environment variables and working folder for the command:


adapted from previous answer


Try reading the InputStream of the runtime:


You might also need to read the error stream (proc.getErrorStream()) if the process is printing error output. You can redirect the error stream to the input stream if you use ProcessBuilder.






My app needs to show Google Maps directions from A to B, but I don't want to put the Google Maps into my application - instead, I want to launch it using an Intent. Is this possible? If yes, how?


You could use something like this:


To start the navigation from the current location, remove the saddr parameter and value.


You can use an actual street address instead of latitude and longitude. However this will give the user a dialog to choose between opening it via browser or Google Maps.


This will fire up Google Maps in navigation mode directly:


UPDATE


In May 2017 Google launched the new API for universal, cross-platform Google Maps URLs:


https://developers.google.com/maps/documentation/urls/guide


You can use Intents with the new API as well.


This is a little off-topic because you asked for "directions", but you can also use the Geo URI scheme described in the Android Documentation:


http://developer.android.com/guide/appendix/g-app-intents.html


The problem using "geo:latitude,longitude" is that Google Maps only centers at your point, without any pin or label.


That's quite confusing, especially if you need to point to a precise place or/and ask for directions.


If you use the query parameter "geo:lat,lon?q=name" in order to label your geopoint, it uses the query for search and dismiss the lat/lon parameters.


I found a way to center the map with lat/lon and display a pin with a custom label, very nice to display and useful when asking for directions or any other action:


NOTE (by @TheNail): Not working in Maps v.7 (latest version at the time of writing). Will ignore the coordinates and search for an object with the given name between the parentheses. See also Intent for Google Maps 7.0.0 with location


Although the current answers are great, none of them did quite what I was looking for, I wanted to open the maps app only, add a name for each of the source location and destination, using the geo URI scheme wouldn't work for me at all and the maps web link didn't have labels so I came up with this solution, which is essentially an amalgamation of the other solutions and comments made here, hopefully it's helpful to others viewing this question.


To use your current location as the starting point (unfortunately I haven't found a way to label the current location) then use the following


For completeness, if the user doesn't have the maps app installed then it's going to be a good idea to catch the ActivityNotFoundException, then we can start the activity again without the maps app restriction, we can be pretty sure that we will never get to the Toast at the end since an internet browser is a valid application to launch this url scheme too.


P.S.
Any latitudes or longitudes used in my example are not representative of my location, any likeness to a true location is pure coincidence, aka I'm not from Africa :P


Using the latest cross-platform Google Maps URLs:
Even if google maps app is missing it will open in browser


Example https://www.google.com/maps/dir/?api=1&origin=81.23444,67.0000&destination=80.252059,13.060604


Well you can try to open the built-in application Android Maps by using the Intent.setClassName method.


try this


This is what worked for me:


First you need to now that you can use the implicit intent, android documentation provide us with a very detailed common intents 
for implementing the map intent you need to create a new intent with two parameters


For action we can use Intent.ACTION_VIEW 
and for Uri we should Build it ,below i attached  a sample code to create,build,start the activity.


For multiple way points, following can be used as well.


First set of coordinates are your starting location. All of the next are way points, plotted route goes through.


Just keep adding way points by concating "/latitude,longitude" at the end. There is apparently a limit of 23 way points according to google docs. Not sure if that applies to Android too.


if you know point A, point B (and whatever features or tracks in between) you can use a KML file along with your intent.


for more info, see this SO answer


NOTE: this example uses a sample file that (as of mar13) is still online.  if it has gone offline, find a kml file online and change your url


If you interested in showing the Latitude and Longitude from the current direction , you can use this :


Directions are always given from the users current location.


The following query will help you perform that . You can pass the destination latitude and longitude here: 


Use above as: 


Or if you want to show via location , use:


More Info here: 
Google Maps Intents for Android






How do I recursively list all files under a directory in Java? Does the framework provide any utility?   


I saw a lot of hacky implementations. But none from the framework or nio 


FileUtils have iterateFiles and listFiles methods. Give them a try. (from commons-io)


Edit: You can check here for a benchmark of different approaches. It seems that the commons-io approach is slow, so pick some of the faster ones from here (if it matters)


Java 8 provides a nice stream to process all files in a tree.


This provides a natural way to traverse files. Since it's a stream you can do all nice stream operations on the result such as limit, grouping, mapping, exit early etc.


UPDATE: I might point out there is also Files.find which takes a BiPredicate that could can be more efficient if you need to check file attributes.


Note that while the JavaDoc eludes that this method could be more efficient than Files.walk it is effectively identical, the difference in performance can be observed if you are also retrieving file attributes within your filter. In the end, if you need to filter on attributes use Files.find, otherwise use Files.walk, mostly because there's overloads and it's more convenient.


TESTS: As requested I've provided a performance comparison of many of the answers. Check out the Github project which contains results and a test case.


// Ready to run


Java 7 will have has Files.walkFileTree:


If you provide a starting point and a file visitor, it will invoke various methods on the file visitor as it walks through the file in the file tree. We expect people to use this if they are developing a recursive copy, a recursive move, a recursive delete, or a recursive operation that sets permissions or performs another operation on each of the files.


There is now an entire Oracle tutorial on this question.


No external libraries needed.
Returns a Collection so you can do whatever you want with it after the call.


I would go with something like: 


The System.out.println is just there to indicate to do something with the file. there is no need to differentiate between files and directories, since a normal file will simply have zero children.


just write it yourself using simple recursion:


I prefer using a queue over recursion for this kind of simple traversion:


With Java 7 you can use the following class:


I think this should do the work:


This way you have files and dirs. Now use recursion and do the same for dirs (File class has isDirectory() method).


In Java 8, we can now use the Files utility to walk a file tree. Very simple.


Apart from the recursive traversal one can use a Visitor based approach as well.


Below code is uses Visitor based approach for the traversal.It is expected that the input to the program is the root directory to traverse.


You can use below code to get a list of files of specific folder or directory recursively.


Non-recursive BFS with a single list (particular example is searching for *.eml files):


My version (of course I could have used the built in walk in Java 8  ;-) ):


Example outputs *.csv files in directory recursive searching Subdirectories using Files.find() from java.nio:


Posting this example, as I had trouble understanding howto pass the filename parameter in the #1 example given by Bryan, using foreach on Stream-result - 


Hope this helps.


Based on stacker answer. Here is a solution working in JSP without any external libraries so you can put it almost anywhere on your server:


Then you just do something like:






I just saw code similar to this:


When ran, this block of code will print out:


I understand why the first is false: because the two objects are separate objects, so the == compares the references. But I can't figure out, why is the second statement returning true? Is there some strange autoboxing rule that kicks in when an Integer's value is in a certain range? What's going on here?


The true line is actually guaranteed by the language specification. From section 5.1.7:


If the value p being boxed is true,
  false, a byte, a char in the range
  \u0000 to \u007f, or an int or short
  number between -128 and 127, then let
  r1 and r2 be the results of any two
  boxing conversions of p. It is always
  the case that r1 == r2.


The discussion goes on, suggesting that although your second line of output is guaranteed, the first isn't (see the last paragraph quoted below):


Ideally, boxing a given primitive
  value p, would always yield an
  identical reference. In practice, this
  may not be feasible using existing
  implementation techniques. The rules
  above are a pragmatic compromise. The
  final clause above requires that
  certain common values always be boxed
  into indistinguishable objects. The
  implementation may cache these, lazily
  or eagerly.


For other values, this formulation
  disallows any assumptions about the
  identity of the boxed values on the
  programmer's part. This would allow
  (but not require) sharing of some or
  all of these references.


This ensures that in most common
  cases, the behavior will be the
  desired one, without imposing an undue
  performance penalty, especially on
  small devices. Less memory-limited
  implementations might, for example,
  cache all characters and shorts, as
  well as integers and longs in the
  range of -32K - +32K.


Output:


Yep the first output is produced for comparing reference; 'a' and 'b' - these are two different reference. In point 1, actually two references are created which is similar as - 


The second output is produced because the JVM tries to save memory, when the Integer falls in a range (from -128 to 127). At point 2 no new reference of type Integer is created for 'd'. Instead of creating new object for the Integer type reference variable 'd', it only assigned with previously created object referenced by 'c'. All of these are done by JVM. 


These memory saving rules are not only for Integer. for memory saving purpose, two instances of the following wrapper objects (while created through boxing), will always be == where their primitive values are the same - 


Integer objects in some range (I think maybe -128 through 127) get cached and re-used.  Integers outside that range get a new object each time.


My guess is that Java keeps a cache of small integers that are already 'boxed' because they are so very common and it saves a heck of a lot of time to re-use an existing object than to create a new one.


Yes, there is a strange autoboxing rule that kicks in when the values are in a certain range. When you assign a constant to an Object variable, nothing in the language definition says a new object must be created. It may reuse an existing object from cache.


In fact, the JVM will usually store a cache of small Integers for this purpose, as well as values such as Boolean.TRUE and Boolean.FALSE.


In Java the boxing works in the range between -128 and 127 for an Integer. When you are using numbers in this range you can compare it with the == operator. For Integer objects outside the range you have to use equals.


That is an interesting point. 
In the book Effective Java suggests always to override equals for your own classes. Also that, to check equality for two object instances of a java class always use the equals method. 


returns:


In Java 5, a new feature was introduced to save the memory and improve performance for Integer type objects handlings. Integer objects are cached internally and reused via the same referenced objects.


This is applicable for Integer values in range between –127 to +127
(Max Integer value).


This Integer caching works only on autoboxing. Integer objects will
not be cached when they are built using the constructor.


For more detail pls go through below Link:


Integer Cache in Detail


If we check the source code of Integer obeject, we will find the source of valueOf method just like this:  


which can explain why Integer objects, which in the range from -128 (Integer.low) to 127 (Integer.high), are the same referenced objects during the autoboxing. And we can see there is a class IntegerCache takes care of the Integer cache array, which is a private static inner class of Integer class.


There is another interesting example may help us understand this weird situation:






How can I check whether a file exists, before opening it for reading in Java? (equivalent of Perl's -e $filename).  


The only similar question on SO deals with writing the file and was thus answered using FileWriter which is obviously not applicable here.


If possible I'd prefer a real API call returning true/false as opposed to some "Call API to open a file and catch when it throws an exception which you check for 'no file' in text", but I can live with the latter.


Using java.io.File:


I would recommend using isFile() instead of exists(). Most of the time you are looking to check if the path points to a file not only that it exists. Remember that exists() will return true if your path points to a directory.


new File("C:/").exists() will return true but will not allow you to open and read from it as a file.


By using nio in Java SE 7,


If both exists and notExists return false, the existence of the file cannot be verified. (maybe no access right to this path)


You can check if path is directory or regular file.


Please check this Java SE 7 tutorial.


This will not create a physical file. Will just create an object of the class File. To physically create a file you have to explicitly create it:


So f.exists() can be used to check whether such a file exists or not.


Using Java 8:


first hit for "java file exists" on google:


You can use the following: File.exists()


Don't. Just catch the FileNotFoundException. The file system has to test whether the file exists anyway. There is no point in doing all that twice, and several reasons not to, such as:


Don't try to second-guess the system. It knows. And don't try to predict the future. In general the best way to test whether any resource is available is just to try to use it.


For me a combination of the accepted answer by Sean A.O. Harney and the resulting comment by Cort3z seems to be the best solution.


Used the following snippet:


Hope this could help someone.


There are multiple ways to achieve this. 


new File("/path/to/file").exists();  In case of just for existence. It could be file or a directory.  


File f = new File("/path/to/file"); 
   if(f.exists() && f.isFile()) {}


Check for file 


File f = new File("/path/to/file"); 
   if(f.exists() && f.isDirectory()) {}


Check for Directory.


Java 7 way. 


Path path = Paths.get("/path/to/file");
Files.exists(path)  - Existence 
Files.isDirectory(path) - is Directory
Files.isRegularFile(path) - Regular file 
Files.isSymbolicLink(path) - Symbolic Link


It's also well worth getting familiar with Commons FileUtils
http://commons.apache.org/io/api-release/org/apache/commons/io/FileUtils.html
This has additional methods for managing files and often better than JDK.


and check the check result


will do the trick


Don't use File constructor with String.
This may not work! 
Instead of this use URI:


File.exists() to check if a file exists, it will return a boolean value to indicate the check operation status; true if the file is existed; false if not exist.


I know I'm a bit late in this thread. However, here is my answer, valid since Java 7 and up.


The following snippet


is perfectly satifactory, because method isRegularFile returns false if file does not exist. Therefore, no need to check if Files.exists(...).


Note that other parameters are options indicating how links should be handled. By default, symbolic links are followed.


From Java Oracle documentation


You can use the following code to check:






I am developing an android broadcast receiver for checking internet connection.


The problem is that my broadcast receiver is being called two times. I want it to get called only when the network is available. If it is unavailable, I don't want notified.


This is the broadcast receiver


This is the manifest.xml


Answer to your first question: Your broadcast receiver is being called two times because 


You have added two <intent-filter> 


Change in network connection :
<action android:name="android.net.conn.CONNECTIVITY_CHANGE" />


Change in WiFi state:
<action android:name="android.net.wifi.WIFI_STATE_CHANGED" />


Just use one:
<action android:name="android.net.conn.CONNECTIVITY_CHANGE" />.


It will respond to only one action instead of two. See here for more information.


Answer to your second question (you want receiver to call only one time if internet connection available):


Your code is perfect; you notify only when internet is available.


UPDATE


You can use this method to check your connectivity if you want just to check whether mobile is connected with the internet or not.


ServiceManager.java


permissions:


Use this method to check the network state:


remember to unregister service in onDestroy.


Cheers!!


Check Intenert Every time using Broadcast Receiver Like same as Youtube Go to 
 online,offline



Source Code


https://drive.google.com/open?id=0BzBKpZ4nzNzUYjhZamFIZTh6VTQ 


This above broadcast receiver will be called only when Network state change to connected and not on disconnected.


I know this thread is old and fully answered but I feel that the following might help some people.


The code in the body of the question contains a bug which no one here addressed.
@Nikhil is checking whether the wifi/mobile is available and not if it's connected.


The fix is here:


Try with this 


This is the broadcast Receiver. soon as internet connection trigger  this will loaded


manifest:


class for receiver:


and classs utils like example:


Add a broadcast receiver which can listen to network connectivity change. Then check wether device is connected to internet or not using ConnectivityManager. Refer to this post or video for detailed understanding. Below is the code:


I wrote this receiver to show a notification on the Screen, that's why you see a local broadcast with the network status. Here is the code to show the notification.


Activity listens to the intent broadcasted by the network receiver and shows the notification on the screen.


}


just for someone else who wanna register a broadcast dynamicly:


CONNECTIVITY_ACTION docs:


Apps targeting Android 7.0 (API level 24) and higher do not receive this broadcast if they declare the broadcast receiver in their manifest. Apps will still receive broadcasts if they register their BroadcastReceiver with Context.registerReceiver() and that context is still valid.


Broadcast receiver code to check internet connectivity change:


add this in manifest file:






Possible Duplicate:
How do I calculate the elapsed time of an event in java? 


I want to have something like this:


Which types to use in order to accomplish this in Java?
(Also it is important that for example if the startTime it's 23:00 and endTime 1:00 to get a duration of 2:00.)


Unfortunately, none of the ten answers posted so far are quite right.


If you are measuring elapsed time, and you want it to be correct, you must use System.nanoTime().  You cannot use System.currentTimeMillis(), unless you don't mind your result being wrong.


The purpose of nanoTime is to measure elapsed time, and the purpose of currentTimeMillis is to measure wall-clock time. You can't use the one for the other purpose. The reason is that no computer's clock is perfect; it always drifts and occasionally needs to be corrected.  This correction might either happen manually, or in the case of most machines, there's a process that runs and continually issues small corrections to the system clock ("wall clock"). These tend to happen often. Another such correction happens whenever there is a leap second.


Since nanoTime's purpose is to measure elapsed time, it is unaffected by any of these small corrections. It is what you want to use. Any timings currently underway with currentTimeMillis will be off -- possibly even negative.


You may say, "this doesn't sound like it would ever really matter that much," to which I say, maybe not, but overall, isn't correct code just better than incorrect code?  Besides, nanoTime is shorter to type anyway.


Previously posted disclaimers about nanoTime usually having only microsecond precision are valid. Also it can take more than a whole microsecond to invoke, depending on circumstances (as can the other one), so don't expect to time very very small intervals correctly.


Which types to use in order to accomplish this in Java?


The short answer is a long. Now, more on how to measure...


The "traditional" way to do this is indeed to use System.currentTimeMillis():


Note that Commons Lang has a StopWatch class that can be used to measure execution time in milliseconds. It has methods methods like split(), suspend(), resume(), etc that allow to take measure at different points of the execution and that you may find convenient. Have a look at it.


You may prefer to use System.nanoTime() if you are looking for extremely precise measurements of elapsed time. From its javadoc: 


Another option would be to use JAMon, a tool that gathers statistics (execution time, number of hit, average execution time, min, max, etc) for any code that comes between start() and stop() methods. Below, a very simple example:


Check out this article on www.javaperformancetunning.com for a nice introduction.


Finally, if you don't want to clutter your code with these measurement (or if you can't change existing code), then AOP would be a perfect weapon. I'm not going to discuss this very deeply but I wanted at least to mention it. 


Below, a very simple aspect using AspectJ and JAMon (here, the short name of the pointcut will be used for the JAMon monitor, hence the call to thisJoinPoint.toShortString()):


The pointcut definition could be easily adapted to monitor any method based on the class name, the package name, the method name, or any combination of these. Measurement is really a perfect use case for AOP.


Your new class:


Usage:


Afterwards, the time passed can be converted to whatever format you like, with a calender for example


Greetz,
GHad


If the purpose is to simply print coarse timing information to your program logs, then the easy solution for Java projects is not to write your own stopwatch or timer classes, but just use the org.apache.commons.lang.time.StopWatch class that is part of Apache Commons Lang.


We have new technology for this now built into Java 8 and later, the java.time framework. 


The java.time framework is defined by JSR 310, inspired by the highly successful Joda-Time project, extended by the ThreeTen-Extra project, and described in the Oracle Tutorial.


The old date-time classes such as java.util.Date/.Calendar bundled with the earliest versions of Java have proven to be poorly designed, confusing, and troublesome. They are supplanted by the java.time classes.


Other answers discuss resolution.


The java.time classes have nanosecond resolution, up to nine digits of a decimal fraction of a second. For example, 2016-03-12T04:29:39.123456789Z.


Both the old java.util.Date/.Calendar classes and the Joda-Time classes have millisecond resolution (3 digits of fraction). For example, 2016-03-12T04:29:39.123Z.


In Java 8, the current moment is fetched with up to only millisecond resolution because of a legacy issue. In Java 9 and later, the current time can be determined up to nanosecond resolution provided your computer’s hardware clock runs so finely.


If you truly want to work with only the time-of-day lacking any date or time zone, use the LocalTime class. 


A Duration represents a span of time it terms of a count of seconds plus nanoseconds.


Dump to console.


sooner: 17:00 | later: 19:00 | duration: PT2H


Notice the default output of Duration::toString is in standard ISO 8601 format. In this format, the P marks the beginning (as in 'Period'), and the T separates any years-months-days portion from the hours-minutes-seconds portion.


Unfortunately, working with time-of-day only gets tricky when you wrap around the clock crossing midnight. The LocalTime class handles this by assuming you want to go backwards to an earlier point in the day. 


Using the same code as above but going from 23:00 to 01:00 results in a negative twenty-two hours (PT-22H).


sooner: 23:00 | later: 01:00 | duration: PT-22H


If you intend to cross midnight, it probably makes sense for you to be working with date-time values rather than time-of-day-only values. 


Time zone is crucial to dates. So we specify three items: (1) the desired date, (2) desired time-of-day, and (3) the time zone as a context by which to interpret that date and time. Here we arbitrarily choose the time zone of the Montréal area.


If you define the date by only an offset-from-UTC, use a ZoneOffset with a OffsetDateTime. If you have a full time zone (offset plus rules for handling anomalies such as Daylight Saving Time), use a ZoneId with a ZonedDateTime.


We specify the later time as next day at 1:00 AM.


We calculate the Duration in the same manner as seen above. Now we get the two hours expected by this Question.


Dump to console.


sooner: 2016-01-23T23:00-05:00[America/Montreal] | later: 2016-01-24T01:00-05:00[America/Montreal] | duration: PT2H


If the date-times at hand had involved Daylight Saving Time (DST) or other such anomaly, the java.time classes would adjust as needed. Read class doc for details.


Java provides the static method System.currentTimeMillis(). And that's returning a long value, so it's a good reference. A lot of other classes accept a 'timeInMillis' parameter which is long as well.


And a lot of people find it easier to use the Joda Time library to do calculations on dates and times.


Which types to use in order to accomplish this in Java?


Answer: long


Usage:


That's my direct answer for your first question. 


For the last "note" I would suggest you to use Joda Time. It contains an interval class suitable for what you need.


It is worth noting that


If you are writing an application that must deal with durations of time, then please take a look at Joda-Time which has class specifically for handling Durations, Intervals, and Periods.  Your getDuration() method looks like it could return a Joda-Time Interval:


If you prefer using Java's Calendar API you can try this,


If you're getting your timestamps from System.currentTimeMillis(), then your time variables should be longs.


i found this code to be useful when timing things:


Use this:


(Also it is important that for example if the startTime it's 23:00 and endTime 1:00 to get a duration of 2:00.)


the "else" part can get it correct






New Java programmers often encounter this message when they attempt to run a Java program:


What does this mean, what can cause it, and what should one do to fix it?


When you use the java command to run a Java application from the command line, e.g.,


the command loads the class that you nominated, and then looks for the entry point method called main.  More specifically, it is looking for a method that is declared as follows:


The specific requirements for the entry point method are:


The argument may be declared using varargs syntax; e.g. String... args.  See https://stackoverflow.com/a/36803396/139985.  The String[] argument is used to pass the arguments from the command line, and is required even if your application takes no command line arguments.


If any one of the above requirements is not satisfied, the java command will fail with the message:


If you encounter this error, check that you have a main method and that it satisfies all 6 of the requirements listed above.


1 - One really obscure variation of this is when one or more of the characters in "main" is NOT a LATIN-1 character ... but a Unicode character that looks like the corresponding LATIN-1 character when displayed.


2 - See Why is the Java main method static? for explanation of why the method is required to be static.


3 - String must correspond to java.lang.String and not a custom class named String hiding it.


The problem is that you do not have a public void main(String[] args) method in the class you attempt to invoke.


It 


Note, that you HAVE actually specified an existing class (otherwise the error would have been different), but that class lacks the main method.


Other answers are doing a good job of summarizing the requirements of main.  I want to gather references to where those requirements are documented.


The most authoritative source is the VM spec (second edition cited).  As main is not a language feature, it is not considered in the Java Language Specification.


Another good resource is the documentation for the application launcher itself:


If you are running the correct class and the main is properly defined, also check if you have a class called String defined in the same package. This definition of String class will be considered and since it doesn't confirm to main(java.lang.String[] args), you will get the same exception.


Suggestion is to never hide library java classes in your package.


The name of the exception suggests that the program tried to call a method that doesn't exist. In this context, it sounds like the program does not have a main method, though it would help if you posted the code that caused the error and the context in which the code was run.


This might have happened if the user tried to run a .class file or a .jar file that has no main method - in Java, the main method is the entry point to begin executing the program.


Normally the compiler is supposed to prevent this from happening so if this does happen, it's usually because the name of the method being called is getting determined ar run-time, rather than compile-time.


To fix this problem, a new programmer must either add the midding method (assuming still that it's main that's missing) or change the method call to the name of a method that does exist.


Read more about the main method here: http://csis.pace.edu/~bergin/KarelJava2ed/ch2/javamain.html


Generally, it means the program you are trying to run does not have a "main" method.  If you are going to execute a java program, the class being executed must have a main method


For example, in the file Foo.java


This program should compile and run no problem - if main was called something else, or was not static, it would generate the error you experienced.


Every executable program, regardless of language, needs an entry point, to tell the interpreter, operating system or machine where to start execution. In Java's case, this is the static method main, which is passed the parameter args[] containing the command line arguments.
it is equivalent to int main(int argc, char** argv) in C


I feel the above answers miss a scenario where this error occurs even when your code has a main(). When you are using JNI that uses Reflection to invoke a method. During runtime if the method is not found, you will get a


java.lang.NoSuchMethodError: No virtual method






In the script it is going from around the 300x300 mark down to 60x60.  Need to improve the overall image quality as it is coming out very poorly at the moment.


Really just need to know if their is something I can plug in that will bump up the quality or if I need to look at something else entirely.


EDIT: Picture comparison.


Source, just picked a random washing machine from google.
http://www.essexappliances.co.uk/images/categories/washing-machine.jpg





The same picture converted in Photoshop to what I need it to be.
http://imgur.com/78B1p





What it looks like being converted like this.
http://imgur.com/8WlXD





The issue you are seeing is actually related to the resampling filter used for downscaling. Obviously, the one used by your library is a bad one for the situation. Nearest neighbor, bilinear and bicubic are typical bad examples to be used when downscaling. I don't know the exact resampling filter Photoshop uses, but I used 3-lobed lanczos and got the following result:





So, to solve your problem, you need to use a smarter resampling filter.


Scaling an image down over a large range is inherently dangerous (from the point of view of quality), especially using a single step.


The recommended method is to use a divide and conquer method.  Basically, you scale the image down in steps of 50% until you reach your desired size.


So, I took the original image of 650x748 and scaled it down to fit within a 60x60 region (52x60)





Divide and conquer compared to one step...





You may, also, find The Perils of Image.getScaledInstance() of interest


dutchman, this is why I maintain the imgscalr library -- to make this kind of stuff painfully easy.


In your example, a single method call would do the trick, right after your first ImageIO.read line:


you can do the following to get what you want (javadoc for this method):


and if that still looked a little jagged (because you are removing so much information from the image, you can add the following OP to the command to apply a light anti-aliasing filter to the image so it looks smoother):


That will replace all the remainder of the code logic you have. The only other thing I would recommend is saving out your really small samples as PNG's so there is no more compression/lossy conversion done on the image OR make sure you use little to none compression on the JPG if you really want it in JPG format. (Here is an article on how to do it; it utilizes the ImageWriteParam class)


imgscalr is licensed under an Apache 2 license and hosted on GitHub so you can do what you want with it; it also includes asynchronous scaling support if you are using the library in a server-side app and queuing up huge numbers of scaling operations and don't want to kill the server.


As already stated, Java's Graphics2D does not provide a very good algorithm for down-scaling. If you don't want to implement a sophisticated algorithm yourself you could try out the current open source libs specialized for this: Thumbnailator, imgscalr and a Java interface for ImageMagick.


While researching for a private project I tried them out (except ImageMagick) and here are the visual results with Photoshop as reference:





A. Thumbnailator 0.4.8 with default settings (no additional internal resizing)
  B. imgscalr 4.2 with ULTRA_QUALTY setting
  C. Photoshop CS5 bicubic filter (save for web)
  D. Graphics2d with all HQ render hints


Here is the used code


Thumbnailator and PS create similar results, while imgscalr seems to be softer. It is subjective which one of the libs creates the preferable results. Another point to consider though is the performance. While Thumbnailator and Graphics2d have similar runtime, imgscalr is considerably slower (with ULTRA_QUALITY) in my benchmarks.


For more info, read this post providing more detail on this matter.






Java requires that if you call this() or super() in a constructor, it must be the first statement. Why?


For example:


The Sun compiler says "call to super must be first statement in constructor". The Eclipse compiler says "Constructor call must be the first statement in a constructor".


However, you can get around this by re-arranging the code a little bit:


Here is another example:


So, it is not stopping you from executing logic before the call to super. It is just stopping you from executing logic that you can't fit into a single expression.


There are similar rules for calling this(). The compiler says "call to this must be first statement in constructor".


Why does the compiler have these restrictions? Can you give a code example where, if the compiler did not have this restriction, something bad would happen?


The parent class' constructor needs to be called before the subclass' constructor. This will ensure that if you call any methods on the parent class in your constructor, the parent class has already been set up correctly.


What you are trying to do, pass args to the super constructor is perfectly legal, you just need to construct those args inline as you are doing, or pass them in to your constructor and then pass them to super:


If the compiler did not enforce this you could do this:


In cases where a parent class has a default constructor the call to super is inserted for you automatically by the compiler. Since every class in Java inherits from Object, objects constructor must be called somehow and it must be executed first. The automatic insertion of super() by the compiler allows this. Enforcing super to appear first, enforces that constructor bodies are executed in the correct order which would be: Object -> Parent -> Child -> ChildOfChild -> SoOnSoForth


I've found a way around this by chaining constructors and static methods.  What I wanted to do looked something like this:


So basically construct an object based on constructor parameters, store the object in  a member, and also pass the result of a method on that object into super's constructor.  Making the member final was also reasonably important as the nature of the class is that it's immutable.  Note that as it happens, constructing Bar actually takes a few intermediate objects, so it's not reducible to a one-liner in my actual use case.


I ended up making it work something like this:


Legal code, and it accomplishes the task of executing multiple statements before calling the super constructor.


Because the JLS says so. Could the JLS be changed in a compatible manner to allow it? Yup. However, it would complicate the language spec, which is already more than complicated enough. It wouldn't be a highly useful thing to do and there are ways around it (call another constructor with the result of a method this(fn()) - the method is called before the other constructor, and hence also the super constructor). So the power to weight ratio of doing the change is unfavourable.


I am fairly sure (those familiar with the Java Specification chime in) that it is to prevent you from (a) being allowed to use a partially-constructed object, and (b), forcing the parent class's constructor to construct on a "fresh" object.


Some examples of a "bad" thing would be:


You asked why, and the other answers, imo, don't really say why it's ok to call your super's constructor, but only if it's the very first line. The reason is that you're not really calling the constructor. In C++, the equivalent syntax is


When you see the initializer clause on its own like that, before the open brace, you know it's special. It runs before any of the rest of the constructor runs and in fact before any of the member variables are initialized. It's not that different for Java. There's a way to get some code (other constructors) to run before the constructor really starts, before any members of the subclass are initialized. And that way is to put the "call" (eg super) on the very first line. (In a way, that super or this is kind of before the first open brace, even though you type it after, because it will be executed before you get to the point that everything is fully constructed.) Any other code after the open brace (like int c = a + b;) makes the compiler say "oh, ok, no other constructors, we can initialize everything then." So it runs off and initializes your super class and your members and whatnot and then starts executing the code after the open brace. 


If, a few lines later, it meets some code saying "oh yeah when you're constructing this object, here are the parameters I want you to pass along to the constructor for the base class", it's too late and it doesn't make any sense. So you get a compiler error.


Simply because this is the inheritance philosophy. And according to the Java language specification,  this is how the constructor's body is defined:


ConstructorBody:
        { ExplicitConstructorInvocationopt    BlockStatementsopt }


The first statement of a constructor body may be:
-an explicit invocation of another constructor of the same class (by using the keyword "this") OR 
-of the direct superclass (by using the keyword "super")


If a constructor body does not begin with an explicit constructor invocation and the constructor being declared is not part of the primordial class Object, then the constructor body implicitly begins with a superclass constructor invocation "super();", an invocation of the constructor of its direct superclass that takes no arguments. And so on.. there will be a whole chain of constructors called all the way back to the constructor of Object; "All Classes in the Java platform are Descendants of Object". This thing is called "Constructor Chaining".


Now why is this?
And the reason why Java defined the ConstructorBody in this way, is that they needed to maintain the hierarchy of the object. Remember the definition of the inheritance; It's extending a class. With that being said, you cannot extend something that doesn't exist. The base (the superclass) needs to be created first, then you can derive it (the subclass). That's why they called them Parent and Child classes; you can't have a child without a parent. 


On a technical level, a subclass inherits all the members (fields, methods, nested classes) from its parent. And since Constructors are NOT members (They don't belong to objects. They are responsible of creating objects) so they are NOT inherited by subclasses, but they can be invoked. And since at the time of object creation only ONE constructor is executed. So how do we guarantee the creation of the superclass when you create the subclass object? Thus the concept of "constructor chaining"; so we have the ability to invoke other constructors (i.e. super) from within the current constructor. And Java required this invocation to be the FIRST line in the subclass constructor to maintain the hierarchy and guarantee it. They assume that if you don't explicitly create the parent object FIRST (like if you forgot about it), they will do it implicitly for you. 


This check is done during compilation. But I'm not sure what would happen on runtime, what kind of runtime error we would get, IF Java doesn't throw a compile-error when we explicitly try to execute a base constructor from within a subclass's constructor in the middle of its body and not from the very first line ... 


I totally agree, the restrictions are too strong. Using a static helper method (as Tom Hawtin - tackline suggested) or shoving all "pre-super() computations" into a single expression in the parameter is not always possible, e.g.:


Using an "object not yet constructed" exception, as Carson Myers suggested, would help, but checking this during each object construction would slow down execution. I would favor a Java compiler that makes a better differentiation (instead of inconsequently forbidding an if-statement but allowing the ?-operator within the parameter), even if this complicates the language spec.


So, it is not stopping you from executing logic before the call to
  super. It is just stopping you from executing logic that you can't fit
  into a single expression.


Actually you can execute logic with several expessions, you just have to wrap your code in a static function and call it in the super statement.


Using your example:


You can use anonymous initializer blocks to initialize fields in the child before calling it's constructor. This example will demonstrate :


This will output :


In parent  
  In initializer 
  In child 


My guess is they did this to make life easier for people writing tools that process Java code, and to some lesser degree also people who are reading Java code.


If you allow the super() or this() call to move around, there are more variations to check for.  For example if you move the super() or this() call into a conditional if() it might have to be smart enough to insert an implicit super() into the else.  It might need to know how to report an error if you call super() twice, or use super() and this() together.  It might need to disallow method calls on the receiver until super() or this() is called and figuring out when that is becomes complicated.


Making everyone do this extra work probably seemed like a greater cost than benefit.


I found a woraround.


This won't compile :


This works :


It makes sense that constructors complete their execution in order of
  derivation. Because a superclass has no knowledge of any subclass, any
  initialization it needs to perform is separate from and possibly
  prerequisite to any initialization performed by the subclass.
  Therefore, it must complete its execution first.


A simple demonstration:


The output from this program is:


The other answers have tackled the "why" of the question. I'll provide a hack around this limitation:


The basic idea is to hijack the super statement with your embedded statements. This can be done by disguising your statements as expressions.


Consider we want to do Statement1() to Statement9() before we call super():


The compiler will of course reject our code. So instead, we can do this:


The only limitation is that the parent class must have a constructor which takes in at least one argument so that we can sneak in our statement as an expression.


Here is a more elaborate example:


Reworked into:


In fact, compilers could have automated this process for us. They'd just chosen not to.


I know I am a little late to the party, but I've used this trick a couple of times (and I know it's a bit unusual):


I create an generic interface InfoRunnable<T> with one method:


And if I need to do something before passing it to the constructor I just do this:


Before you can construct child object your parent object has to be created.
As you know when you write class like this:


it turns to the next (extend and super are just hidden):


First we create an Object and then extend this object to MyClass. We can not create MyClass before the Object.
The simple rule is that parent's constructor has to be called before child constructor.
But we know that classes can have more that one constructor. Java allow us to choose a constructor which will be called (either it will be super() or super(yourArgs...)).
So, when you write super(yourArgs...) you redefine constructor which will be called to create a parent object. You can't execute other methods before super() because the object doesn't exist yet (but after super() an object will be created and you will be able to do anything you want).


So why then we cannot execute this() after any method?
As you know this() is the constructor of the current class. Also we can have different number of constructors in our class and call them like this() or this(yourArgs...). As I said every constructor has hidden method super(). When we write our custom super(yourArgs...) we remove super() with super(yourArgs...). Also when we define this() or this(yourArgs...) we also remove our super() in current constructor because if super() were with this() in the same method, it would create more then one parent object.
That is why the same rules imposed for this() method. It just retransmits parent object creation to another child constructor and that constructor calls super() constructor for parent creation.
So, the code will be like this in fact:


As others say you can execute code like this:


also you can execute code like this:


But you can't execute code like this because your method doesn't exists yet:


Also you are obliged to have super() constructor in your chain of this() methods. You can't have an object creation like this:


See the example if we are calling the constructor C(int x) then value of z is depend on y if we do not call C() in the first line then it will be the problem for z. z would not be able to get correct value.






With reference to the following thread:
Java App : Unable to read iso-8859-1 encoded file correctly


What is the best way to programatically determine the correct charset encoding of an inputstream/file ?


I have tried using the following:


But on a file which I know to be encoded with ISO8859_1 the above code yields ASCII, which is not correct, and does not allow me to correctly render the content of the file back to the console.


I have used this library, similar to jchardet for detecting encoding in Java:
http://code.google.com/p/juniversalchardet/


You cannot determine the encoding of a arbitrary byte stream. This is the nature of encodings. A encoding means a mapping between a byte value and its representation. So every encoding "could" be the right.


The getEncoding() method will return the encoding which was set up (read the JavaDoc) for the stream. It will not guess the encoding for you.


Some streams tell you which encoding was used to create them: XML, HTML. But not an arbitrary byte stream.


Anyway, you could try to guess an encoding on your own if you have to. Every language has a common frequency for every char. In English the char e appears very often but ê will appear very very seldom. In a ISO-8859-1 stream there are usually no 0x00 chars. But a UTF-16 stream has a lot of them.


Or: you could ask the user. I've already seen applications which present you a snippet of the file in different encodings and ask you to select the "correct" one.


check this out:
http://site.icu-project.org/ (icu4j)
 they have libraries for detecting charset from IOStream
could be simple like this:


Here are my favorites:


TikaEncodingDetector


Dependency:


Sample:


GuessEncoding


Dependency:


Sample:


You can certainly validate the file for a particular charset by decoding it with a CharsetDecoder and watching out for "malformed-input" or "unmappable-character" errors. Of course, this only tells you if a charset is wrong; it doesn't tell you if it is correct. For that, you need a basis of comparison to evaluate the decoded results, e.g. do you know beforehand if the characters are restricted to some subset, or whether the text adheres to some strict format? The bottom line is that charset detection is guesswork without any guarantees.


The libs above are simple BOM detectors which of course only work if there is a BOM in the beginning of the file.  Take a look at http://jchardet.sourceforge.net/ which does scans the text 


I found a nice third party library which can detect actual encoding:
http://glaforge.free.fr/wiki/index.php?wiki=GuessEncoding


I didn't test it extensively but it seems to work.


If you don't know the encoding of your data, it is not so easy to determine, but you could try to use a library to guess it. Also, there is a similar question.


For ISO8859_1 files, there is not an easy way to distinguish them from ASCII.  For Unicode files however one can generally detect this based on the first few bytes of the file.


UTF-8 and UTF-16 files include a Byte Order Mark (BOM) at the very beginning of the file.  The BOM is a zero-width non-breaking space.  


Unfortunately, for historical reasons, Java does not detect this automatically.  Programs like Notepad will check the BOM and use the appropriate encoding.  Using unix or Cygwin, you can check the BOM with the file command.  For example:


For Java, I suggest you check out this code, which will detect the common file formats and select the correct encoding:  How to read a file and automatically specify the correct encoding


If you use ICU4J (http://icu-project.org/apiref/icu4j/)


Here is my code:


Remember to put all the try catch need it.


I hope this works for you.


As far as I know, there is no general library in this context to be suitable for all types of problems. So, for each problem you should test the existing libraries and select the best one which satisfies your problem’s constraints, but often none of them is appropriate. In these cases you can write your own Encoding Detector! As I have wrote ...


I’ve wrote a meta java tool for detecting charset encoding of HTML Web pages, using IBM ICU4j and Mozilla JCharDet as the built-in components. Here you can find my tool, please read the README section before anything else. Also, you can find some basic concepts of this problem in my paper and in its references.   


Bellow I provided some helpful comments which I’ve experienced in my work:   


As of this writing, they are three libraries that emerge: 


I don't include Apache Any23 because it uses ICU4j 3.4 under the hood.


It's impossible to certify the charset detected by each above libraries. However, it's possible to ask them in turn and score the returned response.


Each response can be assigned one point. The more points a response have, the more confidence the detected charset has. This is a simple scoring method. You can elaborate others.


Here is a full snippet implementing the strategy described in the previous lines.


Improvements:
The guessEncoding method reads the inputstream entirely. For large inputstreams this can be a concern. All these libraries would read the whole inputstream. This would imply a large time consumption for detecting the charset.


It's possible to limit the initial data loading to a few bytes and perform the charset detection on those few bytes only.


An alternative to TikaEncodingDetector is to use Tika AutoDetectReader.


Can you pick the appropriate char set in the Constructor:






I'm currently testing out Firebase along with a Singleton model I plan to use to access during the lifecycle of the whole app. I'm now stuck with something that seems really trivial but I can't figure it out for the life of me. I have a sample of the model I use: Bookmarks in firebase.


Now when I start the mainActivity with the instance of the Singleton set I get a null error because clearly the function I wrote to load the model data from firebase sets nothing.


Something like this:
MainActivity


Any pointers would be greatly appreciated. I'm kinda new with Firebase so I'm not really sure why this doesn't work as I expect it to. 


Thanks!


Firebase loads and synchronizes data asynchronously. So your loadModelWithDataFromFirebase() doesn't wait for the loading to finish, it just starts loading the data from the database. By the time your loadModelWithDataFromFirebase() function returns, the loading hasn't finished yet.


You can easily test this for yourself with some well-placed log statements:


Contrary to what you likely expect, the order of the log statements will be:


You have two choice for dealing with the asynchronous nature of this loading:


squash the asynchronous bug (usually accompanied by muttering of phrases like: "it was a mistake, these people don't know what they're doing")


embrace the asynchronous beast (usually accompanied by quite some hours of cursing, but after a while by peace and better behaved applications)


If you feel like picking the first option, a well placed synchronization primitive will do the trick:


Update (20160303): when I just tested this on Android, it blocked my app. It works on a regular JVM fine, but Android is more finicky when it comes to threading. Feel free to try and make it work... or


If you instead choose to embrace asynchronous programming, you should rethink your application's logic. 


You currently have "First load the bookmarks. Then load the sample data. And then load even more." 


With an asynchronous loading model, you should think like "Whenever the bookmarks have loaded, I want to load the sample data. Whenever the sample data has loaded, I want to load even more." The bonus of thinking this way is that it also works when the data can be changed and thus synchronized multiple times: "Whenever the bookmarks change, I want to also load the sample data. Whenever the sample data changes, I want to load even more."


In code, this leads to nested calls or event chains:


In the above code we don't just wait for a single value event, we instead deal with all of them. This means that whenever the bookmarks are changed, the onDataChange is executed and we (re)load the sample data (or whatever other action fits your application's needs).


As I mentioned in another post, you can deal with the asynchronous nature of Firebase using promises. It would be like this:


Google API for Android provides a task framework (just like Parse did with Bolts), which is similar to JavaScript promises concept.


First you create a Task for downloading the bookmark from Firebase:


Now that you got the idea, supose that setBookmarks and loadSampleData are also asynchronous. You also can create them as Continuation tasks (just like the previous one) that will run in sequence:


You have to initialize your Singleton when the class is loaded.
Put this on your code:






What's the reason Java doesn't allow us to do


I could understand .NET didn't allow us to do that, as in .NET you have value types that at run-time can have different sizes, but in Java all kinds of T will be object references, thus having the same size (correct me if I'm wrong).


What is the reason?


It's because Java's arrays (unlike generics) contain, at runtime, information about its component type. So you must know the component type when you create the array. Since you don't know what T is at runtime, you can't create the array.


Quote:


Arrays of generic types are not
  allowed because they're not sound. The
  problem is due to the interaction of
  Java arrays, which are not statically
  sound but are dynamically checked,
  with generics, which are statically
  sound and not dynamically checked.
  Here is how you could exploit the
  loophole:


We had proposed to resolve this
  problem using statically safe arrays
  (aka Variance) bute that was rejected
  for Tiger.


-- gafter 


(I believe it is Neal Gafter, but am not sure)


See it in context here: http://forums.sun.com/thread.jspa?threadID=457033&forumID=316


By failing to provide a decent solution, you just end up with something worse IMHO.


The common work around is as follows.


is replaced with (assuming T extends Object and not another class)


I prefer the first example, however more acedemic types seem to prefer the second, or just prefer not to thing about it.  


Most of the examples of why you can't just use an Object[] equally apply to List or Collection (which are supported), so I see them as very poor arguments.


Note: this is one of the reasons the Collections library itself doesn't compile without  warnings.  If you this usecase cannot be supported without warnings, something is fundermentally broken with the generics model IMHO.


The reason this is impossible is that Java implements its Generics purely on the compiler level, and there is only one class file generated for each class.
This is called Type Erasure.


At runtime, the compiled class needs to handle all of its uses with the same bytecode. So, new T[capacity] would have absolutely no idea what type needs to be instantiated.


The answer was already given but if you already have an Instance of T then you can do this:


Hope, I could Help,
Ferdi265


Arrays Are Covariant


Arrays are said to be covariant which basically means that, given the subtyping rules of Java, an array of type T[] may contain elements of type T or any subtype of T. For instance


But not only that, the subtyping rules of Java also state that an array S[] is a subtype of the array T[] if S is a subtype of T, therefore, something like this is also valid:


Because according to the subtyping rules in Java, an array Integer[] is a subtype of an array Number[] because Integer is a subtype of Number.


But this subtyping rule can lead to an interesting question: what would happen if we try to do this?


This last line would compile just fine, but if we run this code, we would get an ArrayStoreException because we’re trying to put a double into an integer array. The fact that we are accessing the array through a Number reference is irrelevant here, what matters is that the array is an array of integers.


This means that we can fool the compiler, but we cannot fool the run-time type system. And this is so because arrays are what we call a reifiable type. This means that at run-time Java knows that this array was actually instantiated as an array of integers which simply happens to be accessed through a reference of type Number[].


So, as we can see, one thing is the actual type of the object, an another thing is the type of the reference that we use to access it, right?


The Problem with Java Generics


Now, the problem with generic types in Java is that the type information for type parameters is discarded by the compiler after the compilation of code is done; therefore this type information is not available at run time. This process is called type erasure. There are good reasons for implementing generics like this in Java, but that’s a long story, and it has to do with binary compatibility with pre-existing code.


The important point here is that since at run-time there is no type information, there is no way to ensure that we are not committing heap pollution.


Let’s consider now the following unsafe code:


If the Java compiler does not stop us from doing this, the run-time type system cannot stop us either, because there is no way, at run time, to determine that this list was supposed to be a list of integers only. The Java run-time would let us put whatever we want into this list, when it should only contain integers, because when it was created, it was declared as a list of integers. That’s why the compiler rejects line number 4 because it is unsafe and if allowed could break the assumptions of the type system.


As such, the designers of Java made sure that we cannot fool the compiler. If we cannot fool the compiler (as we can do with arrays) then we cannot fool the run-time type system either.


As such, we say that generic types are non-reifiable, since at run time we cannot determine the true nature of the generic type.


I skipped some parts of this answers you can read full article here:
https://dzone.com/articles/covariance-and-contravariance 


The main reason is due to the fact that arrays in Java are covariant.


There's a good overview here.


I like the answer indirectly given
by Gafter.  However, I propose it is wrong.  I changed Gafter's code a little.  It compiles and it runs for a while then it bombs where Gafter predicted it would


The output is


So it appears to me you can create generic array types in java.  Did I misunderstand the question?


In my case, I simply wanted an array of stacks, something like this:


Since this was not possible, I used the following as a workaround:


Ugly, but Java is happy.


Note: as mentioned by BrainSlugs83 in the comment to the question, it is totally possible to have arrays of generics in .NET


I know I'm a little late to the party here, but I figured I might be able to help any future googlers since none of these answers fixed my issue.  Ferdi265's answer helped immensely though.


I'm trying to create my own Linked list, so the following code is what worked for me:


In the toArray() method lies the way to create an array of a generic type for me:


From Oracle tutorial:


You cannot create arrays of parameterized types. For example, the following code does not compile:


The following code illustrates what happens when different types are inserted into an array:


If you try the same thing with a generic list, there would be a problem:


If arrays of parameterized lists were allowed, the previous code would fail to throw the desired ArrayStoreException.


To me, it sounds very weak. I think that anybody with a sufficient understanding of generics, would be perfectly fine, and even expect, that the ArrayStoredException is not thrown in such case.


There surely must be a good way around it (maybe using reflection), because it seems to me that that's exactly what ArrayList.toArray(T[] a) does. I quote:


public <T> T[] toArray(T[] a)


Returns an array containing all of the
  elements in this list in the correct order; the runtime type of the
  returned array is that of the specified array. If the list fits in the
  specified array, it is returned therein. Otherwise, a new array is
  allocated with the runtime type of the specified array and the size of
  this list.


So one way around it would be to use this function i.e. create an ArrayList of the objects you want in the array, then use toArray(T[] a) to create the actual array. It wouldn't be speedy, but you didn't mention your requirements.


So does anyone know how toArray(T[] a) is implemented?


It is because generics were added on to java after they made it, so its kinda clunky because the original makers of java thought that when making an array the type would be specified in the making of it. So that does not work with generics so you have to do 
E[] array=(E[]) new Object[15];
This compiles but it gives a warning. 


If we cannot instantiate generic arrays, why does the language have generic array types? What's the point of having a type without objects?


The only reason I can think of, is varargs - foo(T...). Otherwise they could have completely scrubbed generic array types. (Well, they didn't really have to use array for varargs, since varargs didn't exist before 1.5. That's probably another mistake.)


So it is a lie, you can instantiate generic arrays, through varargs!


Of course, the problems with generic arrays are still real, e.g.


We can use this example to actually demonstrate the danger of generic array.


On the other hand, we've been using generic varargs for a decade, and the sky is not falling yet. So we can argue that the problems are being exaggerated; it is not a big deal. If explicit generic array creation is allowed, we'll have bugs here and there; but we've been used to the problems of erasure, and we can live with it.


And we can point to foo2 to refute the claim that the spec keeps us from the problems that they claim to keep us from. If Sun had more time and resources for 1.5, I believe they could have reached a more satisfying resolution.






I'm currently building a Java app that could end up being run on many different platforms, but primarily variants of Solaris, Linux and Windows.


Has anyone been able to successfully extract information such as the current disk space used, CPU utilisation and memory used in the underlying OS? What about just what the Java app itself is consuming?


Preferrably I'd like to get this information without using JNI.


You can get some limited memory information from the Runtime class. It really isn't exactly what you are looking for, but I thought I would provide it for the sake of completeness. Here is a small example. Edit: You can also get disk usage information from the java.io.File class. The disk space usage stuff requires Java 1.6 or higher.


The java.lang.management package does give you a whole lot more info than Runtime - for example it will give you heap memory (ManagementFactory.getMemoryMXBean().getHeapMemoryUsage()) separate from non-heap memory (ManagementFactory.getMemoryMXBean().getNonHeapMemoryUsage()).


You can also get process CPU usage (without writing your own JNI code), but you need to cast the java.lang.management.OperatingSystemMXBean to a com.sun.management.OperatingSystemMXBean. This works on Windows and Linux, I haven't tested it elsewhere.


For example ... call the get getCpuUsage() method more frequently to get more accurate readings.


I think the best method out there is to implement the SIGAR API by Hyperic.  It works for most of the major operating systems ( darn near anything modern ) and is very easy to work with.  The developer(s) are very responsive on their forum and mailing lists.  I also like that it is GPL2 Apache licensed.  They provide a ton of examples in Java too!


SIGAR == System Information, Gathering And Reporting tool.


There's a Java project that uses JNA (so no native libraries to install) and is in active development. It currently supports Linux, OSX, Windows, Solaris and FreeBSD and provides RAM, CPU, Battery and file system information.


You can get some system-level information by using System.getenv(), passing the relevant environment variable name as a parameter. For example, on Windows:


For other operating systems the presence/absence and names of the relevant environment variables will differ.


For windows I went this way.


Here is the link with details.


Have a look at the APIs available in the java.lang.management package. For example: 


There are loads of other useful things in there as well.


Usually, to get low level OS information you can call OS specific commands which give you the information you want with Runtime.exec() or read files such as /proc/* in Linux.


CPU usage isn't straightforward -- java.lang.management via com.sun.management.OperatingSystemMXBean.getProcessCpuTime comes close (see Patrick's excellent code snippet above) but note that it only gives access to time the CPU spent in your process.  it won't tell you about CPU time spent in other processes, or even CPU time spent doing system activities related to your process.


for instance i have a network-intensive java process -- it's the only thing running and the CPU is at 99% but only 55% of that is reported as "processor CPU".


don't even get me started on "load average" as it's next to useless, despite being the only cpu-related item on the MX bean.  if only sun in their occasional wisdom exposed something like "getTotalCpuTime"...


for serious CPU monitoring SIGAR mentioned by Matt seems the best bet.


It is still under development but you can already use jHardware 


It is a simple library that scraps system data using Java. It works in both Linux and Windows.


If you are using Jrockit VM then here is an other way of getting VM CPU usage. Runtime bean can also give you CPU load per processor. I have used this only on Red Hat Linux to observer Tomcat performance. You have to enable JMX remote in catalina.sh for this to work.


Add OSHI dependency via maven:


Get a battery capacity left in percentage:


Hey you can do this with java/com integration.  By accessing WMI features you can get all the information.


On Windows, you can run the systeminfo command and retrieves its output for instance with the following code:






I'm looking for the fastest way to determine if a long value is a perfect square (i.e. its square root is another integer).  I've done it the easy way, by using the built-in Math.sqrt() function, but I'm wondering if there is a way to do it faster by restricting yourself to integer-only domain.  Maintaining a lookup table is impratical (since there are about 231.5 integers whose square is less than 263).


Here is the very simple and straightforward way I'm doing it now:


Notes: I'm using this function in many Project Euler problems.  So no one else will ever have to maintain this code.  And this kind of micro-optimization could actually make a difference, since part of the challenge is to do every algorithm in less than a minute, and this function will need to be called millions of times in some problems.


Update 2:  A new solution posted by A. Rex has proven to be even faster.  In a run over the first 1 billion integers, the solution only required 34% of the time that the original solution used.  While the John Carmack hack is a little better for small values of n, the benefit compared to this solution is pretty small.


Here is the A. Rex solution, converted to Java:


Update:  I've tried the different solutions presented below.


The one suggestion which did show improvements was made by John D. Cook.  You can observe that the last hex digit (i.e. the last 4 bits) of a perfect square must be 0, 1, 4, or 9.  This means that 75% of numbers can be immediately eliminated as possible squares.  Implementing this solution resulted in about a 50% reduction in runtime.


Working from John's suggestion, I investigated properties of the last n bits of a perfect square.  By analyzing the last 6 bits, I found that only 12 out of 64 values are possible for the last 6 bits.  This means 81% of values can be eliminated without using any math.  Implementing this solution gave an additional 8% reduction in runtime (compared to my original algorithm).  Analyzing more than 6 bits results in a list of possible ending bits which is too large to be practical.


Here is the code that I have used, which runs in 42% of the time required by the original algorithm (based on a run over the first 100 million integers).  For values of n less than 410881, it runs in only 29% of the time required by the original algorithm.


Notes:


I figured out a method that works ~35% faster than your 6bits+Carmack+sqrt code, at least with my CPU (x86) and programming language (C/C++).  Your results may vary, especially because I don't know how the Java factor will play out.


My approach is threefold:





I'm pretty late to the party, but I hope to provide a better answer; shorter and (assuming my benchmark is correct) also much faster.


The first test catches most non-squares quickly. It uses a 64-item table packed in a long, so there's no array access cost (indirection and bounds checks). For a uniformly random long, there's a 81.25% probability of ending here.


The second test catches all numbers having an odd number of twos in their factorization. The method Long.numberOfTrailingZeros is very fast as it gets JIT-ed into a single i86 instruction.


After dropping the trailing zeros, the third test handles numbers ending with 011, 101, or 111 in binary, which are no perfect squares. It also cares about negative numbers and also handles 0.


The final test falls back to double arithmetic. As double has only 53 bits mantissa, 
the conversion from long to double includes rounding for big values. Nonetheless, the test is  correct (unless the proof is wrong).


Trying to incorporate the mod255 idea wasn't successful.


You'll have to do some benchmarking.  The best algorithm will depend on the distribution of your inputs.


Your algorithm may be nearly optimal, but you might want to do a quick check to rule out some possibilities before calling your square root routine.  For example, look at the last digit of your number in hex by doing a bit-wise "and."  Perfect squares can only end in 0, 1, 4, or 9 in base 16,  So for 75% of your inputs (assuming they are uniformly distributed) you can avoid a call to the square root in exchange for some very fast bit twiddling.


Kip benchmarked the following code implementing the hex trick.  When testing numbers 1 through 100,000,000, this code ran twice as fast as the original.


When I tested the analogous code in C++, it actually ran slower than the original. However, when I eliminated the switch statement, the hex trick once again make the code twice as fast.


Eliminating the switch statement had little effect on the C# code.


I was thinking about the horrible times I've spent in Numerical Analysis course.


And then I remember, there was this function circling around the 'net from the Quake Source code:


Which basically calculates a square root, using Newton's approximation function (cant remember the exact name).


It should be usable and might even be faster, it's from one of the phenomenal id software's game!


It's written in C++ but it should not be too hard to reuse the same technique in Java once you get the idea:


I originally found it at: http://www.codemaestro.com/reviews/9


Newton's method explained at wikipedia: http://en.wikipedia.org/wiki/Newton%27s_method


You can follow the link for more explanation of how it works, but if you don't care much, then this is roughly what I remember from reading the blog and from taking the Numerical Analysis course:


The approximation function gives more precise values the more you iterate the function over the result. In Quake's case, one iteration is "good enough", but if it wasn't for you... then you could add as much iteration as you need.


This should be faster because it reduces the number of division operations done in naive square rooting down to a simple divide by 2 (actually a * 0.5F multiply operation) and replace it with a few fixed number of multiplication operations instead.


I'm not sure if it would be faster, or even accurate, but you could use John Carmack's Magical Square Root, algorithm to solve the square root faster.  You could probably easily test this for all possible 32 bit integers, and validate that you actually got correct results, as it's only an appoximation.  However, now that I think about it, using doubles is approximating also, so I'm not sure how that would come into play.


If you do a binary chop to try to find the "right" square root, you can fairly easily detect if the value you've got is close enough to tell:


So having calculated n^2, the options are:


(Sorry, this uses n as your current guess, and target for the parameter. Apologise for the confusion!)


I don't know whether this will be faster or not, but it's worth a try.


EDIT: The binary chop doesn't have to take in the whole range of integers, either (2^x)^2 = 2^(2x), so once you've found the top set bit in your target (which can be done with a bit-twiddling trick; I forget exactly how) you can quickly get a range of potential answers. Mind you, a naive binary chop is still only going to take up to 31 or 32 iterations.


I ran my own analysis of several of the algorithms in this thread and came up with some new results. You can see those old results in the edit history of this answer, but they're not accurate, as I made a mistake, and wasted time analyzing several algorithms which aren't close. However, pulling lessons from several different answers, I now have two algorithms that crush the "winner" of this thread. Here's the core thing I do differently than everyone else:


However, this simple line, which most of the time adds one or two very fast instructions, greatly simplifies the switch-case statement into one if statement. However, it can add to the runtime if many of the tested numbers have significant power-of-two factors.


The algorithms below are as follows:


Here is a sample runtime if the numbers are generated using Math.abs(java.util.Random.nextLong())


And here is a sample runtime if it's run on the first million longs only:


As you can see, DurronTwo does better for large inputs, because it gets to use the magic trick very very often, but gets clobbered compared to the first algorithm and Math.sqrt because the numbers are so much smaller. Meanwhile, the simpler Durron is a huge winner because it never has to divide by 4 many many times in the first million numbers.


Here's Durron:


And DurronTwo


And my benchmark harness: (Requires Google caliper 0.1-rc5)


UPDATE: I've made a new algorithm that is faster in some scenarios, slower in others, I've gotten different benchmarks based on different inputs. If we calculate modulo 0xFFFFFF = 3 x 3 x 5 x 7 x 13 x 17 x 241, we can eliminate 97.82% of numbers that cannot be squares. This can be (sort of) done in one line, with 5 bitwise operations:


The resulting index is either 1) the residue, 2) the residue + 0xFFFFFF, or 3) the residue + 0x1FFFFFE. Of course, we need to have a lookup table for residues modulo 0xFFFFFF, which is about a 3mb file (in this case stored as ascii text decimal numbers, not optimal but clearly improvable with a ByteBuffer and so forth. But since that is precalculation it doesn't matter so much. You can find the file here (or generate it yourself): 


I load it into a boolean array like this:


Example runtime. It beat Durron (version one) in every trial I ran.


It should be much faster to use Newton's method to calculate the Integer Square Root, then square this number and check, as you do in your current solution.  Newton's method is the basis for the Carmack solution mentioned in some other answers.  You should be able to get a faster answer since you're only interested in the integer part of the root, allowing you to stop the approximation algorithm sooner.


Another optimization that you can try:  If the Digital Root of a number doesn't end in 
1, 4, 7, or 9 the number is not a perfect square.  This can be used as a quick way to eliminate 60% of your inputs before applying the slower square root algorithm.


I want this function to work with all
  positive 64-bit signed integers


Math.sqrt() works with doubles as input parameters, so you won't get accurate results for integers bigger than 2^53.


It's been pointed out that the last d digits of a perfect square can only take on certain values. The last d digits (in base b) of a number n is the same as the remainder when n is divided by bd, ie. in C notation n % pow(b, d).


This can be generalized to any modulus m, ie. n % m can be used to rule out some percentage of numbers from being perfect squares. The modulus you are currently using is 64, which allows 12, ie. 19% of remainders, as possible squares. With a little coding I found the modulus 110880, which allows only 2016, ie. 1.8% of remainders as possible squares. So depending on the cost of a modulus operation (ie. division) and a table lookup versus a square root on your machine, using this modulus might be faster.


By the way if Java has a way to store a packed array of bits for the lookup table, don't use it. 110880 32-bit words is not much RAM these days and fetching a machine word is going to be faster than fetching a single bit.


Just for the record, another approach is to use the prime decomposition. If every factor of the decomposition is even, then the number is a perfect square. So what you want is to see if a number can be decomposed as a product of squares of prime numbers. Of course, you don't need to obtain such a decomposition, just to see if it exists.


First build a table of squares of prime numbers which are lower than 2^32. This is far smaller than a table of all integers up to this limit.


A solution would then be like this:


I guess it's a bit cryptic. What it does is checking in every step that the square of a prime number divide the input number. If it does then it divides the number by the square as long as it is possible, to remove this square from the prime decomposition.
If by this process, we came to 1, then the input number was a decomposition of square of prime numbers. If the square becomes larger than the number itself, then there is no way this square, or any larger squares, can divide it, so the number can not be a decomposition of squares of prime numbers.


Given nowadays' sqrt done in hardware and the need to compute prime numbers here, I guess this solution is way slower. But it should give better results than solution with sqrt which won't work over 2^54, as says mrzl in his answer.


For performance, you very often have to do some compromsies. Others have expressed various methods, however, you noted Carmack's hack was faster up to certain values of N. Then, you should check the "n" and if it is less than that number N, use Carmack's hack, else use some other method described in the answers here.


An integer problem deserves an integer solution. Thus


Do binary search on the (non-negative) integers to find the greatest integer t such that t**2 <= n. Then test whether r**2 = n exactly. This takes time O(log n). 


If you don't know how to binary search the positive integers because the set is unbounded, it's easy. You starting by computing your increasing function f (above f(t) = t**2 - n) on powers of two. When you see it turn positive, you've found an upper bound. Then you can do standard binary search.


You should get rid of the 2-power part of N right from the start.


2nd Edit
The magical expression for m below should be


and not as written


End of 2nd edit


1st Edit:


Minor improvement:


End of 1st edit


Now continue as usual. This way, by the time you get to the floating point part, you already got rid of all the numbers whose 2-power part is odd (about half), and then you only consider 1/8 of whats left. I.e. you run the floating point part on 6% of the numbers.


This is the fastest Java implementation I could come up with, using a combination of techniques suggested by others in this thread.


I also experimented with these modifications but they did not help performance:





The following simplification of maaartinus's solution appears to shave a few percentage points off the runtime, but I'm not good enough at benchmarking to produce a benchmark I can trust:


It would be worth checking how omitting the first test,


would affect performance.


This a rework from decimal to binary of the old Marchant calculator algorithm (sorry, I don't have a reference), in Ruby, adapted specifically for this question:


Here's a workup of something similar (please don't vote me down for coding style/smells or clunky O/O - it's the algorithm that counts, and C++ is not my home language). In this case, we're looking for residue == 0:


The sqrt call is not perfectly accurate, as has been mentioned, but it's interesting and instructive that it doesn't blow away the other answers in terms of speed. After all, the sequence of assembly language instructions for a sqrt is tiny. Intel has a hardware instruction, which isn't used by Java I believe because it doesn't conform to IEEE.


So why is it slow? Because Java is actually calling a C routine through JNI, and it's actually slower to do so than to call a Java subroutine, which itself is slower than doing it inline. This is very annoying, and Java should have come up with a better solution, ie building in floating point library calls if necessary. Oh well.


In C++, I suspect all the complex alternatives would lose on speed, but I haven't checked them all.
What I did, and what Java people will find usefull, is a simple hack, an extension of the special case testing suggested by A. Rex. Use a single long value as a bit array, which isn't bounds checked. That way, you have 64 bit boolean lookup.


The routine isPerfectSquare5 runs in about 1/3 the time on my core2 duo machine. I suspect that further tweaks along the same lines could reduce the time further on average, but every time you check, you are trading off more testing for more eliminating, so you can't go too much farther on that road.


Certainly, rather than having a separate test for negative, you could check the high 6 bits the same way.


Note that all I'm doing is eliminating possible squares, but when I have a potential case I have to call the original, inlined isPerfectSquare.


The init2 routine is called once to initialize the static values of pp1 and pp2.
Note that in my implementation in C++, I'm using unsigned long long, so since you're signed, you'd have to use the >>> operator.


There is no intrinsic need to bounds check the array, but Java's optimizer has to figure this stuff out pretty quickly, so I don't blame them for that.


Project Euler is mentioned in the tags and many of the problems in it require checking numbers >> 2^64.  Most of the optimizations mentioned above don't work easily when you are working with an 80 byte buffer.


I used java BigInteger and a slightly modified version of Newton's method, one that works better with integers.  The problem was that exact squares n^2 converged to (n-1) instead of n because n^2-1 = (n-1)(n+1) and the final error was just one step below the final divisor and the algorithm terminated.  It was easy to fix by adding one to the original argument before computing the error.  (Add two for cube roots, etc.)


One nice attribute of this algorithm is that you can immediately tell if the number is a perfect square - the final error (not correction) in Newton's method will be zero.  A simple modification also lets you quickly calculate floor(sqrt(x)) instead of the closest integer.  This is handy with several Euler problems.


I like the idea to use an almost correct method on some of the input. Here is a version with a higher "offset". The code seems to work and passes my simple test case.


Just replace your:


code with this one:


I checked all of the possible results when the last n bits of a square is observed. By successively examining more bits, up to 5/6th of inputs can be eliminated. I actually designed this to implement Fermat's Factorization algorithm, and it is very fast there.


The last bit of pseudocode can be used to extend the tests to eliminate more values. The tests above are for k = 0, 1, 2, 3


a is of the form (3 << 2k) - 1
    b is of the form (2 << 2k)
    c is of the form (2 << 2k + 2) - 1
    d is of the form (2 << 2k - 1) * 10


It first tests whether it has a  square residual with moduli of power of two, then it tests based on a final modulus, then it uses the Math.sqrt to do a final test. I came up with the idea from the top post, and attempted to extend upon it. I appreciate any comments or suggestions.


Update: Using the test by a modulus, (modSq) and a modulus base of 44352, my test runs in 96% of the time of the one in the OP's update for numbers up to 1,000,000,000.


Considering for general bit length (though I have used specific type here), I tried to design simplistic algo as below. Simple and obvious check for 0,1,2 or <0 is required initially.
Following is simple in sense that it doesn't try to use any existing maths functions. Most of the operator can be replaced with bit-wise operators. I haven't tested with any bench mark data though. I'm neither expert at maths or computer algorithm design in particular, I would love to see you pointing out problem. I know there is lots of improvement chances there.


If you want speed, given that your integers are of finite size, I suspect that the quickest way would involve (a) partitioning the parameters by size (e.g. into categories by largest bit set), then checking the value against an array of perfect squares within that range. 


Don't know about fastest, but the simplest is to take the square root in the normal fashion, multiply the result by itself, and see if it matches your original value.


Since we're talking integers here, the fasted would probably involve a collection where you can just make a lookup.


If speed is a concern, why not partition off the most commonly used set of inputs and their values to a lookup table and then do whatever optimized magic algorithm you have come up with for the exceptional cases?


Regarding the Carmac method, it seems like it would be quite easy just to iterate once more, which should double the number of digits of accuracy. It is, after all, an extremely truncated iterative method -- Newton's, with a very good first guess.


Regarding your current best, I see two micro-optimizations:


I.e:


Even better might be a simple


Obviously, it would be interesting to know how many numbers get culled at each checkpoint -- I rather doubt the checks are truly independent, which makes things tricky.


"I'm looking for the fastest way to determine if a long value is a perfect square (i.e. its square root is another integer)." 


The answers are impressive, but I failed to see a simple check :


check whether the first number on the right of the long it a member of the set (0,1,4,5,6,9) . If it is not, then it cannot possibly be a 'perfect square' .


eg.


4567 - cannot be a perfect square.


It ought to be possible to pack the 'cannot be a perfect square if the last X digits are N' much more efficiently than that! I'll use java 32 bit ints, and produce enough data to check the last 16 bits of the number - that's 2048 hexadecimal int values.


...


Ok. Either I have run into some number theory that is a little beyond me, or there is a bug in my code. In any case, here is the code:


and here are the results:


(ed: elided for poor performance in prettify.js; view revision history to see.)


Here is a slightly different take, and it is not the fastest (in terms of benchmark) but it is quite simple and fast to write.  If you just want to know if the square is a non-decimal number, and if you do not care if it is an integer, or a long, here is an example of what you can do:


If you do not need micro-optimization, this answer is better in terms of simplicity and maintainability.  






I have some EditTexts that a user enters an ftp address, username, password, port anda testConnection button. If a connection is successfully estabished it returns a boolean value of true. 


I'm reworking my code to use AsyncTasks to perform the various ftp operations, but how can I pass back a boolean value if a connection is successfully made?


And my AsyncTask


If you call myMethod from onPostExecute the code inside it will run on the UI Thread. Otherwise you need to post a Runnable through a Handler


Declare Your asynctask like 


The third parameter is the result parameter that is returned by doinbackground.
(The first one is asynctask param and second one is progress parameter)


so your do in background and onpostexecute will be


Remember that the value returned by doInBackground is cathced by onPostExecute as parameter. so use this in the onPostExecute method. you can update your UI in in this method also. 






Is it possible to specify a Java classpath that includes a JAR file contained within another JAR file?


If you're trying to create a single jar that contains your application and it's required libraries, there are two ways (that I know of) to do that.  The first is One-Jar, which uses a special classloader to allow the nesting of jars.  The second is UberJar, (or Shade), which explodes the included libraries and puts all the classes in the top-level jar.


I should also mention that UberJar and Shade are plugins for Maven1 and Maven2 respectively.  As mentioned below, you can also use the assembly plugin (which in reality is much more powerful, but much harder to properly configure).


You do NOT want to use those "explode JAR contents" solutions.  They definitely make it harder to see stuff (since everything is exploded at the same level).  Furthermore, there could be naming conflicts (should not happen if people use proper packages, but you cannot always control this).


The feature that you want is one of the top 25 Sun RFEs: RFE 4648386, which Sun, in their infinite wisdom, has designated as being of low priority. We can only hope that Sun wakes up...


In the meanwhile, the best solution that I have come across (which I wish that Sun would copy in the JDK) is to use the custom class loader JarClassLoader.


After some research I have found method that doesn't require maven or any 3rd party extension/program. 


You can use "Class-Path" in your manifest file.


For example:


Create manifest file MANIFEST.MF


Compile all your classes and run jar cfm Testing.jar MANIFEST.MF *.class custom_lib.jar


c stands for create archive
f indicates that you want to specify file 
v is for verbose input
m means that we will pass custom manifest file


Be sure that you included lib in jar package. You should be able to run jar in the normal way.


based on: http://www.ibm.com/developerworks/library/j-5things6/


all other information you need about the class-path do you find here


Use the zipgroupfileset tag (uses same attributes as a fileset tag); it will unzip all files in the directory and add to your new archive file.
More information: http://ant.apache.org/manual/Tasks/zip.html


This is a very useful way to get around the jar-in-a-jar problem -- I know because I have googled this exact StackOverflow question while trying to figure out what to do. If you want to package a jar or a folder of jars into your one built jar with Ant, then forget about all this classpath or third-party plugin stuff, all you gotta do is this (in Ant):


If you are building with ant (I am using ant from eclipse), you can just add the extra jar files
by saying to ant to add them...
Not necessarily the best method if you have a project maintained by multiple people but it works for one person project and is easy.


for example my target that was building the .jar file was:


I just added one line to make it:


where


was the dir with the external jars.
And that's it...


Not without writing your own class loader.  You can add jars to the jar's classpath, but they must be co-located, not contained in the main jar.


You need to build a custom class-loader to do this or a third-party library that supports this. Your best bet is to extract the jar from the runtime and add them to the classpath (or have them already added to the classpath).


I use maven for my java builds which has a plugin called the maven assembly plugin.  


It does what your asking, but like some of the other suggestions describe - essentially exploding all the dependent jars and recombining them into a single jar


I was about to advise to extract all the files at the same level, then to make a jar out of the result, since the package system should keep them neatly separated.
That would be the manual way, I suppose the tools indicated by Steve will do that nicely.


Winstone is pretty good http://blog.jayway.com/2008/11/28/executable-war-with-winstone-maven-plugin/. But not for complex sites. And that's a shame because all it takes is to include the plugin.


Well, there is a very easy way if you're using Eclipse. 


Export your project as a "Runnable" Jar file (right-click project folder from within Eclipse, select "Export..."). When you configure the export settings, be sure to select "Extract required libraries into generated Jar." Keep in mind, select "Extract..." and not "Package required libraries...". 


Additionally: You must select a run-configuration in your export settings. So, you could always create an empty main( ) in some class and use it for your run configuration. 


Anyway, it isn't guaranteed to work 100% of the time - as you will notice a pop-up message telling you to make sure you check the licenses of the Jar files you're including and something about not copying signature files. However, I have been doing this for years and have never encountered a problem.


If you have eclpise IDE, you just need to export your JAR and choose "Package Required libraries into generated JAR". eclipse will automatically add the required dependant JARs into the generated JAR as well as generated some eclipse custom class loader that load these JARs automatically.






While looking at online code samples, I have sometimes come across an assignment of a String constant to a String object via the use of the new operator.


For example:


This, of course, compared to


I'm not familiar with this syntax and have no idea what the purpose or effect would be. 
Since String constants typically get stored in the constant pool and then in whatever representation the JVM has for dealing with String constants, would anything even be allocated on the heap?


The one place where you may need new String(String) is to force a substring to copy to a new underlying character array, as in 


However, this behavior is unfortunately undocumented and implementation dependent.


I have been burned by this when reading large files (some up to 20 MiB) into a String and carving it into lines after the fact.  I ended up with all the strings for the lines referencing the char[] consisting of entire file.  Unfortunately, that unintentionally kept a reference to the entire array for the few lines I held on to for a longer time than processing the file - I was forced to use new String() to work around it.  


The only implementation agnostic way to do this is:


This unfortunately must copy the array twice, once for toCharArray() and once in the String constructor.


There needs to be a documented way to get a new String by copying the chars of an existing one; or the documentation of String(String) needs to be improved to make it more explicit (there is an implication there, but it's rather vague and open to interpretation).


In response to the comments, which keep coming in, observe what the Apache Harmony implementation of new String() was:


That's right, no copy of the underlying array there.  And yet, it still conforms to the (Java 7) String documentation, in that it:


Initializes a newly created String object so that it represents the same sequence of characters as the argument; in other words, the newly created string is a copy of the argument string. Unless an explicit copy of original is needed, use of this constructor is unnecessary since Strings are immutable.


The salient piece being "copy of the argument string"; it does not say "copy of the argument string and the underlying character array supporting the string".


Be careful that you program to the documentation and not one implementation.


The only time I have found this useful is in declaring lock variables:


In this case, debugging tools like Eclipse will show the string when listing what locks a thread currently holds or is waiting for. You have to use "new String", i.e. allocate a new String object, because otherwise a shared string literal could possibly be locked in some other unrelated code.


String s1="foo"; literal will go in StringPool and s1 will refer.


String s2="foo"; this time it will check "foo" literal is already available in StringPool or not as now it exist so s2 will refer the same literal.


String s3=new String("foo"); "foo" literal will be created in StringPool first then through string arg constructor String Object will be created i.e "foo" in the heap due to object creation through new operator then s3 will refer it.


String s4=new String("foo"); same as s3


so System.out.println(s1==s2); //true due to literal comparison.


and System.out.println(s3==s4);// false due to object comparison(s3 and s4 is created at different places in heap)


The sole utility for this constructor described by Software Monkey and Ruggs seems to have disappeared from JDK7.
There is no longer an offset field in class String, and substring always use


to trim the char array for the copy.


Well, that depends on what the "..." is in the example.  If it's a StringBuffer, for example, or a byte array, or something, you'll get a String constructed from the data you're passing.


But if it's just another String, as in new String("Hello World!"), then it should be replaced by simply "Hello World!", in all cases.  Strings are immutable, so cloning one serves no purpose -- it's just more verbose and less efficient to create a new String object just to serve as a duplicate of an existing String (whether it be a literal or another String variable you already have).


In fact, Effective Java (which I highly recommend) uses exactly this as one of its examples of "Avoid creating unnecessary objects":


As an extreme example of what not to do, consider this statement:


(Effective Java, Second Edition)


Generally, this indicates someone who isn't comfortable with the new-fashioned C++ style of declaring when initialized.  


Back in the C days, it wasn't considered good form to define auto variables in an inner scope; C++ eliminated the parser restriction, and Java extended that.


So you see code that has


In the extreme case, all the declarations may be at the top of a function, and not in enclosed scopes like the for loop here.


IN general, though, the effect of this is to cause a String ctor to be called once, and the resulting String thrown away.  (The desire to avoid this is just what led Stroustrup to allow declarations anywhere in the code.)  So you are correct that it's unnecessary and bad style at best, and possibly actually bad.


I guess it will depend on the code samples you're seeing. 


Most of the times using the class constructor "new String()" in code sample are only to show a very well know java class instead of creating a new one. 


You should avoid using it most of the times. Not only because string literals are interned  but mainly because string are inmutable. It doesn't make sense have two copies that represent the same object. 


While  the article mensioned by Ruggs is "interesting" it should not be used unless very specific circumstances, because it could create more damage than good. You'll be coding to  an implementation rather than an specification and the same code could not run the same for instance in JRockit, IBM VM, or other.


There are two ways in which Strings can be created in Java. Following are the examples for both the ways:
1) Declare a variable of type String(a class in Java) and assign it to a value which should be put between double quotes. This will create a string in the string pool area of memory.
eg: String str = "JAVA";


2)Use the constructor of String class and pass a string(within double quotes) as an argument.
eg: String s = new String("JAVA");
This will create a new string JAVA in the main memory and also in the string pool if this string is not already present in string pool.






I want to return two objects from a Java method and was wondering what could be a good way of doing so?


The possible ways I can think of are: return a HashMap (since the two Objects are related) or return an ArrayList of Object objects.


To be more precise, the two objects I want to return are (a) List of objects and (b) comma separated names of the same.


I want to return these two Objects from one method because I dont want to iterate through the list of objects to get the comma separated names (which I can do in the same loop in this method).


Somehow, returning a HashMap does not look a very elegant way of doing so.


If you want to return two objects you usually want to return a single object that encapsulates the two objects instead.


You could return a List of NamedObject objects like this:


Then you can easily return a List<NamedObject<WhateverTypeYouWant>>.


Also: Why would you want to return a comma-separated list of names instead of a List<String>? Or better yet, return a Map<String,TheObjectType> with the keys being the names and the values the objects (unless your objects have specified order, in which case a NavigableMap might be what you want.


If you know you are going to return two objects, you can also use a generic pair:


Edit A more fully formed implementation of the above: 


Notes, mainly around rustiness with Java & generics:


In the event the method you're calling is private, or called from one location, try


The caller looks like:


The Pair example by David Hanak has no syntactic benefit, and is limited to two values.  


And the caller looks like:


I almost always end up defining n-Tuple classes when I code in Java. For instance:


I know it's a bit ugly, but it works, and you just have to define your tuple types once. Tuples are something Java really lacks.


EDIT: David Hanak's example is more elegant, as it avoids defining getters and still keeps the object immutable.


We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.


D. Knuth


Before Java 5, I would kind of agree that the Map solution isn't ideal. It wouldn't give you compile time type checking so can cause issues at runtime. However, with Java 5, we have Generic Types.


So your method could look like this:


MyType of course being the type of object you are returning.


Basically I think that returning a Map is the right solution in this case because that's exactly what you want to return - a mapping of a string to an object.


You may use any of following ways:


1) Using Array


2) Using ArrayList


3) Using HashMap 


4) Using your custom container class 


5) Using AbstractMap.simpleEntry


6) Using Pair of Apache Commons 


Alternatively, in situations where I want to return a number of things from a method I will sometimes use a callback mechanism instead of a container. This works very well in situations where I cannot specify ahead of time just how many objects will be generated. 


With your particular problem, it would look something like this:


Regarding the issue about multiple return values in general I usually use a small helper class that wraps a single return value and is passed as parameter to the method:


(for primitive datatypes I use minor variations to directly store the value)


A method that wants to return multiple values would then be declared as follows:


Maybe the major drawback is that the caller has to prepare the return objects in advance in case he wants to use them (and the method should check for null pointers)


Advantages (in comparison to other solutions proposed):


Use of following Entry object
Example :


All possible solutions will be a kludge (like container objects, your HashMap idea, “multiple return values” as realized via arrays). I recommend regenerating the comma-separated list from the returned List. The code will end up being a lot cleaner.


Apache Commons has tuple and triple for this:


Source: https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/tuple/package-summary.html


As I see it there are really three choices here and the solution depends on the context.  You can choose to implement the construction of the name in the method that produces the list.  This is the choice you've chosen, but I don't think it is the best one.  You are creating a coupling in the producer method to the consuming method that doesn't need to exist.  Other callers may not need the extra information and you would be calculating extra information for these callers.


Alternatively, you could have the calling method calculate the name.  If there is only one caller that needs this information, you can stop there.  You have no extra dependencies and while there is a little extra calculation involved, you've avoided making your construction method too specific.  This is a good trade-off.


Lastly, you could have the list itself be responsible for creating the name.  This is the route I would go if the calculation needs to be done by more than one caller.  I think this puts the responsibility for the creation of the names with the class that is most closely related to the objects themselves.


In the latter case, my solution would be to create a specialized List class that returns a comma-separated string of the names of objects that it contains. Make the class smart enough that it constructs the name string on the fly as objects are added and removed from it.  Then return an instance of this list and call the name generation method as needed.  Although it may be almost as efficient (and simpler) to simply delay calculation of the names until the first time the method is called and store it then (lazy loading).  If you add/remove an object, you need only remove the calculated value and have it get recalculated on the next call.


Can do some thing like a tuple in dynamic language (Python)


and use like this


I followed a similar approach than the described in the other answers with a few tweaks based on the requirement I had, basically I created the following classes(Just in case, everything is Java):


Then, my requirement was simple, in the repository Class that reaches the DB, for the Get Methods than retrieve data from the DB, I need to check if it failed or succeed, then, if succeed, I needed to play with the returning list, if failed, stop the execution and notify the error.


So, for example, my methods are like this:


Where ResultMessage is just a class with two fields (code/message) and Customer is any class with a bunch of fields that comes from the DB.


Then, to check the result I just do this:


In C++ (STL) there is a pair class for bundling two objects. In Java Generics a pair class isn't available, although there is some demand for it. You could easily implement it yourself though.


I agree however with some other answers that if you need to return two or more objects from a method, it would be better to encapsulate them in a class.


Why not create a WhateverFunctionResult object that contains your results, and the logic required to parse these results, iterate over then etc. It seems to me that either:


I see this sort of issue crop up again and again. Don't be afraid to create your own container/result classes that contain the data and the associated functionality to handle this. If you simply pass the stuff around in a HashMap or similar, then your clients have to pull this map apart and grok the contents each time they want to use the results.


I have a been using a very basic approach to deal with problems of multiple returns. It serves the purpose, and avoids complexity.


I call it the string separator Approach


And it is effective as it can even return values of Multiple Types e.g. int,double,char,string etc


In this approach we make a use of a string that is very unlikely to occur generally.
We call it as a separator.
This separator would be used to separate various values when used in a function


For example we will have our final return as (for example) intValue separator doubleValue separator...
And Then  using this string we will retrieve all the information required, that can be of diffrent types as well


Following code will Show the working of this concept


The separator used is !@# and
 3 values are being returned intVal,doubleVal and stringVal


OUTPUT


Pass a list to your method and populate it, then return the String with the names, like this:


Then call it like this:


This is not exactly answering the question, but since every of the solution given here has some drawbacks, I suggest to try to refactor your code a little bit so you need to return only one value.


Case one.


You need something inside as well as outside of your method. Why not calculate it outside and pass it to the method?


Instead of:


Try:


This should cover most of your needs, since in most situations one value is created before the other and you can split creating them in two methods. The drawback is that method createThingsB has an extra parameter comparing to createThings, and possibly you are passing exactly the same list of parameters twice to different methods.


Case two.


Most obvious solution ever and a simplified version of case one. It's not always possible, but maybe both of the values can be created independently of each other?


Instead of:


Try:


To make it more useful, these two methods can share some common logic:


While in your case, the comment may be a good way to go, in Android, you can use Pair . Simply


Keep it simple and create a class for multiple result situation. This example accepts an ArrayList and a message text from a databasehelper getInfo.


Where you call the routine that returns multiple values you code:


In the routine getInfo you code:


and define a class multResult with:


}


In C, you would do it by passing pointers to placeholders for the results as arguments:


Let's try something similar, in Java.


PASS A HASH INTO THE METHOD AND POPULATE IT......


public void buildResponse(String data, Map response);






I was surprised to find today that I couldn't track down any simple way to write the contents of an InputStream to an OutputStream in Java. Obviously, the byte buffer code isn't difficult to write, but I suspect I'm just missing something which would make my life easier (and the code clearer).


So, given an InputStream in and an OutputStream out, is there a simpler way to write the following?


As WMR mentioned, org.apache.commons.io.IOUtils from Apache has a method called copy(InputStream,OutputStream) which does exactly what you're looking for.


So, you have:


...in your code.


Is there a reason you're avoiding IOUtils? 


If you are using Java 7, Files (in the standard library) is the best approach:


Edit: Of course it's just useful when you create one of InputStream or OutputStream from file. Use file.toPath() to get path from file.


To write into an existing file (e.g. one created with File.createTempFile()), you'll need to pass the REPLACE_EXISTING copy option (otherwise FileAlreadyExistsException is thrown):


I think this will work, but make sure to test it... minor "improvement", but it might be a bit of a cost at readability.


Since Java 9, InputStream provides a method called transferTo with the following signature:


As the documentation states, transferTo will:


Reads all bytes from this input stream and writes the bytes to the
  given output stream in the order that they are read. On return, this
  input stream will be at end of stream. This method does not close
  either stream. 


This method may block indefinitely reading from the
  input stream, or writing to the output stream. The behavior for the
  case where the input and/or output stream is asynchronously closed, or
  the thread interrupted during the transfer, is highly input and output
  stream specific, and therefore not specified


So in order to write contents of a Java InputStream to an OutputStream, you can write:


Using Guava's ByteStreams.copy():


If you only need this for writing an InputStream to a File then you can use this simple function:


PipedInputStream and PipedOutputStream should only be used when you have multiple threads, as noted by the Javadoc.


Also, note that input streams and output streams do not wrap any thread interruptions with IOExceptions... So, you should consider incorporating an interruption policy to your code:


This would be an useful addition if you expect to use this API for copying large volumes of data, or data from streams that get stuck for an intolerably long time.


There's no way to do this a lot easier with JDK methods, but as Apocalisp has already noted, you're not the only one with this idea: You could use IOUtils from Jakarta Commons IO, it also has a lot of other useful things, that IMO should actually be part of the JDK...


Using Java7 and try-with-resources, comes with a simplified and readable version.


The JDK uses the same code so it seems like there is no "easier" way without clunky third party libraries (which probably don't do anything different anyway). The following is directly copied from java.nio.file.Files.java:


Use Commons Net's Util class:


I think it's better to use a large buffer, because most of the files are greater than 1024 bytes. Also it's a good practice to check the number of read bytes to be positive.


Here comes how I'm doing with simplest for loop.


For those who use Spring framework there is a useful StreamUtils class:


The above does not close the streams. If you want the streams closed after the copy, use FileCopyUtils class instead:


PipedInputStream and PipedOutputStream may be of some use, as you can connect one to the other.


Another possible candidate are the Guava I/O utilities:


http://code.google.com/p/guava-libraries/wiki/IOExplained


I thought I'd use these since Guava is already immensely useful in my project, rather than adding yet another library for one function.


A IMHO more minimal snippet (that also more narrowly scopes the length variable):


As a side note, I don't understand why more people don't use a for loop, instead opting for a while with an assign-and-test expression that is regarded by some as "poor" style.


Try Cactoos:


More details here: http://www.yegor256.com/2017/06/22/object-oriented-input-output-in-cactoos.html


you can use this method






I'm processing some Java source code using Java. I'm extracting the string literals and feeding them to a function taking a String. The problem is that I need to pass the unescaped version of the String to the function (ie. this means converting \n to a newline, and \\ to a single \, etc).


Is there a function inside the Java API that does this? If not, can I obtain such functionality from some library? Obviously the Java compiler has to do this conversion.


PS- In case anyone wants to know: I'm trying to unobfuscate string literals in decompiled obfuscated Java files


EDIT: You can download the full source for the function I discuss below. I also discuss it in more detail in this answer.


The org.apache.commons.lang.StringEscapeUtils.unescapeJava() given here as “the answer” is really very little help at all.


Like many of the other points, their embarrassing ignorance about the names of code points  U+2F and U+5C instills no confidence in them whatsoever. For the record:


So this morning I finally got fed up with not being able to read in strings with embedded escapes in them.  I needed it for writing the test suite for a larger and more intersting project: transparently converting Java’s indefensibly Unicode-ignorant regular expressions into versions where you can use all of \w, \W, \s, \S, \v, \V, \h, \H, \d, \D, \b, \B, \X, and \R in your patterns and have them actually work properly with Unicode. All I do is rewrite the pattern string; it still compiles with the standard java.util.regex.Pattern.compile()  function, so everything works as expected. The string unescaper intentionally passes any \b’s through untouched, in case you call it before you call the converter function to make Java regexes Unicode-aware, since that has to deal with \b in the boundary sense.


Anyway, here's the string unescaper, which although the less interesting of the pair, does solve the OP’s question without all the irritations of the Apache code. It could handle a bit of tightening in a couple places, but I quickly hacked it out over a few hours before lunch just to get it up and running to help drive the test suite.  The other function is a lot more work: that one took me all day yesterday, darn it.


As anybody can plainly see from the Java code above, I'm really a C programmer — Java is anything but my favorite language. I’m afraid that I really do have to side with Rob Pike in his famous public static void talk on this one.


’Nuff said.


Anyway, it’s only a quick morning’s hackery, but if it helps others, you’re welcome to it — no strings attached. If you improve it, I’d love for you to mail me your enhancements, but you certainly don’t have to.


You can use String unescapeJava(String) method of StringEscapeUtils from Apache Commons Lang.


Here's an example snippet:


The utility class has methods to escapes and unescape strings for Java, Java Script, HTML, XML, and SQL. It also has overloads that writes directly to a java.io.Writer.


It looks like StringEscapeUtils handles Unicode escapes with one u, but not octal escapes, or Unicode escapes with extraneous us.


A quote from the JLS:


Octal escapes are provided for compatibility with C, but can express only Unicode values \u0000 through \u00FF, so Unicode escapes are usually preferred.


If your string can contain octal escapes, you may want to convert them to Unicode escapes first, or use another approach.


The extraneous u is also documented as follows:


The Java programming language specifies a standard way of transforming a program written in Unicode into ASCII that changes a program into a form that can be processed by ASCII-based tools. The transformation involves converting any Unicode escapes in the source text of the program to ASCII by adding an extra u-for example, \uxxxx becomes \uuxxxx-while simultaneously converting non-ASCII characters in the source text to Unicode escapes containing a single u each.


This transformed version is equally acceptable to a compiler for the Java programming language and represents the exact same program. The exact Unicode source can later be restored from this ASCII form by converting each escape sequence where multiple u's are present to a sequence of Unicode characters with one fewer u, while simultaneously converting each escape sequence with a single u to the corresponding single Unicode character.


If your string can contain Unicode escapes with extraneous u, then you may also need to preprocess this before using StringEscapeUtils.


Alternatively you can try to write your own Java string literal unescaper from scratch, making sure to follow the exact JLS specifications.


Came across a similar problem, wasn't also satisfied with the presented solutions and implemented this one myself.


Also available as a Gist on Github:


See this from http://commons.apache.org/lang/:


StringEscapeUtils


StringEscapeUtils.unescapeJava(String str)


I know this question was old, but I wanted a solution that doesn't involve libraries outside those included JRE6 (i.e. Apache Commons is not acceptable), and I came up with a simple solution using the built-in java.io.StreamTokenizer:


Output:


I'm a little late on this, but I thought I'd provide my solution since I needed the same functionality. I decided to use the Java Compiler API which makes it slower, but makes the results accurate. Basically I live create a class then return the results. Here is the method:


It takes an array so you can unescape in batches. So the following simple test succeeds:


I came across the same problem, but I wasn't enamoured by any of the solutions I found here. So, I wrote one that iterates over the characters of the string using a matcher to find and replace the escape sequences. This solution assumes properly formatted input. That is, it happily skips over nonsensical escapes, and it decodes Unicode escapes for line feed and carriage return (which otherwise cannot appear in a character literal or a string literal, due to the definition of such literals and the order of translation phases for Java source). Apologies, the code is a bit packed for brevity.


I should note that Apache Commons Lang3 doesn't seem to suffer the weaknesses indicated in the accepted solution. That is, StringEscapeUtils seems to handle octal escapes and multiple u characters of Unicode escapes. That means unless you have some burning reason to avoid Apache Commons, you should probably use it rather than my solution (or any other solution here).


If you are reading unicode escaped chars from a file, then you will have a tough time doing that because the string will be read literally along with an escape for the back slash:


my_file.txt


Here, when you read line 3 from the file the string/line will have:


and the char[] in the string will show:


Commons StringUnescape will not unescape this for you (I tried unescapeXml()). You'll have to do it manually as described here.


So, the sub-string "\u0020" should become 1 single char '\u0020'


But if you are using this "\u0020" to do String.split("... ..... ..", columnDelimiterReadFromFile) which is really using regex internally, it will work directly because the string read from file was escaped and is perfect to use in the regex pattern!! (Confused?)


You might want to take a look at the Eclipse implementation of Stringliteral. 






Whenever a question pops up on SO about Java synchronization, some people are very eager to point out that synchronized(this) should be avoided. Instead, they claim, a lock on a private reference is to be preferred.


Some of the given reasons are:


Other people, including me, argue that synchronized(this) is an idiom that is used a lot (also in Java libraries), is safe and well understood. It should not be avoided because you have a bug and you don't have a clue of what is going on in your multithreaded program. In other words: if it is applicable, then use it.


I am interested in seeing some real-world examples (no foobar stuff) where avoiding a lock on this is preferable when synchronized(this) would also do the job.


Therefore: should you always avoid synchronized(this) and replace it with a lock on a private reference? 


Some further info (updated as answers are given):


I'll cover each point separately.


Some evil code may steal your lock (very popular this one, also has an
  "accidentally" variant)


I'm more worried about accidentally.  What it amounts to is that this use of this is part of your class' exposed interface, and should be documented.  Sometimes the ability of other code to use your lock is desired.  This is true of things like Collections.synchronizedMap (see the javadoc).


All synchronized methods within the same class use the exact same
  lock, which reduces throughput


This is overly simplistic thinking; just getting rid of synchronized(this) won't solve the problem.  Proper synchronization for throughput will take more thought.


You are (unnecessarily) exposing too much information


This is a variant of #1.  Use of synchronized(this) is part of your interface.  If you don't want/need this exposed, don't do it.


Well, firstly it should be pointed out that:


is semantically equivalent to:


which is one reason not to use synchronized(this).  You might argue that you can do stuff around the synchronized(this) block.  The usual reason is to try and avoid having to do the synchronized check at all, which leads to all sorts of concurrency problems, specifically the double checked-locking problem, which just goes to show how difficult it can be to make a relatively simple check threadsafe.


A private lock is a defensive mechanism, which is never a bad idea.


Also, as you alluded to, private locks can control granularity.  One set of operations on an object might be totally unrelated to another but synchronized(this) will mutually exclude access to all of them.


synchronized(this) just really doesn't give you anything.


While you are using synchronized(this) you are using the class instance as a lock itself. This means that while lock is acquired by thread 1 the thread 2 should wait


Suppose the following code


Method 1 modifying the variable a and method 2 modifying the variable b, the concurrent modification of the same variable by two threads should be avoided and it is. BUT while thread1 modifying a and thread2 modifying b it can be performed without any race condition.


Unfortunately, the above code will not allow this since we are using the same reference for a lock; This means that threads even if they are not in a race condition should wait and obviously the code sacrifices concurrency of the program.


The solution is to use 2 different locks for two different variables.


The above example uses more fine grained locks (2 locks instead one (lockA  and lockB for variables a and b respectively) and as a result allows better concurrency, on the other hand it became more complex than the first example ...


While I agree about not adhering blindly to dogmatic rules, does the "lock stealing" scenario seem so eccentric to you? A thread could indeed acquire the lock on your object "externally"(synchronized(theObject) {...}), blocking other threads waiting on synchronized instance methods.


If you don't believe in malicious code, consider that this code could come from third parties (for instance if you develop some sort of application server).


The "accidental" version seems less likely, but as they say, "make something idiot-proof and someone will invent a better idiot".


So I agree with the it-depends-on-what-the-class-does school of thought.


Edit following eljenso's first 3 comments:


I've never experienced the lock stealing problem but here is an imaginary scenario:


Let's say your system is a servlet container, and the object we're considering is the ServletContext implementation. Its getAttribute method must be thread-safe, as context attributes are shared data; so you declare it as synchronized. Let's also imagine that you provide a public hosting service based on your container implementation.


I'm your customer and deploy my "good" servlet on your site. It happens that my code contains a call to getAttribute.


A hacker, disguised as another customer, deploys his malicious servlet on your site. It contains the following code in the init method:


Assuming we share the same servlet context (allowed by the spec as long as the two servlets are on the same virtual host), my call on getAttribute is locked forever. The hacker has achieved a DoS on my servlet.


This attack is not possible if getAttribute is synchronized on a private lock, because 3rd-party code cannot acquire this lock.


I admit that the example is contrived and an oversimplistic view of how a servlet container works, but IMHO it proves the point.


So I would make my design choice based on security consideration: will I have complete control over the code that has access to the instances? What would be the consequence of a thread's holding a lock on an instance indefinitely?


There seems a different consensus in the C# and Java camps on this.  The majority of Java code I have seen uses:


whereas the majority of C# code opts for the arguably safer:


The C# idiom is certainly safer.  As mentioned previously, no malicious / accidental access to the lock can be made from outside the instance.  Java code has this risk too, but it seems that the Java community has gravitated over time to the slightly less safe, but slightly more terse version. 


That's not meant as a dig against Java, just a reflection of my experience working on both languages.


The java.util.concurrent package has vastly reduced the complexity of my thread safe code. I only have anecdotal evidence to go on, but most work I have seen with synchronized(x) appears to be re-implementing a Lock, Semaphore, or Latch, but using the lower-level monitors.


With this in mind, synchronizing using any of these mechanisms is analogous to synchronizing on an internal object, rather than leaking a lock. This is beneficial in that you have absolute certainty that you control the entry into the monitor by two or more threads.


If you've decided that:


then I don't see the a taboo over synchronizezd(this).


Some people deliberately use synchronized(this) (instead of marking the method synchronized) inside the whole contents of a method because they think it's "clearer to the reader" which object is actually being synchronized on. So long as people are making an informed choice (e.g. understand that by doing so they're actually inserting extra bytecodes into the method and this could have a knock-on effect on potential optimisations), I don't particularly see a problem with this. You should always document the concurrent behaviour of your program, so I don't see the "'synchronized' publishes the behaviour" argument as being so compelling.


As to the question of which object's lock you should use, I think there's nothing wrong with synchronizing on the current object if this would be expected by the logic of what you're doing and how your class would typically be used. For example, with a collection, the object that you would logically expect to lock is generally the collection itself.


A Lock provides exclusive access to a shared resource: only one thread at a time can acquire the lock and all access to the shared resource requires that the lock be acquired first.


Sample code to use ReentrantLock which implements Lock interface


Advantages of Lock over Synchronized(this)


The use of synchronized methods or statements forces all lock acquisition and release to occur in a block-structured way.


Lock implementations provide additional functionality over the use of synchronized methods and statements by providing 


A Lock class can also provide behavior and semantics that is quite different from that of the implicit monitor lock, such as 


Have a look at this SE question regarding various type of Locks:


Synchronization vs Lock


You can achieve thread safety by using advanced concurrency API instead of Synchronied blocks. This documentation page provides good programming constructs to achieve thread safety.


Lock Objects support locking idioms that simplify many concurrent applications.


Executors define a high-level API for launching and managing threads. Executor implementations provided by java.util.concurrent provide thread pool management suitable for large-scale applications.


Concurrent Collections make it easier to manage large collections of data, and can greatly reduce the need for synchronization.


Atomic Variables have features that minimize synchronization and help avoid memory consistency errors.


ThreadLocalRandom (in JDK 7) provides efficient generation of pseudorandom numbers from multiple threads.


Refer to java.util.concurrent and java.util.concurrent.atomic packages too for other programming constructs. 


It depends on the situation.
If There is only one sharing entity or more than one.   


See full working example here 


A small introduction.  


Threads and shareable entities
It is possible for multiple threads to access same entity,for eg multiple connectionThreads sharing a single messageQueue. Since the threads run concurrently there may be a chance of overriding one's data by another which may be a messed up situation.
So we need some way to ensure that shareable entity is accessed only by one thread at a time.(CONCURRENCY).  


Synchronized block
synchronized() block is a way to ensure concurrent access of shareable entity.
First,a small analogy
Suppose There are two person P1,P2 (threads) a Washbasin (shareable entity) inside a washroom and there is door (lock).
Now we want one person to use washbasin at a time.
Approach is to lock the door by P1,when the door is locked P2 waits until p1 completes his work
P1 unlocks the door
then only p1 can use washbasin.   


syntax.    


"this" provided the intrinsic lock associated with the class (Java developer designed Object class in such a way that each object can work as monitor).
Above approach works fine when there is only one shared entity and multiple threads (1:N).

N shareable entities-M threads
Now think of a situation when there are two washbasin inside a washroom and only one door. If we are using the previous approach, only p1 can use one washbasin at a time while p2 will wait outside. It is wastage of resource as no one is using B2 (washbasin).
A wiser approach would be to create a smaller rooms inside washroom and provide them one door per washbasin. In this way P1 can access B1 and P2 can access B2 and vice-versa.  






See more on Threads----> here


No, you shouldn't always.  However, I tend to avoid it when there are multiple concerns on a particular object that only need to be threadsafe in respect to themselves.  For example, you might have a mutable data object that has "label" and "parent" fields; these need to be threadsafe, but changing one need not block the other from being written/read.  (In practice I would avoid this by declaring the fields volatile and/or using java.util.concurrent's AtomicFoo wrappers).


Synchronization in general is a bit clumsy, as it slaps a big lock down rather than thinking exactly how threads might be allowed to work around each other.  Using synchronized(this) is even clumsier and anti-social, as it's saying "no-one may change anything on this class while I hold the lock".  How often do you actually need to do that?


I would much rather have more granular locks; even if you do want to stop everything from changing (perhaps you're serialising the object), you can just acquire all of the locks to achieve the same thing, plus it's more explicit that way.  When you use synchronized(this), it's not clear exactly why you're synchronizing, or what the side effects might be.  If you use synchronized(labelMonitor), or even better labelLock.getWriteLock().lock(), it's clear what you are doing and what the effects of your critical section are limited to.


Short answer: You have to understand the difference and make choice depending on the code.


Long answer: In general I would rather try to avoid synchronize(this) to reduce contention but private locks add complexity you have to be aware of. So use the right synchronization for the right job. If you are not so experienced with multi-threaded programming I would rather stick to instance locking and read up on this topic. (That said: just using synchronize(this) does not automatically make your class fully thread-safe.) This is a not an easy topic but once you get used to it, the answer whether to use synchronize(this) or not comes naturally.


I think there is a good explanation on why each of these are vital techniques under your belt in a book called Java Concurrency In Practice by Brian Goetz. He makes one point very clear - you must use the same lock "EVERYWHERE" to protect the state of your object. Synchronised method and synchronising on an object often go hand in hand. E.g. Vector synchronises all its methods. If you have a handle to a vector object and are going to do "put if absent" then merely Vector synchronising its own individual methods isn't going to protect you from corruption of state. You need to synchronise using synchronised (vectorHandle). This will result in the SAME lock being acquired by every thread which has a handle to the vector and will protect overall state of the vector. This is called client side locking. We do know as a matter of fact vector does synchronised (this) / synchronises all its methods and hence synchronising on the object vectorHandle will result in proper synchronisation of vector objects state. Its foolish to believe that you are thread safe just because you are using a thread safe collection. This is precisely the reason ConcurrentHashMap explicitly introduced putIfAbsent method - to make such operations atomic.


In summary


A lock is used for either visibility or for protecting some data from concurrent modification which may lead to race.


When you need to just make primitive type operations to be atomic there are available options like AtomicInteger and the likes.


But suppose you have two integers which are related to each other like x and y co-ordinates, which are related to each other and should be changed in an atomic manner. Then you would protect them using a same lock.


A lock should only protect the state that is related to each other. No less and no more. If you use synchronized(this) in each method then even if the state of the class is unrelated all the threads will face contention even if updating unrelated state.


In the above example I have only one method which mutates both x and y and not two different methods as x and y are related and if I had given two different methods for mutating x and y separately then it would not have been thread safe. 


This example is just to demonstrate and not necessarily the way it should be implemented. The best way to do it would be to make it IMMUTABLE.


Now in opposition to Point example, there is an example of TwoCounters already provided by @Andreas where the state which is being protected by two different locks as the state is unrelated to each other.


The process of using different locks to protect unrelated states is called Lock Striping or Lock Splitting


The reason not to synchronize on this is that sometimes you need more than one lock (the second lock often gets removed after some additional thinking, but you still need it in the intermediate state). If you lock on this, you always have to remember which one of the two locks is this; if you lock on a private Object, the variable name tells you that.


From the reader's viewpoint, if you see locking on this, you always have to answer the two questions: 


An example:


If two threads begin longOperation() on two different instances of BadObject, they acquire 
their locks; when it's time to invoke l.onMyEvent(...), we have a deadlock because neither of the threads may acquire the other object's lock.


In this example we may eliminate the deadlock by using two locks, one for short operations and one for long ones.


As already said here synchronized block can use user-defined variable as lock object, when synchronized function uses only "this". And of course you can manipulate with areas of your function which should be synchronized and so on.


But everyone says that no difference between synchronized function and block which covers whole function using "this" as lock object. That is not true, difference is in byte code which will be generated in both situations. In case of synchronized block usage should be allocated local variable which holds reference to "this". And as result we will have a little bit larger size of function (not relevant if you have only few number of functions).


More detailed explanation of the difference you can find here:
http://www.artima.com/insidejvm/ed2/threadsynchP.html


Also usage of synchronized block is not good due to following point of view:


The synchronized keyword is very limited in one area: when exiting a synchronized block, all threads that are waiting for that lock must be unblocked, but only one of those threads gets to take the lock; all the others see that the lock is taken and go back to the blocked state. That's not just a lot of wasted processing cycles: often the context switch to unblock a thread also involves paging memory off the disk, and that's very, very, expensive.


For more details in this area I would recommend you read this article:
http://java.dzone.com/articles/synchronized-considered


A good example for use synchronized(this).


As you can see here, we use synchronize on this to easy cooperate of lengthly (possibly infinite loop of run method) with some synchronized methods there.


Of course it can be very easily rewritten with using synchronized on private field. But sometimes, when we already have some design with synchronized methods (i.e. legacy class, we derive from, synchronized(this) can be the only solution).


It depends on the task you want to do, but I wouldn't use it. Also, check if the thread-save-ness you want to accompish couldn't be done by synchronize(this) in the first place? There are also some nice locks in the API that might help you :)


I think points one (somebody else using your lock) and two (all methods using the same lock needlessly) can happen in any fairly large application. Especially when there's no good communication between developers.


It's not cast in stone, it's mostly an issue of good practice and preventing errors.






Recalling this post enumerating several problems of using singletons
and having seen several examples of Android applications using singleton pattern, I wonder if it's a good idea to use Singletons instead of single instances shared through global application state (subclassing android.os.Application and obtaining it through context.getApplication()).


What advantages/drawbacks would both mechanisms have?


To be honest, I expect the same answer in this post Singleton pattern with Web application, Not a good idea! but applied to Android. Am I correct? What's different in DalvikVM otherwise?


EDIT: I would like to have opinions on several aspects involved:


I very much disagree with Dianne Hackborn's response. We are bit by bit removing all singletons from our project in favor of lightweight, task scoped objects which can easiliy be re-created when you actually need them.


Singletons are a nightmare for testing and, if lazily initialized, will introduce "state indeterminism" with subtle side effects (which may suddenly surface when moving calls to getInstance() from one scope to another). Visibility has been mentioned as another problem, and since singletons imply "global" (= random) access to shared state, subtle bugs may arise when not properly synchronized in concurrent applications.


I consider it an anti-pattern, it's a bad object-oriented style that essentially amounts to maintaining global state.


To come back to your question:
Although the app context can be considered a singleton itself, it is framework-managed and has a well defined life-cycle, scope, and access path. Hence I believe that if you do need to manage app-global state, it should go here, nowhere else. For anything else, rethink if you really need a singleton object, or if it would also be possible to rewrite your singleton class to instead instantiate small, short-lived objects that perform the task at hand.


I very much recommend singletons.  If you have a singleton that needs a context, have:


I prefer singletons over Application because it helps keep an app much more organized and modular -- instead of having one place where all of your global state across the app needs to be maintained, each separate piece can take care of itself.  Also the fact that singletons lazily initialize (at request) instead of leading you down the path of doing all initialization up-front in Application.onCreate() is good.


There is nothing intrinsically wrong with using singletons.  Just use them correctly, when it makes sense.  The Android framework actually has a lot of them, for it to maintain per-process caches of loaded resources and other such things.


Also for simple applications multithreading doesn't become an issue with singletons, because by design all standard callbacks to the app are dispatched on the main thread of the process so you won't have multi-threading happening unless you introduce it explicitly through threads or implicitly by publishing a content provider or service IBinder to other processes.


Just be thoughtful about what you are doing. :)


From: http://developer.android.com/reference/android/app/Application.html


There is normally no need to subclass Application. In most situation,
  static singletons can provide the same functionality in a more modular
  way. If your singleton needs a global context (for example to register
  broadcast receivers), the function to retrieve it can be given a
  Context which internally uses Context.getApplicationContext() when
  first constructing the singleton.


I had the same problem: Singleton or make a subclass android.os.Application?


First I tried with the Singleton but my app at some point makes a call to the browser


and the problem is that, if the handset doesn't have enough memory, most of your classes (even Singletons) are cleaned to get some memory so, when returning from the browser to my app, it crashed everytime.


Solution: put needed data inside a subclass of Application class.


Application is not the same as the Singleton.The reasons are:


Consider both at the same time:


Furthermore, I suggest that you expand your Context to include not only access to singleton objects but some functionalities that need to be accessed globally, like for example: context.logOffUser(), context.readSavedData(), etc. Probably renaming the Context to Facade would make sense then.


They're actually the same.
There's one difference I can see. With Application class you can initialize your variables in Application.onCreate() and destroy them in Application.onTerminate(). With singleton you have to rely VM initializing and destroying statics.


My 2 cents:


I did notice that some singleton / static fields were reseted when my activity was destroyed. I noticed this on some low end 2.3 devices.


My case was very simple : I just have a private filed "init_done" and a static method "init" that I called from activity.onCreate(). I notice that the method init was re-executing itself on some re-creation of the activity.


While I cannot prove my affirmation, It may be related to WHEN the singleton/class was created/used first. When the activity get destroyed/recycled, it seem that all class that only this activity refer are recycled too.


I moved my instance of singleton to a sub class of Application. I acces them from the application instance. and, since then, did not notice the problem again.


I hope this can help someone.


My activity calls finish() (which doesn't make it finish immediately, but will do eventually) and calls Google Street Viewer. When I debug it on Eclipse, my connection to the app breaks when Street Viewer is called, which I understand as the (whole) application being closed, supposedly to free up memory (as a single activity being finished shouldn't cause this behavior). Nevertheless, I'm able to save state in a Bundle via onSaveInstanceState() and restore it in the onCreate() method of the next activity in the stack. Either by using a static singleton or subclassing Application I face the application closing and losing state (unless I save it in a Bundle). So from my experience they are the same with regards to state preservation. I noticed that the connection is lost in Android 4.1.2 and 4.2.2 but not on 4.0.7 or 3.2.4, which in my understanding suggests that the memory recovery mechanism has changed at some point.


From the proverbial horse's mouth...


When developing your app, you may find it necessary to share data, context or services globally across your app. For example, if your app has session data, such as the currently logged-in user, you will likely want to expose this information. In Android, the pattern for solving this problem is to have your android.app.Application instance own all global data, and then treat your Application instance as a singleton with static accessors to the various data and services.


When writing an Android app, you're guaranteed to only have one instance of the android.app.Application class, and so it's safe (and recommended by Google Android team) to treat it as a singleton. That is, you can safely add a static getInstance() method to your Application implementation. Like so...






This question already has an answer here:


In Java, is it legal to call remove on a collection when iterating through the collection using a foreach loop?  For instance:


As an addendum, is it legal to remove items that have not been iterated over yet? For instance, 


To safely remove from a collection while iterating over it you should use an Iterator.


For example:


From the Java Documentation :


The iterators returned by this class's iterator and listIterator
  methods are fail-fast: if the list is structurally modified at any
  time after the iterator is created, in any way except through the
  iterator's own remove or add methods, the iterator will throw a
  ConcurrentModificationException. Thus, in the face of concurrent
  modification, the iterator fails quickly and cleanly, rather than
  risking arbitrary, non-deterministic behavior at an undetermined time
  in the future.


Perhaps what is unclear to many novices is the fact that iterating over a list using the for/foreach constructs implicitly creates an iterator which is necessarily inaccessible. This info can be found here


You don't want to do that. It can cause undefined behavior depending on the collection. You want to use an Iterator directly. Although the for each construct is syntactic sugar and is really using an iterator, it hides it from your code so you can't access it to call Iterator.remove.


The behavior of an iterator is
  unspecified if the underlying
  collection is modified while the
  iteration is in progress in any way
  other than by calling this method.


Instead write your code:


Note that the code calls Iterator.remove, not List.remove.


Addendum:


Even if you are removing an element that has not been iterated over yet, you still don't want to modify the collection and then use the Iterator. It might modify the collection in a way that is surprising and affects future operations on the Iterator.


The java design of the "enhanced for loop" was to not expose the iterator to code, but the only way to safely remove an item is to access the iterator. So in this case you have to do it old school:


If in the real code the enhanced for loop is really worth it, then you could add the items to a temporary collection and call removeAll on the list after the loop.


EDIT (re addendum): No, changing the list in any way outside the iterator.remove() method while iterating will cause problems. The only way around this is to use a CopyOnWriteArrayList, but that is really intended for concurrency issues.


The cheapest (in terms of lines of code) way to remove duplicates is to dump the list into a LinkedHashSet (and then back into a List if you need). This preserves insertion order while removing duplicates.


You clone the list names and iterate through the clone while you remove from the original list. A bit cleaner than the top answer.


I didn't know about iterators, however here's what I was doing until today to remove elements from a list inside a loop: 


This is always working, and could be used in other languages or structs not supporting iterators.


Yes you can use the for-each loop,
To do that you have to maintain a separate list to hold removing items and then remove that list from names list using removeAll() method,


Those saying that you can't safely remove an item from a collection except through the Iterator aren't quite correct, you can do it safely using one of the concurrent collections such as ConcurrentHashMap.


Make sure this is not code smell.  Is it possible to reverse the logic and be 'inclusive' rather than 'exclusive'?


The situation that led me to this page involved old code that looped through a List using indecies to remove elements from the List. I wanted to refactor it to use the foreach style.  


It looped through an entire list of elements to verify which ones the user had permission to access, and removed the ones that didn't have permission from the list.


To reverse this and not use the remove:


When would "remove" be preferred? One consideration is if gien a large list or expensive "add", combined with only a few removed compared to the list size.  It might be more efficient to only do a few removes rather than a great many adds.  But in my case the situation did not merit such an optimization.


It's better to use an Iterator when you want to remove element from a list


because the source code of remove is 


so ,if you remove an element from the list, the list will be restructure ,the other element's index will be changed, this can result something that you want to happened.


Use


.remove() of Interator or


Use 


CopyOnWriteArrayList






It looks like a standard question, but I couldn't find clear directions anywhere.


I have java code trying to connect to a server with probably self-signed (or expired) certificate. The code reports the following error :


As I understand it, I have to use keytool and tell java that it's OK to allow this connection. 


All instructions to fix this problem assume I'm fully proficient with keytool, such as 


generate private key for server and import it into keystore


Is there anybody who could post detailed instructions?  


I'm running unix, so bash script would be best.


Not sure if it's important, but code executed in jboss.


You have basically two options here: add the self-signed certificate to your JVM truststore or configure your client to 


Export the certificate from your browser and import it in your JVM truststore (to establish a chain of trust):


Disable Certificate Validation (code from Example Depot):


Note that I do not recommend the Option #2 at all. Disabling the trust manager defeats some parts of SSL and makes you vulnerable to man in the middle attacks. Prefer Option #1 or, even better, have the server use a "real" certificate signed by a well known CA. 


I chased down this problem to a certificate provider that is not part of the default JVM trusted hosts as of JDK 8u74. The provider is www.identrust.com, but that was not the domain I was trying to connect to. That domain had gotten its certificate from this provider. See Will the cross root cover trust by the default list in the JDK/JRE? -- read down a couple entries. Also see Which browsers and operating systems support Let’s Encrypt.


So, in order to connect to the domain I was interested in, which had a certificate issued from identrust.com I did the following steps. Basically, I had to get the identrust.com (DST Root CA X3) certificate to be trusted by the JVM. I was able to do that using Apache HttpComponents 4.5 like so:


1: Obtain the certificate from indettrust at Certificate Chain Download Instructions. Click on the DST Root CA X3 link.


2: Save the string to a file named "DST Root CA X3.pem". Be sure to add the lines "-----BEGIN CERTIFICATE-----" and "-----END CERTIFICATE-----" in the file at the beginning and the end.


3: Create a java keystore file, cacerts.jks with the following command: 


4: Copy the resulting cacerts.jks keystore into the resources directory of your java/(maven) application.


5: Use the following code to load this file and attach it to the Apache 4.5 HttpClient. This will solve the problem for all domains that have certificates issued from indetrust.com util oracle includes the certificate into the JRE default keystore.


When the project builds then the cacerts.jks will be copied into the classpath and loaded from there. I didn't, at this point in time, test against other ssl sites, but if the above code "chains" in this certificate then they will work too, but again, I don't know.


Reference: Custom SSL context and How do I accept a self-signed certificate with a Java HttpsURLConnection?


Rather than setting the default socket factory (which IMO is a bad thing) - yhis will just affect the current connection rather than every SSL connection you try to open:


Trust all SSL certificates:-
You can bypass SSL if you want to test on the testing server.
But do not use this code for production. 


} 


Please call this function in onCreate() function in Activity or in your Application Class. 


This can be used for Volley in Android.


If 'they' are using a self-signed certificate it is up to them to take the steps required to make their server usable. Specifically that means providing their certificate to you offline in a trustworthy way. So get them to do that. You then import that into your truststore using the keytool as described in the JSSE Reference Guide. Don't even think about the insecure TrustManager posted here.


EDIT For the benefit of the seventeen (!) downvoters, and numerous commenters below, who clearly have not actually read what I have written here, this is not a jeremiad against self-signed certificates. There is nothing wrong with self-signed certificates when implemented correctly. But, the correct way to implement them is to have the certificate delivered securely via an offline process, rather than via the unauthenticated channel they are going to be used to authenticate. Surely this is obvious? It is certainly obvious to every security-aware organization I have ever worked for, from banks with thousands of branches to my own companies. The client-side code-base 'solution' of trusting all certificates, including self-signed certificates signed by absolutely anybody, or any arbitary body setting itself up as a CA, is ipso facto not secure. It is just playing at security. It is pointless. You are having a private, tamperproof, reply-proof, injection-proof conversation with ... somebody. Anybody. A man in the middle. An impersonator. Anybody. You may as well just use plaintext.






How to set a Timer, say for 2 minutes, to try to connect to a Database then throw exception if there is any issue in connection?


So the first part of the answer is how to do what the subject asks as this was how I initially interpreted it and a few people seemed to find helpful.  The question was since clarified and I've extended the answer to address that.


Setting a timer


First you need to create a Timer (I'm using the java.util version here):


..


To run the task once you would do:


To have the task repeat after the duration you would do:


Making a task timeout


To specifically do what the clarified question asks, that is attempting to perform a task for a given period of time, you could do the following:


This will execute normally with exceptions if the task completes within 2 minutes.  If it runs longer than that, the TimeoutException will be throw.


One issue is that although you'll get a TimeoutException after the two minutes, the task will actually continue to run, although presumably a database or network connection will eventually time out and throw an exception in the thread.  But be aware it could consume resources until that happens.


Use this 


Ok, I think I understand your problem now.  You can use a Future to try to do something and then timeout after a bit if nothing has happened.


E.g.:


How to stop the timer? Stop and play again when do something in this code 


When I use the timer.cancel();


it will stop but if close the form and open it again the exception is thrown






What is a good way of parsing command line arguments in Java?


Check these out:


Or roll your own:


For instance, this is how you use commons-cli to parse 2 string arguments:


usage from command line:


Take a look at the more recent JCommander.


I created it. I’m happy to receive questions or feature requests.


I have been trying to maintain a list of java CLI parsers.


I've used JOpt and found it quite handy: http://jopt-simple.sourceforge.net/


The front page also provides a list of about 8 alternative libraries, check them out and pick the one that most suits your needs.


Someone pointed me to args4j lately which is annotation based. I really like it!


Take a look at the Commons CLI project, lots of good stuff in there.


Yeap.


I think you're looking for something like this:
http://commons.apache.org/cli


The Apache Commons CLI library provides an API for processing command line interfaces.


Maybe these


JArgs command line option parsing
suite for Java - this tiny project provides a convenient, compact, pre-packaged and comprehensively documented suite of command line option parsers for the use of Java programmers. Initially, parsing compatible with GNU-style 'getopt' is provided. 


ritopt, The Ultimate Options Parser for Java - Although, several command line option standards have been preposed, ritopt follows the conventions prescribed in the opt package.


if you are familiar with gnu getopt, there is a java port at: http://www.urbanophile.com/arenn/hacking/download.htm. there appears to be a some classes that do this: http://docs.sun.com/source/816-5618-10/netscape/ldap/util/GetOpt.html, http://xml.apache.org/xalan-j/apidocs/org/apache/xalan/xsltc/cmdline/getopt/GetOpt.html


You might find this meta-article of unhappiness interesting as a jumping off point:


http://furiouspurpose.blogspot.com/2008/07/command-line-parsing-libraries-for-java.html


I wrote another one: http://argparse4j.sourceforge.net/


Argparse4j is a command line argument parser library for Java, based on Python's argparse.


This is Google's command line parsing library open-sourced as part of the Bazel project. Personally I think it's the best one out there, and far easier than apache cli.


https://github.com/pcj/google-options


Create a class that extends OptionsBase and defines your @Option(s).


Parse the arguments and use them.


https://github.com/pcj/google-options


airline @ Github looks good. Based on annotation and trying to emulate git command line structures.


I wouldn't recommend using Apache Common CLI library, as it is non-threadsafe.
It uses stateful classes with static variables and methods to do internal work (e.g. OptionBuilder) and should only be used in single-threaded strongly controlled situations.


Buy or build?


Many small utility-like applications probably roll their own command line parsing to avoid the additional external dependency.


picocli may be interesting. It is designed to be included as source as a simpler alternative to shading jars into an uberjar. 


Another feature you may like is its colorized usage help.





Parser features:


The usage help message is easy to customize with annotations (without programming). For example:


 (source)


I couldn't resist adding one more screenshot to show what usage help messages are possible. Usage help is the face of your application, so be creative and have fun!





Disclaimer: I created picocli. Feedback or questions very welcome.


If you want something lightweight (jar size ~ 20 kb) and simple to use, you can try argument-parser. It can be used in most of the use cases, supports specifying arrays in the argument and has no dependency on any other library. It works for Java 1.5 or above. Below excerpt shows an example on how to use it:


More examples can be found here


Argparse4j is best I have found. It mimics python argparse libary which is very convinient and powerfull.






I have data with latitude and longitude stored in my SQLite database, and I want to get the nearest locations to the parameters I put in (ex. My current location - lat/lng, etc.).


I know that this is possible in MySQL, and I've done quite some research that SQLite needs a custom external function for the Haversine formula (calculating distance on a sphere), but I haven't found anything that is written in Java and works.


Also, if I want to add custom functions, I need the org.sqlite .jar (for org.sqlite.Function), and that adds unnecessary size to the app.


The other side of this is, I need the Order by function from SQL, because displaying the distance alone isn't that much of a problem - I already did it in my custom SimpleCursorAdapter, but I can't sort the data, because I don't have the distance column in my database. That would mean updating the database every time the location changes and that's a waste of battery and performance. So if someone has any idea on sorting the cursor with a column that's not in the database, I'd be grateful too!


I know there are tons of Android apps out there that use this function, but can someone please explain the magic.


By the way, I found this alternative: Query to get records based on Radius in SQLite?


It's suggesting to make 4 new columns for cos and sin values of lat and lng, but is there any other, not so redundant way?


1) At first filter your SQLite data with a good approximation and decrease amount of data that you need to evaluate in your java code. Use the following procedure for this purpose:


To have a deterministic threshold and more accurate filter on data, It is better to calculate 4 locations that are in radius meter of the north, west, east and south of your central point in your java code and then check easily by less than and more than SQL operators (>, <) to determine if your points in database are in that rectangle or not.


The method calculateDerivedPosition(...) calculates those points for you (p1, p2, p3, p4 in picture).





And now create your query:


COL_X is the name of the column in the database that stores latitude values and COL_Y is for longitude.


So you have some data that are near your central point with a good approximation.


2) Now you can loop on these filtered data and determine if they are really near your point (in the circle) or not using the following methods:


Enjoy!


I used and customized this reference and completed it.


Chris's answer is really useful (thanks!), but will only work if you are using rectilinear coordinates (eg UTM or OS grid references).  If using degrees for lat/lng (eg WGS84) then the above only works at the equator.  At other latitudes, you need to decrease the impact of longitude on the sort order.  (Imagine you're close to the north pole... a degree of latitude is still the same as it is anywhere, but a degree of longitude may only be a few feet.  This will mean that the sort order is incorrect).


If you are not at the equator, pre-calculate the fudge-factor, based on your current latitude:


Then order by:


((<lat> - LAT_COLUMN) * (<lat> - LAT_COLUMN) +
     (<lng> - LNG_COLUMN) * (<lng> - LNG_COLUMN) * <fudge>) 


It's still only an approximation, but much better than the first one, so sort order inaccuracies will be much rarer.


I know this has been answered and accepted but thought I'd add my experiences and solution.


Whilst I was happy to do a haversine function on the device to calculate the accurate distance between the user's current position and any particular target location there was a need to sort and limit the query results in order of distance. 


The less than satisfactory solution is to return the lot and sort and filter after the fact but this would result in a second cursor and many unnecessary results being returned and discarded.


My preferred solution was to pass in a sort order of the squared delta values of the long and lats:


There's no need to do the full haversine just for a sort order and there's no need to square root the results therefore SQLite can handle the calculation.


EDIT:


This answer is still receiving love. It works fine in most cases but if you need a little more accuracy, please check out the answer by @Teasel below which adds a "fudge" factor that fixes inaccuracies that increase as the latitude approaches 90.


Have you considered a Geohash tag/index for your entries to reduce the size of your result set and then apply the appropriate function. 


Another stackoverflow question in a similar area:
finding-the-closest-point-to-a-given-point


In order to increase performance as much as possible I suggest improve @Chris Simpson's idea with the following ORDER BY clause:


In this case you should pass the following values from code:


And you should also store LAT_LON_SQ_SUM = LAT_COL^2 + LON_COL^2 as additional column in database. Populate it inserting your entities into database. This slightly improves performance while extracting large amount of data.


Have a look at this post: 


Distance function for sqlite


It seems to allow you to add a custom Distance() function to SQLite which might allow you to avoid jumping through all the hoops in the other answers.


Try something like this:


After this, id contains the item you want from the database so you can fetch it:


Hope that helps!






Does Java have a built-in way to escape arbitrary text so that it can be included in a regular expression? For example, if my users enter "$5", I'd like to match that exactly rather than a "5" after the end of input.


Since Java 1.5, yes:


Difference between Pattern.quote and Matcher.quoteReplacement was not clear to me before I saw following example


It may be too late to respond, but you can also use Pattern.LITERAL, which would ignore all special characters while formatting:


I think what you're after is \Q$5\E.  Also see Pattern.quote(s) introduced in Java5.


See Pattern javadoc for details.


First off, if


it won't put a 1 at the end.  It will look at the search regex for the first matching group and sub THAT in.  That's what $1, $2 or $3 means in the replacement text: matching groups from the search pattern.


I frequently plug long strings of text into .properties files, then generate email subjects and bodies from those.  Indeed, this appears to be the default way to do i18n in Spring Framework.  I put XML tags, as placeholders, into the strings and I use replaceAll() to replace the XML tags with the values at runtime.


I ran into an issue where a user input a dollars-and-cents figure, with a dollar sign.  replaceAll() choked on it, with the following showing up in a stracktrace:


In this case, the user had entered "$3" somewhere in their input and replaceAll() went looking in the search regex for the third matching group, didn't find one, and puked.


Given:


replacing


with 


solved the problem.  The user could put in any kind of characters, including dollar signs, without issue.  It behaved exactly the way you would expect.


To have protected pattern you may replace all symbols with "\\\\", except digits and letters.  And after that you can put in that protected pattern your special symbols to make this pattern working not like stupid quoted text, but really like a patten, but your own.  Without user special symbols.


Pattern.quote("blabla") works nicely.


The Pattern.quote() works nicely. It encloses the sentence with the characters "\Q" and "\E", and if it does escape "\Q" and "\E".
However, if you need to do a real regular expression escaping(or custom escaping), you can use this code:


This method returns: Some/\s/wText*/\,**


Code for example and tests:






How can I use JUnit4 idiomatically to test that some code throws an exception?


While I can certainly do something like this:


I recall that there is an annotation or an Assert.xyz or something that is far less kludgy and far more in-the-spirit of JUnit for these sorts of situations.


JUnit 4 has support for this:


Edit Now that JUnit5 has released, the best option would be to use Assertions.assertThrows() (see my other answer).


If you haven't migrated to JUnit 5, but can use JUnit 4.7, you can use the ExpectedException Rule:


This is much better than @Test(expected=IndexOutOfBoundsException.class) because the test will fail if IndexOutOfBoundsException is thrown before foo.doStuff()


See this article for details


Be careful using expected exception, because it only asserts that the method threw that exception, not a particular line of code in the test.


I tend to use this for testing parameter validation, because such methods are usually very simple, but more complex tests might better be served with:


Apply judgement.


As answered before, there are many ways of dealing with exceptions in JUnit. But with Java 8 there is another one: using Lambda Expressions. With Lambda Expressions we can achieve a syntax like this:


assertThrown accepts a functional interface, whose instances can be created with lambda expressions, method references, or constructor references. assertThrown accepting that interface will expect and be ready to handle an exception.


This is relatively simple yet powerful technique.


Have a look at this blog post describing this technique: http://blog.codeleak.pl/2014/07/junit-testing-exception-with-java-8-and-lambda-expressions.html


The source code can be found here: https://github.com/kolorobot/unit-testing-demo/tree/master/src/test/java/com/github/kolorobot/exceptions/java8


Disclosure: I am the author of the blog and the project.


in junit, there are three ways to test exception. 


use the optional 'expected' attribute of Test annonation


use the ExpectedException rule


finally, you also can use the classic try/catch way widely used under junit 3 framework


so


for more info, you can read this document for details.


tl;dr


pre-JDK8 : I will recommend the old good try-catch block. 


post-JDK8 : Use AssertJ or custom lambdas to assert exceptional behaviour.


the long story


It is possible to write yourself a do it yourself try-catch block or use the JUnit tools (@Test(expected = ...) or the @Rule ExpectedException JUnit rule feature).


But these way are not so elegant and don't mix well readability wise with other tools.


The try-catch block you have to write the block around the tested behavior, and write the assertion in the catch block, that may be fine but many find taht this style interrupts the reading flow of a test. Also you need to write an Assert.fail at the end of the try block otherwise the test may miss one side of the assertions ; PMD, findbugs or Sonar will spot such issues.


The @Test(expected = ...) feature is interesting as you can write less code and then writing this test is supposedly less prone to coding errors. But ths approach is lacking a some areas.


Also as the expectation is placed around in the method, depending on how the tested code is written then the wrong part of the test code can throw the exception, leading to false positive test and I m not sure that PMD, findbugs or Sonar will give hints on such code.


The ExpectedException rule is also an attempt to fix the previous caveats, but it feels a bit awkward to use as it uses an expectation style, EasyMock users knows very well this style. It might be convenient for some, but if you follow Behaviour Driven Development (BDD) or Arrange Act Assert (AAA) principles the ExpectedException rule won't fit in those writing style. Aside of that it may suffer from the same issue as the as the @Test way, depending where you place the expectation.


Even the expected exception is placed before the test statement, it breaks your reading flow if the tests follow BDD or AAA.


Also see this comment issue on JUnit of the author of ExpectedException.


So these above options have all their load of caveats, and clearly not immune to coder errors.


There's a project I became aware after creating this answer that looks promising, it's catch-exception.


As the description of the project says, it let a coder write in a fluent line of code catching the exception and offer this exception for later assertion. And you can use any assertion library like Hamcrest or AssertJ.


A rapid example taken from the home page : 


As you can see the code is really straightforward, you catch the exception on a specific line, the then API is an alias that will use AssertJ APIs (similar to using assertThat(ex).hasNoCause()...). At some point the project relied on FEST-Assert the ancestor of AssertJ. EDIT: It seems the project is brewing a Java 8 Lambdas support.


Currently this library has two shortcomings : 


At the time of this writing it is noteworthy to say this library is based on Mockito 1.x as it creates a mock of the tested object behind the scene. As Mockito is still not updated this library cannot work with final classes or final methods. And even if it was based on mockito 2 in the current version, this would require to declare a global mock maker (inline-mock-maker), something that may not what you want, as this mockmaker has different drawbacks that the regular mockmaker.


It requires yet another test dependency.


These issues won't apply once the library will support lambdas, however the functionality will be duplicated by AssertJ toolset.


Taking all into account if you don't want to use the catch-exception tool, I will recommend the old good way of the try-catch block, at least up to the JDK7. And for JDK 8 users you might prefer to use AssertJ as it offers may more than just asserting exceptions.


With the JDK8, lambdas enter the test scene, and they have proved to be an interesting way to assert exceptional behaviour. AssertJ has been updated to provide a nice fluent API to assert exceptional behaviour.


And a sample test with AssertJ :


With a near complete rewrite of JUnit 5, assertions have been improved a bit, they may prove interesting as an out of the box way to assert properly exception. But really the assertion API is still a bit poor, there's nothing outside assertThrows. 


As you noticed assertEquals is still returning void, and as such doesn't allow chaining assertions like AssertJ.


Also if you remember name clash with Matcher or Assert, be prepared to meet the same clash with Assertions.


I'd like to conclude that today (2017-03-03) AssertJ's ease of use, discoverable API, rapid pace of development and as a de facto test dependency is the best solution with JDK8 regardless of the test framework (JUnit or not), prior JDKs should instead rely on try-catch blocks even if they feel clunky.


This answer has been copied from another question that don't have the same visibility, I am the same author.


To solve the same problem I did set up a small project: 
http://code.google.com/p/catch-exception/


Using this little helper you would write


This is less verbose than the ExpectedException rule of JUnit 4.7.
In comparison to the solution provided by skaffman, you can specify in which line of code you expect the exception. I hope this helps.


How about this:  Catch a very general exception, make sure it makes it out of the catch block, then assert that the class of the exception is what you expect it to be.  This assert will fail if a) the exception is of the wrong type (eg. if you got a Null Pointer instead) and b) the exception wasn't ever thrown.


Using an AssertJ assertion, which can be used alongside JUnit:


It's better than @Test(expected=IndexOutOfBoundsException.class) because it guarantees the expected line in the test threw the exception and lets you check more details about the exception, such as message, easier:


Maven/Gradle instructions here.


You can also do this:


Update: JUnit5 has an improvement for exceptions testing: assertThrows.


following example is from: Junit 5 User Guide


Original asnwer using JUnit 4.


There are several ways to test that an exception is thrown. I have also discussed the below options in my post How to write great unit tests with JUnit


Set the expected parameter @Test(expected = FileNotFoundException.class).


Using try catch


Testing with ExpectedException Rule.


You could read more about exceptions testing in JUnit4 wiki for Exception testing and bad.robot - Expecting Exceptions JUnit Rule.


IMHO, the best way to check for exceptions in JUnit is the try/catch/fail/assert pattern:


The assertTrue might be a bit strong for some people, so assertThat(e.getMessage(), containsString("the message"); might be preferable.


More Infos about JUnit 5 on http://junit.org/junit5/docs/current/user-guide/#writing-tests-assertions


I tried many of the methods here, but they were either complicated or didn't quite meet my requirements.  In fact, one can write a helper method quite simply:


Use it like this:


Zero dependencies: no need for mockito, no need powermock; and works just fine with final classes.


JUnit has built-in support for this, with an "expected" attribute


In my case I always get RuntimeException from db, but messages differ. And exception need to be handled respectively. Here is how I tested it:


If you would like a solution which:


Here is a utility function that I wrote:


(taken from my blog)


Use it as follows:


We can use an assertion fail after the method that must return an exception:


Just make a Matcher that can be turned off and on, like this:


To use it:


add public ExpectedException exception = ExpectedException.none();,
then:


In JUnit 4 or later you can test the exceptions as follows


 this provides a lot of features which can be used to improve our JUnit tests.  If you see the below example I am testing 3 things on the exception.





Additionally to what NamShubWriter has said, make sure that: 


Do not do this:    


Finally, this blog post clearly illustrates how to assert that a certain exception is thrown.


Take for example, you want to write Junit for below mentioned code fragment


The above code is to test for some unknown exception that may occur and the below one is to assert some exception with custom message.


With Java 8 you can create a method taking a code to check and expected exception as parameters:


and then inside your test:


Benefits:


Now that JUnit 5 has released, the best option is to use Assertions.assertThrows() (see
the Junit 5 User Guide).


Here is an example that  verifies an exception is thrown, and uses Truth to  make assertions on the exception message:


The advantages over the approaches in the other answers are:


A similar method will be added to org.junit Assert in JUnit 4.13.


My solution using Java 8 lambdas:


You have to define a FunctionalInterface, because Runnable doesn't declare the required throws.


The method can be used as follows:


I wanted to comment with my solution to this problem, which avoided needing any of the exception related JUnit code.


I used assertTrue(boolean) combined with try/catch to look for my expected exception to be thrown. Here's an example:






How can I play an .mp3 and a .wav file in my Java application? I am using Swing. I tried looking on the internet, for something like this example:


But, this will only play .wav files.


The same with:


http://www.javaworld.com/javaworld/javatips/jw-javatip24.html


I want to be able to play both .mp3 files and .wav files with the same method.


Java FX has Media and MediaPlayer classes which will play mp3 files.


Example code: 


You will need the following import statements:


I wrote a pure java mp3 player: mp3transform.


It's been a while since I used it, but JavaLayer is great for MP3 playback


you can play .wav only with java API:


code:


And play .mp3 with jLayer


I would recommend using the BasicPlayerAPI. It's open source, very simple and it doesn't require JavaFX.
http://www.javazoom.net/jlgui/api.html


After downloading and extracting the zip-file one should add the following jar-files to the build path of the project:


Here is a minimalistic usage example:


Required imports:


That's all you need to start playing music. The Player is starting and managing his own playback thread and provides play, pause, resume, stop and seek functionality.


For a more advanced usage you may take a look at the jlGui Music Player. It's an open source WinAmp clone: http://www.javazoom.net/jlgui/jlgui.html


The first class to look at would be PlayerUI (inside the package javazoom.jlgui.player.amp).
It demonstrates the advanced features of the BasicPlayer pretty well.


Using standard javax.sound API, a single Maven dependency, completely Open Source (Java 7 required) :


The easiest way I found was to download the JLayer jar file from http://www.javazoom.net/javalayer/sources.html and to add it to the Jar library http://www.wikihow.com/Add-JARs-to-Project-Build-Paths-in-Eclipse-%28Java%29


Here is the code for the class


and here are the imports


To give the readers another alternative, I am suggesting JACo MP3 Player library, a cross platform java mp3 player. 


Features:


For a complete list of its methods and attributes you can check its documentation here.


Sample code:


For more details, I created a simple tutorial here that includes a downloadable sourcecode.


You need to install JMF first (download using this link)


don't forget to add JMF jar files


Do a search of freshmeat.net for JAVE (stands for Java Audio Video Encoder) Library (link here). It's a library for these kinds of things. I don't know if Java has a native mp3 function. 


You will probably need to wrap the mp3 function and the wav function together, using inheritance and a simple wrapper function, if you want one method to run both types of files.


To add MP3 reading support to Java Sound, add the mp3plugin.jar of the JMF to the run-time class path of the application.


Note that the Clip class has memory limitations that make it unsuitable for more than a few seconds of high quality sound.






Question:  Is exception handling in Java actually slow?


Conventional wisdom, as well as a lot of Google results, says that exceptional logic shouldn't be used for normal program flow in Java.  Two reasons are usually given,


and 


This question is about #1.


As an example, this page describes Java exception handling as "very slow" and relates the slowness to the creation of the exception message string - "this string is then used in creating the exception object that is thrown. This is not fast."  The article Effective Exception Handling in Java says that "the reason for this is due to the object creation aspect of exception handling, which thereby makes throwing exceptions inherently slow".  Another reason out there is that the stack trace generation is what slows it down.


My testing (using Java 1.6.0_07, Java HotSpot 10.0, on 32 bit Linux), indicates that exception handling is no slower than regular code.  I tried running a method in a loop that executes some code.  At the end of the method, I use a boolean to indicate whether to return or throw.  This way the actual processing is the same. I tried running the methods in different orders and averaging my test times, thinking it may have been the JVM warming up.  In all my tests, the throw was at least as fast as the return, if not faster (up to 3.1% faster).  I am completely open to the possibility that my tests were wrong, but I haven't seen anything out there in the way of code sample, test comparisons, or results in the last year or two that show exception handling in Java to actually be slow.


What lead me down this path was an API I needed to use that threw exceptions as part of normal control logic.  I wanted to correct them in their usage, but now I may not be able to.  Will I instead have to praise them on their forward thinking?


In the paper Efficient Java exception handling in just-in-time compilation, the authors suggest that the presence of exception handlers alone, even if no exceptions are thrown, is enough to prevent the JIT compiler from optimizing the code properly, thus slowing it down.  I haven't tested this theory yet.


It depends how exceptions are implemented. The simplest way is using setjmp and longjmp. That means all registers of the CPU are written to the stack (which already takes some time) and possibly some other data needs to be created... all this already happens in the try statement. The throw statement needs to unwind the stack and restore the values of all registers (and possible other values in the VM). So try and throw are equally slow, and that is pretty slow, however if no exception is thrown, exiting the try block takes no time whatsoever in most cases (as everything is put on the stack which cleans up automatically if the method exists).


Sun and others recognized, that this is possibly suboptimal and of course VMs get faster and faster over the time. There is another way to implement exceptions, which makes try itself lightning fast (actually nothing happens for try at all in general - everything that needs to happen is already done when the class is loaded by the VM) and it makes throw not quite as slow. I don't know which JVM uses this new, better technique... 


...but are you writing in Java so your code later on only runs on one JVM on one specific system? Since if it may ever run on any other platform or any other JVM version (possibly of any other vendor), who says they also use the fast implementation? The fast one is more complicated than the slow one and not easily possible on all systems. You want to stay portable? Then don't rely on exceptions being fast.


It also makes a big difference what you do within a try block. If you open a try block and never call any method from within this try block, the try block will be ultra fast, as the JIT can then actually treat a throw like a simple goto. It neither needs to save stack-state nor does it need to unwind the stack if an exception is thrown (it only needs to jump to the catch handlers). However, this is not what you usually do. Usually you open a try block and then call a method that might throw an exception, right? And even if you just use the try block within your method, what kind of method will this be, that does not call any other method? Will it just calculate a number? Then what for do you need exceptions? There are much more elegant ways to regulate program flow. For pretty much anything else but simple math, you will have to call an external method and this already destroys the advantage of a local try block.


See the following test code:


Result:


The slowdown from the try block is too small to rule out confounding factors such as background processes. But the catch block killed everything and made it 66 times slower!


As I said, the result will not be that bad if you put try/catch and throw all within the same method (method3), but this is a special JIT optimization I would not rely upon. And even when using this optimization, the throw is still pretty slow. So I don't know what you are trying to do here, but there is definitely a better way of doing it than using try/catch/throw.


FYI, I extended the experiment that Mecki did:


The first 3 are the same as Mecki's (my laptop is obviously slower).


method4 is identical to method3 except that it creates a new Integer(1) rather than doing throw new Exception().


method5 is like method3 except that it creates the new Exception() without throwing it.


method6 is like method3 except that it throws a pre-created exception (an instance variable) rather than creating a new one.


In Java much of the expense of throwing an exception is the time spent gathering the stack trace, which occurs when the exception object is created.  The actual cost of throwing the exception, while large, is considerably less than the cost of creating the exception.


My answer unfortunately is just too long to post here. So let me summarize here and refer you to http://www.fuwjax.com/how-slow-are-java-exceptions/ for the gritty details.


The real question here is not "How slow are 'failures reported as exceptions' compared to 'code that never fails'?" as the accepted response might have you believe. Instead the question should be "How slow are 'failures reported as exceptions' compared to failures reported other ways?" Generally the two other ways of reporting failures are either with sentinel values or with result wrappers.


Sentinel values are an attempt to return one class in the case of success and another in the case of failure. You can think of it almost as returning an exception instead of throwing one. This requires a shared parent class with the success object, and then doing an "instanceof" check and a couple casts to get the success or failure information.


It turns out that at the risk of type safety, Sentinel values are faster than exceptions, but only by a factor of roughly 2x. Now, that may seem like a lot, but that 2x only covers the cost of the implementation difference. In practice the factor is much lower since our methods that might fail are much more interesting than a few arithmetic operators as in the sample code elsewhere in this page.


Result Wrappers on the other hand do not sacrifice type safety at all. They wrap the success and failure information in a single class. So instead of "instanceof" they provide an "isSuccess()" and getters for both the success and failure objects. However, result objects are roughly 2x slower than using exceptions. It turns out that creating a new wrapper object every time is much more expensive than throwing an exception sometimes.


On top of that, exceptions are the language supplied way of indicating that a method might fail. There's no other way to tell from just the API which methods are expected to always (mostly) work and which are expected to report failure.


Exceptions are safer than sentinels, faster than result objects, and less surprising than either. I'm not suggesting that try/catch replace if/else, but exceptions are the right way to report failure, even in the business logic.


That said, I would like to point out that the two most frequent ways of substantially impacting performance I've run across are creating unnecessary objects and nested loops. If you have a choice between creating an exception or not creating an exception, don't create the exception. If you have a choice between creating an exception sometimes or creating another object all the time, then create the exception.


Aleksey Shipilëv did a very thorough analysis in which he benchmarks Java exceptions under various combinations of conditions:


He also compares them to the performance of checking an error code at various levels of error frequency.


The conclusions (quoted verbatim from his post) were:


Truly exceptional exceptions are beautifully performant. If you use them as designed, and only communicate the truly exceptional cases among overwhelmingly large number of non-exceptional cases handled by regular code, then using exceptions is the performance win.


The performance costs of exceptions have two major components: stack trace construction when Exception is instantiated, and stack unwinding during Exception throw.


Stack trace construction costs are proportional to stack depth at the moment of exception instantiation. That is already bad, because who on Earth knows the stack depth at which this throwing method would be called? Even if you turn off the stack trace generation and/or cache the exceptions, you can only get rid of this part of the performance cost.


Stack unwinding costs depend on how lucky we are with bringing the exception handler closer in the compiled code. Carefully structuring the code to avoid deep exception handlers lookup is probably helping us get more lucky.


Should we eliminate both effects, the performance cost of exceptions is that of local branch. No matter how beautiful it sounds, that does not mean you should use Exceptions as the usual control flow, because in that case you are at the mercy of optimizing compiler! You should only use them in truly exceptional cases, where the exception frequency amortizes the possible unlucky cost of raising the actual exception.


The optimistic rule-of-thumb seems to be 10^-4 frequency for exceptions is exceptional enough. That of course depends on the heavy-weightness of the exceptions themselves, the exact actions taken in exception handlers, etc.


The upshot is that when an exception isn't thrown, you don't pay a cost, so when the exceptional condition is sufficiently rare exception handling is faster than using an if every time. The full post is very much worth a read.


I've extends the answers given by @Mecki and @incarnate, without stacktrace filling for Java.


With Java 7+, we can use Throwable(String message, Throwable cause, boolean enableSuppression,boolean writableStackTrace). But for Java6, see my answer for this question


Output with Java 1.6.0_45, on Core i7, 8GB Ram:


So, still methods which returns values are faster, compared to methods throwing exceptions. IMHO, we can't design a clear API just using return types for both success & error flows. Methods which throws exceptions without stacktrace are 4-5 times faster than normal Exceptions.


Edit: NoStackTraceThrowable.java Thanks @Greg


Don't know if these topics relate, but I once wanted to implement one trick relying on current thread's stack trace: I wanted to discover the name of the method, which triggered the instantiation inside the instantiated class (yeap, the idea is crazy, I totally gave it up). So I discovered that calling Thread.currentThread().getStackTrace() is extremely slow (due to native dumpThreads method which it uses internally).


So Java Throwable, correspondingly, has a native method fillInStackTrace. I think that the killer-catch block described earlier somehow triggers the execution of this method.


But let me tell you another story...


In Scala some functional features are compiled in JVM using ControlThrowable, which extends Throwable and overrides its fillInStackTrace in a following way:


So I adapted the test above (cycles amount are decreased by ten, my machine is a bit slower :):


So, the results are:


You see, the only difference between method3 and method4 is that they throw different kinds of exceptions. Yeap, method4 is still slower than method1 and method2, but the difference is far more acceptable.


I think the first article refer to the act of traversing the call stack and creating a stack trace as being the expensive part, and while the second article doesn't say it, I think that is the most expensive part of object creation. John Rose has an article where he describes different techniques for speeding up exceptions. (Preallocating and reusing an exception, exceptions without stack traces, etc)


But still - I think this should be considered only a necessary evil, a last resort. John's reason for doing this is to emulate features in other languages which aren't (yet) available in the JVM. You should NOT get into the habit of using exceptions for control flow. Especially not for performance reasons! As you yourself mention in #2, you risk masking serious bugs in your code this way, and it will be harder to maintain for new programmers.


Microbenchmarks in Java are surprisingly hard to get right (I've been told), especially when you get into JIT territory, so I really doubt that using exceptions is faster than "return" in real life. For instance, I suspect you have somewhere between 2 and 5 stack frames in your test? Now imagine your code will be invoked by a JSF component deployed by JBoss. Now you might have a stack trace which is several pages long.


Perhaps you could post your test code?


I've done some performance testing with JVM 1.5 and using exceptions was at least 2x slower. On average: Execution time on a trivially small method more than tripled (3x) with exceptions. A trivially small loop that had to catch the exception saw a 2x increase in self-time.


I've seen similar numbers in production code as well as micro benchmarks.


Exceptions should definately NOT be used for anything that's called frequently. Throwing a thousands of exceptions a second would cause a huge bottle neck.


For example, using "Integer.ParseInt(...)" to find all bad values in a very large text file--very bad idea. (I have seen this utility method kill performance on production code)


Using an exception to report a bad value on a user GUI form, probably not so bad from a performance standpoint.


Whether or not its a good design practice, I'd go with the rule: if the error is normal/expected, then use a return value. If it's abnormal, use an exception. For example: reading user inputs, bad values are normal--use an error code. Passing a value to an internal utility function, bad values should be filtered by calling code--use an exception.


A while back I wrote a class to test the relative performance of converting strings to ints using two approaches: (1) call Integer.parseInt() and catch the exception, or (2) match the string with a regex and call parseInt() only if the match succeeds.  I used the regex in the most efficient way I could (i.e., creating the Pattern and Matcher objects before intering the loop), and I didn't print or save the stacktraces from the exceptions.


For a list of ten thousand strings, if they were all valid numbers the parseInt() approach was four times as fast as the regex approach.  But if only 80% of the strings were valid, the regex was twice as fast as parseInt().  And if 20% were valid, meaning the exception was thrown and caught 80% of the time, the regex was about twenty times as fast as parseInt().


I was surprised by the result, considering that the regex approach processes valid strings twice: once for the match and again for parseInt().  But throwing and catching exceptions more than made up for that.  This kind of situation isn't likely to occur very often in the real world, but if it does, you definitely should not use the exception-catching technique.  But if you're only validating user input or something like that, by all means use the parseInt() approach.


Even if throwing an exception isn't slow, it's still a bad idea to throw exceptions for normal program flow. Used this way it is analogous to a GOTO...


I guess that doesn't really answer the question though. I'd imagine that the 'conventional' wisdom of throwing exceptions being slow was true in earlier java versions (< 1.4). Creating an exception requires that the VM create the entire stack trace. A lot has changed since then in the VM to speed things up and this is likely one area that has been improved.


Exception performance in Java and C# leaves much to be desired. 


As programmers this forces us to live by the rule "exceptions should be caused infrequently", simply for practical performance reasons.


However, as computer scientists, we should rebel against this problematic state. The person authoring a function often has no idea how often it will be called, or whether success or failure is more likely. Only the caller has this information. Trying to avoid exceptions leads to unclear API idoms where in some cases we have only clean-but-slow exception versions, and in other cases we have fast-but-clunky return-value errors, and in still other cases we end up with both. The library implementor may have to write and maintain two versions of APIs, and the caller has to decide which of two versions to use in each situation. 


This is kind of a mess. If exceptions had better performance, we could avoid these clunky idioms and use exceptions as they were meant to be used... as a structured error return facility.


I'd really like to see exception mechanisms implemented using techniques closer to return-values, so we could have performance closer to return values.. since this is what we revert to in performance sensitive code.


Here is a code-sample that compares exception performance to error-return-value performance.


public class TestIt {


}


And here are the results:


Checking and propagating return-values does add some cost vs the baseline-null call, and that cost is proportional to call-depth. At a call-chain depth of 8, the error-return-value checking version was about 27% slower than the basline version which did not check return values.


Exception performance, in comparison, is not a function of call-depth, but of exception frequency. However, the degredation as exception frequency increases is much more dramatic. At only a 25% error frequency, the code ran 24-TIMES slower. At an error frequency of 100%, the exception version is almost 100-TIMES slower. 


This suggests to me that perhaps are making the wrong tradeoffs in our exception implementations. Exceptions could be faster, either by avoiding costly stalk-walks, or by outright turning them into compiler supported return-value checking. Until they do, we're stuck avoiding them when we want our code to run fast.


HotSpot is quite capable of removing exception code for system generated exceptions, so long as it is all inlined. However, explicitly created exception and those otherwise not removed spend a lot of time creating the stack trace. Override fillInStackTrace to see how this can affect performance.


Just compare let's say Integer.parseInt to the following method, which just returns a default value in the case of unparseable data instead of throwing an Exception:


As long as you apply both methods to "valid" data, they both will work at approximately the same rate (even although Integer.parseInt manages to handle more complex data). But as soon as you try to parse invalid data (e.g. to parse "abc" 1.000.000 times), the difference in performance should be essential.


I changed @Mecki 's answer above to have method1 return a boolean and a check in the calling method, as you cannot just replace an Exception with nothing. After two runs, method1 was still either the fastest or as fast as method2.


Here is snapshot of the code:


and results:


Run 1


Run 2


My opinion about Exception speed versus checking data programmatically. 


Many classes had String to value converter (scanner / parser), respected and well-known libraries too ;)


usually has form


exception name is only example, usually is unchecked (runtime), so throws declaration is only my picture


sometimes exist second form:


never throwing


When the second ins't available (or programmer read too less docs and use only first), write such code with regular expression. Regular expression are cool, politically correct etc:


with this code programmers hasn't cost of exceptions. BUT HAS comparable very HIGH cost of regular expressions ALWAYS versus small cost of exception sometimes.


I use almost always in such context 


without analysing stacktrace etc, I believe after lectures of Yours quite speed.


Do not be afraid Exceptions


Why should exceptions be any slower than normal returns?


As long as you don't print the stacktrace to the terminal, save it into a file or something similar, the catch-block doesn't do any more work than other code-blocks. So, I can't imagine why "throw new my_cool_error()" should be that slow. 


Good question and I'm looking forward to further information on this topic! 






We currently have a crude mechanism to convert numbers to words (e.g. using a few static arrays) and based on the size of the number translating that into an english text. But we are running into issues for numbers which are huge.


Is there an easy to use function in any of the math libraries which I can use for this purpose?


Here is the code, I don't think there is any method in SE.


It basically converts number to string and parses String and associates it with the weight


for example


1 is treated as thousand position and 1 gets mapped to "one" and thousand because of position



This is the code from the website:


English


Français
Quite different than the english version but french is a lot more difficult!


You can handle "dollar and cent" conversion by calling the "convert" method two times.


Another way to use a built-in function of your DBMS (if available).
For Oracle


Because you cannot have a general algorithm for every locale, no. You have to implement your own algorithm for every locale that you are supporting.


** EDIT **


Just for the heck of it, I played around until I got this class. It cannot display Long.MIN_VALUE because of bit restrictions... but I presume it could be modified and change long value types to double for decimal or even bigger numbers It can display any numbers up to 66 digits and 26 decimals using a string representation of the number. You may add more ScaleUnit for more decimals...


and a sample output (for the random big number generator)


ICU4J contains nice number-spellout support. The files with the "rules" can be easily edited, and it's no problem to add other languages (we did it e.g. for Polish and Russian).


I think that this solution is not the best, since it works only for int, but i think it's great for a beginner.


The test creates 20 random numbers up to Integer.MAX_VALUE and than some that know to be problematic, because of 0, 10, etc.. Output:


Hope it helps :)


In this post i have just update Yanick Rochon's code. I have make it workable with lower version of java 1.6 and i was getting the output for 1.00 = one and  hundredth. So i have update the code. New i get the output for 1.00 = one and zero hundredth.


I don't not what should i do. Add a new answer or edit that post. As the answer is highly ranked so i have made a new post with updating the code. I have just change this two things have mention above.


The output is


Take a look at Tradukisto. It's a Java library I've written which does the job.


I have written a clean version for 32-bit integers and american English:


http://www.source-code.biz/snippets/java/13.htm


I've developed a Java component to convert given number into words. All you've to do is - just copy the whole class from Java program to convert numbers to words and paste it in your project.


Just invoke it like below


My program supports up to 10 million. If you want, you can still extend this. Just below the example output


Thanks


Santhosh


Just uploaded an extensible version! NumberReader @ SourceForge


This is another way...(with limited range)


I think this may help you...programme is very simple and works fine  


this might help


You probably don't need this any more, but I recently wrote a java class to do this. Apparently Yanick Rochon did something similar. It will convert numbers up to 999 Novemdecillion (999*10^60). It could do more if I knew what came after Novemdecillion, but I would be willing to bet it's unnecessary. Just feed the number as a string in cents. The output is also grammatically correct.


Here is a link to the Bitbucket Repo


I implemented it like this


and the resource file is :


This one is implemented till 10 lakhs only


I have used 2 dimensional array...


}






While working in a Java app, I recently needed to assemble a comma-delimited list of values to pass to another web service without knowing how many elements there would be in advance. The best I could come up with off the top of my head was something like this:


I realize this isn't particularly efficient, since there are strings being created all over the place, but I was going for clarity more than optimization.


In Ruby, I can do something like this instead, which feels much more elegant:


But since Java lacks a join command, I couldn't figure out anything equivalent.


So, what's the best way to do this in Java?


Apache's commons lang is your friend here - it provides a join method very similar to the one you refer to in Ruby: 


StringUtils.join(java.lang.Iterable,char)


Java 8 provides joining out of the box via StringJoiner and String.join(). The snippets below show how you can use them:


StringJoiner


String.join(CharSequence delimiter, CharSequence... elements))


String.join(CharSequence delimiter, Iterable<? extends CharSequence> elements)


You could write a little join-style utility method that works on java.util.Lists


Then use it like so:


In the case of Android, the StringUtils class from commons isn't available, so for this I used


http://developer.android.com/reference/android/text/TextUtils.html


The Google's Guava library has com.google.common.base.Joiner class which helps to solve such tasks.


Samples:


Here is an article about Guava's string utilities.


In Java 8 you can use String.join():


Also have a look at this answer for a Stream API example.


You can generalize it, but there's no join in Java, as you well say.


This might work better. 


Use an approach based on java.lang.StringBuilder!  ("A mutable sequence of characters. ")


Like you mentioned, all those string concatenations are creating Strings all over.  StringBuilder won't do that.


Why StringBuilder instead of StringBuffer?  From the StringBuilder javadoc:


Where possible, it is recommended that this class be used in preference to StringBuffer as it will be faster under most implementations. 


I would use Google Collections.  There is a nice Join facility.
http://google-collections.googlecode.com/svn/trunk/javadoc/index.html?com/google/common/base/Join.html


But if I wanted to write it on my own,


I think it works better with an object collection, since now you don't have to convert your objects to strings before you join them.


in Java 8 you can do this like:


if list has nulls you can use:


Apache commons StringUtils class has a join method.


You can use Java's StringBuilder type for this. There's also StringBuffer, but it contains extra thread safety logic that is often unnecessary.


If you are using Spring MVC then you can try following steps.


It will result to a,b,c


Use StringBuilder and class Separator


Separator wraps a delimiter. The delimiter is returned by Separator's toString method, unless on the first call which returns the empty string!


Source code for class Separator


Why not write your own join() method?  It would take as parameters collection of Strings and a delimiter String.  Within the method iterate over the collection and build up your result in a StringBuffer.


You should probably use a StringBuilder with the append method to construct your result, but otherwise this is as good of a solution as Java has to offer.


Why don't you do in Java the same thing you are doing in ruby, that is creating the delimiter separated string only after you've added all the pieces to the array?


You may want to move that for loop in a separate helper method, and also use StringBuilder instead of StringBuffer...


Edit: fixed the order of appends.


With Java 5 variable args, so you don't have to stuff all your strings into a collection or array explicitly:


For those who are in a Spring context their StringUtils class is useful as well:


There are many useful shortcuts like:


and many others. 


This can be helpful if you are not already using Java 8 and you are already in a Spring context.


I prefer it against the Apache Commons (although very good as well) for the Collection support which is easier like this:


And a minimal one (if you don't want to include Apache Commons or Gauva into project dependencies just for the sake of joining strings)


If you're using Eclipse Collections, you can use makeString() or appendString().


makeString() returns a String representation, similar to toString().


It has three forms


Code example:


appendString() is similar to makeString(), but it appends to an Appendable (like StringBuilder) and is void. It has the same three forms, with an additional first argument, the Appendable.


If you can't convert your collection to an Eclipse Collections type, just adapt it with the relevant adapter.


Note: I am a committer for Eclipse collections.


You can try something like this:


So basically something like this:


Don't know if this really is any better, but at least it's using StringBuilder, which may be slightly more efficient.


Down below is a more generic approach if you can build up the list of parameters BEFORE doing any parameter delimiting.


Your approach is not too bad, but you should use a StringBuffer instead of using the + sign. The + has the big disadvantage that a new String instance is being created for each single operation. The longer your string gets, the bigger the overhead. So using a StringBuffer should be the fastest way:


After you have finished creating your string simply call toString() on the returned StringBuffer.


Instead of using string concatenation, you should use StringBuilder if your code is not threaded, and StringBuffer if it is.


You're making this a little more complicated than it has to be. Let's start with the end of your example:


With the small change of using a StringBuilder instead of a String, this becomes:


When you're done (I assume you have to check a few other conditions as well), just make sure you remove the tailing comma with a command like this:


And finally, get the string you want with


You could also replace the "," in the second call to append with a generic delimiter string that can be set to anything. If you have a list of things you know you need to append (non-conditionally), you could put this code inside a method that takes a list of strings. 


So a couple of things you might do to get the feel that it seems like you're looking for:


1) Extend List class - and add the join method to it.  The join method would simply do the work of concatenating and adding the delimiter (which could be a param to the join method)


2) It looks like Java 7 is going to be adding extension methods to java - which allows you just to attach a specific method on to a class:  so you could write that join method and add it as an extension method to List or even to Collection.


Solution 1 is probably the only realistic one, now, though since Java 7 isn't out yet :) But it should work just fine.


To use both of these, you'd just add all your items to the List or Collection as usual, and then call the new custom method to 'join' them.


using Dollar is simple as typing:


NB: it works also for Array and other data types


Internally it uses a very neat trick:


the class Separator return the empty String only the first time that it is invoked, then it returns the separator:






I need to execute some amount of tasks 4 at a time, something like this:


How can I get notified once all of them are complete? For now I can't think about anything better than setting some global task counter and decrease it at the end of every task, then monitor in infinite loop this counter to become 0; or get a list of Futures and in infinite loop monitor isDone for all of them. What are better solutions not involving infinite loops?


Thanks.


Basically on an ExecutorService you call shutdown() and then awaitTermination():


Use a CountDownLatch:


and within your task (enclose in try / finally)


ExecutorService.invokeAll() does it for you.


You can use Lists of Futures, as well:


then when you want to join on all of them, its essentially the equivalent of joining on each, (with the added benefit that it re-raises exceptions from child threads to the main):


Basically the trick is to call .get() on each Future one at a time, instead of infinite looping calling isDone() on (all or each).  So you're guaranteed to "move on" through and past this block as soon as the last thread finishes.  The caveat is that since the .get() call re-raises exceptions, if one of the threads dies, you would raise from this possibly before the other threads have finished to completion [to avoid this, you could add a catch ExecutionException around the get call].  The other caveat is it keeps a reference to all threads so if they have thread local variables they won't get collected till after you get past this block (though you might be able to get around this, if it became a problem, by removing Future's off the ArrayList).  If you wanted to know which Future "finishes first" you could use some something like https://stackoverflow.com/a/31885029/32453


Just my two cents.
To overcome the requirement of CountDownLatch to know the number of tasks beforehand, you could do it the old fashion way by using a simple Semaphore.


In your task just call s.release() as you would latch.countDown();


In Java8 you can do it with CompletableFuture:


The CyclicBarrier class in Java 5 and later is designed for this sort of thing.


A bit late to the game but for the sake of completion...


Instead of 'waiting' for all tasks to finish, you can think in terms of the Hollywood principle, "don't call me, I'll call you" - when I'm finished.
I think the resulting code is more elegant...


Guava offers some interesting tools to accomplish this.


An example ::


Wrap an ExecutorService into a ListeningExecutorService ::


Submit a collection of callables for execution ::


Now the essential part: 


Attach a callback to the ListenableFuture, that you can use to be notified when all futures complete ::


This also offers the advantage that you can collect all the results in one place once the processing is finished...


More information here


You could wrap your tasks in another runnable, that will send notifications:


I've just written a sample program that solves your problem. There was no concise implementation given, so I'll add one. While you can use executor.shutdown() and executor.awaitTermination(), it is not the best practice as the time taken by different threads would be unpredictable.


Just to provide more alternatives here different to use latch/barriers.
You can also get the partial results until all of them finish using CompletionService.


From Java Concurrency in practice:
"If you have a batch of computations to submit to an Executor and you want to retrieve their results as they become
available, you could retain the Future associated with each task and repeatedly poll for completion by calling get with a
timeout of zero. This is possible, but tedious. Fortunately there is a better way: a completion service."


Here the implementation


Follow one of below approaches. 


Related SE questions:


How is CountDownLatch used in Java Multithreading?


How to properly shutdown java ExecutorService


You could use your own subclass of ExecutorCompletionService to wrap taskExecutor, and your own implementation of BlockingQueue to get informed when each task completes and perform whatever callback or other action you desire when the number of completed tasks reaches your desired goal.


you should use executorService.shutdown() and executorService.awaitTermination method.


An example as follows :


Java 8 - We can use stream API to process stream. Please see snippet below


You could use this code:


This might help


You could call waitTillDone() on this Runner class:


You can reuse this class and call waitTillDone() as many times as you want to before calling shutdown(), plus your code is extremly simple. Also you don't have to know the number of tasks upfront.


To use it just add this gradle/maven compile 'com.github.matejtymes:javafixes:1.1.1' dependency to your project.


More details can be found here:


https://github.com/MatejTymes/JavaFixes


http://matejtymes.blogspot.com/2016/04/executor-that-notifies-you-when-task.html


There is a method in executor getActiveCount() - that gives the count of active threads. 


After spanning the thread, we can check if the activeCount() value is 0. Once the value is zero, it is meant that there are no active threads currently running which means task is finished:






I'm experimenting with this code:


This prints foo(Object o) three times. I expect the method selection to take in consideration the real (not the declared) parameter type. Am I missing something? Is there a way to modify this code so that it'll print foo(12), foo("foobar") and foo(Object o)?


I expect the method selection to take
  in consideration the real (not the
  declared) parameter type. Am I missing
  something?


Yes. Your expectation is wrong. In Java, dynamic method dispatch happens only for the object the method is called on, not for the parameter types of overloaded methods.


Citing the Java Language Specification:


When a method is invoked (§15.12), the
  number of actual arguments (and any
  explicit type arguments) and the
  compile-time types of the arguments
  are used, at compile time, to
  determine the signature of the method
  that will be invoked (§15.12.2). If
  the method that is to be invoked is an
  instance method, the actual method to
  be invoked will be determined at run
  time, using dynamic method lookup
  (§15.12.4).


As mentioned before overloading resolution is performed at compile time.


Java Puzzlers has a nice example for that:


Puzzle 46: The Case of the Confusing Constructor


This puzzle presents you with two Confusing constructors. The main method invokes a constructor,
but which one? The program's output depends on the answer. What does the program print, or is it
even legal?


Solution 46: Case of the Confusing Constructor


...
Java's overload resolution process operates in two phases. The first phase selects all the methods or constructors that are accessible and applicable. The second phase selects the most specific of the methods or constructors selected in the first phase. One method or constructor is less specific than another if it can accept any parameters passed to the other [JLS 15.12.2.5].


In our program, both constructors are accessible and applicable. The constructor
Confusing(Object) accepts any parameter passed to Confusing(double[]), so
Confusing(Object) is less specific. (Every double array is an Object, but not every Object is a double array.) The most specific constructor is therefore Confusing(double[]), which explains the program's output.


This behavior makes sense if you pass a value of type double[]; it is counterintuitive if you pass null. The key to understanding this puzzle is that the test for which method or constructor is most specific does not use the actual parameters: the parameters appearing in the invocation.
They are used only to determine which overloadings are applicable. Once the compiler determines which overloadings are applicable and accessible, it selects the most specific overloading, using only the formal parameters: the parameters appearing in the declaration.


To invoke the Confusing(Object) constructor with a null parameter, write new
Confusing((Object)null). This ensures that only Confusing(Object) is applicable. More
generally, to force the compiler to select a specific overloading, cast actual parameters to the declared types of the formal parameters.


Ability to  dispatch a call to a method based on types of arguments is called multiple dispatch. In Java this is done with Visitor pattern.


However, since you're dealing with Integers and Strings, you cannot easily incorporate this pattern (you just cannot modify these classes). Thus, a giant switch on object run-time will be your weapon of choice.


In Java the method to call (as in which method signature to use) is determined at compile time, so it goes with the compile time type.


The typical pattern for working around this is to check the object type in the method with the Object signature and delegate to the method with a cast.


If you have many types and this is unmanageable, then method overloading is probably not the right approach, rather the public method should just take Object and implement some kind of strategy pattern to delegate the appropriate handling per object type.


I had a similar issue with calling the right constructor of a class called "Parameter" that could take several basic Java types such as String, Integer, Boolean, Long, etc. Given an array of Objects, I want to convert them into an array of my Parameter objects by calling the most-specific constructor for each Object in the input array. I also wanted to define the constructor Parameter(Object o) that would throw an IllegalArgumentException. I of course found this method being invoked for every Object in my array. 


The solution I used was to look up the constructor via reflection...


No ugly instanceof, switch statements, or visitor pattern required! :)


Java looks at the reference type when trying to determine which method to call.  If you want to force your code you choose the 'right' method, you can declare your fields as instances of the specific type:


You could also cast your params as the type of the param:


If there is an exact match between the number and types of arguments specified in the method call and the method signature of an overloaded method then that is the method that will be invoked. You are using Object references, so java decides at compile time that for Object param, there is a method which accepts directly Object. So it called that method 3 times.






For example:


This comes up in Java 5 and later if you're using collections without type specifiers (e.g., Arraylist() instead of ArrayList<String>()).  It means that the compiler can't check that you're using the collection in a type-safe way, using generics.


To get rid of the warning, just be specific about what type of objects you're storing in the collection.  So, instead of 


use


In Java 7 you can shorten generic instantiation by using Type Inference.


If you do what it suggests and recompile with the "-Xlint:unchecked" switch, it will give you more detailed information.


As well as the use of raw types (as described by the other answers), an unchecked cast can also cause the warning.


Once you've compiled with -Xlint, you should be able to rework your code to avoid the warning.  This is not always possible, particularly if you are integrating with legacy code that cannot be changed.  In this situation, you may decide to suppress the warning in places where you know that the code is correct:


This warning means that your code operates on a raw type, recompile the example with the 


to get the details 


like this:  


docs.oracle.com talks about it here: 
http://docs.oracle.com/javase/tutorial/java/generics/rawTypes.html


for example when you call a function that returns Generic Collections and you don't specify the generic parameters yourself.


for a function


will generate this error.


To solve it you would just add the parameters


The "unchecked or unsafe operations" warning was added when java added Generics, if I remember correctly. It's usually asking you to be more explicit about types, in one way or another. 


For example. the code ArrayList foo = new ArrayList(); triggers that warning because javac is looking for ArrayList<String> foo = new ArrayList<String>();


I just want to add one example of the kind of unchecked warning I see quite often. If you use classes that implement an interface like Serializable, often you will call methods that return objects of the interface, and not the actual class. If the class being returned must be cast to a type based on generics, you can get this warning. 


Here is a brief (and somewhat silly) example to demonstrate:


getInstance() returns an object that implements Serializable. This must be cast to the actual type, but this is an unchecked cast.


The solution would be to use specific type in <> like ArrayList.


example: 


File curfolder = new File( "C:\\Users\\username\\Desktop");
File[] file = curfolder.listFiles();
ArrayList filename = Arrays.asList(file);


above code generate warning because ArrayList is not of specific type.


File curfolder = new File( "C:\\Users\\username\\Desktop");
File[] file = curfolder.listFiles();
ArrayList<File> filename = Arrays.asList(file);


above code will do fine. Only change is in third line after ArrayList.






I have some questions regarding the usage and significance of the synchronized keyword. 


The synchronized keyword is all about different threads reading and writing to the same variables, objects and resources.  This is not a trivial topic in Java, but here is a quote from Sun:


synchronized methods enable a simple
  strategy for preventing thread
  interference and memory consistency
  errors: if an object is visible to
  more than one thread, all reads or
  writes to that object's variables are
  done through synchronized methods.


In a very, very small nutshell: When you have two threads that are reading and writing to the same 'resource', say a variable named foo, you need to ensure that these threads access the variable in an atomic way.  Without the synchronized keyword, your thread 1 may not see the change thread 2 made to foo, or worse, it may only be half changed.  This would not be what you logically expect.


Again, this is a non-trivial topic in Java.  To learn more, explore topics here on SO and the Interwebs  about:


Keep exploring these topics until the name "Brian Goetz" becomes permanently associated with the term "concurrency" in your brain.  


Well, I think we had enough of theoretical explanations, so consider this code


Note: synchronized blocks the next thread's call to method test() as long as the previous thread's execution is not finished. Threads can access this method one at a time. Without synchronized all threads can access this method simultaneously.


When a thread calls the synchronized method 'test' of the object (here object is an instance of 'TheDemo' class) it acquires the lock of that object, any new thread cannot call ANY synchronized method of the same object as long as previous thread which had acquired the lock does not release the lock.


Similar thing happens when any static synchronized method of the class is called. The thread acquires the lock associated with the class(in this case any non static synchronized method of an instance of that class can be called by any thread because that object level lock is still available). Any other thread will not be able to call any static synchronized method of the class as long as the class level lock is not released by the thread which currently holds the lock.


Output with synchronised


Output without synchronized


The synchronized keyword prevents concurrent access to a block of code or object by multiple Threads.  By default, a Hashtable is synchronized, so only one thread can access the table at a time.  


On usage of non-synchronized constructs like HashMap,you must build thread safety features in your code to prevent memory consistency errors.


synchronized means that in a multi threaded environment, an object having  synchronized method(s)/block(s) does not let two threads to access the synchronized method(s)/block(s) of code at the same time. This means that one thread can't read while another thread updates it.


The second thread will instead wait until the first thread completes its execution. The overhead is speed, but the advantage is guaranteed consistency of data.


If your application is single threaded though, synchronized blocks does not provide benefits.


The synchronized keyword causes a thread to obtain a lock when entering the method, so that only one thread can execute the method at the same time (for the given object instance, unless it is a static method).


This is frequently called making the class thread-safe, but I would say this is a euphemism. While it is true that synchronization protects the internal state of the Vector from getting corrupted, this does not usually help the user of Vector much. 


Consider this:


Even though the methods involved are synchronized, because they are being locked and unlocked individually, two unfortunately timed threads can create a vector with two elements.


So in effect, you have to synchronize in your application code as well.


Because method-level synchronization is a) expensive when you don't need it and b) insufficient when you need synchronization, there are now un-synchronized replacements (ArrayList in the case of Vector).


More recently, the concurrency package has been released, with a number of clever utilities that take care of multi-threading issues.


Synchronized keyword in Java has to do with thread-safety, that is, when multiple threads read or write the same variable.
This can happen directly (by accessing the same variable) or indirectly (by using a class that uses another class that accesses the same variable).


The synchronized keyword is used to define a block of code where multiple threads can access the same variable in a safe way.


Syntax-wise the synchronized keyword takes an Object as it's parameter (called a lock object), which is then followed by a { block of code }.


When execution encounters this keyword, the current thread tries to "lock/acquire/own" (take your pick) the lock object and execute the associated block of code after the lock has been acquired.


Any writes to variables inside the synchronized code block are guaranteed to be visible to every other thread that similarly executes code inside a synchronized code block using the same lock object.


Only one thread at a time can hold the lock, during which time all other threads trying to acquire the same lock object will wait (pause their execution). The lock will be released when execution exits the synchronized code block.


Adding synchronized keyword to a method definition is equal to the entire method body being wrapped in a synchronized code block with the lock object being this (for instance methods) and ClassInQuestion.getClass() (for class methods).


- Instance method is a method which does not have static keyword.
- Class method is a method which has static keyword.


Without synchronization, it is not guaranteed in which order the reads and writes happen, possibly leaving the variable with garbage.
(For example a variable could end up with half of the bits written by one thread and half of the bits written by another thread, leaving the variable in a state that neither of the threads tried to write, but a combined mess of both.)


It is not enough to complete a write operation in a thread before (wall-clock time) another thread reads it, because hardware could have cached the value of the variable, and the reading thread would see the cached value instead of what was written to it.


Thus in Java's case, you have to follow the Java Memory Model to ensure that threading errors do not happen.
In other words: Use synchronization, atomic operations or classes that use them for you under the hoods.


http://docs.oracle.com/javase/specs/jls/se8/html/index.html
Java® Language Specification, 2015-02-13


Think of it as a kind of turnstile like you might find at a football ground. There are parallel steams of people wanting to get in but at the turnstile they are 'synchronised'. Only one person at a time can get through. All those wanting to get through will do, but they may have to wait until they can go through.


What is the synchronized keyword?


Threads communicate primarily by sharing access to fields and the objects reference fields refer to. This form of communication is extremely efficient, but makes two kinds of errors possible: thread interference and memory consistency errors. The tool needed to prevent these errors is synchronization. 


Synchronized blocks or methods prevents thread interference and make sure that data is consistent. At any point of time, only one thread can access a synchronized block or method (critical section) by acquiring a lock. Other thread(s) will wait for release of lock to access critical section. 


When are methods synchronized?


Methods are synchronized when you add synchronized to method definition or declaration. You can also synchronize a particular block of code with-in a method. 


What does it mean pro grammatically and logically?


It means that only one thread can access critical section by acquiring a lock. Unless this thread release this lock, all other thread(s) will have to wait to acquire a lock. They don't have access to enter critical section with out acquiring lock.


This can't be done with a magic. It's programmer  responsibility to identify critical section(s) in application and guard it accordingly. Java provides a framework to guard your application, but where and what all sections to be guarded is the responsibility of programmer.


More details from java documentation page


Intrinsic Locks and Synchronization:


Synchronization is built around an internal entity known as the intrinsic lock or monitor lock. Intrinsic locks play a role in both aspects of synchronization: enforcing exclusive access to an object's state and establishing happens-before relationships that are essential to visibility.


Every object has an intrinsic lock associated with it. By convention, a thread that needs exclusive and consistent access to an object's fields has to acquire the object's intrinsic lock before accessing them, and then release the intrinsic lock when it's done with them.


A thread is said to own the intrinsic lock between the time it has acquired the lock and released the lock. As long as a thread owns an intrinsic lock, no other thread can acquire the same lock. The other thread will block when it attempts to acquire the lock.


When a thread releases an intrinsic lock, a happens-before relationship is established between that action and any subsequent acquisition of the same lock. 


Making methods synchronized has two effects:


First, it is not possible for two invocations of synchronized methods on the same object to interleave. 


When one thread is executing a synchronized method for an object, all other threads that invoke synchronized methods for the same object block (suspend execution) until the first thread is done with the object.


Second, when a synchronized method exits, it automatically establishes a happens-before relationship with any subsequent invocation of a synchronized method for the same object. 


This guarantees that changes to the state of the object are visible to all threads.


Look for other alternatives to synchronization in :


Avoid synchronized(this) in Java?


To my understanding synchronized basically means that the compiler write a monitor.enter and monitor.exit around your method. As such it may be thread safe depending on how it is used (what I mean is you can write an object with synchronized methods that isn't threadsafe depending on what your class does).


I know that you have already gotten your answer . I write this, only to help the people who have the same question and are looking up this page for an answer . 
here is an  explanation from java documentation : 
Consider the following code : 


if count is an instance of   SynchronizedCounter then making these methods synchronized has two effects:


synchronized simple means no two threads can access the block/method simultaneously. When we say any block/method of a class is synchronized it means only one thread can access them at a time. Internally the thread which tries to access it first take a lock on that object and as long as this lock is not available no other thread can access any of the synchronized methods/blocks of that instance of the class.


Note another thread can access a method of the same object which is not defined to be synchronized. A thread can release the lock by calling


Synchronized simply means that multiple threads if associated with single object can prevent dirty read and write if synchronized block is used on particular object. To give you more clarity , lets take an example :


We've created two MyRunnable class objects , runnable1 being shared with thread 1 and thread 3 & runnable2 being shared with thread 2 only.
Now when t1 and t3 starts without synchronized being used , PFB output which suggest that both threads 1 and 3 simultaneously affecting var value where for thread 2 , var has its own memory.


Using Synchronzied, thread 3 waiting for thread 1 to complete in all scenarios. There are two locks acquired , one on runnable1 shared by thread 1 and thread 3 and another on runnable2 shared by thread 2 only.


What the other answers are missing is one important aspect: memory barriers. Thread synchronization basically consists of two parts: serialization and visibility. I advise everyone to google for "jvm memory barrier", as it is a non-trivial and extremely important topic (if you modify shared data accessed by multiple threads). Having done that, I advise looking at java.util.concurrent package's classes that help to avoid using explicit synchronization, which in turn helps keeping programs simple and efficient, maybe even preventing deadlocks.


One such example is ConcurrentLinkedDeque. Together with the command pattern it allows to create highly efficient worker threads by stuffing the commands into the concurrent queue -- no explicit synchronization needed, no deadlocks possible, no explicit sleep() necessary, just poll the queue by calling take().


In short: "memory synchronization" happens implicitly when you start a thread, a thread ends, you read a volatile variable, you unlock a monitor (leave a synchronized block/function) etc. This "synchronization" affects (in a sense "flushes") all writes done before that particular action. In the case of the aforementioned ConcurrentLinkedDeque, the documentation "says":


Memory consistency effects: As with other concurrent collections,
  actions in a thread prior to placing an object into a
  ConcurrentLinkedDeque happen-before actions subsequent to the access
  or removal of that element from the ConcurrentLinkedDeque in another
  thread.


This implicit behavior is a somewhat pernicious aspect because most Java programmers without much experience will just take a lot as given because of it. And then suddenly stumble over this thread after Java isn't doing what it is "supposed" to do in production where there is a different work load -- and it's pretty hard to test concurrency issues.


synchronized is a keyword in Java which is used to make happens before relationship in multithreading environment to avoid memory inconsistency and thread interference error.






This question already has an answer here:


if I set


in my hibernate.cfg.xml configuration file in the console I can see the SQL.


But it's not real SQL... Can I see the SQL code that will be passed directly to database?


Example:


I see 


Can I see


the real SQL?


Can I see (...) the real SQL


If you want to see the SQL sent directly to the database (that is formatted similar to your example), you'll have to use some kind of jdbc driver proxy like P6Spy (or log4jdbc).


Alternatively you can enable logging of the following categories (using a log4j.properties file here):


The first is equivalent to hibernate.show_sql=true, the second prints the bound parameters among other things.


Some frameworks use persistence.xml:


If you can already see the SQL being printed, that means you have the code below in your hibernate.cfg.xml:


To print the bind parameters as well, add the following to your log4j.properties file:


Worth noting that the code you see is sent to the database as is, the queries are sent separately to prevent SQL injection. AFAIK The ? marks are placeholders that are replaced by the number params by the database, not by hibernate.


select this_.code from true.employee this_ where this_.code=? is what will be sent to your database.


this_ is an alias for that instance of the employee table.






I am new to the Java application and having trouble compiling a simple Helloworld program.


JDK 1.7.0 is installed in my Windows 7 and was able to set the path variable but didn't work, so I tried something but still keeps on giving me the same error.  In my cmd it says  this:


Check your javac path on Windows using Windows Explorer C:\Program Files\Java\jdk1.7.0_02\bin and copy the address.


Go to Control Panel. Environment Variables and Insert the address at the beginning of var. Path followed by semicolon. i.e C:\Program Files\Java\jdk1.7.0_02\bin; . Do not delete the path existent, just click in and go to the left end and paste the line above. Do not try anything else, because you just need to link your code to "javac.exe" and you just need to locate it.


Close your command prompt and reopen it,and write the code for compile and execution.


try this.. 
I had it too but now it solved in XP..


Correct the path - you missed a backslash after C:


If java command is working and getting problem with javac. then first check in jdk's bin directory javac.exe file is there or not.
If javac.exe file is exist then set JAVA_HOME as System variable.


Here write set Path="C:\Program Files\Java\jdk1.7.0_09\bin" or set  PATH="C:\Program Files\Java\jdk1.7.0_09\bin" 


Don't write path.


you can also go without set.


I have tried it works well.


Check your environment variables.


In my case I had JAVA_HOME set in the System variables as well as in my User Account variables and the latter was set to a wrong version of Java. I also had the same problem with the Path variable.


After deleting JAVA_HOME from my User Account variables and removing the wrong path from the Path variable it worked correctly.






I just got bit by using .clone() on my 2d boolean array, thinking that this was a deep copy.


How can I perform a deep copy of my boolean[][] array?


Should I loop through it and do a series of System.arraycopy's?


Yes, you should iterate over 2D boolean array in order to deep copy it. Also look at java.util.Arrays#copyOf methods if you are on Java 6.


I would suggest the next code for Java 6:


I'm a fan of the Arrays utility. It has a copyOf method that will do a deep copy of a 1-D array for you, so you'd want something like this:


I've managed to come up with a recursive array deep copy. It seems to work pretty well even for multi dimensional arrays with varying dimension lengths e.g.


Here is the utility method.


EDIT: Updated the code to work with primitive arrays.


Yes, that's the only way to do it. Neither java.util.Arrays not commons-lang offer deep copy for arrays.


In Java 8 this can be accomplished as a one-liner using lambdas:






I saw the line below in code for a DOM parser at this tutorial.


Why do we do this normalization ?
I read the docs but I could not understand a word.


Puts all Text nodes in the full depth of the sub-tree underneath this Node


Okay, then can someone show me (preferably with a picture) what this tree looks like ?


Can anyone explain me why normalization is needed?
What happens if we don't normalize ?


The rest of the sentence is:


where only structure (e.g., elements, comments, processing instructions, CDATA sections, and entity references) separates Text nodes, i.e., there are neither adjacent Text nodes nor empty Text nodes.


This basically means that the following XML element


could be represented like this in a denormalized node:


When normalized, the node will look like this


And the same goes for attributes: <foo bar="Hello world"/>, comments, etc.


As an extension to @JBNizet's answer for more technical users here's what implementation of org.w3c.dom.Node interface in com.sun.org.apache.xerces.internal.dom.ParentNode looks like, gives you the idea how it actually works. 


It traverses all the nodes recursively and calls kid.normalize()
This mechanism is overridden in org.apache.xerces.dom.ElementImpl 


Hope this saves you some time.


In simple, Normalisation is Reduction of Redundancies. 
Examples of Redundancies:
a) white spaces outside of the root/document tags(...<document></document>...)
b) white spaces within start tag (<...>) and end tag (</...>)
c) white spaces between attributes and their values (ie. spaces between key name and =") 
d) superfluous namespace declarations
e) line breaks/white spaces in texts of attributes and tags
f) comments etc...






I need to trigger a block of code after 20 minutes from the AlarmManager being set.


Can someone show me sample code on how to use an AlarmManager in ِAndroid?


I have been playing around with some code for a few days and it just won't work.


"Some sample code" is not that easy when it comes to AlarmManager.


Here is a snippet showing the setup of AlarmManager:


In this example, I am using setRepeating(). If you want a one-shot alarm, you would just use set(). Be sure to give the time for the alarm to start in the same time base as you use in the initial parameter to set(). In my example above, I am using AlarmManager.ELAPSED_REALTIME_WAKEUP, so my time base is SystemClock.elapsedRealtime().


Here is a larger sample project showing this technique.


There are some good examples in the android sample code


.\android-sdk\samples\android-10\ApiDemos\src\com\example\android\apis\app


The ones to check out are:


First of, you need a receiver, something that can listen to your alarm when it is triggered. Add the following to your AndroidManifest.xml file


Then, create the following class


Then, to trigger an alarm, use the following (for instance in your main activity):


. 


Or, better yet, make a class that handles it all and use it like this


this way, you have it all in one place (don't forget to edit the AndroidManifest.xml)


What you need to do is first create the intent you need to schedule. Then obtain the pendingIntent of that intent. You can schedule activities, services and broadcasts. To schedule an activity e.g MyActivity:


Give this pendingIntent to alarmManager:


Now MyActivity will be launched after 5 seconds of the application launch, no matter you stop your application or device went in sleep state (due to RTC_WAKEUP option).
You can read complete example code Scheduling activities, services and broadcasts #Android


I wanted to comment but <50 rep, so here goes. Friendly reminder that if you're running on 5.1 or above and you use an interval of less than a minute, this happens:


See here.


Some sample code when you want to call a service from the Alarmmanager:


You dont have to ask userpermissions.






I was using readLine of BufferedReader to get input/new password from user, but wanted to mask the password so I am trying to use java.io.Console class. Problem is that System.console() returns null when an application is debugged in Eclipse. I am new to Java and Eclipse not sure is this the best way to achieve? I am right clicking on the source file and selecting "Debug As" > "Java Application". Is there any workaround?


This is a bug #122429 of eclipse


This code snippet should do the trick:


While testing in Eclipse, your password input will be shown in clear. At least, you will be able to test. Just don't type in your real password while testing. Keep that for production use ;).


System.console() returns null if there is no console.


You can work round this either by adding a layer of indirection to your code or by running the code in an external console and attaching a remote debugger.


I also ran into this problem when trying to write a simple command line application.  


Another alternative to creating your own BufferedReader object from System.in is to use java.util.Scanner like this:


Of course this will not be a drop-in replacement to Console, but will give you access to a variety of different input functions.


Here's more documentation on Scanner from Oracle.


According to the docs:


If the virtual machine is started automatically, for example by a background job scheduler, then it will typically not have a console.


According to the API:


"If the virtual machine is started from an interactive command line without redirecting the standard input and output streams then its console will exist and will typically be connected to the keyboard and display from which the virtual machine was launched. If the virtual machine is started automatically, for example by a background job scheduler, then it will typically not have a console."


I believe that in the run configurations for Eclipse, you can configure whether to assign a console or not - ensure this is checked.  (It's been a while since I used Eclipse so I can't give specific instructions I'm afraid).


If that doesn't work, then something that will definitely do this job is starting your application in debug mode, then connect to the process with Eclipse.  Search for "eclipse remote debugging" if you're not sure how to do this.


Furthermore, in general it is a bad idea to require a console to be assigned as this very much impacts the flexibility of your application - as you've just discovered.  Many ways of invoking Java will not assign a console, and your application is unusable in these instances (which is bad).  Perhaps you could alternatively allow arguments to be specified on the command line.  (If you're testing the console input specifically then fair enough, but it would potentially be useful for people to be able to invoke your application from scripts and/or on headless servers, so this sort of flexible design is almost always a good idea.  It often leads to better-organised code, too.)


That is right.


You will have to run the application outside of Eclipse.  Look at the launcher configuration panels within Eclipse and see if you can spot the option that says to run the command in a separate JVM.


add -console in your program arguments to start OSGi console






Is it possible to call a constructor from another (within the same class, not from a subclass)? If yes how? And what could be the best way to call another constructor (if there are several ways to do it)?


Yes, it is possible:


To chain to a particular superclass constructor instead of one in the same class, use super instead of this. Note that you can only chain to one constructor, and it has to be the first statement in your constructor body.


See also this related question, which is about C# but where the same principles apply.


Using this(args). The preferred pattern is to work from the smallest constructor to the largest.


You can also use a more recently advocated approach of valueOf or just "of":


To call a super class, use super(asdf). The call to super must be the first call in the constructor or you will get a compiler error.


[Note: I just want to add one aspect, which I did not see in the other answers: how to overcome limitations of the requirement that this() has to be on the first line).]


In Java another constructor of the same class can be called from a constructor via this(). Note however that this has to be on the first line.


That this has to appear on the first line looks like a big limitation, but you can construct the arguments of other constructors via static methods. For example:


When I need to call another constructor from inside the code (not on the first line), I usually use a helper method like this:


But most often I try to do it the other way around by calling the more complex constructors from the simpler ones on the first line, to the extent possible. For the above example


Within a constructor, you can use the this keyword to invoke another constructor in the same class. Doing so is called an explicit constructor invocation. 


Here's another Rectangle class, with a different implementation from the one in the Objects section.


This class contains a set of constructors. Each constructor initializes some or all of the rectangle's member variables.


As everybody already have said, you use this(…), which is called an explicit constructor invocation.


However, keep in mind that within such an explicit constructor invocation statement you may not refer to


As stated in JLS (§8.8.7.1).


You can a constructor from another constructor of same class by using "this" keyword.
Example -


Output -
string as arg constructor..
Default constructor..
int as arg constructor..


I tel you an easy way


There are two types of constructors:


I will explain in one Example


In the above example I showed 3 types of calling


Note:
this must be first statement in constructor.


Yes it is possible to call on constructor from another. But there is a rule to it. If a call is made from one constructor to another, then 


that new constructor call must be the first statement in the current constructor


So something like below will not work.


Calling constructor from another constructor


Also you can call parent constructor by using super() call


The keyword this can be used to call a constructor from a constructor, when writing several constructor for a class, there are times when you'd like to call one constructor from another to avoid duplicate code.


Bellow is a link that I explain other topic about constructor and getters() and setters() and I used a class with two constructors. I hope the explanations and examples help you.


Setter methods or constructors


Yes it is possible to call one constructor from another with use of this()


Yes, any number of constructors can be present in a class and they can be called by another constructor using this()[Please do not confuse this() constructor call with this keyword].
this() or this(args) should be the first line in the constructor.  


This is known as constructor overloading.
Please note that for constructor only overloading concept is applicable and not inheritance or overriding.


Another way of chaining is using constructor delegation (since C++11): 






Being somewhat new to the Java language I'm trying to familiarize myself with all the ways (or at least the non-pathological ones) that one might iterate through a list (or perhaps other collections) and the advantages or disadvantages of each. 


Given a List<E> list object, I know of the following ways to loop through all elements:


Note: As @amarseillan pointed out, this form is a poor choice
for iterating over Lists because the actual implementation of
the get method may not be as efficient as when using an Iterator.
For example, LinkedList implementations must traverse all of
the elements preceding i to get the i-th element.
In the above example there's no way for the List implementation to
"save its place" to make future iterations more efficient. 
For an ArrayList it doesn't really matter because the complexity/cost of get is constant time (O(1)) whereas for a LinkedList is it proportional to the size of the list (O(n)). 
For more information about the computational complexity of the built-in Collections implementations, check out this question.


EDIT: Added ListIterator


EDIT: Added "functional-style" solution (thanks Dave Newton)


EDIT: Added map method from Java 8's Stream API (see @i_am_zero's answer)


In Java 8 collection classes that implement Iterable (for example all Lists) now have a forEach method, which can be used instead of the for loop statement demonstrated above. (Here is another question that provides a good comparison.)


What other ways are there, if any?


I feel like this has got to be a duplicate, but I haven't been able to find what I'm looking for, so I apologize for this question potentially being redundant.
(BTW, my interest does not stem at all from a desire to optimize performance; I just want to know what forms are available to me as a developer.)


EDIT: Moved ListIterationExample.java to a suggested answer


The three forms of looping are nearly identical. The enhanced for loop:


is, according to the Java Language Specification, identical in effect to the explicit use of an iterator with a traditional for loop. In the third case, you can only modify the list contents by removing the current element, and then only if you do it through the remove method of the iterator itself. With index-based iteration, you are free to modify the list in any way. However, adding or removing elements that come before the current index risks having your loop skipping elements or processing the same element multiple times; you need to adjust the loop index properly when you make such changes.


In all cases, element is a reference to the actual list element. None of the iteration methods makes a copy of anything in the list. Changes to the internal state of element will always be seen in the internal state of the corresponding element on the list.


Essentially, there only two ways to iterate over a list: by using an index or by using an iterator. The enhanced for loop is just a syntactic shortcut introduced in Java 5 to avoid the tedium of explicitly defining an iterator. For both styles, you can come up with essentially trivial variations using for, while or do while blocks, but they all boil down to the same thing (or, rather, two things).


EDIT: As @iX3 points out in a comment, you can use a ListIterator to set the current element of a list as you are iterating. You would need to use List#listIterator() instead of List#iterator() to initialize the loop variable (which, obviously, would have to be declared a ListIterator rather than an Iterator).


Example of each kind listed in the question:


The basic loop is not recommended as you do not know the implementation of the list.


If that was a LinkedList, each call to 


would be iterating over the list, resulting in N^2 time complexity.


A JDK8-style iteration:


I don't know what you consider pathological, but let me provide some alternatives you could have not seen before:


Or its recursive version:


Also, a recursive version of the classical for(int i=0... :


I mention them because you are "somewhat new to Java" and this could be interesting.


In Java 8 collection classes that implement Iterable (for example all lists) now have forEach method:


The above example makes use of method-reference introduced in Java 8. We can also iterate over a list using Stream as:


The advantage with later option is that we can also make use of parallel streams wherever appropriate. If the objective is only to print the items irrespective of the order then we can use parallel stream as:


For a backward search you should use the following:


If you want to know a position, use iterator.previousIndex(). It also helps to write an inner loop that compares two positions in the list (iterators are not equal).


Right, many alternatives listed, the easiest and cleanest would be just using the enhanced for statement as below, the Expression is of some type that is iterable. 


For example, to iterate through, List ids, we can simply so, 


You could always switch out the first and third examples with a while loop and a little more code. This gives you the advantage of being able to use the do-while:


Of course, this kind of thing might cause a NullPointerException if the list.size() returns 0, becuase it always gets executed at least once. This can be fixed by testing if element is null before using its attributes / methods tho. Still, it's a lot simpler and easier to use the for loop






I know that garbage collection is automated in Java. But I understood that if you write System.gc() in your code the Java VM may or may not decide at runtime to do a garbage collection at that point. How does this work precisely? On what basis/parameters exactly does the VM decide to do (or not do) a GC when it sees a System.gc()? Are there maybe examples in which case it is a good idea to put this in your code?


In practice, it usually decides to do a garbage collection.  The answer varies depending on lots of factors, like which JVM you're running on, which mode it's in, and which garbage collection algorithm it's using.  


I wouldn't depend on it in your code.  If the JVM is about to throw an OutOfMemoryError, calling System.gc() won't stop it, because the garbage collector will attempt to free as much as it can before it goes to that extreme.  The only time I've seen it used in practice is in IDEs where it's attached to a button that a user can click, but even there it's not terribly useful.


The only example I can think of where it makes sense to call System.gc() is when profiling an application to search for possible memory leaks. I believe the profilers call this method just before taking a memory snapshot.


You have no control over GC in java -- the VM decides.  I've never run across a case where System.gc() is needed.  Since a System.gc() call simply SUGGESTS that the VM do a garbage collection and it also does a FULL garbage collection (old and new generations in a multi-generational heap), then it can actually cause MORE cpu cycles to be consumed than necessary.


In some cases, it may make sense to suggest to the VM that it do a full collection NOW as you may know the application will be sitting idle for the next few minutes before heavy lifting occurs.  For example, right after the initialization of a lot of temporary object during application startup (i.e., I just cached a TON of info, and I know I won't be getting much activity for a minute or so).  Think of an IDE such as eclipse starting up -- it does a lot to initialize, so perhaps immediately after initialization it makes sense to do a full gc at that point.


The Java Language Specification does not guarantee that the JVM will start a GC when you call System.gc(). This is the reason of this "may or may not decide to do a GC at that point".


Now, if you look at OpenJDK source code, which is the backbone of Oracle JVM, you will see that a call to System.gc() does start a GC cycle. If you use another JVM, such as J9, you have to check their documentation to find out the answer. For instance, Azul's JVM has a garbage collector that runs continuously, so a call to System.gc() won't do anything


Some other answer mention starting a GC in JConsole or VisualVM. Basically, these tools make a remote call to System.gc().


Usually, you don't want to start a garbage collection cycle from your code, as it messes up with the semantics of your application. Your application does some business stuff, the JVM takes care of memory management. You should keep those concerns separated (don't make your application do some memory management, focus on business).


However, there are few cases where a call to System.gc() might be understandable. Consider, for example, microbenchmarks. No-one wants to have a GC cycle to happen in the middle of a microbenchmark. So you may trigger a GC cycle between each measurement to make sure every measurement starts with an empty heap.


You need to be very careful if you call System.gc(). Calling it can add unnecessary performance issues to your application, and it is not guaranteed to actually perform a collection. It is actually possible to disable explicit System.gc() via the java argument -XX:+DisableExplicitGC.


I'd highly recommend reading through the documents available at Java HotSpot Garbage Collection for more in depth details about garbage collection.


If you use direct memory buffers, the JVM doesn't run the GC for you even if you are running low on direct memory.


If you call ByteBuffer.allocateDirect() and you get an OutOfMemoryError you can find this call is fine after triggering a GC manually.


System.gc() is implemented by the VM, and what it does is implementation specific. The implementer could simply return and do nothing, for instance. 


As for when to issue a manual collect, the only time when you may want to do this is when you abandon a large collection containing loads of smaller collections--a 
Map<String,<LinkedList>>   for instance--and you want to try and take the perf hit then and there, but for the most part, you shouldn't worry about it. The GC knows better than you--sadly--most of the time.


Most JVMs will kick off a GC (depending on the -XX:DiableExplicitGC and -XX:+ExplicitGCInvokesConcurrent switch). But the specification is just less well defined in order to allow better implementations later on.


The spec needs clarification: Bug #6668279: (spec) System.gc() should indicate that we don't recommend use and don't guarantee behaviour


Internally the gc method is used by RMI and NIO, and they require synchronous execution, which: this is currently in discussion:


Bug #5025281: Allow System.gc() to trigger concurrent (not stop-the-world) full collections


There is a LOT to be said in taking the time to test out the various garbage collection settings, but as was mentioned above it usually not useful to do so.


I am currently working on a project involving a memory-limited environment and a relatively large amounts of data--there are a few large pieces of data that push my environment to its limit, and even though I was able to bring memory usage down so that in theory it should work just fine, I would still get heap space errors---the verbose GC options showed me that it was trying to garbage collect, but to no avail. In the debugger, I could perform System.gc() and sure enough there would be "plenty" of memory available...not a lot of extra, but enough.


Consequently, The only time my application calls System.gc() is when it is about to enter the segment of code where large buffers necessary for processing the data will be allocated, and a test on the free memory available indicates that I'm not guaranteed to have it.  In particular, I'm looking at a 1gb environment where at least 300mb is occupied by static data, with the bulk of the non-static data being execution-related except when the data being processed happens to be at least 100-200 MB at the source.  It's all part of an automatic data conversion process, so the data all exists for relatively short periods of time in the long run.


Unfortunately, while information about the various options for tuning the garbage collector is available, it seems largely an experimental process and the lower level specifics needed to understand how to handle these specific situations are not easily obtained.  


All of that being said, even though I am using System.gc(), I still continued to tune using command line parameters and managed to improve the overall processing time of my application by a relatively significant amount, despite being unable to get over the stumbling block posed by working with the larger blocks of data.   That being said, System.gc() is a tool....a very unreliable tool, and if you are not careful with how you use it, you will wish that it didn't work more often than not.


I can't think of a specific example when it is good to run explicit GC. 


In general, running explicit GC can actually cause more harm than good, because an explicit gc will trigger a full collection, which takes significantly longer as it goes through every object.  If this explicit gc ends up being called repeatedly it could easily lead to a slow application as a lot of time is spent running full GCs.


Alternatively if going over the heap with a heap analyzer and you suspect a library component to be calling explicit GC's you can turn it off adding: gc=-XX:+DisableExplicitGC  to the JVM parameters.


Normally, the VM would do a garbage collection automatically before throwing an OutOfMemoryException, so adding an explicit call shouldn't help except in that it perhaps moves the performance hit to an earlier moment in time.


However, I think I encountered a case where it might be relevant. I'm not sure though, as I have yet to test whether it has any effect:


When you memory-map a file, I believe the map() call throws an IOException when a large enough block of memory is not available. A garbage collection just before the map() file might help prevent that, I think. What do you think?


we can never force garbage collection. System.gc is only suggesting vm for garbage collection, however, really what time the mechanism runs, nobody knows, this is as stated by JSR specifications.


In short:


Parameters is VM dependent.


Example usage- can't think of one for runtime/production apps, but it is useful to run it for some profiling harnesses, like calling 


If you want to know if your System.gc() is called, you can with the new Java 7 update 4 get notification when the JVM performs Garbage Collection.


I am not 100% sure that the GarbageCollectorMXBean class was introduces in Java 7 update 4 though, because I couldn't find it in the release notes, but I found the information in the javaperformancetuning.com site 


Accroding to Thinking in Java by Bruce Eckel, one use case for explicit System.gc() call is when you want to force finalization, i.e. the call to finalize method.


while system.gc works,it will stop the world:all respones are stopped so garbage collector can scan every object to check if it is needed deleted. if the application is a web project, all request are stopped until gc finishes,and this will cause your web project can not work in a monent.


Garbage Collection is good in Java, if we are executing Software coded in java in Desktop/laptop/server. You can call System.gc() or Runtime.getRuntime().gc() in Java.


Just note that none of those calls are guaranteed to do anything. They are just a suggestion for the jvm to run the Garbage Collector. It's up the the JVM whether it runs the GC or not. So, short answer: we don't know when it runs. Longer answer: JVM would run gc if it has time for that.


I believe, the same applies for Android. However, this might slow down your system.






The Jackson data binding documentation indicates that Jackson supports deserialising  "Arrays of all supported types" but I can't figure out the exact syntax for this.


For a single object I would do this:


Now for an array I want to do this:


Anyone know if there is a magic missing command? If not then what is the solution?


First create a mapper :


As Array:


As List:


Another way to specify the List type:


From Eugene Tskhovrebov


This solution seems to be the best for me


For Generic Implementation:


First create an instance of ObjectReader which is thread-safe.


Then use it :






If something is not working properly or some plugins are loaded properly in my Eclipse. I often get suggestion to open Eclipse in clean mode. So, how to run in clean mode? and what happens if I do so?


What it does:


if set to "true", any cached data used
  by the OSGi framework and eclipse
  runtime will be wiped clean. This will
  clean the caches used to store bundle
  dependency resolution and eclipse
  extension registry data. Using this
  option will force eclipse to
  reinitialize these caches.


How to use it:


(From: http://www.eclipsezone.com/eclipse/forums/t61566.html)


Other eclipse command line options: http://help.eclipse.org/indigo/index.jsp?topic=%2Forg.eclipse.platform.doc.isv%2Freference%2Fmisc%2Fruntime-options.html


For clean mode: start the platform like


That's all. The platform will clear some cached OSGi bundle information, it helps or is recommended if you install new plugins manually or remove unused plugins.


It will not affect any workspace related data.


You can start Eclipse in clean mode from the command line:


Using the -clean option is the way to go, as mentioned by the other answers.


Make sure that you remove it from your .ini or shortcut after you've fixed the problem.  It causes Eclipse to reevaluate all of the plugins everytime it starts and can dramatically increase startup time, depending on how many Eclipse plugins you have installed.


it will take much time then normal start and it will fresh up all resources.


For cleaning up in a launch configuration, see this tip:


http://www.eclipsezone.com/eclipse/forums/t83410.html


For Windows users:
You can do as RTA said or through command line do this:
Navigate to the locaiton of the eclipse executable then run:


First check the name of your executable using the command 'dir' on its path


For Mac OS X Yosemite I was able to use the open command.


This worked for me:


Easier option is to
use ./eclipse -clean






How might I convert an ArrayList<String> object to a String[] array in Java?


For example:


The toArray() method without passing any argument returns Object[]. So you have to pass an array as an argument, which will be filled with the data from the list, and returned. You can pass an empty array as well, but you can also pass an array with the desired size.


Important update: Originally the code above used new String[list.size()]. However, this blogpost reveals that due to JVM optimizations, using new String[0] is better now.


An alternative in Java 8:


Using copyOf, ArrayList to arrays might be done also.


You can use the toArray() method for List:


Or you can manually add the elements to an array:


Hope this helps!


In Java 8:


in case some extra manipulation of the data is desired, for which the user wants a function, this approach is not perfect (as it requires passing the class of the element as second parameter), but works:


import java.util.ArrayList;
import java.lang.reflect.Array;


Generics solution to covert any List<Type> to String []:


Note You must override toString() method.


You can use Iterator<String> to iterate the elements of the ArrayList<String>


Code : 


Now you can retrive elements from String[] using any Loop.


By using toArray() method of ArrayList you can get 0bject[].
Cast that Object[] to String[]
Here the sample code:


This is enough:






I have a JTable, that has one column that is text which is not editable and the second column is a check box that displays boolean values.... Now what i want is, when the user selects multiple rows and unchecks any one of the selected check boxes, then all the check boxes under selection should get unchecked and vice versa.


Using @Hovercraft's example and @camickr's advice, the example below shows a suitable user interface. Although it uses buttons, the SelectionAction would also be suitable for a menu or popup.





The problem is that when you click on a check box to change the value of the check box, the selection of all the rows will be lost. So you may need to use a right mouse click to display a popup menu that contains select/deselect values. 


Then you can use table.getSelectedRows(), to get the indexes of all the selected rows you need to update.


You can get the selection interval with code similar to this:


Then, when one checkbox is checked (listen to ItemEvent) you should iterate from the minSelectedRow to the maxSelectedRow and change checked boxes state. That's it.


I agree with Roman that his idea would work if you use a class field to hold the min and max selection.  For instance:






I'm trying to split text in a JTextArea using a regex to split the String by \n However, this does not work and I also tried by \r\n|\r|n and many other combination of regexes.
Code:


This should cover you:


There's only really two newlines (UNIX and Windows) that you need to worry about.


If you don’t want empty lines:


split method is using regex (regular expressions). Since Java 8 regex supports \R which represents (from documentation of Pattern class):


Linebreak matcher
  \R         Any Unicode linebreak sequence, is equivalent to
  \u000D\u000A|[\u000A\u000B\u000C\u000D\u0085\u2028\u2029]


So we can use it to match:


As you see \r\n is placed at start of regex which ensures that regex will try to first match this pair, and only if it fails it will try to match single character line separators.


So if you want to split on line separator use split("\\R"). 


If you don't want to remove from resulting array trailing empty strings "" use split(regex, limit) with negative limit parameter like split("\\R", -1).


If you want to treat one or more continues empty lines as single delimiter use split("\\R+").


This should be system independent


You don't have to double escape characters in character groups.


For all non empty lines use:


Maybe this would work:


Remove the double backslashes from the parameter of the split method:


The above code doesnt actually do anything visible - it just calcualtes then dumps the calculation. Is it the code you used, or just an example for this question? 


try doing textAreaDoc.insertString(int, String, AttributeSet) at the end?


For preserving empty lines from getting squashed use:


All answers given here actually do not respect Javas definition of new lines as given in e.g. BufferedReader#readline. Java is accepting \n, \r and \r\n as new line. Some of the answers match multiple empty lines or malformed files. E..g. <sometext>\n\r\n<someothertext> when using [\r\n]+would result in two lines. 


In contrast, the answer above has the following properties:


String lines[] =String.split( System.lineSeparator())


After failed attempts on the basis of all given solutions. I replace \n with some special word and then split. For me following did the trick:


I couldn't replicate the example given in the question. But, I guess this logic can be applied.


As an alternative to the previous answers, guava's Splitter API can be used if other operations are to be applied to the resulting lines, like trimming lines or filtering empty lines :


Note that the result is an Iterable and not an array.






Sometime I see many application such as msn, windows media player etc that are single instance applications (when user executes while application is running a new application instance will not created).


In C#, I use Mutex class for this but I don't know how to do this in Java.


If I believe this article, by :


having the first instance attempt to open a listening socket on the localhost interface.  If it's able to open the socket, it is assumed that this is the first instance of the application to be launched.  If not, the assumption is that an instance of this application is already running.  The new instance must notify the existing instance that a launch was attempted, then exit.  The existing instance takes over after receiving the notification and fires an event to the listener that handles the action.


Note: Ahe mentions in the comment that using InetAddress.getLocalHost() can be tricky:


it is surprising to have getLocalHost return 127.0.0.1 on Linux but not on windows.


Or you may use ManagementFactory object. As explained here:


The getMonitoredVMs(int processPid) method receives as parameter the current application PID, and catch the application name that is called from command line, for example, the application was started from c:\java\app\test.jar path, then the value variable is "c:\\java\\app\\test.jar". This way, we will catch just application name on the line 17 of the code below.
  After that, we search JVM for another process with the same name, if we found it and the application PID is different, it means that is the second application instance.


JNLP offers also a SingleInstanceListener


I use the following method in the main method.  This is the simplest, most robust, and least intrusive method I have seen so I thought that I'd share it.


If the app. has a GUI, launch it with JWS and use the SingleInstanceService.  See the demo. of the SingleInstanceService for (demo. and) example code.


Yes this is a really decent answer for eclipse RCP eclipse single instance application
below is my code


in application.java


We use file locking for this (grab an exclusive lock on a magic file in the user's app data directory), but we are primarily interested in preventing multiple instances from ever running.


If you are trying to have the second instance pass command line args, etc... to the first instance, then using a socket connection on localhost will be killing two birds with one stone.  General algorithm:


On Windows, you can use launch4j.


I have found a solution, a bit cartoonish explanation, but still works in most cases. It uses the plain old lock file creating stuff, but in a quite different view:


http://javalandscape.blogspot.com/2008/07/single-instance-from-your-application.html


I think it will be a help to those with a strict firewall setting.


You can use JUnique library. It provides support for running single-instance java application and is open-source.


http://www.sauronsoftware.it/projects/junique/


The JUnique library can be used to prevent a user to run at the same
  time more instances of the same Java application.


JUnique implements locks and communication channels shared between all
  the JVM instances launched by the same user.


Under the hood, it creates file locks in %USER_DATA%/.junique folder and creates a server socket at random port for each unique appId that allows sending/receiving messages between java applications.


ManagementFactory class supported in J2SE 5.0 or later detail


but now i use J2SE 1.4 and I found this one http://audiprimadhanty.wordpress.com/2008/06/30/ensuring-one-instance-of-application-running-at-one-time/ but I never test. What do you think about it?


You could try using the Preferences API. It is platform independent.


You can open a Memory Mapped File and then see if that file is OPEN already. if it is already open, you can return from main.


Other ways is to use lock files(standard unix practice). One more way is to put something into the clipboard when main starts after checking if something is already in the clipboard.


Else, you can open a socket in a listen mode(ServerSocket). First try to connect to hte socket ; if you cannot connect, then open a serversocket. if you connect, then you know that another instance is already running.


So, pretty much any system resource can be used for knowing that an app is running.


BR,
~A


I used sockets for that and depending if the application is on the client side or server side the behavior is a bit different:


A more generic way of limiting the number of instance's on a single machine, or even an entire network, is to use a multicast socket. 


Using a  multicast socket, enables you to broadcast a message to any amount of instances of your application, some of which can be on physically remote machines across a corporate network.


In this way you can enable many types of configurations, to control things like


Java's multicast support is via java.net package with MulticastSocket & DatagramSocket being the main tools. 


Note: MulticastSocket's do not guarantee delivery of data packets, so you should use a tool built on top of multicast sockets like JGroups. JGroups does guarantee delivery of all data. It is one single jar file, with a very simple API.


JGroups has been around a while, and has some impressive usages in industry, for example it underpins JBoss's clustering mechanism do broadcast data to all instance of a cluster.


To use JGroups, to limit the number on instances of an app (on a machine or a network) is conceptually very simple : 


EDIT: I would like to know why this was downvoted. It's the best solution I have seen so far. E.g. the server socket approach fails if another application happens to already be listening to the port.


Just download Microsoft Windows Sysinternals TCPView (or use netstat), start it, sort by "State", look for the line block that says "LISTENING", pick one whose remote address says your computer's name, put that port into your new-Socket()-solution. In my implementation of it, I can produce failure every time. And it's logical, because it's the very foundation of the approach. Or what am I not getting regarding how to implement this?


Please inform me if and how I am wrong about this!


My view - which I am asking you to disprove if possible - is that developers are being advised to use an approach in production code that will fail in at least 1 of about 60000 cases. And if this view happens to be correct, then it can absolutely not be that a solution presented that does not have this problem is downvoted and criticized for its amount of code.


Disadvantages of the socket approach in comparison:


I just had a nice idea for how to solve the new-instance-to-existing-instance Java communication problem in a way that should work on every system. So, I whipped up this class in about two hours. Works like a charm :D


It's based on Robert's file lock approach (also on this page), which I have used ever since. To tell the already running instance that another instance tried to start (but didn't) ... a file is created and immediately deleted, and the first instance uses the WatchService to detect this folder content change. I can't believe that apparently this is a new idea, given how fundamental the problem is.


This can easily be changed to just create and not delete the file, and then information can be put into it that the proper instance can evaluate, e.g. the command line arguments - and the proper instance can then perform the deletion. Personally, I only needed to know when to restore my application's window and send it to front.


Example use:


Here's the class:






Why isn't Collection.remove(Object o) generic?  


Seems like Collection<E> could have boolean remove(E o); 


Then, when you accidentally try to remove (for example) Set<String> instead of each individual String from a Collection<String>, it would be a compile time error instead of a debugging problem later.


Josh Bloch and Bill Pugh refer to this issue in Java Puzzlers IV: The 
Phantom Reference Menace, Attack of the Clone, and Revenge of The 
Shift.


Josh Bloch says (6:41) that they attempted to generify the get method 
of Map, remove method and some other, but "it simply didn't work".


There are too many reasonable programs that could not be generified if 
you only allow the generic type of the collection as parameter type. 
The example given by him is an intersection of a List of Numbers and a 
List of Longs.


remove() (in Map as well as in Collection) is not generic because you should be able to pass in any type of object to remove(). The object removed does not have to be the same type as the object that you pass in to remove(); it only requires that they be equal. From the specification of remove(), remove(o) removes the object e such that (o==null ? e==null : o.equals(e)) is true. Note that there is nothing requiring o and e to be the same type. This follows from the fact that the equals() method takes in an Object as parameter, not just the same type as the object.


Although it may be commonly true that many classes have equals() defined so that its objects can only be equal to objects of its own class, that is certainly not always the case. For example, the specification for List.equals() says that two List objects are equal if they are both Lists and have the same contents, even if they are different implementations of List. So coming back to the example in this question, it is possible to have a Map<ArrayList, Something> and for me to call remove() with a LinkedList as argument, and it should remove the key which is a list with the same contents. This would not be possible if remove() were generic and restricted its argument type.


Because if your type parameter is a wildcard, you can't use a generic remove method.


I seem to recall running into this question with Map's get(Object) method.  The get method in this case isn't generic, though it should reasonably expect to be passed an object of the same type as the first type parameter.  I realized that if you're passing around Maps with a wildcard as the first type parameter, then there's no way to get an element out of the Map with that method, if that argument was generic.  Wildcard arguments can't really be satisfied, because the compiler can't guarantee that the type is correct.  I speculate that the reason add is generic is that you're expected to guarantee that the type is correct before adding it to the collection.  However, when removing an object, if the type is incorrect then it won't match anything anyway.  If the argument were a wildcard the method would simply be unusable, even though you may have an object which you can GUARANTEE belongs to that collection, because you just got a reference to it in the previous line....


I probably didn't explain it very well, but it seems logical enough to me.


In addition to the other answers, there is another reason why the method should accept an Object, which is predicates. Consider the following sample:


The point is that the object being passed to the remove method is responsible for defining the equals method. Building predicates becomes very simple this way.


Assume one has a collection of Cat, and some object references of types Animal, Cat, SiameseCat, and Dog.  Asking the collection whether it contains the object referred to by the Cat or SiameseCat reference seems reasonable.  Asking whether it contains the object referred to by the Animal reference may seem dodgy, but it's still perfectly reasonable.  The object in question might, after all, be a Cat, and might appear in the collection.


Further, even if the object happens to be something other than a Cat, there's no problem saying whether it appears in the collection--simply answer "no, it doesn't".  A "lookup-style" collection of some type should be able to meaningfully accept reference of any supertype and determine whether the object exists within the collection.  If the passed-in object reference is of an unrelated type, there's no way the collection could possibly contain it, so the query is in some sense not meaningful (it will always answer "no").  Nonetheless, since there isn't any way to restrict parameters to being subtypes or supertypes, it's most practical to simply accept any type and answer "no" for any objects whose type is unrelated to that of the collection.


I always figured this was because remove() has no reason to care what type of object you give it. It's easy enough, regardless, to check if that object is one of the ones the Collection contains, since it can call equals() on anything. It's necessary to check type on add() to ensure that it only contains objects of that type.


Remove is not a generic method so that existing code using a non-generic collection will still compile and still have the same behavior.


See http://www.ibm.com/developerworks/java/library/j-jtp01255.html for details.


Edit: A commenter asks why the add method is generic.  [...removed my explanation...]  Second commenter answered the question from firebird84 much better than me.


Another reason is because of interfaces. Here is an example to show it :


Because it would break existing (pre-Java5) code. e.g.,


Now you might say the above code is wrong, but suppose that o came from a heterogeneous set of objects (i.e., it contained strings, number, objects, etc.). You want to remove all the matches, which was legal because remove would just ignore the non-strings because they were non-equal. But if you make it remove(String o), that no longer works. 






How do I format a number in Java?
What are the "Best Practices"?


Will I need to round a number before I format it?


32.302342342342343 => 32.30


.7323 => 0.73


etc.


From this thread, there are different ways to do this:


The DecimalFormat() seems to be the most dynamic way to do it, and it is also very easy to understand when reading others code.


You and String.format() will be new best friends!


http://java.sun.com/j2se/1.5.0/docs/api/java/util/Formatter.html#syntax


Be aware that classes that descend from NumberFormat (and most other Format descendants) are not synchronized. It is a common (but dangerous) practice to create format objects and store them in static variables in a util class. In practice, it will pretty much always work until it starts experiencing significant load.


Round numbers, yes. This is the main example source.   


Try this:


Simple and efficient.


Use DecimalFormat.


There are two approaches in the standard library. One is to use java.text.DecimalFormat. The other more cryptic methods (String.format, PrintStream.printf, etc) based around java.util.Formatter should keep C programmers happy(ish).


As Robert has pointed out in his answer: DecimalFormat is neither synchronized nor does the API guarantee thread safety (it might depend on the JVM version/vendor you are using). 


Use Spring's Numberformatter instead, which is thread safe.


For instance, if the double value passed into the formatDouble() method is 345.9372, the following will 
be the result:
345.937
Similarly, if the value .7697 is passed to the method, the following will be the result:
.770






What's the difference between:


and


and


When are each one more appropriate to use than the others?


The file that I want to read is in the classpath as my class that reads the file.  My class and the file are in the same jar and packaged up in an EAR file, and deployed in WebSphere 6.1.


There are subtle differences as to how the fileName you are passing is interpreted. Basically, you have 2 different methods: ClassLoader.getResourceAsStream() and Class.getResourceAsStream(). These two methods will locate the resource differently.


In Class.getResourceAsStream(path), the path is interpreted as a path local to the package of the class you are calling it from. For example calling, String.getResourceAsStream("myfile.txt") will look for a file in your classpath at the following location: "java/lang/myfile.txt". If your path starts with a /, then it will be considered an absolute path, and will start searching from the root of the classpath. So calling String.getResourceAsStream("/myfile.txt") will look at the following location in your class path ./myfile.txt.


ClassLoader.getResourceAsStream(path) will consider all paths to be absolute paths. So calling String.getClassLoader().getResourceAsStream("myfile.txt") and String.getClassLoader().getResourceAsStream("/myfile.txt") will both look for a file in your classpath at the following location: ./myfile.txt.


Everytime I mention a location in this post, it could be a location in your filesystem itself, or inside the corresponding jar file, depending on the Class and/or ClassLoader you are loading the resource from.


In your case, you are loading the class from an Application Server, so your should use Thread.currentThread().getContextClassLoader().getResourceAsStream(fileName) instead of this.getClass().getClassLoader().getResourceAsStream(fileName). this.getClass().getResourceAsStream() will also work.


Read this article for more detailed information about that particular problem.


One of the answers to this question states that my explanation seems to be incorrect for Tomcat 7. I've tried to look around to see why that would be the case.


So I've looked at the source code of Tomcat's WebAppClassLoader for several versions of Tomcat. The implementation of findResource(String name) (which is utimately responsible for producing the URL to the requested resource) is virtually identical in Tomcat 6 and Tomcat 7, but is different in Tomcat 8.


In versions 6 and 7, the implementation does not attempt to normalize the resource name. This means that in these versions, classLoader.getResourceAsStream("/resource.txt") may not produce the same result as classLoader.getResourceAsStream("resource.txt") event though it should (since that what the Javadoc specifies). [source code]


In version 8 though, the resource name is normalized to guarantee that the absolute version of the resource name is the one that is used. Therefore, in Tomcat 8, the two calls described above should always return the same result. [source code]


As a result, you have to be extra careful when using ClassLoader.getResourceAsStream() or Class.getResourceAsStream() on Tomcat versions earlier than 8. And you must also keep in mind that class.getResourceAsStream("/resource.txt") actually calls classLoader.getResourceAsStream("resource.txt") (the leading / is stripped).


Use MyClass.class.getClassLoader().getResourceAsStream(path) to load resource associated with your code. Use MyClass.class.getResourceAsStream(path) as a shortcut, and for resources packaged within your class' package.


Use Thread.currentThread().getContextClassLoader().getResourceAsStream(path) to get resources that are part of client code, not tightly bounds to the calling code. You should be careful with this as the thread context class loader could be pointing at anything.


Plain old Java on plain old Java 7 and no other dependencies demonstrates the difference...


I put file.txt in c:\temp\ and I put c:\temp\ on the classpath.


There is only one case where there is a difference between the two call.


All these answers around here, as well as the answers in this question, suggest that loading absolute URLs, like "/foo/bar.properties" treated the same by class.getResourceAsStream(String) and class.getClassLoader().getResourceAsStream(String). This is NOT the case, at least not in my Tomcat configuration/version (currently 7.0.40).


Sorry, I have absolutely no satisfying explanation, but I guess that tomcat does dirty tricks and his black magic with the classloaders and cause the difference. I always used class.getResourceAsStream(String) in the past and haven't had any problems.


PS: I also posted this over here


It Works , try out this : 






This question already has an answer here:


I'm trying to parse a JSON string like this one


into a list of objects.


Here's an object class I'm using.


But it throws me with


Any ideas how should I fix it?


The problem is you're telling Gson you have an object of your type. You don't. You have an array of objects of your type. You can't just try and cast the result like that and expect it to magically work ;)


The User guide for Gson Explains how to deal with this:


https://github.com/google/gson/blob/master/UserGuide.md


This will work:


But this is better:


The problem is that you are asking for an object of type channelSearchEnum but what you actually have is an object of type List<channelSearchEnum>. 


You can achieve this with:


In my case JSON string:


and I print "category" and "url_title" in recycleview


Datum.class


RequestInterface


/**
 * Created by Shweta.Chauhan on 13/07/16.
 */


}


DataAdapter


/**
 * Created by Shweta.Chauhan on 13/07/16.
 */


and finally MainActivity.java


Alternative could be


to make your response look like


myCustom_JSONResponse


instead of 


server_JSONResponse


CODE


After this it will be just any other GSON Parsing


according to GSON User guide, you cannot.


Collections Limitations


Can serialize collection of arbitrary objects but can not deserialize from it. Because there is no way for the user to indicate the type of the resulting object






I constructed a class with one String field. Then I created two objects and I have to compare them using == operator and .equals() too. Here's what I've done:


After compile it shows two times false as a result. Why is it false if the two objects have the same fields - "test"?


== compares object references, it checks to see if the two operands point to the same object (not equivalent objects, the same object).


If you want to compare strings (to see if they contain the same characters), you need to compare the strings using equals.


In your case, if two instances of MyClass really are considered equal if the strings match, then:


...but usually if you are defining a class, there's more to equivalency than the equivalency of a single field (a in this case).


Side note: If you override equals, you almost always need to override hashCode. As it says in the equals JavaDoc:


Note that it is generally necessary to override the hashCode method whenever this method is overridden, so as to maintain the general contract for the hashCode method, which states that equal objects must have equal hash codes.


you should override equals 


It looks like equals2 is just calling equals, so it will give the same results.


Your equals2() method always will return the same as equals() !!


Your code with my comments:


The overwrite function equals() is wrong.
The object "a" is an instance of the String class and "object2" is an instance of the MyClass class. They are different classes, so the answer is "false".


The best way to compare 2 objects is by converting them into json strings and compare the strings, its the easiest solution when dealing with complicated nested objects, fields and/or objects that contain arrays.


sample:


Statements a == object2 and  a.equals(object2) both will always return false because a is a string while object2 is an instance of MyClass


the return type of object.equals is already boolean.
there's no need to wrap it in a method with branches. so if you want to compare 2 objects simply compare them:


b is already either true or false.


When we use == , the Reference of object is compared not the actual objects. We need to override equals method to compare Java Objects. 


Some additional information C++ has operator over loading & Java does not provide operator over loading.
Also other possibilities in java are implement Compare Interface .which defines a compareTo method. 


Comparator interface is also used compare two objects


Your implementation must like:


With this implementation your both methods would work.


Your class might implement the Comparable interface to achieve the same functionality. Your class should implement the compareTo() method declared in the interface.


The "==" operator returns true only if the two references pointing to the same object in memory. The equals() method on the other hand returns true based on the contents of the object.


Example:


Output:
Comparing two strings with == operator: false
Comparing two Strings with same content using equals method: true
Comparing two references pointing to same String with == operator: true


You can also get more details from the link: http://javarevisited.blogspot.in/2012/12/difference-between-equals-method-and-equality-operator-java.html?m=1


Here the output will be false , false beacuse in first sopln statement you are trying to compare a string type varible of Myclass type to the other MyClass type and it will allow because of both are Object type and you have used "==" oprerator which will check the reference variable value holding the actual memory not the actual contnets inside the memory . 
In the second sopln also it is the same as you are again calling a.equals(object2) where a is a varible inside object1 . Do let me know your findings on this .


IN the below code you are calling the overriden method .equals().


public boolean equals2(Object object2) {
    if(a.equals(object2)) { // here you are calling the overriden method, that is why you getting false 2 times.
        return true;
    }
    else return false;
}






Does any one know how do I get the current open windows or process of a local machine using Java?  


What I'm trying to do is: list the current open task, windows or process open, like in  Windows Taskmanager, but using a multi-platform approach - using only Java if it's possible.


This is another approach to parse the the process list from the command "ps -e":


If you are using Windows, then you should change the line: "Process p = Runtime.getRun..." etc... (3rd line), for one that looks like this:


Hope the info helps!


On Windows there is an alternative using JNA:


The only way I can think of doing it is by invoking a command line application that does the job for you and then screenscraping the output (like Linux's ps and Window's tasklist). 


Unfortunately, that'll mean you'll have to write some parsing routines to read the data from both.


YAJSW (Yet Another Java Service Wrapper) looks like it has JNA-based implementations of its org.rzo.yajsw.os.TaskList interface for win32, linux, bsd and solaris and is under an LGPL license.  I haven't tried calling this code directly, but YAJSW works really well when I've used it in the past, so you shouldn't have too many worries.


You can easily retrieve the list of running processes using jProcesses


There is no platform-neutral way of doing this. In the 1.6 release of Java, a "Desktop" class was added the allows portable ways of browsing, editing, mailing, opening, and printing URI's. It is possible this class may someday be extended to support processes, but I doubt it.


If you are only curious in Java processes, you can use the java.lang.management api for getting thread/memory information on the JVM.


Using code to parse ps aux for linux and tasklist for windows are your best options, until something more general comes along.


For windows, you can reference: http://www.rgagnon.com/javadetails/java-0593.html


Linux can pipe the results of ps aux through grep too, which would make processing/searching quick and easy. I'm sure you can find something similar for windows too.


For windows I use following:


Finally, with Java 9 it is possible with ProcessHandle:


Edit: "will be" → "is"


TASKLIST /v /FI "STATUS eq running" /FO "CSV" /FI "Username eq LHPL002\soft"  /FI "MEMUSAGE gt 10000"  /FI "Windowtitle ne N/A" /NH






I am trying to launch Mozilla but still I am getting this error:


Exception in thread "main" java.lang.IllegalStateException: The path to the driver executable must be set by the webdriver.gecko.driver system property; for more information, see https://github.com/mozilla/geckodriver. The latest version can be downloaded from https://github.com/mozilla/geckodriver/releases


I am using Selenium 3.0.01 Beta version and Mozilla 45. I have tried with Mozilla 47 too. but still the same thing.


The Selenium client bindings will try to locate the geckodriver executable from the system PATH. You will need to add the directory containing the executable to the system path.


On Unix systems you can do the following to append it to your system’s search path, if you’re using a bash-compatible shell:


On Windows you need to update the Path system variable to add the full directory path to the executable. The principle is the same as on Unix.


All below configuration for launching latest firefox using any programming language binding is applicable for Selenium2 to enable Marionette explicitly. With Selenium 3.0 and later, you shouldn't need to do anything to use Marionette, as it's enabled by default.


To use Marionette in your tests you will need to update your desired capabilities to use it.


Java :


As exception is clearly saying you need to download latest geckodriver.exe from here and set downloaded geckodriver.exe path where it's exists in your computer as system property with with variable webdriver.gecko.driver before initiating marionette driver and launching firefox as below :-


And for Selenium3 use as :- 


If you're still in trouble follow this link as well which would help you to solving your problem


.NET :


Python :


Ruby :


JavaScript (Node.js) :


Using RemoteWebDriver


If you want to use RemoteWebDriver in any language, this will allow you to use Marionette in Selenium Grid.


Python:


Ruby :


Java :


.NET


Note : Just like the other drivers available to Selenium from other browser vendors, Mozilla has released now an executable that will run alongside the browser. Follow this for more details.


You can download latest geckodriver executable to support latest firefox from here


.


Selenium WebDriver Java code:


Download Gecko Driver from  https://github.com/mozilla/geckodriver/releases based on your platform. Extract it in a location by your choice. Write the following code:






Can an abstract class have a constructor?


If so, how can it be used and for what purposes?


Yes, an abstract class can have a constructor. Consider this:


The superclass Product is abstract and has a constructor. The concrete class TimesTwo has a constructor that just hardcodes the value 2. The concrete class TimesWhat has a constructor that allows the caller to specify the value.


Abstract constructors will frequently be used to enforce class constraints or invariants such as the minimum fields required to setup the class.


NOTE: As there is no default (or no-arg) constructor in the parent
  abstract class, the constructor used in subclass must explicitly call
  the parent constructor.


You would define a constructor in an abstract class if you are in one of these situations:


Note that:


In any case, don't forget that if you don't define a constructor, then the compiler will automatically generate one for you (this one is public, has no argument, and does nothing).


Yes it can have a constructor and it is defined and behaves just like any other class's constructor.  Except that abstract classes can't be directly instantiated, only extended, so the use is therefore always from a subclass's constructor.


Yes! Abstract classes can have constructors!


Yes when we define a class to be an Abstract Class it cannot be instantiated but that does not mean an Abstract class cannot have a constructor. Each abstract class must have a concrete subclass which will implement the abstract methods of that abstract class.


When we create an object of any subclass all the constructors in the corresponding inheritance tree are invoked in top to bottom approach. Same case applies to abstract classes. Though we cannot create an object of abstract class, when we create an object of a class which is concrete and subclass of the abstract class, constructor of the abstract class is automatically invoked.Hence we can have a constructor in abstract classes.


Note :  A non-abstract class cannot have an abstract methods but an abstract class can have a non-abstract method. Reason is similar to that of constructors, difference being instead of getting invoked automatically we can call super(). Also there is nothing like abstract constructor as it makes no sense at all.


Not only can it, it always does. If you do not specify one then it has a default no arg constructor, just like any other class. In fact, ALL classes, including nested and anonymous classes, will get a default constructor if one is not specified (in the case of anonymous classes it is impossible to specify one, so you will always get the default constructor).


A good example of an abstract class having a constructor is the Calendar class. You get a Calendar object by calling Calendar.getInstance(), but it also has constructors which are protected. The reason its constructors are protected is so that only its subclasses can call them (or classes in the same package, but since it's abstract, that doesn't apply). GregorianCalendar is an example of a class that extends Calendar.


Yes it can, abstract classes constructors are generally used for super calls for initialization events common to all the subclasses


An abstract class can have a constructor BUT you can not create an object of abstract class so how do you use that constructor?


Thing is, when you inherit that abstract class in your subclass you can pass values to its(abstract's) constructor through super(value) method in your subclass and no you don't inherit a constructor. 


so using super you can pass values in constructor of abstract class and as far as i remember it has to be the first statement in your method or constructor. 


Consider this:


The superclass is abstract and has a constructor.


In a concrete class, declaration of a constructor for a concrete type Fnord effectively exposes two things:


A means by which code can request the creation of an instance of Fnord


A means by which an instance of a type derived from Fnord which is under construction can request that all base-class features be initialized.


While there should perhaps be a means by which these two abilities could be controlled separately, for every concrete type one definition will enable both.  Although the first ability is not meaningful for an abstract class, the second ability is just as meaningful for an abstract class as it would be for any other, and thus its declaration is just as necessary and useful.


Of Course, abstract class can have a constructor.Generally class constructor is used to initialise fields.So, an abstract class constructor is used to initialise fields of the abstract class. You would provide a constructor for an abstract class if you want to initialise certain fields of the abstract class before the instantiation of a child-class takes place. An abstract class constructor can also be used to execute code that is relevant for every child class. This prevents code duplication.


We cannot create an instance of an abstract class,But we can create instances of classes those are derived from the abstract class. So, when an instance of derived class is created, the parent abstract class constructor is automatically called.


Reference :This Article


As described by javafuns here, this is an example:


Yes, Abstract Classes can have constructors ! 


Here is an example using constructor in abstract class:


So I think you got the answer.


Abstract class can have a constructor though it cannot be instantiated. But the constructor defined in an abstract class can be used for instantiation of concrete class of this abstract class. Check JLS:


It is a compile-time error if an attempt is made to create an instance of an abstract class using a class instance creation
  expression.


A subclass of an abstract class that is not itself abstract may be
  instantiated, resulting in the execution of a constructor for the
  abstract class and, therefore, the execution of the field initializers
  for instance variables of that class.


inorder to achieve constructor chaining the abstract class will have constructor.
The compiler keeps Super() statement inside the subclass constructer, which will call the superclass constructor.If there were no constructors for abstract classes then java rules are violated and we can't achieve constructor chaining.


Yes surely you can add one, as already mentioned for initialization of Abstract class variables.
BUT if you dont explicitly declare one, it anyways has an implicit constructor for "Constructor Chaining" to work. 


Yes an Abstract Class can have a Constructor.You Can Overload as many Constructor as you want in an Abstract Class.These Contructor's Can be used to Initialized the initial state of the Objects Extending the Abstract Class. As we know we can't make an object of an Abstract Class because Objects are Created by the "new" keywords and not by the constructors...they are there for only initializing the state of the subclass Objects..


Although there are many good answers, I would like to give my 2 cents.


Constructor DOES NOT BUILD THE OBJECT. It is used to initialize object.


Yes, an Abstract class always has a constructor. If you do not define your own constructor, compiler will give a default constructor to the Abstract class.
Above holds true for all classes - nested, abstract, anonymous, etc. 


An abstract class (unlike interface) can have non final non static fields which needs initialization. You can write your own constructor in abstract class to do that. But, in that case there won't be any default constructor.


Be careful while extending above abstract class, you have to explicitly call super from each constructor.The first line of any constructor is call to super(). if you do not explicitly call super(), java will do that for you.
Below code will not compile:


You have to use it like below example:


yes it is. And a constructor of abstract class is called when an instance of a inherited class is created. For example, the following is a valid Java program.


This is the output of the above code,


Base Constructor Called
Derived Constructor Called


references:
enter link description here


Yes..It is like any other class. It can have a constructor and it is called after creating object for the base class.






Assume you have some objects which have several fields they can be compared by:


So in this example, when you ask if:


you might be asking if a's last name comes before b's, or if a is older than b, etc...


What is the cleanest way to enable multiple comparison between these kinds of objects without adding unnecessary clutter or overhead?


So what is the best way to go about this?


You can write a comparator class which compares two Person objects, and you can examine as many of the fields as you like. You can put in a variable in your comparator that tells it which field to compare to, although it would probably be simpler to just write multiple comparators.


With Java 8: 


If you have accessor methods:


If a class implements Comparable then such comparator may be used in compareTo method:


You should implement Comparable <Person>. Assuming all fields will not be null (for simplicity sake), that age is an int, and compare ranking is first, last, age, the compareTo method is quite simple:


(from House of Code)


This requires a lot of typing, maintenance and is error prone.


Obviously this is is more concise, but even more error prone as you lose your direct reference to the fields by using Strings instead. Now if a field is renamed, the compiler won’t even report a problem. Moreover, because this solution uses reflection, the sorting is much slower.


This is much better, but requires some boiler plate code for the most common use case: null-values should be valued less by default. For null-fields, you have to provide an extra directive to Guava what to do in that case. This is a flexible mechanism if you want to do something specific, but often you want the default case (ie. 1, a, b, z, null).


Like Guava’s ComparisonChain, this library class sorts easily on multiple fields, but also defines default behavior for null values (ie. 1, a, b, z, null). However, you can’t specify anything else either, unless you provide your own Comparator.


Ultimately it comes down to flavor and the need for flexibility (Guava’s ComparisonChain) vs. concise code (Apache’s CompareToBuilder).


I found a nice solution that combines multiple comparators in order of priority on CodeReview in a MultiComparator:


Ofcourse Apache Commons Collections has a util for this already:


ComparatorUtils.chainedComparator(comparatorCollection)


@Patrick To sort more than one field consecutively try ComparatorChain


A ComparatorChain is a Comparator that wraps one or more Comparators in sequence. The ComparatorChain calls each Comparator in sequence until either 1) any single Comparator returns a non-zero result (and that result is then returned), or 2) the ComparatorChain is exhausted (and zero is returned). This type of sorting is very similar to multi-column sorting in SQL, and this class allows Java classes to emulate that kind of behaviour when sorting a List.


To further facilitate SQL-like sorting, the order of any single Comparator in the list can >be reversed.


Calling a method that adds new Comparators or changes the ascend/descend sort after compare(Object, Object) has been called will result in an UnsupportedOperationException. However, take care to not alter the underlying List of Comparators or the BitSet that defines the sort order.


Instances of ComparatorChain are not synchronized. The class is not thread-safe at construction time, but it is thread-safe to perform multiple comparisons after all the setup operations are complete.


Another option you can always consider is Apache Commons. It provides a lot of options.


import org.apache.commons.lang3.builder.CompareToBuilder;


Ex:


You can also have a look at Enum that implements Comparator.


http://tobega.blogspot.com/2008/05/beautiful-enums.html


e.g.
Collections.sort(myChildren, Child.Order.ByAge.descending());


Writing a Comparator manually for such an use case is a terrible solution IMO. Such ad hoc approaches have many drawbacks: 


So what's the solution?


First some theory.


Let us denote the proposition "type A supports comparison" by Ord A. (From program perspective, you can think of Ord A as an object containing logic for comparing two As. Yes, just like Comparator.) 


Now, if Ord A and Ord B, then their composite (A, B) should also support comparison. i.e. Ord (A, B). If Ord A, Ord B, and Ord C, then Ord (A, B, C). 


We can extend this argument to arbitrary arity, and say:


Ord A, Ord B, Ord C, ..., Ord Z ⇒ Ord (A, B, C, .., Z)


Let's call this statement 1.


The comparison of the composites will work just as you described in your question: the first comparison will be tried first, then the next one, then the next, and so on.


That's the first part of our solution. Now the second part.


If you know that Ord A, and know how to transform B to A (call that transformation function f), then you can also have Ord B.  How? Well, when the two B instances are to be compared,  you first transform them to A using f and then apply Ord A.


Here, we are mapping the transformation B → A to Ord A → Ord B. This is known as contravariant mapping (or comap for short).


Ord A, (B → A) ⇒comap Ord B


Let's call this statement 2.


Now let's apply this to your example. 


You have a data type named Person that comprises three fields of type String. 


We know that Ord String. By statement 1, Ord (String, String, String). 


We can easily write a function from Person to (String, String, String). (Just return the three fields.)  Since we know Ord (String, String, String) and Person → (String, String, String), by statement 2, we can use comap to get Ord Person. 


QED.


How do I implement all these concepts?


The good news is you don't have to. There already exists a library which implements all the ideas described in this post. (If you are curious how these are implemented, you can look under the hood.)


This is how the code will look with it:


Explanation:


Hope that helps.


For those able to use the Java 8 streaming API, there is a neater approach that is well documented here:
Lambdas and sorting


I was looking for the equivalent of the C# LINQ:


I found the mechanism in Java 8 on the Comparator:


So here is the snippet that demonstrates the algorithm.


Check out the link above for a neater way and an explanation about how Java's type inference makes it a bit more clunky to define compared to LINQ.


Here is the full unit test for reference:


Instead of comparison methods you may want to just define several types of "Comparator" subclasses inside the Person class.  That way you can pass them into standard Collections sorting methods.


I think it'd be more confusing if your comparison algorithm were "clever". I'd go with the numerous comparison methods you suggested.


The only exception for me would be equality. For unit testing, it's been useful to me to override the .Equals (in .net) in order to determine if several fields are equal between two objects (and not that the references are equal).


If there are multiple ways a user might order person, you could also have multiple Comparators setup as constants somewhere. Most of the sort operations and sorted collections take a comparator as a parameter.


If you implement the Comparable interface, you'll want to choose one simple property to order by. This is known as natural ordering. Think of it as the default. It's always used when no specific comparator is supplied. Usually this is name, but your use case may call for something different. You are free to use any number of other Comparators you can supply to various collections APIs to override the natural ordering.


Also note that typically if a.compareTo(b) == 0, then a.equals(b) == true. It's ok if not but there are side effects to be aware of. See the excellent javadocs on the Comparable interface and you'll find lots of great information on this.


Following blog given good chained Comparator example 


http://www.codejava.net/java-core/collections/sorting-a-list-by-multiple-attributes-example


Calling Comparator:


Starting from Steve's answer the ternary operator can be used:


Its easy to do using Google's Guava library.


e.g. Objects.equal(name, name2) && Objects.equal(age, age2) && ...


More examples:






I have a question regarding return statements used within if() while() or for() statements.
As you can see in the following method, it is expecting that I return a String value.
The problem is that if i where to use a return within my if statement block, the compiler would return the error missing return statement.


Of course I could change the method header to void and use System.out.println instead of return. But is this the right way to do it? am i missing something?


Any help is highly appreciated.


If you put return statement in if, while or for statement then it may or may not return value. If it will not go inside these statement then also that method should return some value ( that could be null). To ensure that, compiler will force  you to write this return statement which is after if, while or for.


But if you write if / else block and each one of them is having return in it then compiler knows that either if or else will get execute and method will return a value. So this time compiler will not force you.


That's because the function needs to return a value. Imagine what happens if you execute myMethod() and it doesn't go into if(condition) what would your function returns? The compiler needs to know what to return in every possible execution of your function


Checking Java documentation:


Definition: If a method declaration has a return type then there must
  be a return statement at the end of the method. If the return
  statement is not there the missing return statement error is thrown.


This error is also thrown if the method does not have a return type
  and has not been declared using void (i.e., it was mistakenly
  omitted).


You can do to solve your problem:


Try with, as if if condition returns false, so it will return empty otherwise nothing to return.


Because the compiler doesn't know if any of those if blocks will ever be reached, so it's giving you an error.


That is illegal syntax. It is not an optional thing for you to return a variable. You MUST return a variable of the type you specify in your method.


You are effectively saying, I promise any class can use this method(public) and I promise it will always return a String(String).


Then you are saying IF my condition is true I will return x. Well that is too bad, there is no IF in your promise. You promised that myMethod will ALWAYS return a String. Even if your condition is ALWAYS true the compiler has to assume that there is a possibility of it being false. Therefore you always need to put a return at the end of your non-void method outside of any conditions JUST IN CASE all of your conditions fail.


It's because if you don't go in the if, there is nothing to return, so it miss a return. :)


should be :


This will return the string only if the condition is true.


try this:


You have to add a return statement if the condition is false.


FYI:


Oracle docs for return statement


Any how myMethod() should return a String value .what if your condition is false is myMethod return anything? ans is no so you  need to define return null or some string value in false condition






I know this will give me the day of the month as a number (11, 21, 23):


But how do you format the day of the month to include an ordinal indicator, say 11th, 21st or 23rd in Java?


The table from @kaliatech is nice, but since the same information is repeated, it opens the chance for a bug. Such a bug actually exists in the table for 7tn, 17tn, and 27tn (this bug might get fixed as time goes on because of the fluid nature of StackOverflow, so check the version history on the answer to see the error).


There is nothing in JDK to do this.


Or using Calendar:


Per comments by @thorbjørn-ravn-andersen, a table like this can be helpful when localizing:


Question is little old. As this question is very noisy so posting what I have solved with simple static method. Just copy and paste!


For testing purose


Just call this from main method!


If you try to be aware of i18n the solution get even more complicated.


The problem is that in other languages the suffix may depend not only on the number itself, but also on the noun it counts. For example in Russian it would be "2-ой день", but "2-ая неделя" (these mean "2nd day", but "2nd week"). This is not apply if we formatting only days, but in a bit more generic case you should be aware of complexity.


I think nice solution (I didn't have time to actually implement) would be to extend SimpleDateFormetter to apply Local-aware MessageFormat before passing to the parent class. This way you would be able to support let say for March formats %M to get "3-rd", %MM to get "03-rd" and %MMM to get "third". From outside this class looks like regular SimpleDateFormatter, but supports more formats. Also if this pattern would be by mistake applied by regular SimpleDateFormetter the result would be incorrectly formatted, but still readable.


Only issue with the solution provided by Greg is that it does not account for number greater than 100 with the "teen" numbers ending.  For example, 111 should be 111th, not 111st.  This is my solution:


Many of the examples here will not work for 11, 12, 13. This is more generic and will work for all case.


There is a simpler and sure way of doing this.  The function you'll need to use is getDateFromDateString(dateString);  It basically removes the st/nd/rd/th off of a date string and simply parses it.  You can change your SimpleDateFormat to anything and this will work.


}


I can't be satisfied by the answers calling for a English-only solution based on manual formats. I've been looking for a proper solution for a while now and I finally found it.


You should be using RuleBasedNumberFormat. It works perfectly and it's respectful of the Locale. 


The following is a more efficient answer to the question rather than hard-coding the style.


To change the day to ordinal number you need to use the following suffix.


Find my completed answer in this question.


The following method can be used to get the formatted string of the date which is passed in to it. It'll format the date to say 1st,2nd,3rd,4th .. using SimpleDateFormat in Java. eg:- 1st of September 2015






I want to be able to call the following method after a specified delay.
 In objective c there was something like:


Is there an equivalent of this method in android with java?
For example I need to be able to call a method after 5 seconds.


Better version:


I couldn't use any of the other answers in my case.
I used the native java Timer instead.


Note: This answer was given when the question didn't specify Android as the context. For an answer specific to the Android UI thread look here.


It looks like the Mac OS API lets the current thread continue, and schedules the task to run asynchronously. In the Java, the equivalent function is provided by the java.util.concurrent package. I'm not sure what limitations Android might impose.


For executing something in the UI Thread after 5 seconds:


you can use Handler inside UIThread:


Thanks for all the great answers, I found a solution that best suits my needs.


If you have to use the Handler, but you are into another thread, you can use runonuithread to run the handler in UI thread. This will save you from Exceptions thrown asking to call Looper.Prepare()


Looks quite messy, but this is one of the way.


See this demo:


I perfer to use View.postDelayed() method, simple code below:


Here is my shortest solution: 


I suggest the Timer, it allows you to schedule a method to be called on a very specific interval. This will not block your UI, and keep your app resonsive while the method is being executed.


The other option, is the wait(); method, this will block the current thread for the specified length of time. This will cause your UI to stop responding if you do this on the UI thread.


I created simpler method to call this. 


To use it, just call : .CallWithDelay(5000, this, "DoSomething");


If you are using Android Studio 3.0 and above you can use lambda expressions. The method callMyMethod() is called after 2 seconds:


In case you need to cancel all the delayed runnables:


Here is another tricky way: it won't throw exception when the runnable change UI elements.


}


You can call the animation like this:


Animation can attach to any view.


you can make it much cleaner by using the newly introduced lambda expressions:


It's very easy using the CountDownTimer.
For more details https://developer.android.com/reference/android/os/CountDownTimer.html


A suitable solution in android: 


everybody seems to forget to clean the Handler before posting a new runnable or message on it. Otherway they could potentially accumulate and cause bad behaviour.






What is the best connection pooling library available for Java/JDBC?


I'm considering the 2 main candidates (free / open-source): 


I've read a lot about them in blogs and other forums but could not reach a decision.


Are there any relevant alternatives to these two?


DBCP is out of date and not production grade. Some time back we conducted an in-house analysis of the two, creating a test fixture which generated load and concurrency against the two to assess their suitability under real life conditions. 


DBCP consistently generated exceptions into our test application and struggled to reach levels of performance which C3P0 was more than capable of handling without any exceptions. 


C3P0 also robustly handled DB disconnects and transparent reconnects on resume whereas DBCP never recovered connections if the link was taken out from beneath it. Worse still DBCP was returning Connection objects to the application for which the underlying transport had broken. 


Since then we have used C3P0 in 4 major heavy-load consumer web apps and have never looked back.


UPDATE: It turns out that after many years of sitting on a shelf, the Apache Commons folk have taken DBCP out of dormancy and it is now, once again, an actively developed project. Thus my original post may be out of date. 


That being said, I haven't yet experienced this new upgraded library's performance, nor heard of it being de-facto in any recent app framework, yet.


I invite you to try out BoneCP -- it's free, open source, and faster than the available alternatives (see benchmark section).


Disclaimer: I'm the author so you could say I'm biased :-)


Wallace


UPDATE: As of March 2010, still around 35% faster than the new rewritten Apache DBCP ("tomcat jdbc") pool. See dynamic benchmark link in benchmark section.


Update #2: (Dec '13) After 4 years at the top, there's now a much faster competitor : https://github.com/brettwooldridge/HikariCP


Update #3: (Sep '14) Please consider BoneCP to be deprecated at this point, recommend switching to HikariCP.


Update #4: (April '15) -- I no longer own the domain jolbox.com, but the new owner has kept the old content so beware.


I was having trouble with DBCP when the connections times out so I trialled c3p0.  I was going to release this to production but then started performance testing.  I found that c3p0 performed terribly.  I couldn't configure it to perform well at all.  I found it twice as slow as DBCP.


I then tried the Tomcat connection pooling.


This was twice as fast as c3p0 and fixed other issues I was having with DBCP.  I spent a lot of time investigating and testing the 3 pools.  My advice if you are deploying to Tomcat is to use the new Tomcat JDBC pool.


For the auto-reconnect issue with DBCP, has any tried using the following 2 configuration parameters?


Have been using DBCP for a couple of years now in production. It is stable, survives DB server reboot. Just configure it properly. It only requires a handful of parameters to be specified so don't be lazy. Here is a snippet from our system production code which lists parameters that we explicitly set to make it work:


Here are some articles that show that DBCP has significantly higher performance than C3P0 or Proxool. Also in my own experience c3p0 does have some nice features, like prepared statement pooling and is more configurable than DBCP, but DBCP is plainly faster in any environment I have used it in.


Difference between dbcp and c3p0? Absolutely nothing! (A Sakai developers blog)
 http://blogs.nyu.edu/blogs/nrm216/sakaidelic/2007/12/difference_between_dbcp_and_c3.html


See also the like to the JavaTech article "Connection Pool Showdown" in the comments on the blog post.


Another alternative, Proxool, is mentioned in this article.


You might be able to find out why Hibernate bundles c3p0 for its default connection pool implementation?


Unfortunately they are all out of date. DBCP has been updated a bit recently, the other two are 2-3 years old, with many outstanding bugs.


Dbcp is production ready if configured properly.


It is for example used on a commerce Website of 350000 visitors/ day and with pools of 200 connections.


It handles very well timeouts provided you configure it correctly.


Version 2 is on progress and it has a background which makes it reliable since Many
Production problems have been tackled.


We use it for our batch server solution and it has been running hundreds of batches That work on millions of lines in database.


Performance tests run by tomcat jdbc pool show it has better performance than cp30.


Another alternative is HikariCP.


Here is the comparison benchmark


Just got done wasting a day and a half with DBCP. Even though I'm using the latest DBCP release, I ran into exactly the same problems as j pimmel did. I would not recommend DBCP at all, especially it's knack of throwing connections out of the pool when the DB goes away, its inability to reconnect when the DB comes back and its inability to dynamically add connection objects back into the pool (it hangs forever on a post JDBCconnect I/O socket read)


I'm switching over to C3P0 now. I've used that in previous projects and it worked and performed like a charm.


c3p0 is good when we are using mutithreading projects. In our projects we used simultaneously multiple thread executions by using DBCP, then we got connection timeout if we used more thread executions. So we went with c3p0 configuration.


A good alternative which is easy to use is DBPool. 


"A Java-based database connection pooling utility, supporting time-based expiry, statement caching, connection validation, and easy configuration using a pool manager."


http://www.snaq.net/java/DBPool/ 






Why is the following algorithm not halting for me?
(str is the string I am searching in, findStr is the string I am trying to find)


EDIT- updated, still not working


The last line was creating a problem. lastIndex would never be at -1, so there would be an infinite loop. This can be fixed by moving the last line of code into the if block.


How about using StringUtils.countMatches from Apache Commons Lang?


That outputs:


Your lastIndex += findStr.length(); was placed outside the brackets, causing an infinite loop (when no occurence was found, lastIndex was always to findStr.length()). 


Here is the fixed version :


Do you really have to handle the matching yourself ? Especially if all you need is the number of occurences, regular expressions are tidier :


A shorter version. ;)


at the end of the loop count is 3; hope it helps


A lot of the given answers fail on one or more of:


Here's what I wrote:


Example call:


If you want a non-regular-expression search, just compile your pattern appropriately with the LITERAL flag:


Here it is, wrapped up in a nice and reusable method:


Increment lastIndex whenever you look for next occurrence. 


Otherwise it's always finding the first substring (at position 0).


Returns the index within this string of the first occurrence of the specified character, starting the search at the specified index.


So your lastindex value is always 0 and it always finds hello in the string.


try adding lastIndex+=findStr.length() to the end of your loop, otherwise you will end up in an endless loop because once you found the substring, you are trying to find it again and again from the same last position.


Try this one. It replaces all the matches with a -.


And if you don't want to destroy your str you can create a new string with the same content:


After executing this block these will be your values:


The answer given as correct is no good for counting things like line returns and is far too verbose. Later answers are better but all can be achieved simply with


It does not drop trailing matches using the example in the question.


As @Mr_and_Mrs_D suggested:


Based on the existing answer(s) I'd like to add a "shorter" version without the if:


You can number of occurrences using inbuilt library function:


This below method show how many time substring repeat on ur whole string. Hope use full to you:-


here is the other solution without using regexp/patterns/matchers  or even not using StringUtils.


If you need the index of each substring within the original string, you can do something with indexOf like this:


Here is the advanced version for counting how many times the token occurred in a user entered string:


I can't believe no one has mentioned this one liner. It's simple, concise and performs slightly better than str.split(target, -1).length-1






I'm learning Spring 3 and I don't seem to grasp the functionality behind <context:annotation-config> and <context:component-scan>.


From what I've read they seem to handle different annotations (@Required, @Autowired etc vs @Component, @Repository, @Service etc) but also from what I've read they register the same bean post processor classes.


To confuse me even more, there is an annotation-config attribute on <context:component-scan>.


Can someone shed some light on these tags? What's similar, what's different, is one superseded by the other, they complete each other, do I need one of them, both?


<context:annotation-config> is used to activate annotations in beans already registered in the application context (no matter if they were defined with XML or by package scanning).


<context:component-scan> can also do what <context:annotation-config> does but <context:component-scan> also scans packages to find and register beans within the application context.


I'll use some examples to show the differences/similarities. 


Lets start with a basic setup of three beans of type A, B and C, with B and C being injected into A.


With the following XML configuration :


Loading the context produces the following output:


OK, this is the expected output. But this is "old style" Spring. Now we have annotations so lets use those to simplify the XML.


First, lets autowire the bbb and ccc properties on bean A like so:


This allows me to remove the following rows from the XML:


My XML is now simplified to this:


When I load the context I get the following output:


OK, this is wrong! What happened? Why aren't my properties autowired?


Well, annotations are a nice feature but by themselves they do nothing whatsoever. They just annotate stuff. You need a processing tool to find the annotations and do something with them. 


<context:annotation-config> to the rescue. This activates the actions for the annotations that it finds on the beans defined in the same application context where itself is defined.


If I change my XML to this:


when I load the application context I get the proper result:


OK, this is nice, but I've removed two rows from the XML and added one. That's not a very big difference. The idea with annotations is that it's supposed to remove the XML.


So let's remove the XML definitions and replace them all with annotations:


While in the XML we only keep this:


We load the context and the result is... Nothing. No beans are created, no beans are autowired. Nothing!


That's because, as I said in the first paragraph, the <context:annotation-config /> only works on beans registered within the application context. Because I removed the XML configuration for the three beans there is no bean created and <context:annotation-config /> has no "targets" to work on.


But that won't be a problem for <context:component-scan> which can scan a package for "targets" to work on. Let's change the content of the XML config into the following entry:


When I load the context I get the following output:


Hmmmm... something is missing. Why? 


If you look closelly at the classes, class A has package com.yyy but I've specified in the <context:component-scan> to use package com.xxx so this completely missed my A class and only picked up B and C which are on the com.xxx package.


To fix this, I add this other package also:


and now we get the expected result:


And that's it! Now you don't have XML definitions anymore, you have annotations.


As a final example, keeping the annotated classes A, B and C and adding the following to the XML, what will we get after loading the context?


We still get the correct result:


Even if the bean for class A isn't obtained by scanning, the processing tools are still applied by <context:component-scan> on all beans registered
in the application context, even for A which was manually registered in the XML.


But what if we have the following XML, will we get duplicated beans because we've specified both <context:annotation-config /> and <context:component-scan>?


No, no duplications, We again get the expected result:


That's because both tags register the same processing tools (<context:annotation-config /> can be omitted if <context:component-scan> is specified) but Spring takes care of running them only once.


Even if you register the processing tools yourself multiple times, Spring will still make sure they do their magic only once; this XML:


will still generate the following result:


OK, that about raps it up. 


I hope this information along with the responses from @Tomasz Nurkiewicz and @Sean Patrick Floyd are all you need to understand how 
<context:annotation-config> and <context:component-scan> work.


I found this nice summary of which annotations are picked up by which declarations. By studying it you will find that <context:component-scan/> recognizes a superset of annotations recognized by <context:annotation-config/>, namely:


As you can see <context:component-scan/> logically extends <context:annotation-config/> with CLASSPATH component scanning and Java @Configuration features.


Spring allows you to do two things:


1. Autowiring
Usually in applicationContext.xml you define beans and other beans are wired using
constructor or setter methods. You can wire beans using XML or annotations.
In case you use annotations, you need to activate annotations and you have to add
<context:annotation-config /> in applicationContext.xml. This will simplify the
structure of the  tag from applicationContext.xml, because you will not have to manually wire beans (constructor or setter). You can use @Autowire annotation and the beans will be wired by type.


A step forward for escaping the manual XML configuration is  


2. Autodiscovery
Autodiscovery is simplifying the XML one step further, in the sense that you don't even need too add the <bean> tag in applicationContext.xml. You just mark the specific beans with one of the following annotation and Spring will automatically wire the marked beans and their dependencies into the Spring container. The annotations are as follow:  @Controller, @Service, @Component, @Repository. By using <context:component-scan> and pointing the base package, Spring will auto-discover and wire the components into Spring container.


As a conclusion:


<context:annotation-config> activates many different annotations in beans, whether they are defined in XML or through component scanning.


<context:component-scan> is for defining beans without using XML


For further information, read:


The difference between the two is really simple!.


Enables you to use annotations that are restricted to wiring up properties and constructors only of beans!.


Where as


Enables everything that <context:annotation-config /> can do, with addition of using stereotypes eg.. @Component, @Service , @Repository. So you can wire entire beans and not just restricted to constructors or properties!.    


The <context:annotation-config> tag tells Spring to scan the codebase for automatically resolving dependency requirements of the classes containing @Autowired annotation.


Spring 2.5 also adds support for JSR-250 annotations such as @Resource, @PostConstruct, and @PreDestroy.Use of these annotations also requires that certain BeanPostProcessors be registered within the Spring container. As always, these can be registered as individual bean definitions, but they can also be implicitly registered by including <context:annotation-config> tag in spring configuration.


Taken from Spring documentation of Annotation Based Configuration


Spring provides the capability of automatically detecting 'stereotyped' classes and registering corresponding BeanDefinitions with the ApplicationContext.


According to javadoc of org.springframework.stereotype:


Stereotypes are Annotations denoting the roles of types or methods in the overall architecture (at a conceptual, rather than implementation, level). 
Example: @Controller @Service @Repository etc.
These are intended for use by tools and aspects (making an ideal target for pointcuts).


To autodetect such 'stereotype' classes, <context:component-scan> tag is required.


The <context:component-scan> tag also tells Spring to scan the code for injectable beans under the package (and all its subpackages) specified.


tl;dr
<context:annotation-config>: Scanning and activating annotations for already registered beans in spring config xml.


<context:component-scan>: Bean registration + <context:annotation-config>


@Autowired and @Required are targets property level so bean should register in spring IOC before use these annotations. To enable these annotations either have to register respective beans or include <context:annotation-config />. i.e. <context:annotation-config /> works with registered beans only.


@Required enables  RequiredAnnotationBeanPostProcessor  processing tool
@Autowired enables  AutowiredAnnotationBeanPostProcessor processing tool


Note: Annotation itself nothing to do, we need a Processing Tool, which is a class underneath, responsible for the core process.


@Repository, @Service and @Controller  are @Component, and they targets class level.


<context:component-scan> it scans the package and find and register the beans, and it includes the work done by <context:annotation-config />.


Only resolves the @Autowired and @Qualifer annotations, thats all, it about the Dependency Injection, There are other annotations that do the same job, I think how @Inject, but all about to resolve DI through annotations.


Be aware, even when you have declared the <context:annotation-config> element, you must declare your class how a Bean anyway, remember we have three available options


Now with


It does two things:


Therefore if you declare <context:component-scan>, is not necessary anymore declare <context:annotation-config> too.


Thats all 


A common scenario was for example declare only a bean through XML and resolve the DI through annotations, for example


We have only declared the beans, nothing about <constructor-arg> and <property>, the DI is configured in their own classes through @Autowired. It means the Services use @Autowired for their Repositories components and the Repositories use @Autowired for the JdbcTemplate, DataSource etc..components


try with <context:component-scan base-package="..." annotation-config="false"/> , in your configuration @Service, @Repository, @Component works fine, but @Autowired,@Resource and @Inject doesn't work.


This means AutowiredAnnotationBeanPostProcessor will not be enabled and Spring container will not process the Autowiring annotations.


The other important point to note is that context:component-scan implicitly calls the context:annotation-config to activate the annotations on beans. Well if you don't want context:component-scan to implicitly activate annotations for you, you can go on setting the annotation-config element of the context:component-scan to false.


To summarize:


A <context:component-scan/> custom tag registers the same set of bean definitions as is done by , apart from its primary responsibility of scanning the java packages and registering bean definitions from the classpath.


If for some reason this registration of default bean definitions are to be avoided, the way to do that is to specify an additional "annotation-config" attribute in component-scan, this way:


Reference:
http://www.java-allandsundry.com/2012/12/contextcomponent-scan-contextannotation.html


<context:component-scan base-package="package name" />:


This is used to tell the container that there are bean classes in my package scan those bean classes. In order to scan  bean classes by container on top of the bean we have to write one of the stereo type annotation like following.


@Component, @Service, @Repository, @Controller


<context:annotation-config />:


If we don't want to write bean tag explicitly in XML then how the container knows if there is a auto wiring in the bean. This is possible by using @Autowired annotation. we have to inform to the container that there is auto wiring in my bean by context:annotation-config.


context:annotation-config:


This tells Spring that I am gona use Annoatted beans as spring bean adn those would be wired through @Autowired annotation, instead of declaring in spring config xml file.


context:component-scan base-package="com.test..." : 
This tells Spring container, where to start searching those annotated beans. Here spring will sear all sub packages of the 






I've mapped the Spring MVC dispatcher as a global front controller servlet on /*.


However, this mapping stops the access to static files like CSS, JS, images etc which are all in the /res/ folder.


How can I access them anyway?


I've run into this also and never found a great solution.  I ended up mapping my servlet one level higher in the URL hierarchy:


And now everything at the base context (and in your /res directory) can be served up by your container.


Map the controller servlet on a more specific url-pattern like /pages/*, put the static content in a specific folder like /static and create a Filter listening on /* which transparently continues the chain for any static content and dispatches requests to the controller servlet for other content.


In a nutshell:


with the following in filter's doFilter():


No, this does not end up with /pages in browser address bar. It's fully transparent. You can if necessary make "/static" and/or "/pages" an init-param of the filter.


With Spring 3.0.4.RELEASE and higher you can use


As seen in Spring Reference.


If you use Tomcat, you can map resources to the default servlet:


and access your resources with url http://{context path}/static/res/...


Also works with Jetty, not sure about other servlet containers.


What you do is add a welcome file in your web.xml


And then add this to your servlet mappings so that when someone goes to the root of your application, they get sent to index.html internally and then the mapping will internally send them to the servlet you map it to


End result: You visit /Application, but you are presented with /Application/MainActions servlet without disrupting any other root requests.


Get it? So your app still sits at a sub url, but automatically gets presented when the user goes to the root of your site. This allows you to have the /images/bob.img still go to the regular place, but '/' is your app.


Serving static content with appropriate suffix in multiple servlet-mapping definitions solved the security issue which is mentioned in one of the comments in one of the answers posted. Quoted below:


This was a security hole in Tomcat (WEB-INF and META-INF contents are accessible this way) and it has been fixed in 7.0.4 (and will be ported to 5.x and 6.x as well). – BalusC Nov 2 '10 at 22:44


which helped me a lot.
And here is how I solved it:


As of 3.0.4 you should be able to use mvc:resources in combination with mvc:default-servlet-handler as described in the spring documentation to achieve this.


http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/mvc.html#mvc-static-resources


'Static' files in App Engine aren't directly accessible by your app. You either need to upload them twice, or serve the static files yourself, rather than using a static handler.


The reason for the collision seems to be because, by default, the context root, "/", is to be handled by org.apache.catalina.servlets.DefaultServlet. This servlet is intended to handle requests for static resources.


If you decide to bump it out of the way with your own servlet, with the intent of handling dynamic requests, that top-level servlet must also carry out any tasks accomplished by catalina's original "DefaultServlet" handler.


If you read through the tomcat docs, they make mention that True Apache (httpd) is better than Apache Tomcat for handling static content, since it is purpose built to do just that. My guess is because Tomcat by default uses org.apache.catalina.servlets.DefaultServlet to handle static requests. Since it's all wrapped up in a JVM, and Tomcat is intended to as a Servlet/JSP container, they probably didn't write that class as a super-optimized static content handler. It's there. It gets the job done. Good enough. 


But that's the thing that handles static content and it lives at "/". So if you put anything else there, and that thing doesn't handle static requests, WHOOPS, there goes your static resources. 


I've been searching high and low for the same answer and the answer I'm getting everywhere is "if you don't want it to do that, don't do that".


So long story short, your configuration is displacing the default static resource handler with something that isn't a static resource handler at all. You'll need to try a different configuration to get the results you're looking for (as will I).


The best way to handle this is using some kind of URL re-writing.  In this way, you can have clean restful URLs, and NOT with any extensions i.e abc.com/welcom/register as opposed to abc.com/welcome/resister.html


I use Tuckey URL which is pretty cool.


It's got instructions on how to set up your web app.I have set it up with my Spring MVC web app. Of course, everything was fine until I wanted to use annotations for Spring 3 validations like @Email or @Null for domain objects.  


When I add the Spring mvc directives:


.. it breaks the good ol Tuckey code. Apparently, < mvc:default-servlet-handler /> replaces Tuckey, which I'm still trying to solve. 


Add the folders which you don't want to trigger servlet processing to the <static-files> section of your appengine-web.xml file.


I just did this and looks like things are starting to work ok.  Here's my structure:


/


/pages/<.jsp files>


/css


I added "/pages/**" and "/css/**" to the <static-files> section and I can now forward to a .jsp file from inside a servlet doGet without causing an infinite loop.


After trying the filter approach without success (it did for some reason not enter the doFilter() function) I changed my setup a bit and found a very simple solution for the root serving problem:


Instead of serving " / * "
in my main Servlet, I now only listen to dedicated language prefixes
"EN", "EN/ *", "DE", "DE/ *"


Static content gets served by the default Servlet and the empty root requests go to the index.jsp which calls up my main Servlet with the default language:


< jsp:include page="/EN/" />
  (no other content on the index page.)


I found that using 


in the spring MVC servlet bean definition file works for me. It passes any request that isn't handled by a registered MVC controller on to the container's original default handler, which should serve it as static content.  Just make sure you have no controller registered that handles everything, and it should work just fine.  Not sure why @logixplayer suggests URL rewriting; you can achieve the effect he's looking for just adequately using Spring MVC alone.


I'd recommend trying to use a Filter instead of a default servlet whenever possible.


Other two possibilities:


Write a FileServlet yourself. You'll find plenty examples, it should just open the file by URL and write its contents into output stream. Then, use it to serve static file request.


Instantiate a FileServlet class used by Google App Engine and call service(request, response) on that FileServlet when you need to serve the static file at a given URL.


You can map /res/* to YourFileServlet or whatever to exclude it from DispatcherServlets' handling, or call it directly from DispatcherServlet.


And, I have to ask, what does Spring documentation say about this collision? I've never used it.


I found a simpler solution with a dummy index file.


Create a Servlet (or use the one you wanted to respond to "/") which maps to "/index.html"
(Solutions mentioned here use the mapping via XML, I used the 3.0 version with annotation @WebServlet)
Then create a static (empty) file at the root of the static content named "index.html"


I was using Jetty, and what happened was that the server recognized the file instead of listing the directory but when asked for the resource, my Servlet took control instead. All other static content remained unaffected.


In Embedded Jetty I managed to achieve something similar by adding a mapping for the "css" directory in web.xml. Explicitly telling it to use DefaultServlet:


and if you want to use annotation based configuration use below code






Why does Java have transient fields?


The transient keyword in Java is used to indicate that a field should not be serialized.


From the Java Language Specification, Java SE 7 Edition, Section 8.3.1.3. transient Fields:


Variables may be marked transient to
  indicate that they are not part of the
  persistent state of an object.


For example, you may have fields that are derived from other fields, and should only be done so programmatically, rather than having the state be persisted via serialization. 


Here's a GalleryImage class which contains an image and a thumbnail derived from the image:


In this example, the thumbnailImage is a thumbnail image that is generated by invoking the generateThumbnail method.


The thumbnailImage field is marked as transient, so only the original image is serialized rather than persisting both the original image and the thumbnail image. This means that less storage would be needed to save the serialized object. (Of course, this may or may not be desirable depending on the requirements of the system -- this is just an example.)


At the time of deserialization, the readObject method is called to perform any operations necessary to restore the state of the object back to the state at which the serialization occurred. Here, the thumbnail needs to be generated, so the readObject method is overridden so that the thumbnail will be generated by calling the generateThumbnail method.


For additional information, the Discover the secrets of the Java Serialization API article (which was originally available on the Sun Developer Network) has a section which discusses the use of and presents a scenario where the transient keyword is used to prevent serialization of certain fields.


Before understanding the transient keyword, one has to understand the concept of serialization. If the reader knows about serialization, please skip the first point.


Serialization is the process of making the object's state persistent. That means the state of the object is converted into a stream of bytes and stored in a file. In the same way, we can use the deserialization to bring back the object's state from bytes. This is one of the important concepts in Java programming because serialization is mostly used in networking programming. The objects that need to be transmitted through the network have to be converted into bytes. For that purpose, every class or interface must implement the Serializable interface. It is a marker interface without any methods.


By default, all of object's variables get converted into a persistent state. In some cases, you may want to avoid persisting some variables because you don't have the need to persist those variables. So you can declare those variables as transient. If the variable is declared as transient, then it will not be persisted. That is the main purpose of the transient keyword.


I want to explain the above two points with the following example:


And the output will be the following:


Middle Name is declared as transient, so it will not be stored in the persistent storage.


Source


To allow you to define variables that you don't want to serialise. 


In an object you may have information that you don't want to serialise/persist (perhaps a reference to a parent factory object), or perhaps it doesn't make sense to serialise. Marking these as 'transient' means the serialisation mechanism will ignore these fields.


My small contribution :


What is transient variable in Java?
In simple sentence any variable which is modified with transient keyword becomes transient variable in java.
Why do we need transient variable in java?
Transient keyword provides you some control over serialization process and gives you flexibility to exclude some of object properties from serialization process. Some time it does make sense not to serialize certain attributes of an object, we will see which variables should not be serialized and should be made transient in next section.
Which variable you should mark transient?
Since we know the purpose of transient keyword or having transient variable its make sense to think about which variable should be marked as transient. My rule is that any variable whose value can be calculated from other variables doesn't require to be saved. For example if you have a field called "interest" whose value can be derived from other fields e.g. principle, rate, time etc then there is no need to serialize it.
Another example is of word count, if you are saving article then no need to save word count, because it can be created when article gets deserialized. Another good example of transient keyword is "Logger" since most of the time you have logger instance for logging in Java but you certainly don't want it to serialize correct?


A transient variable is a variable that may not be serialized. 


One example of when this might be useful that comes to mind are variables that make only sense in the context of a specific object instance and which become invalid once you have serialized and deserialized the object. In that case it is useful to have those variables become null instead so that you can re-initialize them with useful data when needed. 


transient is used to indicate that a class field doesn't need to be serialized.
Probably the best example is a Thread field. There's usually no reason to serialize a Thread, as its state is very 'flow specific'. 


Because not all variables are of a serializable nature


Serialization systems other than the native java one can also use this modifier. Hibernate, for instance, will not persist fields marked with either @Transient or the transient modifier. Terracotta as well respects this modifier.


I believe the figurative meaning of the modifier is "this field is for in-memory use only. don't persist or move it outside of this particular VM in any way. Its non-portable". i.e. you can't rely on its value in another VM memory space. Much like volatile means you can't rely on certain memory and thread semantics.


Serialization is the process of saving an object’s states in a persistent format (such as file stream or database), and later restoring them back from the stream (de-serialization). 
In Java, an object of a class is serializable if the class implements the java.io.Serializable interface. This is a marker interface which tells the JVM that the class is eligible for serialization. 


There are three important points in this model class:
It must implements the Serializable interface. Otherwise, we’ll get a java.io.NotSerializableException when trying to serialize an object of the class.
A constant named serialVersionUID  is declared and assigned a long value:


This is a conventional constant which should be declared when a class implements the Serializable interface. The serial version UID strongly ensures compatibility between the serialized and de-serialized versions of objects of a class, because the process of serialization and de-serialization can happen on different computers and systems. Although this declaration is optional, it’s always recommended to declare the serialVersionUID for a serializable class.


Notice that the password field is marked as transient: 


Because we don’t want store the password when serializing the object. The rule is, when a variable is marked as transient, its object won’t be serialized during serialization.  


A transient variable is a variable that may not be serialized. You use the transient keyword to indicate to the Java virtual machine that the indicated variable is not part of the persistent state of the object.


The access modifiers supported by Java are static, final, abstract, synchronized, native, volatile, transient and strictfp.


Following table gives the list of access specifiers and modifiers Java that can be applied to variables, methods and classes.


Before I respond to this question, I must explain to you the SERIALIZATION, because if you understand what it means serialization in science computer you can easily understand this keyword.


Serialization
When an object is transferred through the network / saved on physical media(file,...), the object must be "serialized". Serialization converts byte status object series. These bytes are sent on the network/saved and the object is re-created from these bytes.
Example


Now IF YOU WANT TO do NOT TRANSFERT/SAVED field of this object SO, you can use keyword transient 


Example 


It's needed when you don't want to share some sensitive data that go with serialization.


as per google
transient meaning ==  lasting only for a short time; impermanent.


now if want to make anything transient in java use transient keyword.


Q: where to use transient? 


A: Generally in java we can save data to files by acquiring them in variables and writing those variables to files, this process is known as Serialization. Now if we want to avoid variable data to be written to file, we would make that variable as transient.


transient int result=10;


Note: transient variables cannot be local.






I'm currently configuring hadoop on a server running CentOs. When I run start-dfs.sh or stop-dfs.sh, I get the following error:


WARN util.NativeCodeLoader: Unable to load native-hadoop library for
  your platform... using builtin-java classes where applicable


I'm running Hadoop 2.2.0. 


Doing a search online brought up this link: http://balanceandbreath.blogspot.ca/2013/01/utilnativecodeloader-unable-to-load.html


However, the contents of /native/ directory on hadoop 2.x appear to be different so I am not sure what to do.


I've also added these two environment variables in hadoop-env.sh:


export HADOOP_OPTS="$HADOOP_OPTS
  -Djava.library.path=/usr/local/hadoop/lib/"


export HADOOP_COMMON_LIB_NATIVE_DIR="/usr/local/hadoop/lib/native/"


Any ideas?


I assume you're running Hadoop on 64bit CentOS. The reason you saw that warning is the native Hadoop library $HADOOP_HOME/lib/native/libhadoop.so.1.0.0 was actually compiled on 32 bit. 


Anyway, it's just a warning, and won't impact Hadoop's functionalities.


Here is the way if you do want to eliminate this warning, download the source code of Hadoop  and recompile libhadoop.so.1.0.0 on 64bit system, then replace the 32bit one. 


Steps on how to recompile source code are included here for Ubuntu:


Good luck.


Just append word native to your HADOOP_OPTS like this:


export HADOOP_OPTS="$HADOOP_OPTS -Djava.library.path=$HADOOP_HOME/lib/native"


PS: Thank Searene


The answer depends... I just installed Hadoop 2.6 from tarball on 64-bit CentOS 6.6. The Hadoop install did indeed come with a prebuilt 64-bit native library. For my install, it is here:


And I know it is 64-bit:


Unfortunately, I stupidly overlooked the answer right there staring me in the face as I was focuses on, "Is this library 32 pr 64 bit?":


So, lesson learned. Anyway, the rest at least led me to being able to suppress the warning. So I continued and did everything recommended in the other answers to provide the library path using the HADOOP_OPTS environment variable to no avail. So I looked at the source code. The module that generates the error tells you the hint (util.NativeCodeLoader):


So, off to here to see what it does:


http://grepcode.com/file/repo1.maven.org/maven2/com.ning/metrics.action/0.2.6/org/apache/hadoop/util/NativeCodeLoader.java/


Ah, there is some debug level logging - let's turn that on a see if we get some additional help. This is done by adding the following line to $HADOOP_CONF_DIR/log4j.properties file:


Then I ran a command that generates the original warning, like stop-dfs.sh, and got this goodie:


And the answer is revealed in this snippet of the debug message (the same thing that the previous ldd command 'tried' to tell me:


What version of GLIBC do I have? Here's simple trick to find out:


So, can't update my OS to 2.14. Only solution is to build the native libraries from sources on my OS or suppress the warning and just ignore it for now. I opted to just suppress the annoying warning for now (but do plan to build from sources in the future) buy using the same logging options we used to get the debug message, except now, just make it ERROR level.


I hope this helps others see that a big benefit of open source software is that you can figure this stuff out if you take some simple logical steps.


In my case , after I build hadoop on my 64 bit Linux mint OS, I replaced the native library in hadoop/lib. Still the problem persist. Then I figured out the hadoop pointing to hadoop/lib not to the hadoop/lib/native. So I just moved all content from native library to its parent. And the warning just gone.


I had the same issue. It's solved by adding following lines in .bashrc:


After a continuous research as suggested by KotiI got resolved the issue. 


Cheers


For those on OSX with Hadoop installed via Homebrew, follow these steps replacing the path and Hadoop version where appropriate


then update hadoop-env.sh with


@zhutoulala -- FWIW your links worked for me with Hadoop 2.4.0 with one exception I had to tell maven not to build the javadocs.  I also used the patch in the first link for 2.4.0 and it worked fine.  Here's the maven command I had to issue


After building this and moving the libraries, don't forget to update hadoop-env.sh :)


Thought this might help someone who ran into the same roadblocks as me


This also would work:


Move your compiled native library files to $HADOOP_HOME/lib folder.


Then set your environment variables by editing .bashrc file


Make sure your compiled native library files are in $HADOOP_HOME/lib folder.


it should work.


This line right here:


From KunBetter's answer is where the money is


This line right here:


From KunBetter's answer, worked for me.
Just append it to .bashrc file and reload .bashrc contents


I had the same problem with JDK6,I changed the JDK to JDK8,the problem solved.
Try to use JDK8!!!


In addition to @zhutoulala accepted answer, here is an update to make it work with latest stable version to date (2.8) on ARMHF platforms (Raspberry Pi 3 model B).
First I can confirm that you must recompile native libraries to 64 bit ARM, other answers here based on setting some environment variables won't work. As indicated in Hadoop documentation, the pre-built native libraries are 32 bit.


High level steps given in the fist link (http://www.ercoppa.org/posts/how-to-compile-apache-hadoop-on-ubuntu-linux.html) are correct.
On this url http://www.instructables.com/id/Native-Hadoop-260-Build-on-Pi/ you get more details specific to Raspberry Pi, but not for Hadoop version 2.8.


Here are my indications pour Hadoop 2.8  :


CMake file patching method must be changed. Moreovere, files to patch are not the same. Unfortunately, there is no accepted patch on JIRA specific to 2.8. On this URL (https://issues.apache.org/jira/browse/HADOOP-9320) you must copy and paste Andreas Muttscheller proposed patch on your namenode :


Once build is successful :


And replace the content of the lib/native directory of your Hadoop install with the content of this archive. Warning message when running Hadoop should disappear. 


For installing Hadoop it is soooooo much easier installing the free version from Cloudera. It comes with a nice GUI that makes it simple to add nodes, there is no compiling or stuffing around with dependencies, it comes with stuff like hive, pig etc.


http://www.cloudera.com/content/support/en/downloads.html


Steps are:
1) Download
2) Run it
3) Go to web GUI (1.2.3.4:7180)
4) Add extra nodes in the web gui (do NOT install the cloudera software on other nodes, it does it all for you)
5) Within the web GUI go to Home, click Hue and Hue Web UI. This gives you access to Hive, Pig, Sqoop etc.


Verified remedy from earlier postings:


1) Checked that the libhadoop.so.1.0.0 shipped with the Hadoop distribution was compiled for my machine architecture, which is x86_64:


2) Added -Djava.library.path=<path> to HADOOP_OPT in hadoop-env.sh:


This indeed made the annoying warning disappear.


Firstly: You can modify the glibc version.CentOS provides safe softwares tranditionally,it also means the version is old such as glibc,protobuf ...


You can compare the version of current glibc with needed glibc.


Secondly: If the version of current glibc is old,you can update the glibc. 
DownLoad Glibc


If the version of current glibc id right,you can append word native to your HADOOP_OPTS


I'm not using CentOS. Here is what I have in Ubuntu 16.04.2, hadoop-2.7.3, jdk1.8.0_121. Run start-dfs.sh or stop-dfs.sh successfully w/o error:


Replace /j01/sys/jdk, /j01/srv/hadoop with your installation path


I also did the following for one time setup on Ubuntu, which eliminates the need to enter passwords for multiple times when running start-dfs.sh:


Replace user with your username






How can I change the current working directory from within a Java program? Everything I've been able to find about the issue claims that you simply can't do it, but I can't believe that that's really the case.


I have a piece of code that opens a file using a hard-coded relative file path from the directory it's normally started in, and I just want to be able to use that code from within a different Java program without having to start it from within a particular directory. It seems like you should just be able to call System.setProperty( "user.dir", "/path/to/dir" ), but as far as I can figure out, calling that line just silently fails and does nothing.


I would understand if Java didn't allow you to do this, if it weren't for the fact that it allows you to get the current working directory, and even allows you to open files using relative file paths....


There is no reliable way to do this in pure Java. Setting the user.dir property via System.setProperty() or java -Duser.dir=... does seem to affect subsequent creations of Files, but not e.g. FileOutputStreams.


The File(String parent, String child) constructor can help if you build up your directory path separately from your file path, allowing easier swapping.


An alternative is to set up a script to run Java from a different directory, or use JNI native code as suggested below.


The relevant Sun bug was closed in 2008 as "will not fix".


If you run your legacy program with ProcessBuilder, you will be able to specify its working directory.


There is a way to do this using the system property "user.dir".  The key part to understand is that getAbsoluteFile() must be called (as shown below) or else relative paths will be resolved against the default "user.dir" value.


It is possible to change the PWD, using JNA/JNI to make calls to libc. The JRuby guys have a handy java library for making POSIX calls called jna-posix Here's the maven info


You can see an example of its use here (Clojure code, sorry). Look at the function chdirToRoot


If I understand correctly, a Java program starts with a copy of the current environment variables. Any changes via System.setProperty(String, String) are modifying the copy, not the original environment variables. Not that this provides a thorough reason as to why Sun chose this behavior, but perhaps it sheds a little light...


As mentioned you can't change the CWD of the JVM but if you were to launch another process using Runtime.exec() you can use the overloaded method that lets you specify the working directory. This is not really for running your Java program in another directory but for many cases when one needs to launch another program like a Perl script for example, you can specify the working directory of that script while leaving the working dir of the JVM unchanged.


See Runtime.exec javadocs


Specifically,


where dir is the working directory to run the subprocess in


The working directory is a operating system feature (set when the process starts). 
Why don't you just pass your own System property (-Dsomeprop=/my/path) and use that in your code as the parent of your File:


The smarter/easier thing to do here is to just change your code so that instead of opening the file assuming that it exists in the current working directory (I assume you are doing something like new File("blah.txt"), just build the path to the file yourself.


Let the user pass in the base directory, read it from a config file, fall back to user.dir if the other properties can't be found, etc. But it's a whole lot easier to improve the logic in your program than it is to change how environment variables work.


I have tried to invoke


String oldDir = System.setProperty("user.dir", currdir.getAbsolutePath());


It seems to work. But 


File myFile = new File("localpath.ext");
 InputStream openit = new FileInputStream(myFile);


throws a FileNotFoundException though


myFile.getAbsolutePath()


shows the correct path. 
I have read this. I think the problem is:


The solution may be: 


File myFile = new File(System.getPropety("user.dir"), "localpath.ext");


It creates a file Object as absolute one with the current directory which is known by the JVM. But that code should be existing in a used class, it needs changing of reused codes.


~~~~JcHartmut


The other possible answer to this question may depend on the reason you are opening the file.  Is this a property file or a file that has some configuration related to your application?


If this is the case you may consider trying to load the file through the classpath loader, this way you can load any file Java has access to.


If you run your commands in a shell you can write something like "java -cp" and add any directories you want separated by ":" if java doesnt find something in one directory it will go try and find them in the other directories, that is what I do.


You can use 


new File("relative/path").getAbsoluteFile() 


after 


System.setProperty("user.dir", "/some/directory")


Will print


Use FileSystemView 






I have a simple setter method for a property and null is not appropriate for this particular property. I have always been torn in this situation: should I throw an IllegalArgumentException, or a NullPointerException? From the javadocs, both seem appropriate. Is there some kind of an understood standard?  Or is this just one of those things that you should do whatever you prefer and both are really correct?


It seems like an IllegalArgumentException is called for if you don't want null to be an allowed value, and the NullPointerException would be thrown if you were trying to use a variable that turns out to be null.


You should be using IllegalArgumentException (IAE), not NullPointerException (NPE) for the following reasons:


First, the NPE JavaDoc explicitly lists the cases where NPE is appropriate.  Notice that all of them are thrown by the runtime when null is used inappropriately.  In contrast, the IAE JavaDoc couldn't be more clear: "Thrown to indicate that a method has been passed an illegal or inappropriate argument."  Yup, that's you!


Second, when you see an NPE in a stack trace, what do you assume?  Probably that someone dereferenced a null.  When you see IAE, you assume the caller of the method at the top of the stack passed in an illegal value.  Again, the latter assumption is true, the former is misleading.


Third, since IAE is clearly designed for validating parameters, you have to assume it as the default choice of exception, so why would you choose NPE instead?  Certainly not for different behavior -- do you really expect calling code to catch NPE's separately from IAE and do something different as a result?  Are you trying to communicate a more specific error message?  But you can do that in the exception message text anyway, as you should for all other incorrect parameters.


Fourth, all other incorrect parameter data will be IAE, so why not be consistent?  Why is it that an illegal null is so special that it deserves a separate exception from all other types of illegal arguments?


Finally, I accept the argument given by other answers that parts of the Java API use NPE in this manner.  However, the Java API is inconsistent with everything from exception types to naming conventions, so I think just blindly copying (your favorite part of) the Java API isn't a good enough argument to trump these other considerations.


The standard is to throw the NullPointerException. The generally infallible "Effective Java" discusses this briefly in Item 42 (in the first edition) or Item 60 (in the second edition) "Favor the use of standard exceptions":


"Arguably, all erroneous method
  invocations boil down to an illegal
  argument or illegal state, but other
  exceptions are standardly used for
  certain kinds of illegal arguments and
  states. If a caller passes null in
  some parameter for which null values
  are prohibited, convention dictates
  that NullPointerException be thrown
  rather than IllegalArgumentException."


I was all in favour of throwing IllegalArgumentException for null parameters, until today, when I noticed the java.util.Objects.requireNonNull method in Java 7.  With that method, instead of doing:


you can do:


and it will throw a NullPointerException if the parameter you pass it is null.


Given that that method is right bang in the middle of java.util I take its existence to be a pretty strong indication that throwing NullPointerException is "the Java way of doing things".


I think I'm decided at any rate.


Note that the arguments about hard debugging are bogus because you can of course provide a message to NullPointerException saying what was null and why it shouldn't be null.  Just like with IllegalArgumentException.


One added advantage of NullPointerException is that, in highly performance critical code, you could dispense with an explicit check for null (and a NullPointerException with a friendly error message), and just rely on the NullPointerException you'll get automatically when you call a method on the null parameter.  Provided you call a method quickly (i.e. fail fast), then you have essentially the same effect, just not quite as user friendly for the developer.  Most times it's probably better to check explicitly and throw with a useful message to indicate which parameter was null, but it's nice to have the option of changing that if performance dictates without breaking the published contract of the method/constructor.


I tend to follow the design of JDK libraries, especially Collections and Concurrency (Joshua Bloch, Doug Lea, those guys know how to design solid APIs). Anyway, many APIs in the JDK pro-actively throws NullPointerException. 


For example, the Javadoc for Map.containsKey states:


@throws NullPointerException if the key is null and this map
    does not permit null keys (optional).


It's perfectly valid to throw your own NPE. The convention is to include the parameter name which was null in the message of the exception. 


The pattern goes:


Whatever you do, don't allow a bad value to get set and throw an exception later when other code attempts to use it. That makes debugging a nightmare. You should always the follow the "fail-fast" principle.


Voted up Jason Cohen's argument because it was well presented. Let me dismember it step by step. ;-)


The NPE JavaDoc explicitly says, "other illegal uses of the null object". If it was just limited to situations where the runtime encounters a null when it shouldn't, all such cases could be defined far more succinctly.


Can't help it if you assume the wrong thing, but assuming encapsulation is applied properly, you really shouldn't care or notice whether a null was dereferenced inappropriately vs. whether a method detected an inappropriate null and fired an exception off.


I'd choose NPE over IAE for multiple reasons


Actually, other invalid arguments can result in all kinds of other exceptions. UnknownHostException, FileNotFoundException, a variety of syntax error exceptions, IndexOutOfBoundsException, authentication failures, etc., etc.


In general, I feel NPE is much maligned because traditionally has been associated with code that fails to follow the fail fast principle. That, plus the JDK's failure to populate NPE's with a message string really has created a strong negative sentiment that isn't well founded. Indeed, the difference between NPE and IAE from a runtime perspective is strictly the name. From that perspective, the more precise you are with the name, the more clarity you give to the caller.


It's a "Holy War" style question. In others words, both alternatives are good, but people will have their preferences which they will defend to the death.


If it's a setter method and null is being passed to it, I think it would make more sense to throw an IllegalArgumentException. A NullPointerException seems to make more sense in the case where you're attempting to actually use the null.


So, if you're using it and it's null, NullPointer. If it's being passed in and it's null, IllegalArgument.


Apache Commons Lang has a NullArgumentException that does a number of the things discussed here: it extends IllegalArgumentException and its sole constructor takes the name of the argument which should have been non-null.


While I feel that throwing something like a NullArgumentException or IllegalArgumentException more accurately describes the exceptional circumstances, my colleagues and I have chosen to defer to Bloch's advice on the subject.


The accepted practice if to use the IllegalArgumentException( String message ) to declare a parameter to be invalid and give as much detail as possible... So to say that a parameters was found to be null while exception non-null, you would do something like this:


You have virtually no reason to implicitly use the "NullPointerException". The NullPointerException is an exception thrown by the Java Virtual Machine when you try to execute code on null reference (Like toString()).


Couldn't agree more with what's being said.  Fail early, fail fast.  Pretty good Exception mantra. 


The question about which Exception to throw is mostly a matter of personal taste.  In my mind IllegalArgumentException seems more specific than using a NPE since it's telling me that the problem was with an argument I passed to the method and not with a value that may have been generated while performing the method.


My 2 Cents


Actually, the question of throwing IllegalArgumentException or NullPointerException is in my humble view only a "holy war" for a minority with an incomlete understanding of exception handling in Java. In general, the rules are simple, and as follows:


There are at least three very good reasons against the case of mapping all kinds of argument constraint violations to IllegalArgumentException, with the third probably being so severe as to mark the practice bad style:


(1) A programmer cannot a safely assume that all cases of argument constraint violations result in IllegalArgumentException, because the large majority of standard classes use this exception rather as a wastebasket if there is no more specific kind of exception available. Trying to map all cases of argument constraint violations to IllegalArgumentException in your API only leads to programmer frustration using your classes, as the standard libraries mostly follow different rules that violate yours, and most of your API users will use them as well!


(2) Mapping the exceptions actually results in a different kind of anomaly, caused by single inheritance: All Java exceptions are classes, and therefore support single inheritance only. Therefore, there is no way to create an exception that is truly say both a NullPointerException and an IllegalArgumentException, as subclasses can only inherit from one or the other. Throwing an IllegalArgumentException in case of a null argument therefore makes it harder for API users to distinguish between problems whenever a program tries to programmatically correct the problem, for example by feeding default values into a call repeat!


(3) Mapping actually creates the danger of bug masking: In order to map argument constraint violations into IllegalArgumentException, you'll need to code an outer try-catch within every method that has any constrained arguments. However, simply catching RuntimeException in this catch block is out of the question, because that risks mapping documented RuntimeExceptions thrown by libery methods used within yours into IllegalArgumentException, even if they are no caused by argument constraint violations. So you need to be very specific, but even that effort doesn't protect you from the case that you accidentally map an undocumented runtime exception of another API (i.e. a bug) into an IllegalArgumentException of your API. Even the most careful mapping therefore risks masking programming errors of other library makers as argument constraint violations of your method's users, which is simply hillareous behavior!


With the standard practice on the other hand, the rules stay simple, and exception causes stay unmasked and specific. For the method caller, the rules are easy as well:
- if you encounter a documented runtime exception of any kind because you passed an illegal value, either repeat the call with a default (for this specific exceptions are neccessary), or correct your code
- if on the other hand you enccounter a runtime exception that is not documented to happen for a given set of arguments, file a bug report to the method's makers to ensure that either their code or their documentation is fixed.


I wanted to single out Null arguments from other illegal arguments, so I derived an exception from IAE named NullArgumentException. Without even needing to read the exception message, I know that a null argument was passed into a method and by reading the message, I find out which argument was null. I still catch the NullArgumentException with an IAE handler, but in my logs is where I can see the difference quickly.


Throwing an exception that's exclusive to null arguments (whether NullPointerException or a custom type) makes automated null testing more reliable. This automated testing can be done with reflection and a set of default values, as in Guava's NullPointerTester. For example, NullPointerTester would attempt to call the following method...


...with two lists of arguments: "", null and null, ImmutableList.of(). It would test that each of these calls throws the expected NullPointerException. For this implementation, passing a null list does not produce NullPointerException. It does, however, happen to produce an IllegalArgumentException because NullPointerTester happens to use a default string of "". If NullPointerTester expects only NullPointerException for null values, it catches the bug. If it expects IllegalArgumentException, it misses it.


Some collections assume that null is rejected using NullPointerException rather than IllegalArgumentException. For example, if you compare a set containing null to a set that rejects null, the first set will call containsAll on the other and catch its NullPointerException -- but not IllegalArgumentException. (I'm looking at the implementation of AbstractSet.equals.)


You could reasonably argue that using unchecked exceptions in this way is an antipattern, that comparing collections that contain null to collections that can't contain null is a likely bug that really should produce an exception, or that putting null in a collection at all is a bad idea. Nevertheless, unless you're willing to say that equals should throw an exception in such a case, you're stuck remembering that NullPointerException is required in certain circumstances but not in others. ("IAE before NPE except after 'c'...")


NullPointerException thrown when attempting to access an object with a reference variable whose current value is null


IllegalArgumentException thrown when a method receives an argument formatted differently than the method expects


As an subjective question this should be closed, but as its still open:


This is part of the the internal policy used at my previous place of employment and it worked really well. This is all from memory so I can't remember the exact wording. Its worth noting that they did not use checked exceptions, but that is beyond the scope of the question. The unchecked exceptions they did use fell into 3 main categories.


NullPointerException: Do not throw intentionally. NPEs are to be thrown only by the VM when dereferencing a null reference. All possible effort is to be made to ensure that these are never thrown. @Nullable and @NotNull should be used in conjunction with code analysis tools to find these errors.


IllegalArgumentException: Thrown when an argument to a function does not conform to the public documentation, such that the error can be identified and described in terms of the arguments passed in. The OP's situation would fall into this category.


IllegalStateException: Thrown when a function is called and its arguments are either unexpected at the time they are passed or incompatible with the state of the object the method is a member of.


For example, there were two internal versions of the IndexOutOfBoundsException used in things that had a length. One a sub-class of IllegalStateException, used if the index was larger than the length. The other a subclass of IllegalArgumentException, used if the index was negative. This was because you could add more items to the object and the argument would be valid, while a negative number is never valid.


As I said, this system works really well, and it took someone to explain why the distinction is there: "Depending on the type of error it is quite straight forward for you to figure out what to do. Even if you can't actually figure out what went wrong you can figure out where to catch that error and create additional debugging information."


NullPointerException: Handle the Null case or put in an assertion so that the NPE is not thrown. If you put in an assertion it must one of the other two types. If possible, continue debugging as if the assertion was there in the first place.


IllegalArgumentException: you have something wrong at your callsite. If the values being passed in are from another function, find out why you are receiving an incorrect value. If you are passing in one of your arguments propagate the error checks up the call stack until you find the function that is not returning what you expect.


IllegalStateException: You have not called your functions in the correct order. If you are using one of your arguments, check them and throw an IllegalArgumentException describing the issue. You can then propagate the cheeks up the stack until you find the issue.


Anyway, his point was that you can only copy the IllegalArgumentAssertions up the stack. There is no way for you to propagate the IllegalStateExceptions or NullPointerExceptions up the stack because they had something to do with your function.


In general, a developer should never throw a NullPointerException. This exception is thrown by the runtime when code attempts to dereference a variable who's value is null. Therefore, if your method wants to explicitly disallow null, as opposed to just happening to have a null value raise a NullPointerException, you should throw an IllegalArgumentException.


the dichotomy... Are they non-overlapping? Only non-overlapping parts of a whole can make a dichotomy. As i see it:


According to your scenario, IllegalArgumentException is the best pick, because null is not a valid value for your property.


Ideally runtime exceptions should not be thrown. A checked exception(business exception) should be created for your scenario. Because if either of these exception is thrown and logged, it misguides the developer while going through the logs. Instead business exceptions do not create that panic and usually ignored while troubleshooting logs.


The definitions from the links to the two exceptions above are
IllegalArgumentException: Thrown to indicate that a method has been passed an illegal or inappropriate argument. 
NullPointerException: Thrown when an application attempts to use null in a case where an object is required.


The big difference here is the IllegalArgumentException is supposed to be used when checking that an argument to a method is valid. NullPointerException is supposed to be used whenever an object being "used" when it is null.


I hope that helps put the two in perspective.


If it's a "setter", or somewhere I'm getting a member to use later, I tend to use IllegalArgumentException.


If it's something I'm going to use (dereference) right now in the method, I throw a NullPointerException proactively. I like this better than letting the runtime do it, because I can provide a helpful message (seems like the runtime could do this too, but that's a rant for another day).


If I'm overriding a method, I use whatever the overridden method uses.


You should throw an IllegalArgumentException, as it will make it obvious to the programmer that he has done something invalid.  Developers are so used to seeing NPE thrown by the VM, that any programmer would not immediately realize his error, and would start looking around randomly, or worse, blame your code for being 'buggy'.


In this case, IllegalArgumentException conveys clear information to the user using your API that the " should not be null". As other forum users pointed out you could use NPE if you want to as long as you convey the right information to the user using your API. 


GaryF and tweakt dropped "Effective Java" (which I swear by) references which recommends using NPE. And looking at how other good APIs are constructed is the best way to see how to construct your API.


Another good example is to look at the Spring APIs. For example, org.springframework.beans.BeanUtils.instantiateClass(Constructor ctor, Object[] args) has a Assert.notNull(ctor, "Constructor must not be null") line. org.springframework.util.Assert.notNull(Object object, String message) method checks to see if the argument (object) passed in is null and if it is it throws a new IllegalArgumentException(message) which is then caught in the org.springframework.beans.BeanUtils.instantiateClass(...) method.


If you choose to throw a NPE and you are using the argument in your method, it might be redundant and expensive to explicitly check for a null. I think the VM already does that for you.






Given an array of n Objects, let's say it is an array of strings, and it has the following values:


What do I have to do to delete/remove all the strings/objects equal to "a" in the array?


[If you want some ready-to-use code, please scroll to my "Edit3" (after the cut). The rest is here for posterity.]


To flesh out Dustman's idea:


Edit: I'm now using Arrays.asList instead of Collections.singleton: singleton is limited to one entry, whereas the asList approach allows you to add other strings to filter out later: Arrays.asList("a", "b", "c").


Edit2: The above approach retains the same array (so the array is still the same length); the element after the last is set to null. If you want a new array sized exactly as required, use this instead:


Edit3: If you use this code on a frequent basis in the same class, you may wish to consider adding this to your class:


Then the function becomes:


This will then stop littering your heap with useless empty string arrays that would otherwise be newed each time your function is called.


cynicalman's suggestion (see comments) will also help with the heap littering, and for fairness I should mention it:


I prefer my approach, because it may be easier to get the explicit size wrong (e.g., calling size() on the wrong list).


Make a List out of the array with Arrays.asList(), and call remove() on all the appropriate elements. Then call toArray() on the 'List' to make back into an array again.


Not terribly performant, but if you encapsulate it properly, you can always do something quicker later on.


An alternative in Java 8: 


You can always do:


See code below


You can use external library:


It is in project Apache Commons Lang http://commons.apache.org/lang/


Something about the make a list of it then remove then back to an array strikes me as wrong.  Haven't tested, but I think the following will perform better.  Yes I'm probably unduly pre-optimizing.


If you need to remove multiple elements from array without converting it to List nor creating additional array, you may do it in O(n) not dependent on count of items to remove.


Here, a is initial array, int... r are distinct ordered indices (positions) of elements to remove:


Small testing:


In your task, you can first scan array to collect positions of "a", then call removeItems().  


I realise this is a very old post, but some of the answers here helped me out, so here's my tuppence' ha'penny's worth!


I struggled getting this to work for quite a while before before twigging that the array that I'm writing back into needed to be resized, unless the changes made to the ArrayList leave the list size unchanged.


If the ArrayList that you're modifying ends up with greater or fewer elements than it started with, the line List.toArray() will cause an exception, so you need something like List.toArray(new String[] {}) or List.toArray(new String[0]) in order to create an array with the new (correct) size.


Sounds obvious now that I know it.  Not so obvious to an Android/Java newbie who's getting to grips with new and unfamiliar code constructs and not obvious from some of the earlier posts here, so just wanted to make this point really clear for anybody else scratching their heads for hours like I was!


EDIT:


The point with the nulls in the array has been cleared. Sorry for my comments. 


Original:


Ehm... the line


replaces all gaps in the array where the removed element has been with null. This might be dangerous, because the elements are removed, but the length of the array remains the same!


If you want to avoid this, use a new Array as parameter for toArray(). If you don`t want to use removeAll, a Set would be an alternative:


Gives:


Where as the current accepted answer from Chris Yester Young outputs:


with the code


without any null values left behind.


My little contribution to this problem.


}


There are a lot of answers here--the problem as I see it is that you didn't say WHY you are using an array instead of a collection, so let me suggest a couple reasons and which solutions would apply (Most of the solutions have already been answered in other questions here, so I won't go into too much detail):


reason:     You didn't know the collection package existed or didn't trust it


solution:   Use a collection.  


If you plan on adding/deleting from the middle, use a LinkedList.  If you are really worried about size or often index right into the middle of the collection use an ArrayList.  Both of these should have delete operations.


reason:    You are concerned about size or want control over memory allocation


solution:  Use an ArrayList with a specific initial size.


An ArrayList is simply an array that can expand itself, but it doesn't always need to do so.  It will be very smart about adding/removing items, but again if you are inserting/removing a LOT from the middle, use a LinkedList.


reason:    You have an array coming in and an array going out--so you want to operate on an array


solution:  Convert it to an ArrayList, delete the item and convert it back


reason:   You think you can write better code if you do it yourself


solution: you can't, use an Array or Linked list.


reason: this is a class assignment and you are not allowed or you do not have access to the collection apis for some reason


assumption: You need the new array to be the correct "size"


solution:
Scan the array for matching items and count them.  Create a new array of the correct size (original size - number of matches).  use System.arraycopy repeatedly to copy each group of items you wish to retain into  your new Array.  If this is a class assignment and you can't use System.arraycopy, just copy them one at a time by hand in a loop but don't ever do this in production code because it's much slower.  (These solutions are both detailed in other answers)


reason:     you need to run bare metal


assumption: you MUST not allocate space unnecessarily or take too long


assumption: You are tracking the size used in the array (length) separately because otherwise you'd have to reallocate your array for deletes/inserts.


An example of why you might want to do this: a single array of primitives (Let's say int values) is taking a significant chunk of your ram--like 50%!  An ArrayList would force these into a list of pointers to Integer objects which would use a few times that amount of memory.


solution:   Iterate over your array and whenever you find an element to remove (let's call it element n),  use System.arraycopy to copy the tail of the array over the "deleted" element (Source and Destination are same array)--it is smart enough to do the copy in the correct direction so the memory doesn't overwrite itself:


You'll probably want to be smarter than this if you are deleting more than one element at a time.  You would only move the area between one "match" and the next rather than the entire tail and as always, avoid moving any chunk twice.


In this last case, you absolutely must do the work yourself, and using System.arraycopy is really the only way to do it since it's going to choose the best possibly way to move memory for your computer architecture--it should be many times faster than any code you could reasonably write yourself.


It depends on what you mean by "remove"? An array is a fixed size construct - you can't change the number of elements in it. So you can either a) create a new, shorter, array without the elements you don't want or b) assign the entries you don't want to something that indicates their 'empty' status; usually null if you are not working with primitives.


In the first case create a List from the array, remove the elements, and create a new array from the list. If performance is important iterate over the array assigning any elements that shouldn't be removed to a list, and then create a new array from the list. In the second case simply go through and assign null to the array entries.


Arrgh, I can't get the code to show up correctly. Sorry, I got it working. Sorry again, I don't think I read the question properly.


Will copy all elements except the one with index i:


Use: 


Assign null to the array locations.






This is similar to this question:
How to convert int[] to Integer[] in Java?


I'm new to Java. How can i convert a List<Integer> to int[] in Java? I'm confused because List.toArray() actually returns an Object[], which can be cast to nether Integer[] or int[].


Right now I'm using a loop to do so:


I'm sure there's a better way to do this.


Unfortunately, I don't believe there really is a better way of doing this due to the nature of Java's handling of primitive types, boxing, arrays and generics. In particular:


I believe there are libraries which have autogenerated versions of this kind of method for all the primitive types (i.e. there's a template which is copied for each type). It's ugly, but that's the way it is I'm afraid :(


Even though the Arrays class came out before generics arrived in Java, it would still have to include all the horrible overloads if it were introduced today (assuming you want to use primitive arrays).


No one mentioned yet streams added in Java 8 so here it goes:


Thought process: 


so now only thing we need to figure out is how to convert our Stream<Integer> (which will be returned from list.stream()) to that shiny IntStream. Here mapToInt method comes to rescue. All we need to do is provide some mapping from Integer to int. We could use something like Integer#getValue which returns int:


mapToInt( (Integer i) -> i.intValue()) 


(or if someone prefers   mapToInt(Integer::intValue) )


but similar code can be generated using unboxing, since compiler knows that result of this lambda must be int (lambda in mapToInt is implementation of ToIntFunction interface which expects body for int applyAsInt(T value) method which is expected to return int).  


So we can simply write


mapToInt((Integer i)->i)


or simpler (since Integer i type can be inferred by compiler because List<Integer>#stream() returns Stream<Integer>)


mapToInt(i -> i) 


In addition to Commons Lang, you can do this with Guava's method Ints.toArray(Collection<Integer> collection):


This saves you having to do the intermediate array conversion that the Commons Lang equivalent requires yourself.


The easiest way to do this is to make use of Apache Commons Lang.  It has a handy ArrayUtils class that can do what you want.  Use the toPrimitive method with the overload for an array of Integers.


This way you don't reinvent the wheel.  Commons Lang has a great many useful things that Java left out.  Above, I chose to create an Integer list of the right size.  You can also use a 0-length static Integer array and let Java allocate an array of the right size:


Slight change to your code to avoid expensive list indexing (since a List is not necessarily an ArrayList, but could be a linked list, for which random access is expensive)


Here is Java 8 single line code for this


Java 8 has given us a easy way to do this via streams...


Using the collections stream() function and then mapping to ints, you'll get an IntStream. With the IntStream we can call toArray() which gives us int []


to int []


to IntStream


I'll throw one more in here. I've noticed several uses of for loops, but you don't even need anything inside the loop. I mention this only because the original question was trying to find less verbose code.


If Java allowed multiple declarations in a for loop the way C++ does, we could go a step further and do for(int i = 0, Iterator it...


In the end though (this part is just my opinion), if you are going to have a helping function or method to do something for you, just set it up and forget about it. It can be a one-liner or ten; if you'll never look at it again you won't know the difference.


This simple loop is always correct! no bugs


If you are simply mapping an Integer to an int then you should consider using parallelism, since your mapping logic does not rely on any variables outside its scope.


Just be aware of this 


Note that parallelism is not automatically faster than performing operations serially, although it can be if you have enough data and processor cores. While aggregate operations enable you to more easily implement parallelism, it is still your responsibility to determine if your application is suitable for parallelism.


There are two ways to map Integers to their primitive form:


Via a ToIntFunction.


Via explicit unboxing with lambda expression.


Via implicit (auto-) unboxing with lambda expression.


Given a list with a null value


Here are three options to handle null:


Filter out the null values before mapping.


Map the null values to a default value.


Handle null inside the lambda expression.


There is really no way of "one-lining" what you are trying to do because toArray returns an Object[] and you cannot cast from Object[] to int[] or Integer[] to int[]


try also Dollar (check this revision):


Using a lambda you could do this (compiles in jdk lambda):


I would recommend you to use List<?> skeletal implementation from the java collections API, it appears to be quite helpful in this particular case:


Beware of boxing/unboxing drawbacks


With Eclipse Collections, you can do the following if you have a list of type  java.util.List<Integer>:


If you already have an Eclipse Collections type like MutableList, you can do the following:


Note: I am a committer for Eclipse Collections






When I try opening Eclipse, a pop-up dialog states:


Failed to load the JNI shared library "C:/JDK/bin/client/jvm.dll"`.


Following this, Eclipse force closes.


Here's a few points I'd like to make:  


Downloading the 32-bit versions is something I only want to do as a very last resort.
What would be suggested to solve this issue?


You need a 64-bit trio: 


I had several JDKs and JREs installed.


Each of them had their own entry in the PATH variable, all was working more or less.


Judging from the PATH variables, some installations were completely useless, since they were never used. Of course, the "inactive" Javas could be referenced manually from within Eclipse if I needed, but I never did that, so I really did not need them. (At least I thought so at that time...)


I cleaned up the mess, deinstalled all current Java's, installed only JDK + JRE 1.7 64-bit. 


One of the Eclipse 'installations' failed afterwards with the Failed to Load the JNI shared Library and a given path relative to the fresh installed JDK where it thought the jvm.dll to be.


The failing Eclipse was the only one of all my IDEs that was still a 32-bit version on my otherwise all-64-bit setup.


Make sure your eclipse.ini file includes the following lines.


My eclipse.ini for example:


Use OS and Eclipse both 64 bit or both 32 bit keep same and config eclipse.ini.


Your eclipse.ini file can be found in your eclipse folder.


I had same problem


I resolved it by installing 64 bit JVM from 


http://www.java.com/en/download/manual.jsp


Another option is:


Create a shortcut to the Eclipse.exe. Open the shortcut and change the target to:


For your installation, make sure the locations point to the correct Eclipse installation directory and the correct javaw.exe installation directory. 


(The 64/32 bit versions of Eclipse and Java need to be the same, of course.)


I have multiple versions of Java installed, both Sun JDK & JRockit, both 32 bit and 64-bit, etc. and ran into this problem with a fresh install of 64-bit Eclipse for Java EE (JUNO). 


64-bit trio as suggested by Peter Rader: 


I'm using 64-bit Eclipse on 64-bit OS (Windows 7). 


I ensured Sun JDK 7 64-bit was the default java version.  When I typed "java -version" from command line (cmd.exe), Sun JDK 7 64-bit was returned...


This did not resolve the problem for me.


Adding -vm option to eclipse.ini as suggested by Jayesh Kavathiya: 


I added the following to eclipse.ini:


I did not have to uninstall any of the various versions of JDK or JRE I have on my machine.


This error means that the architecture of Eclipse does not match the architecture of the Java runtime, i.e. if one is 32-bit the other must be the same, and not 64-bit.


The most reliable fix is to specify the JVM location in eclipse.ini:


Important: These two lines must come before -vmargs. Do not use quotes; spaces are allowed.


For a missing jvm.dll file, we can provide the path of the dll file in eclipse.ini file as


Here it is important to remove any space in the path and the double quotes.
It worked for me when i removed the quotes and space.


I hope it helps someone.


I had a similar problem. It was solved doing the following.


I have both versions of Java installed, but Eclipse kept trying to use the 32-bit one.


Sure, you need to have a compatible version of JDK and Eclipse, but you also need to add in the eclipse.ini file the below lines:


Make them the first two lines of your eclipse.ini file.


As many folks already alluded to, this is a 32 vs. 64 bit problem for both Eclipse and Java. You cannot mix up 32 and 64 bit. Since Eclipse doesn't use JAVA_HOME, you'll likely have to alter your PATH prior to launching Eclipse to ensure you are using not only the appropriate version of Java, but also if 32 or 64 bit (or modify the INI file as Jayath noted).  


If you are installing Eclipse from a company-share, you should ensure you can tell which Eclipse version you are unzipping, and unzip to the appropriate Program Files directory to help keep track of which is which, then change the PATH (either permanently via (Windows) Control Panel -> System or set PATH=/path/to/32 or 64bit/java/bin;%PATH% (maybe create a batch file if you don't want to set it in your system and/or user environment variables). Remember, 32-bit is in Program files (x86).


If unsure, just launch Eclipse, if you get the error, change your PATH to the other 'bit' version of Java, and then try again. Then move the Eclipse directory to the appropriate Program Files directory.


Alternatively, get the same "bit" version of JRE and Eclipse and then create a new shortcut with the below target (replace the installed JRE and Eclipse location/path):


That should do the trick.


You can solve that problem as many other replicated. You need that Eclipse and the JDK be 32-bits or both on 64-bits. The architecture of the OS doesn't matter while the others remains on the same type of arquitecture.


The answers above me got me tempted so much, that I decided to dry run all the possible combinations with OS, Eclipse and JVM trio. Anyway, whoever is digging down and reading my post, check the following as a hot spot (I am Windows 7 user).


You understand Program Files and Program File (x86) are two different folders... x86 stands for the 32-bit version of programs and the former is the 64-bit version.


If you have multiple versions of Java installed with different bitness and release versions, which is bound to happen with so many open source IDEs, managers, administrative consoles, the best option is to set the VM argument directly in the eclipse.ini file. If you don't, Eclipse will go crazy and try searching itself which is not good.


One of the easy ways to resolve it is to copy the jre folder from installed the JDK into the Eclipse installation folder. Make sure that JDK you copy from is the same architecture as your Eclipse installation.


I had to configure my machine that way, because I run both Eclipse and Appcelerator Titanium Studio on my machine. The Studio needs 32-bit Java, while Eclipse needs 64-bit.


Yes, just make sure your versions of Eclipse and JDK are both 64-bit. Just to make sure everything is correct uninstalled JDK and install it in Program Files and not in Program Files (x86). At least that resolved my problem.


You should uninstall all old [JREs][1] and then install the newest one... I had the same problem and now I solve it. I've:


Better install Jre 6 32 bit. It really works.


Downloaded 64 bit JVM from site and installed it manually and updated the system path variable. That solved the issue. 


Thank you misterfrb, I realised that Eclipse was giving this error, because I had just installed Oracle 10g Developer suite, and it was looking for the jvm.dll file in the C:\DevSuiteHome_1 folder (I must have opted to install JDK again along with developer suite). 


After removing the DevSuiteHome lines from the paths variable and adding the correction location for 64-bit jvm.dll (not sure if this was necessary, didn't try without), Eclipse worked again, and Developer suite still does too.


Just check the PATH environment variable. In My Computer - > Properties -> Advanced System settings -> Environment Variables -> (left upper window "User Variables for "some name of PC"" ) just check the PATH variable. If it doesn't exist create it with the following -- > C:\Program Files (x86)\Java\jre7\bin <--


I was faced with the same problem after had updated my Eclipse. I've found that the path asked 64-bit version, but I had the 32-bit in dif path. It was helpful for me. P.S.: I have a 64-bit OS, 32-bit JRE and 32-bit Eclipse. All works fine :)


Simple, I have a 64-bit OS, 32-bit Eclipse and both JDK 32 & 64 installed... I just uninstalled the 64-bit JDK and Eclipse is working fine..


I had the same issue after upgrading from Java 6 to Java 7. After I removed Java 6 (64 bit) and reinstalled Java 7 (64 bit), Eclipse worked. :)


Make sure you are starting Eclipse with Administrator rights.


It is crucial to add the -vm parameter and its value on 2 lines AT THE BEGINNING of the eclipse.ini


-vm
C:\Program Files\Java\jdk1.7.0_45\bin\javaw.exe


You can install the 32-bit version of JDK on a 64-bit machine. See JDK 7 downloads.


And for PDT users - avoid the Zend download page - it doesn't have any 64-bit downloads linked.


Use the Elipse site itself.


The above link had an older 3.6 Eclipse which then failed to update itself due to Eclipse Bug #317785.


My solution was to just install 32-bit Java alongside 64-bit - this allowed the Zend installer to work.


It's depressing that amount of Java / Eclipse cruft one has to go through to get a PHP IDE.


If you use whole 64-bit trio and it still doesn't work (I've come to this problem while launching Android Monitor in Intellij Idea), probably wrong jvm.dll is being used opposed to what your java expects. Just follow these steps:


Find the jvm.dll in your JRE directory:
C:\Program Files\Java\jre7\server\bin\jvm.dll


Find the jvm.dll in your JDK directory:
c:\Program Files\Java\jdk1.7.0_xx\jre\bin\server\


Copy the jvm.dll from JRE drectory into your JDK directory and overwrite the jvm.dll in JDK.


Don't forget to make a backup, just in case. No need to install or uninstall anything related to Java.


The same occurred to me. I had 64-bit Eclipse, but my JDK was 32-bit. So I installed the 64-bit version and it's OK right now.


I'm not sure why but I had the jre installed into my c:\windows directory and java.exe and javaw.exe inside my windows\system32 directory.


Obviously these directories were getting priority even AFTER adding the -vm flag to my eclipse.ini file.


Delete them from here fixed the issue for me.


You have change proper version of the JAVA_HOME and PATH in environmental variables.






I'm confused about this. Most of us have been told that there isn't any goto statement in Java.


But I found that it is one of the keywords in Java. Where can it be used? If it can not be used, then why was it included in Java as a keyword?


The Java keyword list specifies the goto keyword, but it is marked as "not used".


It was in the original JVM (see answer by @VitaliiFedorenko), but then removed. It was probably kept as a reserved keyword in case it were to be added to a later version of Java.


If goto was not on the list, and it gets added to the language later on, existing code that used the word goto as an identifier (variable name, method name, etc...) would break. But because goto is a keyword, such code will not even compile in the present, and it remains possible to make it actually do something later on, without breaking existing code.


James Gosling created the original JVM with support of goto statements, but then he removed this feature as needless. The main reason goto is unnecessary is that usually it can be replaced with more readable statements (like break/continue) or by extracting a piece of code into a method.


Source: James Gosling, Q&A session


To prevent people from being killed by velociraptors.





The keyword exists, but it is not implemented.


The only good reason to use goto that I can think of is this:


In Java you can do this like this:


http://java.sun.com/docs/books/tutorial/java/nutsandbolts/_keywords.html


"The keywords const and goto are
  reserved, even though they are not
  currently used. "


So they could be used one day if the language designers felt the need.


Also, if programmers from languages that do have these keywords (eg. C, C++) use them by mistake, then the Java compiler can give a useful error message.


Or maybe it was just to stop programmers using goto :)


They are reserved for future use (see: Java Language Keywords)


The keywords const and goto are reserved, even though they are not currently used.


The reason why there is no goto statement in Java can be found in "The Java Language Environment":


Java has no goto statement. Studies illustrated that goto is (mis)used more often than not simply "because it's there". Eliminating goto led to a simplification of the language--there are no rules about the effects of a goto into the middle of a for statement, for example. Studies on approximately 100,000 lines of C code determined that roughly 90 percent of the goto statements were used purely to obtain the effect of breaking out of nested loops. As mentioned above, multi-level break and continue remove most of the need for goto statements.


An example of how to use "continue" labels in Java is:


Results:


No, goto is not used, but you can define labels and leave a loop up to the label. You can use break or continue followed by the label. So you can jump out more than one loop level. Have a look at the tutorial.


It is important to understand that the goto construct is remnant from the days that programmers programmed in machine code and assembly language.  Because those languages are so basic (as in, each instruction does only one thing), program control flow is done completely with goto statements (but in assembly language, these are referred to as jump or branch instructions).  


Now, although the C language is fairly low-level, it can be thought of as very high-level assembly language - each statement and function in C can easily be broken down into assembly language instructions.  Although C is not the prime language to program computers with nowadays, it is still heavily used in low level applications, such as embedded systems.  Because C's function so closely mirrors assembly language's function, it only makes sense that goto is included in C.


It is clear that Java is an evolution of C/C++.  Java shares a lot of features from C, but abstracts a lot more of the details, and therefore is simply written differently.  Java is a very high-level language, so it simply is not necessary to have low-level features like goto when more high-level constructs like functions, for, for each, and while loops do the program control flow.  Imagine if you were in one function and did a goto to a label into another function.  What would happen when the other function returned?  This idea is absurd.  


This does not necessarily answer why Java includes the goto statement yet won't let it compile, but it is important to know why goto was ever used in the first place, in lower-level applications, and why it just doesn't make sense to be used in Java.


Java has GOTO at the bytecode level as goto and goto_w. However, in the Java language there is no GOTO.


Although Java bans GOTO, Microsoft decided to keep it in the .NET arsenal. C# does allow the GOTO:


goto (C# Reference)


The goto statement transfers the program control directly to a labeled
  statement. A common use of goto is to transfer control to a specific
  switch-case label or the default label in a switch statement. The goto
  statement is also useful to get out of deeply nested loops.


Given that C# (Java's main competitor in .NET) allows GOTO, I do not see why it would be such a big deal if Java had it too.


There are workarounds, such as this project:


JavaGoto


It does come in handy when converting legacy code. For example, some legacy Fortran code is so convoluted that keeping the GOTOs intact may be the most efficient solution before migrating the code to proper constructs.


The allowance of Goto in C# has not resulted in the abuse of GOTO, and I doubt that Java would be any worse off if they had allowed it too.


Because it's not supported and why would you want a goto keyword that did nothing or a variable named goto?


Although you can use break label; and continue label; statements to effectively do what goto does. But I wouldn't recommend it.


No, thankfully, there isn't goto in Java.


The goto keyword is only reserved, but not used (the same goes for const).


No, goto is not used in Java, despite being a reserved word. The same is true for const. Both of these are used in C++, which is probably the reason why they're reserved; the intention was probably to avoid confusing C++ programmers migrating to Java, and perhaps also to keep the option of using them in later revisions of Java.


As was pointed out, there is no goto in Java, but the keyword was reserved in case Sun felt like adding goto to Java one day. They wanted to be able to add it without breaking too much code, so they reserved the keyword. Note that with Java 5 they added the enum keyword and it did not break that much code either.


Although Java has no goto, it has some constructs which correspond to some usages of goto, namely being able to break and continue with named loops. Also, finally can be thought of as a kind of twisted goto.


http://docs.oracle.com/javase/specs/jvms/se7/html/jvms-6.html#jvms-6.5.goto


If you have been told that there is no goto statement in Java you have been fooled. Indeed, Java consists two layers of 'source' code.


I'm not a fan of goto either, as it usually makes code less readable. However I do believe that there are exceptions to that rule (especially when it comes to lexers and parsers!)


Of Course you can always bring your program into Kleene Normalform by translating it to something assembler-like and then write something like


(So you basically write a VM that executes your binary code... where line corresponds to the instruction pointer)


That is so much more readable than code that uses goto, isn't it?


To prohibit declarations of variables with the same name.


e.g. 
int i = 0, goto;


It's very much considered one of those things you Do Not Do, but was probably listed as a reserved word to avoid confusion for developers.


Because although the Java language doesn't use it, JVM bytecode does.


Note that you can replace most of the benign uses of goto by


return


break


break label


throw inside try-catch-finally


See the following link is shows all java reserved words and tells you what versions they where added.


http://java.sun.com/docs/books/tutorial/java/nutsandbolts/_keywords.html


goto is reserved, even though it is not currently used, never say never however :)


Of course it is keyword, but it is not used on level of source code.


But if you use jasmin or other lower level language, which is transformed to bytecode, then "goto" is there


goto is not in Java


you have to use  GOTO
But it don't work correctly.in key java word it is not used.
http://docs.oracle.com/javase/tutorial/java/nutsandbolts/_keywords.html






We can put code in a constructor or a method or an initialization block. What is the use of initialization block? Is it necessary that every java program must have it? 


First of all, there are two types of initialization blocks:


This code should illustrate the use of them and in which order they are executed:


Prints:


Instance itialization blocks are useful if you want to have some code run regardless of which constructor is used or if you want to do some instance initialization for anonymous classes.


would like to add to @aioobe's answer


Order of execution:


static initialization blocks of super classes


static initialization blocks of the class


instance initialization blocks of super classes


constructors of super classes


instance initialization blocks of the class


constructor of the class.


A couple of additional points to keep in mind (point 1 is reiteration of @aioobe's answer):


The code in static initialization block will be executed at class load time (and yes, that means only once per class load), before any instances of the class are constructed and before any static methods are called.


The instance initialization block is actually copied by the Java compiler into every constructor the class has. So every time the code in instance initialization block is executed exactly before the code in constructor.


nice answer by aioobe
adding few more points


this gives 


its like stating the obvious but seems a little more clear.


The sample code, which is approved as an answer here is correct, but I disagree with it. It does not shows what is happening and I'm going to show you a good example to understand how actually the JVM works:


Before to start commenting on the source code, I'll give you a short explanation of static variables of a class:


First thing is that they are called class variables, they belong to the class not to particular instance of the class. All instances of the class share this static(class) variable. Each and every variable has a default value, depending on primitive or reference type. Another thing is when you reassign the static variable in some of the members of the class (initialization blocks, constructors, methods, properties) and doing so you are changing the value of the static variable not for particular instance, you are changing it for all instances. To conclude static part I will say that the static variables of a class are created not when you instantiate for first time the class, they are created when you define your class, they exist in JVM without the need of any instances. Therefor the correct access of static members from external class (class in which they are not defined) is by using the class name following by dot and then the static member, which you want to access (template: <CLASS_NAME>.<STATIC_VARIABLE_NAME>).


Now let's look at the code above:


The entry point is the main method - there are just three lines of code. I want to refer to the example which is currently approved. According to it the first thing which must be printed after printing "Static Initialization block" is "Initialization block" and here is my disagreement, the non-static initialization block is not called before the constructor, it is called before any initializations of the constructors of the class in which the initialization block is defined. The constructor of the class is the first thing involved when you create an object (instance of the class) and then when you enter the constructor the first part called is either implicit (default) super constructor or explicit super constructor or explicit call to another overloaded constructor (but at some point if there is a chain of overloaded constructors, the last one calls a super constructor, implicitly or explicitly). 


There is polymorphic creation of an object, but before to enter the class B and its main method, the JVM initializes all class(static) variables, then goes through the static initialization blocks if any exist and then enters the class B and starts with the execution of the main method. It goes to the constructor of class B then immediately (implicitly) calls constructor of class A, using polymorphism the method(overridden method) called in the body of the constructor of class A is the one which is defined in class B and in this case the variable named instanceVariable is used before reinitialization. After closing the constructor of class B the thread is returned to constructor of class B but it goes first to the non-static initialization block before printing "Constructor". For better understanding debug it with some IDE, I prefer Eclipse.


Initializer block contains the code that is always executed whenever an instance is created. It is used to declare/initialise the common part of various constructors of a class. 


The order of initialization constructors and initializer block doesn’t matter, initializer block is always executed before constructor. 


What if we want to execute some code once for all objects of a class?


We use Static Block in Java. 


Initialization blocks are executed whenever the class is initialized and before constructors are invoked. They are typically placed above the constructors within braces. It is not at all necessary to include them in your classes.


They are typically used to initialize reference variables. This page gives a good explanation


The question is not entirely clear, but here's a brief description of ways you can initialise data in an object. Let's suppose you have a class A that holds a list of objects.


1) Put initial values in the field declaration:


2) Assign initial values in the constructor:


These both assume that you do not want to pass "data" as a constructor argument.


Things get a little tricky if you mix overloaded constructors with internal data like above. Consider:


Notice that there is a lot of repeated code. You can fix this by making constructors call each other, or you can have a private initialisation method that each constructor calls:


or


The two are (more or less) equivalent.


I hope that gives you some hints on how to initialise data in your objects. I won't talk about static initialisation blocks as that's probably a bit advanced at the moment.


EDIT: I've interpreted your question as "how do I initialise my instance variables", not "how do initialiser blocks work" as initialiser blocks are a relatively advanced concept, and from the tone of the question it seems you're asking about the simpler concept. I could be wrong.


To know the use of static Initialization block , refer the Class.forName source code also this article of it's use http://cephas.net/blog/2005/07/31/java-classfornamestring-classname-and-jdbc/  , they use initialization block for dynamic class loading. 


Output:


An initializer block is defined within a class, not as a part of a method. It executes for every object that’s created for a class. In the following example, the class Employee defines an initializer block:






In Java, I have text from a text field in a String variable called "text".


How can I save the contents of the "text" variable to a file?


If you're simply outputting text, rather than any binary data, the following will work:


Then, write your String to it, just like you would to any output stream:


You'll need exception handling, as ever. Be sure to call out.close() when you've finished writing.


If you are using Java 7 or later, you can use the "try-with-resources statement" which will automatically close your PrintStream when you are done with it (ie exit the block) like so:


You will still need to explicitly throw the java.io.FileNotFoundException as before.


Apache Commons IO contains some great methods for doing this, in particular FileUtils contains the following method:


which allows you to write text to a file in one method call:


You might also want to consider specifying the encoding for the file as well.


Just did something similar in my project. Use FileWriter will simplify part of your job. And here you can find nice tutorial.


Take a look at the Java File API


a quick example:


Use FileUtils.writeStringToFile() from Apache Commons IO. No need to reinvent this particular wheel.


In Java 7 you can do this:


There is more info here:
http://www.drdobbs.com/jvm/java-se-7-new-file-io/231600403


You can use the modify the code below to write your file from whatever class or function is handling the text.  One wonders though why the world needs a new text editor...


Use Apache Commons IO api. Its simple 


Use API as


Maven Dependency


You can insert this method into your classes. If you are using this method in a class with a main method, change this class to static by adding the static key word. Either way you will need to import java.io.* to make it work otherwise File, FileWriter and BufferedWriter will not be recognized. 


I prefer to rely on libraries whenever possible for this sort of operation. This makes me less likely to accidentally omit an important step (like mistake wolfsnipes made above). Some libraries are suggested above, but my favorite for this kind of thing is Google Guava. Guava has a class called Files which works nicely for this task:


You could do this:


Use this, it is very readable:


Using Java 7:


Using org.apache.commons.io.FileUtils:


In case if you need create text file based on one single string:


If you only care about pushing one block of text to file, this will overwrite it each time.


This example allows the user to select a file using a file chooser.


It's better to close the writer/outputstream in a finally block, just in case something happen


You can use the ArrayList to put all the contents of the TextArea for exemple, and send as parameter by calling the save, as the writer just wrote string lines, then we use the "for" line by line to write our ArrayList in the end we will be content TextArea in txt file. if something does not make sense, I'm sorry is google translator and I who do not speak English.


Watch the Windows Notepad, it does not always jump lines, and shows all in one line, use Wordpad ok.


private void SaveActionPerformed(java.awt.event.ActionEvent evt) {


} 


public void SaveFile(String name, ArrayList< String> message) {


}






I'm trying to configure my e-mail on Jenkins/Hudson and I constantly receive the error


I've seen a good amount of information online about the error, but have not gotten any to work.  I'm using Sun's JDK on fedora linux (not openJDK).  


Here are a few things I've tried.  I tried following the advice from this post but it copying the cacerts from windows over to my Fedora box hosting Jenkins didn't work.  I tried following this guide as I'm trying to configure gmail as my SMTP server but it didn't work either.  I also tried to download and move those cacert files manually and move them over to my java folder using a variation of the commands on this guide.


I open to any suggestions as I'm currently stuck right now.  I have gotten it to work from a Windows Hudson server but I am struggling on Linux.


This bizarre message means that the truststore you specified was not found, or couldn't be opened due to access permissions for example.


See also @AdamPlumb's answer below.


This fixed the problem for me on Ubuntu:


(found here: https://bugs.launchpad.net/ubuntu/+source/ca-certificates-java/+bug/1396760)


ca-certificates-java is not a dependency in the Oracle JDK/JRE so this must be explicitly installed.


I ran into this solution from http://architecturalatrocities.com/post/19073788679/fixing-the-trustanchors-problem-when-running-openjdk-7:


Fixing the trustAnchors problem when running OpenJDK 7 on OS X. If you're running OpenJDK 7 on OS X and have seen this exception:


There's a simple fix, just link in the same cacerts file that Apple’s JDK 1.6 uses:


You need to do this for every OpenJDK version you have installed, just change -v 1.7 to the version you want to fix. Run /usr/libexec/java_home -V to see all the JREs and JDKs you have installed.


Perhaps the OpenJDK guys could add this to their install scripts.


EJP basically answered the question (and I realize this has an accepted answer) but I just dealt with this edge-case gotcha and wanted to immortalize my solution.  I had the InvalidAlgorithmParameterException error on a hosted jira server that I had previously set up for SSL-only access.  The issue was that I had set up my keystore in the PKCS#12 format, but my truststore was in the JKS format.  In my case, I had edited my server.xml file to specify the keystoreType to PKCS, but did not specify the truststoreType, so it defaults to whatever the keystoreType is.  Specifying the truststoreType explicitly as JKS solved it for me.


I ran into this exact problem on OSX, using JDK 1.7, after upgrading to Maverick. The fix that worked for me was to simply re-install the Apple version of Java, available here: http://support.apple.com/kb/DL1572


In Ubuntu >= 12.10, the certificates are held in the ca-certificates-java package. Using -Djavax.net.ssl.trustStore=/etc/ssl/certs/java/cacerts will pick them up regardless of what JDK you're using.


Ran 


to create cert file then 


and I was back in business thanks guys, a pity it's not included in the installation but got there in the end.


I've had lot of security issues after upgrading to OSX Mavericks


I applied this JAVA update and it fixed all my issues: http://support.apple.com/kb/DL1572?viewlocale=en_US


I expected things like this, being that I use an alternate jvm in my Talend Open Studio. (support at the moment exists only until jdk1.7) i use 8 for security purposes... anyway


sudo update-ca-certificates -f


then 


sudo gedit $(path to your architecture specific ini i.e. TOS_DI...ini) 


-Djavax.net.ssl.trustStore=/etc/ssl/certs/java/cacerts


-Djavax.net.ssl.trustAnchors=/etc/ssl/certs/java/cacerts


for me, the second entry worked. I think, depending on the version of TOS/TEnt + jvm, it has a different parameter name, but looks for the same keystore file 


For me it was caused by the lack of a trustedCertEntry in the truststore


To test use keytool -list -keystore keystore.jks


Gives me


Even though my PrivateKeyEntry contains a CA it needed to be imported separately


imports the certificate, and then re-running keytool -list -keystore keystore.jks now gives


Now it has a trustedCertEntry tomcat will start successfully.


Also encountered this on OS X after updating Mavericks, when the old Java 6 was being used and tried to access an https URL. Fix was the inverse of Peter Kriens, I needed to copy the cacerts from the 1.7 space to the location linked by the 1.6 version:


If you experience this on Ubuntu with JDK9 and Maven, you can add this JVM option - first check if the path exists:


If the file is missing, try to install the ca-certificates-java as someone noted:


In my case the JKS file used in client application was corrupted. I created new one and import the destination server SSL certificates in it. Then I use the new JKS file in the client application as trust store like :


Source: java SSL and cert keystore


I use the (KeyStore Explorer) tool to create the new JKS. You can downloaded from this link KeyStore Explorer


The error tells that the system cannot find the truststore in the path provided with the parameter javax.net.ssl.trustStore.


Under Windows I copied the cacerts file from jre/lib/security location into the eclipse install directory (same place as eclipse.ini file) and added the following settings in eclipse.ini:


Had some troubles with the path to the cacerts (the %java_home% env variable is somehow overwritten), so I used this trivial solve.


The idea is to provide a valid path to the truststore file - ideally would be to use a relative one. You may also use an absolute path.


To make sure the store type is JKS, you would run the following command:


keytool -list -keystore cacerts


You have to add above two lines in your code. It is not able to find the truststore.


For the record, none of the answers here worked for me.  My gradle build started failing mysteriously with this error, unable to fetch HEAD from maven central for a particular pom file.


It turned out that I had JAVA_HOME set to my own personal build of OpenJDK, which I had built for debugging a javac issue.  Setting it back to the jdk installed on my system fixed it.


I have faced with the issue while importing a Gradle project in IntelliJ IDEA 14.
A solution was using a local copy of Gradle instead of a wrapper from the project directory.


On RedHat Linux I got this issue resolved by importing the certs to /etc/pki/java/cacerts


The answers here are very helpful for Linux and Mac.


If you're on Windows 10, this problem can be caused by a Java update. These seem to change the directory path of the JRE (even if you have a JDK and JRE installed separately).


What worked for me was creating a symlink (Use MinGW, Cygwin, or your favorite Bash shell for Windows) in the c/Program Files/Java directory with the same name as the pre-update version like this:


That way, your old security settings can find the right path. This is admittedly a hack, but it works.


I got the same error when sending emails, but NOT always. In my case i've changed one line of code to get every time a new Session object:


to 


Since then sending e-mails works every time. This may help someone.


Error i got:


javax.mail.MessagingException: Could not convert socket to TLS;
  nested exception is:  javax.net.ssl.SSLException:
  java.lang.RuntimeException: Unexpected error:
  java.security.InvalidAlgorithmParameterException: the trustAnchors
  parameter must be non-empty   at
  com.sun.mail.smtp.SMTPTransport.startTLS(SMTPTransport.java:1907)     at
  com.sun.mail.smtp.SMTPTransport.protocolConnect(SMTPTransport.java:666)
    at javax.mail.Service.connect(Service.java:317)     at
  javax.mail.Service.connect(Service.java:176)  at
  javax.mail.Service.connect(Service.java:125)  at
  javax.mail.Transport.send0(Transport.java:194)    at
  javax.mail.Transport.send(Transport.java:124)


On Ubuntu:


sudo apt install ca-certificates-java


or


sudo apt-get install ca-certificates-java


sorted it for me.


Another reason for this is its actually valid error. Some nefarious wifi hotspots will mess with certificates and man in the middle attack you to do who knows what (run away!). 


Some large employers will do this same trick, especially in sensitive network zones so they can monitor all the encrypted traffic (not great from end user perspective but there may be good reasons for this). 


I got this error when using a truststore which was exported using a IBM Websphere JDK keytool in #PKCS12 format and trying to communicate over ssl using that file on an Oracle JRE. My solution was to run on an IBM jre or convert the truststore to JKS using an IBM Websphere keytool so I was able to run it in an Oracle jre.


In my case I was configuring a server for two way security, I didn't put in the keystore a public certificate or authorities certificates to recognize the client part.


I was including only the server private certificate, so the solution in my case was to add a public certificate or the authority certificate.


You may also encounter this error after upgrading to Spring Boot 1.4.1 (or newer) because it brings along Tomcat 8.5.5 as part of it's dependencies. The problem is due to the way that Tomcat deals with the trust store, if you happen to have specified your trust store location as the same as your keystore in the Spring Boot config you'll likely get the trustAnchors parameter must be non-empty message when starting the application.


Simply remove the server.ssl.trust-store configuration unless you know that you need it, in which case consult the links below.


The following issue contain more details about the problem:


I faced this problem while running a particular suite of android for testing on ubuntu 14.04. Two things worked for me as suggested by shaheen


sudo update-ca-certificates -f 


sudo /var/lib/dpkg/info/ca-certificates-java.postinst configure 






I have installed an application, when I try to run it (it's an executable jar) nothing happens. When I run it from the commandline with: 


java -jar "app.jar"


I get the following message:


no main manifest attribute, in "app.jar"


Normally, if I had created the program myself, I would have added a main class attribute to the manifest file. But in this case, since the file is from an application, i cannot do that. I also tried extracting the jar to see if I could find the main class, but there are to many classes and none of them has the word "main" in it's name. There must be a way to fix this because the program runs fine on other systems.


First, it's kind of weird, to see you run java -jar "app" and not java -jar app.jar


Second, to make a jar executable... you need to jar a file called META-INF/MANIFEST.MF


the file itself should have (at least) this one liner:


Where com.mypackage.MyClass is the class holding the public static void main(String[] args) entry point.


Note that there are several ways to get this done either with the CLI, Maven or Ant:


For CLI, the following command will do: (tks @dvvrt)

jar cmvf META-INF/MANIFEST.MF <new-jar-filename>.jar  <files to include>



For Maven, something like the following snippet should do the trick. Note that this is only the plugin definition, not the full pom.xml:


(Pick a <version> appropriate to your project.)


For Ant, the snippet below should help:


Credits Michael Niemand -


That should have been java -jar app.jar instead of java -jar "app".


The -jar option only works if the JAR file is an executable JAR file, which means it must have a manifest file with a Main-Class attribute in it. See Packaging Programs in JAR Files to learn how to create an executable JAR.


If it's not an executable JAR, then you'll need to run the program with something like:


where com.somepackage.SomeClass is the class that contains the main method to run the program. (What that class is depends on the program, it's impossible to tell from the information you've supplied).


Alternatively, you can use maven-assembly-plugin, as shown in the below example:


In this example all the dependency jars as specified in  section will be automatically included in your single jar. Note that jar-with-dependencies should be literally put as, not to be replaced with the jar file names you want to include.


That is because Java cannot find the Main attribute in the MANIFEST.MF file.
The Main attribute is necessary to tell java which class it should use as the application's entry point. Inside the jar file, the MANIFEST.MF file is located in META-INF folder. Wondering how you could look at what's inside a jar file? Open the jar file with WinRAR.


The main attribute inside the MANIFEST.MF looks like this:


You get this "no main manifest attribute" error when this line is missing from the MANIFEST.MF file. 


It's really a huge mess to specify this attribute inside the MANIFEST.MF file.


Update: I just found a really neat way to specify the Application's entry point in eclipse.
When you say Export, 





The Gradle answer is to add a jar/manifest/attributes setting like this:


For maven, this is what solved it (for me, for a Veetle codebase on GitHub):


Cheers...


Try this command to include the jar: 


For me, none of the answers really helped - I had the manifest file in correct place, containing the Main-Class and everything. What tripped me over was this:


Warning: The text file from which you are creating the manifest must
  end with a new line or carriage return. The last line will not be
  parsed properly if it does not end with a new line or carriage return.


(source). Adding a newline at the end of the manifest fixed it.


I had this issue when creating a jar using IntelliJ IDEA. See this discussion.


What solved it for me was to re-create the jar artifact, choosing JAR > From modules with dependencies, but not accepting the default Directory for META-INF/MANIFEST.MF. Change it from -/src/main/java to -/src/main/resources.


Otherwise it was including a manifest file in the jar, but not the one in -/src/main/java that it should have.


If the jar isn't following the rules, it's not an executable jar.


If using Maven, include following in the pom


I faced the same issue and it's fixed now:)
Just follow the below steps and the error could be for anything, but the below steps makes the process smoother. I spend lot of time to find the fix.


1.Try restart the Eclipse (if you are using Eclipse to built JAR file)
--> Actually this helped my issue in exporting the JAR file properly.


2.After eclipse restart, try to see if your eclipse is able to recognize the main class/method by your Java project --> right click --> Run as --> Run configurations --> Main --> click Search button to see if your eclipse is able to lookup for your main class in the JAR file.
--> This is for the validation that JAR file will have the entry point to the main class.


After this, export your Java Dynamic project as "Runnable JAR" file and not JAR file.


In Java launch configuration, choose your main class.


Once export the jar file, use the below command to execute.
java -cp [Your JAR].jar [complete package].MainClass
eg: java -cp AppleTCRuleAudit.jar com.apple.tcruleaudit.classes.TCRuleAudit


You might face the unsupported java version error. the fix is to change the java_home in your shell bash profile to match the java version used to compile the project in eclipse.


Hope this helps! Kindly let me know if you still have any issues.


Any executable jar file Should run either by clicking or running using command prompt like java -jar app.jar (use "if path of jar contains space" - i.e. java -jar "C:\folder name\app.jar"). If your executable jar is not running, which means it is not created properly.


For better understanding, extract the jar file (or view using any tool, for windows 7-Zip is nice one) and check the file under /META-INF/MANIFEST.MF. If you find any entry like


Main-Class: your.package.name.ClaaswithMain - then it's fine, otherwise you have to provide it.


Be aware of appending Main-Class entry on MANIFEST.MF file, check where you are saving it! 


You might not have created the jar file properly:


ex: missing option m in jar creation


The following works:


For me this error occurred simply because I forgot tell Eclipse that I wanted a runnable jar file and not a simple library jar file.  So when you create the jar file in Eclipse make sure that you click the right radio button


You Can Simply follow this step 
 Create a jar file using


While running the jar file simple run like this


The above answers were only partly helpful for me. java -cp was part of the answer, but I needed more specific info on how to identify the class to run. Here is what worked for me:


Step 1: find the class I need to run


The top lines of the result were:


App.class contained the main class to run. I'm not 100% sure if you can always assume the class you need is the first one, but it was for me. If it isn't, I'd imagine it isn't too hard to use grep to exclude library-related results to pare the class list down to a manageable size.


From there it was easy: I just use that path (minus the ".class" suffix):


I had the same problem. A lot of the solutions mentioned here didn't give me the whole picture, so I'll try to give you a summary of how to pack jar files from the command line.


If you want to have your .class files in packages, add the package in the beginning of the .java.


Test.java


To compile your code with your .class files ending up with the structure given by the package name use:


The -d . makes the compiler create the directory structure you want.


When packaging the .jar file, you need to instruct the jar routine on how to pack it. Here we use the option set cvfeP. This is to keep the package structure (option P), specify the entry point so that the manifest file contains meaningful information (option e). Option f lets you specify the file name, option c creates an archive and option v sets the output to verbose. The important things to note here are P and e.


Then comes the name of the jar we want test.jar.


Then comes the entry point .


And then comes -C . <packagename>/ to get the class files from that folder, preserving the folder structure.


Check your .jar file in a zip program. It should have the following structure


test.jar


The MANIFEST.MF should contain the following


If you edit your manifest by hand be sure to keep the newline at the end otherwise java doesn't recognize it.


Execute your .jar file with


Since you've add MANIFEST.MF, I think you should consider the order of Field in this file. My env is  java version "1.8.0_91"


and my MANIFEST.MF as here


However, this as below run through


I had the same issue today. My problem was solved my moving META-INF to the resources folder. 


(first post - so it may not be clean)


This is my fix for OS X 11.6, Maven-based Netbeans 8.2 program. Up to now my app is 100% Netbeans - no tweaking (just a few shell escapes for the impossible!).


Having tried most all of the answers here and elsewhere to no avail, I returned to the art of "use what works". 


The top answer here (olivier-refalo thanx) looked like the right place to start but didn't help. 


Looking at other projects which did work, I noticed some minor differences in the manifest lines: 


Not sure why (I am only 3 months into java) or how, but can only say this worked. 


Here is just the modified manifest block used:


I got same error just now.
If u're using gradle, just add next one in ur gradle.build:


Where com.company.project.MainClass path to ur class with public static void main(String[] args) method.


You might have the same problem as I do. After creating your .jar file, write jar xf app.jar META-INF/MANIFEST.MF. This will create a copy of the file to your current directory so you can read it. If it only says something like:


Manifest-Version: 1.0


Created-By: 1.8.0_51 (Oracle Corporation)


and does not contain the "Main-Class" declaration, then I think you found your problem.


I do not know how to solve it, though. I checked other people with same/similar problems on StackOverflow and couldn't find an answer. However with this information you can perhaps get some better help (given the fact that you have the same problem as I).


Edit: I had tried with a manifest-file but didn't get it to work, but my mistake was to only name one of the classes when creating the jar-file. I wrote *.class instead and it works now.


Although I don't know why there is a need to create a manifest-file. But I guess it's fine as long as it works.


Check your local .m2 direcory for a sub directory of this artifact.
If exixts - delete it, and perform Maven update again


If you are using the command line to assemble .jar it is possible to point to the main without adding Manifest file. Example:


(param "e" does that: TheNameOfClassWithMainMethod is a name of the class with the method main()  and app.jar - name of executable .jar and *.class - just all classes files to assemble)


check your jar file inside MANIFEST.MF Main-Class is available or not


first.java


Before:


After: 


I had a similar issue as you, 
in below a syntax to create successfully .war File:-


jar {cvf} [jar-file] [manifest-file]


manifest
  When creating (c) or updating (u) a JAR file, the manifest operand defines the preexisting manifest files with names and values of attributes to be included in MANIFEST.MF in the JAR file. The manifest operand must be specified if the f option is present '[1]'.


In order to create manifest file you need to defined a value for some attributes, you could put asterisk after the (.WAR) file name to avoid creating manifest file:-


jar -cvf foo.war *


To be honest with you I don't know if that is a best practice but it do the work for me :).


I had this problem and i solved it recently by doing this in Netbeans 8 (Refer to the image below):





Just to make one point clear about 


If you don't have package you have to ignore that part, like this:


I personally think all the answers here are mis-understanding the question.  The answer to this lies in the difference of how spring-boot builds the .jar.  Everyone knows that Spring Boot sets up a manifest like this,  which varies from everyones asssumption that this is a standard .jar launch, which it may or may not be :


Perhaps it needs to executed with org.springframework.boot.loader.JarLauncher on the classpath?






I want the message box to appear immediately after the user changes the value in the textfield. Currently, I need to hit the enter key to get the message box to pop out. Is there anything wrong with my code?


Any help would be appreciated!


Add a listener to the underlying Document, which is automatically created for you.


The usual answer to this is "use a DocumentListener". However, I always find that  interface cumbersome. Truthfully the interface is over-engineered. It has three methods, for insertion, removal, and replacement of text, when it only needs one method: replacement. (An insertion can be viewed as a replacement of no text with some text, and a removal can be viewed as a replacement of some text with no text.)


Usually all you want is to know is when the text in the box has changed, so a typical DocumentListener implementation has the three methods calling one method.


Therefore I made the following utility method, which lets you use a simpler ChangeListener rather than a DocumentListener. (It uses Java 8's lambda syntax, but you can adapt it for old Java if needed.)


Unlike with adding a listener directly to the document, this handles the (uncommon) case that you install a new document object on a text component. Additionally, it works around the problem mentioned in Jean-Marc Astesana's answer, where the document sometimes fires more events than it needs to.


Anyway, this method lets you replace annoying code which looks like this:


With:


Code released to public domain. Have fun!


Be aware that when the user modify the field, the DocumentListener can, sometime, receive two events. For instance if the user selects the whole field content, then press a key, you'll receive a removeUpdate (all the content is remove) and an insertUpdate.
In your case, I don't think it is a problem but, generally speaking, it is.
Unfortunately, it seems there's no way to track the content of the textField without subclassing JTextField.
Here is the code of a class that provide a "text" property :


I know this relates to a really old problem, however, it caused me some problems too. As kleopatra responded in a comment above, I solved the problem with a JFormattedTextField. However, the solution requires a bit more work, but is neater.


The JFormattedTextField doesn't by default trigger a property change after every text changes in the field. The default constructor of JFormattedTextField does not create a formatter.


However, to do what the OP suggested, you need to use a formatter which will invoke the commitEdit() method after each valid edit of the field. The commitEdit() method is what triggers the property change from what I can see and without the formatter, this is triggered by default on a focus change or when the enter key is pressed. 


See http://docs.oracle.com/javase/tutorial/uiswing/components/formattedtextfield.html#value for more details.


Create a default formatter (DefaultFormatter) object to be passed to the JFormattedTextField either via its constructor or a setter method. One method of the default formatter is setCommitsOnValidEdit(boolean commit), which sets the formatter to trigger the commitEdit() method every time the text is changed. This can then be picked up using a PropertyChangeListener and the propertyChange() method.


Just crate an interface that extends DocumentListener and implements all DocumentListener methods:


and then:


or you can even use lambda expression:


You can use even "MouseExited" to control.
example:


it was the update version of Codemwnci. his code is quite fine and works great except the error message. To avoid error you must change the condition statement. 


Use a KeyListener (which triggers on any key) rather than the ActionListener (which triggers on enter)


I am brand new to WindowBuilder, and, in fact, just getting back into Java after a few years, but I implemented "something", then thought I'd look it up and came across this thread.


I'm in the middle of testing this, so, based on being new to all this, I'm sure I must be missing something.


Here's what I did, where "runTxt" is a textbox and "runName" is a data member of the class:


Seems a lot simpler than what's here so far, and seems to be working, but, since I'm in the middle of writing this, I'd appreciate hearing of any overlooked gotchas.  Is it an issue that the user could enter & leave the textbox w/o making a change?  I think all you've done is an unnecessary assignment.


DocumentFilter ? It gives you the ability to manipulate.


[ http://www.java2s.com/Tutorial/Java/0240__Swing/FormatJTextFieldstexttouppercase.htm ]


Sorry. J am using Jython (Python in Java) - but easy to understand






i am trying to integrate google sign in , in my app,i added these libraries:


also add this to project build gradle:


also add plugin to app build gradle:


then add required permissions
but when i try to run my app , received this error:


Try adding multiDexEnabled true to your app build.gradle file.


EDIT:


Try Steve's answer first. In case it happens frequently or first step didn't help multiDexEnabled might help. For those who love to dig deeper here is couple similar issues (with more answers):


:app:dexDebug ExecException finished with non-zero exit value 2 


Error:Execution failed for task ':app:dexDebug'. com.android.ide.common.process.ProcessException


Another thing to watch for, is that you don't use 


That will import ALL the play services, and it'll only take little more than a hello world to exceed the 65535 method limit of a single dex APK.


Always specify only the services you need, for instance: 


I just had to Clean my project and then it built successfully afterwards.


This error began appearing for me when I added some new methods to my project. I knew that I was nowhere near the 65k method limit and did not want to enable multiDex support for my project if I could help it.


I resolved it by increasing the memory available to the :app:transformClassesForDexForDebug task. I did this by specifying javaMaxHeapSize in gradle.build.


gradle.build


I tried this after having had no success with other common solutions to this problem:


Error


Error:Execution failed for task
  > ':app:transformClassesWithDexForDebug'. 
  com.android.build.api.transform.TransformException:
  com.android.ide.common.process.ProcessException:
  org.gradle.process.internal.ExecException: Process 'command
  '/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/bin/java''
  finished with non-zero exit value 1


Note: increasing the memory available to the DEX task can cause performance problems on systems with lower memory - link. 


I also faced similar issue in Android Studio 1.5.1 and gradle 1.5.0.
I just have to remove unwanted libraries from dependencies which may be automatically added in my app's build.gradle file.
One was :  compile 'com.google.android.gms:play-services:8.4.0'.
So for best practices try to only include specific play services library like for ads include only


Although


this will also solve the issue, but provides with a lot of Notes in gradle console, making it confusing to find the other real issues during build


you can see the documentation of Android


Manifest.xml


I'm using AS 1.5.1 and encountered the same problem. But just cleaning the project just wont do, so I tried something.


This worked with me, so I hope this helps.


At my case change buildToolsVersion from "24" to "23.0.2", solve the problem.


I had same problem when i rolled back to old version via git, and that version had previous .jar library of one 3rd party api, and for some reason turned out that both jar of the same sdk, just different versions were in /libs folder. 


First Delete intermediates files
  YOUR APP FOLDER\app\build\intermediates
OR
  Clean your project and then rebuild.


Thent add    


i.e. 


It's work for me


In my case the Exception occurred because all google play service extensions are not with same version as follows


It worked when I changed this to 


 In build.gradle you need to add the next one. 


 Add the next one in local.properties 


 After that into Application class you need to add the Multidex too. 


 Don't forget add the line code into Manifest.xml 


That's it with this was enough for resolve the bug:
Execution failed for task ':app:transformClassesWithDexForDebug. 

Check very well into build.gradle with javaMaxHeapSize "2g" and the local.properties org.gradle.jvmargs=-Xmx2048m are of 2 gigabyte.


If you are using the latest gradle version ie  classpath 'com.android.tools.build:gradle:1.5.0' and  classpath 'com.google.gms:google-services:1.4.0-beta3', then try updating the latest support respository from the SDK manager and rebuild the entire project.


If you need add this reference for cordova plugin add next line in your plugin.xml file.


If the different dependencies have a same jar also cause this build error.


For example:


If "library1" and "library2" has a same jar named xxx.jar, this will make such an error.


It happened to me because of Eclipse memory leak. I had to restart my computer.


I changed a couple of pngs and the build number in the gradle and now I get this.  No amount of cleaning and restarting helped.  Disabling Instant Run fixed it for me.  YMMV


I had the same option and as soon as I turned off Instant run, it worked fine on my API16 device, but on the API24 device it worked fine with Instant run. 


Hope this helps someone having the same issue


Simply go to Build - Edit Build Types - Properties Tab - Build Type Version and downgrade it to ver 23.0.1. Click ok.
This works for android studio 1.5.
It worked for me.


this code solved problem


For easiest way to implement google sign in visit: google sign in android


Also try


Also keep same version number for different services.


I solved this issue by adding:
In build.gradle:


in local.properties ,


mention dependency:


Clean and Rebuild.


the write answer is in gradle put
defaultConfig {
        multiDexEnabled true
}
then application name in manifest 
android:name="android.support.multidex.MultiDexApplication"
wish this answer is hellpful to some one






I'm developing an Android app which reads data from MySQL database and I faced this error. I have this XML layout:


And this is the my Java file:


When this Activity is called, I receive this error message:


I don't know how to fix this error.


Change


To


There are different versions of setText - one takes a String and one takes an int resource id. If you pass it an integer it will try to look for the corresponding string resource id - which it can't find, which is your error.


I guess app.getTotalDl() returns an int. You need to specifically tell setText to set it to the String value of this int.


setText (int resid) vs  setText (CharSequence text)


Replace


With


When you try to set text in Edittext or textview you
should pass only String format.


to






Is there a difference between ++x and x++ in java?


++x is called preincrement while x++ is called postincrement. 


yes


++x increments the value of x and then returns x
x++ returns the value of x and then increments


example:


after the code is run both a and b will be 1 but x will be 2.


These are known as postfix and prefix operators. Both will add 1 to the variable but there is a difference in the result of the statement.


Yes,


will print 6 and


will print 5.


I landed here from one of its recent dup's, and though this question is more than answered, I couldn't help decompiling the code and adding "yet another answer" :-)


To be accurate (and probably, a bit pedantic),


is compiled into:


If you javac this Y.java class:


and javap -c Y, you get the following jvm code (I have allowed me to comment the main method with the help of the Java Virtual Machine Specification):


Thus, we finally have:


When considering what the computer actually does...


++x: load x from memory, increment, use, store back to memory.


x++: load x from memory, use, increment, store back to memory.


Consider:
    a = 0
    x = f(a++)
    y = f(++a)


where function f(p) returns p + 1


x will be 1 (or 2)


y will be 2 (or 1)


And therein lies the problem.  Did the author of the compiler pass the parameter after retrieval, after use, or after storage.


Generally, just use x = x + 1.  It's way simpler.


Yes.


Yes, using ++X, X+1 will be used in the expression. Using X++, X will be used in the expression and X will only be increased after the expression has been evaluated.


So if X = 9, using ++X, the value 10 will be used, else, the value 9.


If it's like many other languages you may want to have a simple try:


If the above doesn't happen like that, they may be equivalent


Yes, the value returned is the value after and before the incrementation, respectively.


OK, I landed here because I recently came across the same issue when checking the classic stack implementation. Just a reminder that this is used in the array based implementation of Stack, which is a bit faster than the linked-list one.


Code below, check the push and pop func.


Yes, there is a difference, incase of x++(postincrement), value of x will be used in the expression and x will be incremented by 1 after the expression has been evaluated, on the other hand ++x(preincrement), x+1 will be used in the expression. 
Take an example:


The Question is already answered, but allow me to add from my side too. 


First of all ++ means increment by one and -- means decrement by one.


Now x++ means Increment x after this line and ++x means Increment x before this line.


Check this Example


It will give the following output:


In Java there is a difference between x++ and ++x


++x is a prefix form:
It increments the variables expression then uses the new value in the expression.


For example if used in code:


x++ is a postfix form:
The variables value is first used in the expression and then it is incremented after the operation.


For example if used in code:


Hope this is clear. Running and playing with the above code should help your understanding.


With i++, it's called postincrement, and the value is used in whatever context then incremented; ++i is preincrement increments the value first and then uses it in context. 


If you're not using it in any context, it doesn't matter what you use, but postincrement is used by convention. 


There is a huge difference. 


As most of the answers have already pointed out the theory, I would like to point out an easy example:


Now let's see ++x:






In the App Engine docs, what is the ellipsis (JID...) for in this method signature?


What's the function of those three dots?


Those are Java varargs. They let you pass any number of objects of a specific type (in this case they are of type JID).


In your example, the following function calls would be valid:


See more here:
http://java.sun.com/j2se/1.5.0/docs/guide/language/varargs.html


The way to use the ellipsis or varargs inside the method is as if it were an array:


This method can be called as following:


Inside PrintWithEllipsis, the type of setOfStrings is an array of String.
So you could save the compiler some work and pass an array:


For varargs methods, a sequence parameter is treated as being an array of the same type. So if two signatures differ only in that one declares a sequence and the other an array, as in this example:


then a compile-time error occurs.


Source: The Java Programming Language specification, where the technical term is variable arity parameter rather than the common term varargs.


The three dot (...) notation is actually borrowed from mathematics, and it means "...and so on".


As for its use in Java, it stands for varargs, meaning that any number of arguments can be added to the method call. The only limitations are that the varargs must be at the end of the method signature and there can only be one per method.


Those are varargs they are used to create a method that receive any number of arguments.


For instance PrintStream.printf method uses it, since you don't know how many would arguments you'll use.


They can only be used as final position of the arguments.


varargs was was added on Java 1.5 


It means that the method accepts a variable number of arguments ("varargs") of type JID. Within the method, recipientJids is presented.


This is handy for cases where you've a method that can optionally handle more than one argument in a natural way, and allows you to write calls which can pass one, two or three parameters to the same method, without having the ugliness of creating an array on the fly.


It also enables idioms such as sprintf from C; see String.format(), for example.


You can define a parameter that can accept variable arguments (varargs) in your methods. Following is an example of class Employee, which defines a method daysOffWork that accepts variable arguments:


The ellipsis (...) that follows the data type indicates that the method parameter days may be passed an array or multiple comma-separated values.






What is the difference between:


and 


The annotation @JoinColumn indicates that this entity is the owner of the relationship (that is: the corresponding table has a column with a foreign key to the referenced table), whereas the attribute mappedBy indicates that the entity in this side is the inverse of the relationship, and the owner resides in the "other" entity. This also means that you can access the other table from the class which you've annotated with "mappedBy" (fully bidirectional relationship).


In particular, for the code in the question the correct annotations would look like this:


@JoinColumn could be used on both sides of the relationship. The question was about using @JoinColumn on the @OneToMany side (rare case). And the point here is in physical information duplication (column name) along with not optimized SQL query that will produce some additional UPDATE statements.


According to documentation:


Since many to one are (almost) always the owner side of a bidirectional relationship in the JPA spec, the one to many association is annotated by @OneToMany(mappedBy=...)


Troop has a bidirectional one to many relationship with Soldier through the troop property. You don't have to (must not) define any physical mapping in the mappedBy side.


To map a bidirectional one to many, with the one-to-many side as the owning side, you have to remove the mappedBy element and set the many to one @JoinColumn as insertable and updatable to false. This solution is not optimized and will produce some additional UPDATE statements.


The annotation mappedBy ideally should always be used in the Parent side (Company class) of the bi directional relationship, in this case it should be in Company class pointing to the member variable 'company' of the Child class (Branch class) 


The annotation @JoinColumn is used to specify a mapped column for joining an entity association, this annotation can be used in any class (Parent or Child) but it should ideally be used only in one side (either in parent class or in Child class not in both) here in this case i used it in the Child side (Branch class) of the bi directional relationship indicating the foreign key in the Branch class.


below is the working example :


parent class , Company


child class, Branch


I'd just like to add that @JoinColumn does not always have to be related to the physical information location as this answer suggests.  You can combine @JoinColumn with @OneToMany even if the parent table has no table data pointing to the child table.


How to define unidirectional OneToMany relationship in JPA


Unidirectional OneToMany, No Inverse ManyToOne, No Join Table


It seems to only be available in JPA 2.x+ though.  It's useful for situations where you want the child class to just contain the ID of the parent, not a full on reference.






After validation of select combo box the which I have selected I am not able to insert in my database. Tomcat gives following error


How is this caused and how can I solve it?


You will get this error when you call any of the setXxx() methods on PreparedStatement, while the SQL query string does not have any placeholders ? for this. 


For example this is wrong:


You need to fix the SQL query string accordingly to specify the placeholders.


Note the parameter index starts with 1 and that you do not need to quote those placeholders like so:


Otherwise you will still get the same exception, because the SQL parser will then interpret them as the actual string values and thus can't find the placeholders anymore.


This is an issue with the jdbc Driver version. I had this issue when I was using 
mysql-connector-java-commercial-5.0.3-bin.jar but when I changed to a later driver version
 mysql-connector-java-5.1.22.jar, the issue was fixed.


Here is some code to achieve what you want






I have created the following function for checking the connection status:


When I shut down the server for testing the execution waits a long time at line


Does anyone know how to set the timeout in order to avoid waiting too long?


Thanks!


In my example two timeouts are set. The connection timeout throws "java.net.SocketTimeoutException: Socket is not connected" and the socket timeout "java.net.SocketTimeoutException: The operation timed out".


If you want to set the Parameters of any existing HTTPClient (e.g. DefaultHttpClient or AndroidHttpClient) you can use the function setParams().


To set settings on the client:


I've used this successfully on JellyBean, but should also work for older platforms ....


HTH


If your are using Jakarta's http client library then you can do something like:


If you're using the default http client, here's how to do it using the default http params:


Original credit goes to http://www.jayway.com/2009/03/17/configuring-timeout-with-apache-httpclient-40/


For those saying that the answer of @kuester2000 does not work, please be aware that HTTP requests, first try to find the host IP with a DNS request and then makes the actual HTTP request to the server, so you may also need to set a timeout for the DNS request. 


If your code worked without the timeout for the DNS request it's because you are able to reach a DNS server or you are hitting the Android DNS cache. By the way you can clear this cache by restarting the device.


This code extends the original answer to include a manual DNS lookup with a custom timeout:


Used method:


This class is from this blog post. Go and check the remarks if you will use it.


If you are using the HttpURLConnection, call setConnectTimeout():


http://developer.android.com/reference/java/net/URLConnection.html#setConnectTimeout(int)


you can creat HttpClient instance by the way with Httpclient-android-4.3.5,it can work well.


An option is to use the OkHttp client, from Square.


Add the library dependency


In the build.gradle, include this line:


Where x.x.x is the desired library version.


Set the client 


For example, if you want to set a timeout of 60 seconds, do this way:


ps: If your minSdkVersion is greater than 8, you can use TimeUnit.MINUTES. So, you can simply use:


For more details about the units, see TimeUnit.






Why doesn't the compiler automatically put break statements after each code block in the switch? Is it for historical reasons? When would you want multiple code blocks to execute?


Sometimes it is helpful to have multiple cases associated with the same code block, such as


etc. Just an example.


In my experience, usually it is bad style to "fall through" and have multiple blocks of code execute for one case, but there may be uses for it in some situations.


Historically, it's because the case was essentially defining a label, also known as the target point of a goto call.  The switch statement and its associated cases really just represent a multiway branch with multiple potential entry points into a stream of code.


All that said, it has been noted a nearly infinite number of times that break is almost always the default behavior that you'd rather have at the end of every case.


Java comes from C and that is the syntax from C.


There are times where you want multiple case statements to just have one execution path.
Below is a sample that will tell you how many days in a month.


You can do all sorts of interesting things with case fall-through.


For example, lets say you want to do a particular action for all cases, but in a certain case you want to do that action plus something else.  Using a switch statement with fall-through would make it quite easy.


Of course, it is easy to forget the break statement at the end of a case and cause unexpected behavior.  Good compilers will warn you when you omit the break statement. 


I think it is a mistake. As a language construct it is just as easy to have break as the default and instead have a fallthrough keyword. Most of the code I have written and read has a break after every case.


Why doesn't the compiler automatically put break statements after each code block in the switch?


Leaving aside the good desire to be able to use the identical block for several cases (which could be special-cased)...


Is it for historical reasons? When would you want multiple code blocks to execute?


It's mainly for compatibility with C, and is arguably an ancient hack from the days of old when goto keywords roamed the earth. It does enable some amazing things, of course, such as Duff's Device, but whether that's a point in its favor or against is… argumentative at best.


So you do not have to repeat code if you need several cases to do the same thing:


Or you can do things like :


In a cascade fashion.


Really bug/confusion prone, if you ask me.


Java is derived from C, whose heritage includes a technique known as Duff's Device .
It's an optimization that relies on the fact that control falls through from one case to the next, in the absence of a break; statement. By the time C was standardized, there was plenty of code like that "in the wild", and it would have been counterproductive to change the language to break such constructions.  


As far as the historical record goes, Tony Hoare invented the case statement in the 1960s, during the "structured programming" revolution.  Tony's case statement supported multiple labels per case and automatic exit with no stinking break statements.  The requirement for an explicit break was something that came out of the BCPL/B/C line.  Dennis Ritchie writes (in ACM HOPL-II):


For example, the endcase that escapes from a BCPL switchon statement was not present in the language
  when we learned it in the 1960s, and so the overloading of the break keyword to escape
  from the B and C switch statement owes to divergent evolution rather than conscious change.


I haven't been able to find any historical writings about BCPL, but Ritchie's comment suggests that the break was more or less a historical accident.  BCPL later fixed the problem, but perhaps Ritchie and Thompson were too busy inventing Unix to be bothered with such a detail :-)


Not having an automatic break added by the compiler makes it possible to use a switch/case to test for conditions like 1 <= a <= 3 by removing the break statement from 1 and 2.


because there are situations where you want to flow through the first block for example to avoid writing the same code in multiple blocks but still be able to divide them for mroe control. There are also a ton of other reasons.


It is an old question but actually I ran into using the case without break statement today. Not using break is actually very useful when you need to combine different functions in sequence.


e.g. using http response codes to authenticate user with time token


server response code 401 - token is outdated -> regenerate token and log user in.
server response code 200 - token is OK -> log user in.


in case statements:


Using this you do not need to call log in user function for 401 response because when the token is regenerated, the runtime jumps into the case 200.


You can makes easily to separate other type of number, month, count.
This is better then if in this case;


I am now working on project where I am in need of break in my switch statement otherwise the code won't work. Bare with me and I will give you a good example of why you need break in your switch statement. 


Imagine you have three states, one that waits for the user to enter a number, the second to calculate it and the third to print the sum.    


In that case you have: 


Looking at the states, you would want the order of exaction to start on state1, then state3 and finally state2. Otherwise we will only print users input without calculating the sum. Just to clarify it again, we wait for the user to enter a value, then calculate the sum and prints the sum. 


Here is an example code:


If we don't use break, it will execute in this order, state1, state2 and state3. But using break, we avoid this scenario, and can order in the right procedure which is to begin with state1, then state3 and last but not least state2.


As people said before, it is to allow fall-through and it is not a mistake, it is a feature. 
If too many break statements annoy you, you can easily get rid of them by using return statements instead. This is actually a good practice, because your methods should be as small as possible (for the sake of readability and maintainability), so a switch statement is already big enough for a method, hence, a good method should not contain anything else, this is an example:


The execution prints:


as expected.


Exactly, because with some clever placement you can execute blocks in cascade.






My System.out.println() and System.err.println() calls aren't being printed to the console in the order I make them.


This produces:


Instead of alternating out and err. Why is this?


They are different streams and are flushed at different times.


If you put 


inside your loop, it will work as expected.


To clarify, output streams are cached so all the write goes into this memory buffer.  After a period of quiet, they are actually written out.


You write to two buffers, then after a period of inactivity they both are flushed (one after the other).


This is caused by a feature in the JVM and unless you make a hack such as the one provided by Marcus A. it's not really that easy to work around. The .flush() works in this case but the reason for this is a lot more complicated to work around.


The JVM is smart but also very, very autistic. When you program in Java you're not telling the computer straight what to do, you're telling the JVM (Java Virtual Machine) what you would want it to do. And it will do that, but in a more efficient manner. Your code isn't exact detailed instructions, in that case you'd only need a compiler like in C and C++, the JVM takes your code as a specification list for what it's supposed to optimise and then do. This is what's happening here. Java sees that you're pushing strings into two different buffer streams. The most efficient way of doing this is by buffering all the strings you want the streams to output and then output it. This happen one stream at the time, essentially transforming your code do something like this (beware: pseudo code):


Because this is more efficient, this is what the JVM will do instead. Adding the .flush() in the loop will signal to the JVM that a flush needs to be done in each loop, which can't be improved with the above method. But if you for the sake of explaining how this works would have left out the loop, the JVM will reorder your code to have the printing done last, because this is more efficient.


This code will always be re-organized to something like this:


Because buffering many buffers only to flush them right after takes a lot more time than to buffer all the code to be buffered and then flush it all at the same time.


This is where code-design and architecture might come into play; you kinda don't solve this. To work around this, you have to make it more efficient to buffer print/flush, buffer print/flush than buffer all then flush. This will most likely be luring you into bad design. If it is important to you how to output it orderly, I suggest you try a different approach. For-looping with .flush() is one way to hack it, but you're still hacking the JVM's feature to re-arrange and optimize your code for you.


* I can't verify that the buffer you added to first always will print first, but it most likely will.


If you are using the Eclipse console, there seem to be two different phenomena at work:One, as described by @Gemtastic, is the JVMs handling of the streams and the other is the way Eclipse reads these streams, as mentioned by @DraganBozanovic. Since I'm using Eclipse, the elegant flush()-solution posted by @BillK, which only addresses the JVM-issue, is not sufficient.


I ended up writing myself a helper-class called EclipseTools with the following content (and the required package declaration and imports). It's a bit of a hack but fixes both issues:


To use, just call EclipseTools.fixConsole() once in the beginning of your code.


Basically, this replaces the two streams System.err and System.out with a custom set of streams that simply forward their data to the original streams, but keep track of which stream was written to last. If the stream that is written to changes, for example a System.err.something(...) followed by a System.out.something(...), it flushes the output of the last stream and waits for 200ms to give the Eclipse console time to complete printing it.


Note: The 200ms are just a rough initial value. If this code reduces, but does not eliminate the problem for you, increase the delay in Thread.sleep from 200 to something higher until it works. Alternatively, if this delay works but impacts performance of your code (if you alternate streams often), you can try reducing it gradually until you start getting errors.


The two println statements are handled by two different threads. The output again depends on what environment you are running the code in.
For eg, I executed the following code in IntelliJ and command-line 5 times each. 


This resulting in the following output:
Commandline  


IntelliJ:  


I guess different environments handles the buffers differently.
One way to see that these streams are infact handled by different threads is to add a sleep statement in the loop. You can try varying the value that you set for the sleep and see that these are infact handled by different threads.


The output in this case turned out to be


One way to force it to print it in the same order would be use the .flush(), which worked for me. But itseems that not everyone is getting the right results with it.


The two streams handled by 2 two different threads is probably the reason why we sometimes see the ERROR message printed by some libraries that we use, getting printed before some print statements that we were supposed to see according to the order of execution.


This is a bug in Eclipse. It seems that Eclipse uses separate threads to read the content of out and err streams without any synchronization.


If you compile the class and execute it in the console (with the classic java <main class name>), the order is as expected.






I'm trying to read CSV files using Java. Some of the files may have a byte order mark in the beginning, but not all. When present, the byte order gets read along with the rest of the first line, thus causing problems with string compares.


Is there an easy way to skip the byte order mark when it is present?


Thanks!


EDIT: I've made a proper release on GitHub: https://github.com/gpakosz/UnicodeBOMInputStream


Here is a class I coded a while ago, I just edited the package name before pasting. Nothing special, it is quite similar to solutions posted in SUN's bug database. Incorporate it in your code and you're fine.


And you're using it this way:


The Apache Commons IO library has an InputStream that can detect and discard BOMs: BOMInputStream (javadoc):


If you also need to detect different encodings, it can also distinguish among various different byte-order marks, e.g. UTF-8 vs. UTF-16 big + little endian - details at the doc link above.  You can then use the detected ByteOrderMark to choose a Charset to decode the stream.  (There's probably a more streamlined way to do this if you need all of this functionality - maybe the UnicodeReader in BalusC's answer?).  Note that, in general, there's not a very good way to detect what encoding some bytes are in, but if the stream starts with a BOM, apparently this can be helpful.


Edit: If you need to detect the BOM in UTF-16, UTF-32, etc, then the constructor should be:


Upvote @martin-charlesworth's comment :)


More simple solution:


Usage sample:


It works with all 5 UTF encodings!


Google Data API has an UnicodeReader which automagically detects the encoding.


You can use it instead of InputStreamReader. Here's an -slightly compactized- extract of its source which is pretty straightforward:


The Apache Commons IO Library's BOMInputStream has already been mentioned by @rescdsk, but I did not see it mention how to get an InputStream without the BOM.


Here's how I did it in Scala.


Regrettably not. You'll have to identify and skip yourself. This page details what you have to watch for. Also see this SO question for more details.


To simply remove the BOM characters from your file, I recomend using Apache Common IO


Set include to false and your BOM characters will be excluded.






I mostly use Java and generics are relatively new. I keep reading that Java made the wrong decision or that .NET has better implementations etc. etc.


So, what are the main differences between C++, C#, Java in generics? Pros/cons of each?


I'll add my voice to the noise and take a stab at making things clear:


and then the compiler will prevent you from putting things that aren't Person into the list.
Behind the scenes the C# compiler is just putting List<Person> into the .NET dll file, but at runtime the JIT compiler  goes and builds a new set of code, as if you had written a special list class just for containing people - something like ListOfPerson.


The benefit of this is that it makes it really fast. There's no casting or any other stuff, and because the dll contains the information that this is a List of Person, other code that looks at it later on using reflection can tell that it contains Person objects (so you get intellisense and so on).


The downside of this is that old C# 1.0 and 1.1 code (before they added generics) doesn't understand these new List<something>, so you have to manually convert things back to plain old List to interoperate with them. This is not that big of a problem, because C# 2.0 binary code is not backwards compatible. The only time this will ever happen is if you're upgrading some old C# 1.0/1.1 code to C# 2.0


On the surface it looks the same, and it sort-of is. The compiler will also prevent you from putting things that aren't Person into the list.


The difference is what happens behind the scenes. Unlike C#, Java does not go and build a special ListOfPerson - it just uses the plain old ArrayList which has always been in Java. When you get things out of the array, the usual Person p = (Person)foo.get(1); casting-dance still has to be done. The compiler is saving you the key-presses, but the speed hit/casting is still incurred just like it always was.
When people mention "Type Erasure" this is what they're talking about. The compiler inserts the casts for you, and then 'erases' the fact that it's meant to be a list of Person not just Object


The benefit of this approach is that old code which doesn't understand generics doesn't have to care. It's still dealing with the same old ArrayList as it always has. This is more important in the java world because they wanted to support compiling code using Java 5 with generics, and having it run on old 1.4 or previous JVM's, which microsoft deliberately decided not to bother with.


The downside is the speed hit I mentioned previously, and also because there is no ListOfPerson pseudo-class or anything like that going into the .class files, code that looks at it later on (with reflection, or if you pull it out of another collection where it's been converted into Object or so on) can't tell in any way that it's meant to be a list containing only Person and not just any other array list.


It looks like C# and Java generics, and it will do what you think it should do, but behind the scenes different things are happening.


It has the most in common with C# generics in that it builds special pseudo-classes rather than just throwing the type information away like java does, but it's a whole different kettle of fish.


Both C# and Java produce output which is designed for virtual machines. If you write some code which has a Person class in it, in both cases some information about a Person class will go into the .dll or .class file, and the JVM/CLR will do stuff with this.


C++ produces raw x86 binary code. Everything is not an object, and there's no underlying virtual machine which needs to know about a Person class. There's no boxing or unboxing, and functions don't have to belong to classes, or indeed anything. 


Because of this, the C++ compiler places no restrictions on what you can do with templates - basically any code you could write manually, you can get templates to write for you.
The most obvious example is adding things:


In C# and Java, the generics system needs to know what methods are available for a class, and it needs to pass this down to the virtual machine. The only way to tell it this is by either hard-coding the actual class in, or using interfaces. For example:


That code won't compile in C# or Java, because it doesn't know that the type T actually provides a method called Name(). You have to tell it - in C# like this:


And then you have to make sure the things you pass to addNames implement the IHasName interface and so on. The java syntax is different (<T extends IHasName>), but it suffers from the same problems.


The 'classic' case for this problem is trying to write a function which does this


You can't actually write this code because there are no ways to declare an interface with the + method in it. You fail.


C++ suffers from none of these problems. The compiler doesn't care about passing types down to any VM's - if both your objects have a .Name() function, it will compile. If they don't, it won't. Simple.


So, there you have it :-)


C++ rarely uses the “generics” terminology. Instead, the word “templates” is used and is more accurate. Templates describes one technique to achieve a generic design.


C++ templates is very different from what both C# and Java implement for two main reasons. The first reason is that C++ templates don't only allow compile-time type arguments but also compile-time const-value arguments: templates can be given as integers or even function signatures. This means that you can do some quite funky stuff at compile time, e.g. calculations:


This code also uses the other distinguished feature of C++ templates, namely template specialization. The code defines one class template, product that has one value argument. It also defines a specialization for that template that is used whenever the argument evaluates to 1. This allows me to define a recursion over template definitions. I believe that this was first discovered by Andrei Alexandrescu.


Template specialization is important for C++ because it allows for structural differences in data structures. Templates as a whole is a means of unifying an interface across types. However, although this is desirable, all types cannot be treated equally inside the implementation. C++ templates takes this into account. This is very much the same difference that OOP makes between interface and implementation with the overriding of virtual methods.


C++ templates are essential for its algorithmic programming paradigm. For example, almost all algorithms for containers are defined as functions that accept the container type as a template type and treat them uniformly. Actually, that's not quite right: C++ doesn't work on containers but rather on ranges that are defined by two iterators, pointing to the beginning and behind the end of the container. Thus, the whole content is circumscribed by the iterators: begin <= elements < end.


Using iterators instead of containers is useful because it allows to operate on parts of a container instead of on the whole.


Another distinguishing feature of C++ is the possibility of partial specialization for class templates. This is somewhat related to pattern matching on arguments in Haskell and other functional languages. For example, let's consider a class that stores elements:


This works for any element type. But let's say that we can store pointers more effciently than other types by applying some special trick. We can do this by partially specializing for all pointer types:


Now, whenever we instance a container template for one type, the appropriate definition is used:


Anders Hejlsberg himself described the differences here "Generics in C#, Java, and C++".


There are already a lot of good answers on what the differences are, so let me give a slightly different perspective and add the why.


As was already explained, the main difference is type erasure, i.e. the fact that the Java compiler erases the generic types and they don't end up in the generated bytecode. However, the question is: why would anyone do that? It doesn't make sense! Or does it?


Well, what's the alternative? If you don't implement generics in the language, where do you implement them? And the answer is: in the Virtual Machine. Which breaks backwards compatibility.


Type erasure, on the other hand, allows you to mix generic clients with non-generic libraries. In other words: code that was compiled on Java 5 can still be deployed to Java 1.4.


Microsoft, however, decided to break backwards compatibility for generics. That's why .NET Generics are "better" than Java Generics.


Of course, Sun aren't idiots or cowards. The reason why they "chickened out", was that Java was significantly older and more widespread than .NET when they introduced generics. (They were introduced roughly at the same time in both worlds.) Breaking backwards compatibility would have been a huge pain.


Put yet another way: in Java, Generics are a part of the Language (which means they apply only to Java, not to other languages), in .NET they are part of the Virtual Machine (which means they apply to all languages, not just C# and Visual Basic.NET).


Compare this with .NET features like LINQ, lambda expressions, local variable type inference, anonymous types and expression trees: these are all language features. That's why there are subtle differences between VB.NET and C#: if those features were part of the VM, they would be the same in all languages. But the CLR hasn't changed: it's still the same in .NET 3.5 SP1 as it was in .NET 2.0. You can compile a C# program that uses LINQ with the .NET 3.5 compiler and still run it on .NET 2.0, provided that you don't use any .NET 3.5 libraries. That would not work with generics and .NET 1.1, but it would work with Java and Java 1.4.


Follow-up to my previous posting.


Templates are one of the main reasons why C++ fails so abysmally at intellisense, regardless of the IDE used. Because of template specialization, the IDE can never be really sure if a given member exists or not. Consider:


Now, the cursor is at the indicated position and it's damn hard for the IDE to say at that point if, and what, members a has. For other languages the parsing would be straightforward but for C++, quite a bit of evaluation is needed beforehand.


It gets worse. What if my_int_type were defined inside a class template as well? Now its type would depend on another type argument. And here, even compilers fail.


After a bit of thinking, a programmer would conclude that this code is the same as the above: Y<int>::my_type resolves to int, therefore b should be the same type as a, right?


Wrong. At the point where the compiler tries to resolve this statement, it doesn't actually know Y<int>::my_type yet! Therefore, it doesn't know that this is a type. It could be something else, e.g. a member function or a field. This might give rise to ambiguities (though not in the present case), therefore the compiler fails. We have to tell it explicitly that we refer to a type name:


Now, the code compiles. To see how ambiguities arise from this situation, consider the following code:


This code statement is perfectly valid and tells C++ to execute the function call to Y<int>::my_type. However, if my_type is not a function but rather a type, this statement would still be valid and perform a special cast (the function-style cast) which is often a constructor invocation. The compiler can't tell which we mean so we have to disambiguate here.


Both Java and C# introduced generics after their first language release.  However, there are differences in how the core libraries changed when generics was introduced.  C#'s generics are not just compiler magic and so it was not possible to generify existing library classes without breaking backwards compatibility.


For example, in Java the existing Collections Framework was completely genericised.  Java does not have both a generic and legacy non-generic version of the collections classes.  In some ways this is much cleaner - if you need to use a collection in C# there is really very little reason to go with the non-generic version, but those legacy classes remain in place, cluttering up the landscape. 


Another notable difference is the Enum classes in Java and C#.  Java's Enum has this somewhat tortuous looking definition:


(see Angelika Langer's very clear explanation of exactly why this is so.  Essentially, this means Java can give type safe access from a string to its Enum value:


Compare this to C#'s version:


As Enum already existed in C# before generics was introduced to the language, the definition could not change without breaking existing code.  So, like collections, it remains in the core libraries in this legacy state.


11 months late, but I think this question is ready for some Java Wildcard stuff.


This is a syntactical feature of Java. Suppose you have a method:


And suppose you don't need to refer to the type T in the method body. You're declaring a name T and then only using it once, so why should you have to think of a name for it? Instead, you can write:


The question-mark asks the the compiler to pretend that you declared a normal named type parameter that only needs to appear once in that spot.


There's nothing you can do with wildcards that you can't also do with a named type parameter (which is how these things are always done in C++ and C#).


Wikipedia has great write-ups comparing both Java/C# generics and Java generics/C++ templates. The main article on Generics seems a bit cluttered but it does have some good info in it.


The biggest complaint is type erasure.  In that, generics are not enforced at runtime.  Here's a link to some Sun docs on the subject.


Generics are implemented by type
  erasure: generic type information is
  present only at compile time, after
  which it is erased by the compiler.


C++ templates are actually much more powerful than their C# and Java counterparts as they are evaluated at compile time and support specialization. This allows for Template Meta-Programming and makes the C++ compiler equivalent to a Turing machine (i.e. during the compilation process you can compute anything that is computable with a Turing machine).


In Java, generics are compiler level only, so you get:


Note that the type of 'a' is an array list, not a list of strings. So the type of a list of bananas would equal() a list of monkeys.


So to speak.


Looks like, among other very interesting proposals, there is one about refining generics and breaking backwards compatibility:


Currently, generics are implemented
  using erasure, which means that the
  generic type information is not
  available at runtime, which makes some
  kind of code hard to write. Generics
  were implemented this way to support
  backwards compatibility with older
  non-generic code. Reified generics
  would make the generic type
  information available at runtime,
  which would break legacy non-generic
  code. However, Neal Gafter has
  proposed making types reifiable only
  if specified, so as to not break
  backward compatibility.


at Alex Miller's article about Java 7 Proposals


NB: I don't have enough point to comment, so feel free to move this as a comment to appropriate answer.


Contrary to popular believe, which I never understand where it came from, .net implemented true generics without breaking backward compatibility, and they spent explicit effort for that.
You don't have to change your non-generic .net 1.0 code into generics just to be used in .net 2.0. Both the generic and non-generic lists are still available in .Net framework 2.0 even until 4.0, exactly for nothing else but backward compatibility reason. Therefore old codes that still used non-generic ArrayList will still work, and use the same ArrayList class as before.
Backward code compatibility is always maintained since 1.0 till now... So even in .net 4.0, you still have to option to use any non-generics class from 1.0 BCL if you choose to do so.


So I don't think java has to break backward compatibility to support true generics.






I am reading some Java text and got the following code:


In the text, the author did not give a clear explanation and the effect of the last line is: a[1] = 0;


I am not so sure that I understand: how did the evaluation happen?


Let me say this very clearly, because people misunderstand this all the time:


Order of evaluation of subexpressions is independent of both associativity and precedence. Associativity and precedence determine in what order the operators are executed but do not determine in what order the subexpressions are evaluated. Your question is about the order in which subexpressions are evaluated. 


Consider A() + B() + C() * D(). Multiplication is higher precedence than addition, and addition is left-associative, so this is equivalent to (A() + B()) + (C() * D())  But knowing that only tells you that the first addition will happen before the second addition, and that the multiplication will happen before the second addition. It does not tell you in what order A(), B(), C() and D() will be called! (It also does not tell you whether the multiplication happens before or after the first addition.) It would be perfectly possible to obey the rules of precedence and associativity by compiling this as:


All the rules of precedence and associativity are followed there -- the first addition happens before the second addition, and the multiplication happens before the second addition. Clearly we can do the calls to A(), B(), C() and D() in any order and still obey the rules of precedence and associativity!


We need a rule unrelated to the rules of precedence and associativity to explain the order in which the subexpressions are evaluated. The relevant rule in Java (and C#) is "subexpressions are evaluated left to right". Since A() appears to the left of C(), A() is evaluated first, regardless of the fact that C() is involved in a multiplication and A() is involved only in an addition.


So now you have enough information to answer your question.  In a[b] = b = 0 the rules of associativity say that this is a[b] = (b = 0); but that does not mean that the b=0 runs first! The rules of precedence say that indexing is higher precedence than assignment, but that does not mean that the indexer runs before the rightmost assignment.


The rules of precedence and associativity impose the restrictions that:


Precedence and associativity only tell us that the assignment of zero to b must happen before the assignment to a[b]. Precedence and associativity says nothing about whether the a[b] is evaluated before or after the b=0. 


Again, this is just the same as: A()[B()] = C() -- All we know is that the indexing has to happen before the assignment. We don't know whether A(), B(), or C() runs first based on precedence and associativity. We need another rule to tell us that.


The rule is, again, "when you have a choice about what to do first, always go left to right": the a[b] is to the left of the b=0, so the a[b] runs first, resulting in a[1]. Then the b=0 happens, and then the assignment of the value to a[1] happens last. 


Things to the left happen before things to the right. That's the rule you're looking for. Talk of precedence and associativity is both confusing and irrelevant.


People get this stuff wrong all the time, even people who should know better. I have edited far too many programming books that stated the rules incorrectly, so it is no surprise that lots of people have completely incorrect beliefs about the relationship between precedence/associativity, and evaluation order -- namely, that in reality there is no such relationship; they are independent.


If this topic interests you, see my articles on the subject for further reading:


http://blogs.msdn.com/b/ericlippert/archive/tags/precedence/


They are about C#, but most of this stuff applies equally well to Java.


Eric Lippert's masterful answer is nonetheless not properly helpful because it is talking about a different language. This is Java, where the Java Language Specification is the definitive description of the semantics.  In particular, §15.26.1 is relevant because that describes the evaluation order for the = operator (we all know that it is right-associative, yes?). Cutting it down a little to the bits that we care about in this question:


If the left-hand operand expression is an array access expression (§15.13), then many steps are required:


[… it then goes on to describe the actual meaning of the assignment itself, which we can ignore here for brevity …]


In short, Java has a very closely defined evaluation order that is pretty much exactly left-to-right within the arguments to any operator or method call. Array assignments are one of the more complex cases, but even there it's still L2R. (The JLS does recommend that you don't write code that needs these sorts of complex semantic constraints, and so do I: you can get into more than enough trouble with just one assignment per statement!)


C and C++ are definitely different to Java in this area: their language definitions leave evaluation order undefined deliberately to enable more optimizations. C# is like Java apparently, but I don't know its literature well enough to be able to point to the formal definition. (This really varies by language though, Ruby is strictly L2R, as is Tcl — though that lacks an assignment operator per se for reasons not relevant here — and Python is L2R but R2L in respect of assignment, which I find odd but there you go.)


1) array indexing operator has higher precedence then assignment operator (see this answer):


2) According to 15.26. Assignment Operators of JLS


There are 12 assignment operators; all are syntactically right-associative (they group right-to-left). Thus, a=b=c means a=(b=c), which assigns the value of c to b and then assigns the value of b to a.


3) According to 15.7. Evaluation Order of JLS


The Java programming language guarantees that the operands of operators appear to be evaluated in a specific evaluation order, namely, from left to right.


and


The left-hand operand of a binary operator appears to be fully evaluated before any part of the right-hand operand is evaluated. 


So:


a) (a[b]) evaluated first to a[1]


b) then (b=0) evaluated to 0


c) (a[1] = 0) evaluated last


Your code is equivalent to:


which explains the result.


Here's another example to outline order of precedence in Java 


Consider the following sample code:


Question: What is the output of x? Try to solve this before continuing to the answer below.


Answer: 


Step 1: The compiler allocates 20 to variable x - This is important- all variables are defined first i.e.


Step 2: The compiler applies the rules of order of precedence i.e. parenthesis first: 


Now we have: 


Which results in:


Therefore output is 25:


Conclusions:


It is imperative that you are that:


Consider another more in-depth example below.


It's best to have a table of the Order of Precedence Rules and Associativity available to read when solving these questions e.g. http://introcs.cs.princeton.edu/java/11precedence/


Here is a good example: 


Question: What's the Output of the above Line?


Answer: Apply the Rules of Precedence and Associativity


Step 1: According to rules of precedence:  / and * operators take priority over + - operators. Therefore the starting point to execute this equation will the narrowed to:


Step 2: According to the rules and precedence: / and * are equal in precedence. 


As / and * operators are equal in precedence, we need to look at the associativity between those operators. 


According to the ASSOCIATIVITY RULES of these two particular operators, 
we start executing the equation from the LEFT TO RIGHT i.e. 100/10 gets executed first:


Step 3: The equation is now in the following state of execution: 


According to the rules and precedence: + and - are equal in precedence. 


We now need to look at the associativity between the operators + and - operators. According to the associativity of these two particular operators, 
we start executing the equation from the LEFT to RIGHT i.e. 3+20 gets executed first:


10 is the correct output when compiled


Again, it is important to have a  table of the Order of Precedence Rules and Associativity with you when solving these questions e.g. http://introcs.cs.princeton.edu/java/11precedence/


It will print 30 20 30


The statement iA[i] = i = 30 ; will be processed as follows:


iA[i] = i = 30; => iA[0] = i = 30 ;  =>  i = 30; iA[0] = i ; =>   iA[0] = 30 ;


Here is what JLS says on this:


1 Evaluate Left-Hand Operand First
2 Evaluate Operands before Operation
3 Evaluation Respects Parentheses and Precedence
4 Argument Lists are Evaluated Left-to-Right  


For Arrays: First, the dimension expressions are evaluated, left-to-right. If any of the expression evaluations completes abruptly, the expressions to the right of it are not evaluated.


